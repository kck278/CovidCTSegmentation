GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

  | Name       | Type             | Params
------------------------------------------------
0 | encoder1   | EncoderBlock     | 37.6 K
1 | encoder2   | EncoderBlock     | 221 K 
2 | bottleneck | ConvolutionBlock | 885 K 
3 | dropout    | Dropout2d        | 0     
4 | decoder1   | DecoderBlock     | 573 K 
5 | decoder2   | DecoderBlock     | 143 K 
6 | conv       | Conv2d           | 130   
7 | softmax    | Softmax2d        | 0     
------------------------------------------------
1.9 M     Trainable params
0         Non-trainable params
1.9 M     Total params
7.447     Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Validation sanity check:  50%|█████     | 1/2 [00:06<00:06,  6.75s/it]Validation sanity check: 100%|██████████| 2/2 [00:07<00:00,  3.01s/it]                                                                      /home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Training: -1it [00:00, ?it/s]Training:   0%|          | 0/41 [00:00<00:00, 26379.27it/s]Epoch 0:   0%|          | 0/41 [00:00<00:00, 4266.84it/s]  Epoch 0:   2%|▏         | 1/41 [00:00<00:19,  2.04it/s]  Epoch 0:   2%|▏         | 1/41 [00:00<00:19,  2.04it/s, loss=0.681, v_num=0, train_loss_step=0.681]Epoch 0:   5%|▍         | 2/41 [00:01<00:15,  2.46it/s, loss=0.681, v_num=0, train_loss_step=0.681]Epoch 0:   5%|▍         | 2/41 [00:01<00:15,  2.46it/s, loss=0.682, v_num=0, train_loss_step=0.682]Epoch 0:   7%|▋         | 3/41 [00:01<00:13,  2.90it/s, loss=0.682, v_num=0, train_loss_step=0.682]Epoch 0:   7%|▋         | 3/41 [00:01<00:13,  2.90it/s, loss=0.692, v_num=0, train_loss_step=0.713]Epoch 0:  10%|▉         | 4/41 [00:01<00:11,  3.20it/s, loss=0.692, v_num=0, train_loss_step=0.713]Epoch 0:  10%|▉         | 4/41 [00:01<00:11,  3.20it/s, loss=0.692, v_num=0, train_loss_step=0.691]Epoch 0:  12%|█▏        | 5/41 [00:01<00:10,  3.47it/s, loss=0.692, v_num=0, train_loss_step=0.691]Epoch 0:  12%|█▏        | 5/41 [00:01<00:10,  3.47it/s, loss=0.69, v_num=0, train_loss_step=0.681] Epoch 0:  15%|█▍        | 6/41 [00:01<00:09,  3.69it/s, loss=0.69, v_num=0, train_loss_step=0.681]Epoch 0:  15%|█▍        | 6/41 [00:01<00:09,  3.69it/s, loss=0.692, v_num=0, train_loss_step=0.702]Epoch 0:  17%|█▋        | 7/41 [00:02<00:08,  3.87it/s, loss=0.692, v_num=0, train_loss_step=0.702]Epoch 0:  17%|█▋        | 7/41 [00:02<00:08,  3.87it/s, loss=0.695, v_num=0, train_loss_step=0.714]Epoch 0:  20%|█▉        | 8/41 [00:02<00:08,  4.08it/s, loss=0.695, v_num=0, train_loss_step=0.714]Epoch 0:  20%|█▉        | 8/41 [00:02<00:08,  4.07it/s, loss=0.696, v_num=0, train_loss_step=0.704]Epoch 0:  22%|██▏       | 9/41 [00:02<00:07,  4.22it/s, loss=0.696, v_num=0, train_loss_step=0.704]Epoch 0:  22%|██▏       | 9/41 [00:02<00:07,  4.22it/s, loss=0.698, v_num=0, train_loss_step=0.712]Epoch 0:  24%|██▍       | 10/41 [00:02<00:07,  4.34it/s, loss=0.698, v_num=0, train_loss_step=0.712]Epoch 0:  24%|██▍       | 10/41 [00:02<00:07,  4.34it/s, loss=0.698, v_num=0, train_loss_step=0.703]Epoch 0:  27%|██▋       | 11/41 [00:02<00:06,  4.45it/s, loss=0.698, v_num=0, train_loss_step=0.703]Epoch 0:  27%|██▋       | 11/41 [00:02<00:06,  4.45it/s, loss=0.696, v_num=0, train_loss_step=0.673]Epoch 0:  29%|██▉       | 12/41 [00:02<00:06,  4.54it/s, loss=0.696, v_num=0, train_loss_step=0.673]Epoch 0:  29%|██▉       | 12/41 [00:02<00:06,  4.54it/s, loss=0.695, v_num=0, train_loss_step=0.680]Epoch 0:  32%|███▏      | 13/41 [00:03<00:06,  4.65it/s, loss=0.695, v_num=0, train_loss_step=0.680]Epoch 0:  32%|███▏      | 13/41 [00:03<00:06,  4.65it/s, loss=0.696, v_num=0, train_loss_step=0.717]Epoch 0:  34%|███▍      | 14/41 [00:03<00:05,  4.73it/s, loss=0.696, v_num=0, train_loss_step=0.717]Epoch 0:  34%|███▍      | 14/41 [00:03<00:05,  4.73it/s, loss=0.696, v_num=0, train_loss_step=0.692]Epoch 0:  37%|███▋      | 15/41 [00:03<00:05,  4.83it/s, loss=0.696, v_num=0, train_loss_step=0.692]Epoch 0:  37%|███▋      | 15/41 [00:03<00:05,  4.83it/s, loss=0.695, v_num=0, train_loss_step=0.676]Epoch 0:  39%|███▉      | 16/41 [00:03<00:05,  4.90it/s, loss=0.695, v_num=0, train_loss_step=0.676]Epoch 0:  39%|███▉      | 16/41 [00:03<00:05,  4.90it/s, loss=0.694, v_num=0, train_loss_step=0.687]Epoch 0:  41%|████▏     | 17/41 [00:03<00:04,  4.97it/s, loss=0.694, v_num=0, train_loss_step=0.687]Epoch 0:  41%|████▏     | 17/41 [00:03<00:04,  4.97it/s, loss=0.693, v_num=0, train_loss_step=0.668]Epoch 0:  44%|████▍     | 18/41 [00:03<00:04,  5.03it/s, loss=0.693, v_num=0, train_loss_step=0.668]Epoch 0:  44%|████▍     | 18/41 [00:03<00:04,  5.03it/s, loss=0.692, v_num=0, train_loss_step=0.688]Epoch 0:  46%|████▋     | 19/41 [00:03<00:04,  5.08it/s, loss=0.692, v_num=0, train_loss_step=0.688]Epoch 0:  46%|████▋     | 19/41 [00:03<00:04,  5.07it/s, loss=0.691, v_num=0, train_loss_step=0.673]Epoch 0:  49%|████▉     | 20/41 [00:04<00:04,  5.13it/s, loss=0.691, v_num=0, train_loss_step=0.673]Epoch 0:  49%|████▉     | 20/41 [00:04<00:04,  5.13it/s, loss=0.692, v_num=0, train_loss_step=0.703]Epoch 0:  51%|█████     | 21/41 [00:04<00:03,  5.17it/s, loss=0.692, v_num=0, train_loss_step=0.703]Epoch 0:  51%|█████     | 21/41 [00:04<00:03,  5.17it/s, loss=0.691, v_num=0, train_loss_step=0.662]Epoch 0:  54%|█████▎    | 22/41 [00:04<00:03,  5.22it/s, loss=0.691, v_num=0, train_loss_step=0.662]Epoch 0:  54%|█████▎    | 22/41 [00:04<00:03,  5.22it/s, loss=0.69, v_num=0, train_loss_step=0.667] Epoch 0:  56%|█████▌    | 23/41 [00:04<00:03,  5.26it/s, loss=0.69, v_num=0, train_loss_step=0.667]Epoch 0:  56%|█████▌    | 23/41 [00:04<00:03,  5.26it/s, loss=0.688, v_num=0, train_loss_step=0.678]Epoch 0:  59%|█████▊    | 24/41 [00:04<00:03,  5.29it/s, loss=0.688, v_num=0, train_loss_step=0.678]Epoch 0:  59%|█████▊    | 24/41 [00:04<00:03,  5.29it/s, loss=0.688, v_num=0, train_loss_step=0.683]Epoch 0:  61%|██████    | 25/41 [00:04<00:02,  5.35it/s, loss=0.688, v_num=0, train_loss_step=0.683]Epoch 0:  61%|██████    | 25/41 [00:04<00:02,  5.34it/s, loss=0.688, v_num=0, train_loss_step=0.675]Epoch 0:  63%|██████▎   | 26/41 [00:05<00:02,  5.38it/s, loss=0.688, v_num=0, train_loss_step=0.675]Epoch 0:  63%|██████▎   | 26/41 [00:05<00:02,  5.38it/s, loss=0.685, v_num=0, train_loss_step=0.651]Epoch 0:  66%|██████▌   | 27/41 [00:05<00:02,  5.43it/s, loss=0.685, v_num=0, train_loss_step=0.651]Epoch 0:  66%|██████▌   | 27/41 [00:05<00:02,  5.43it/s, loss=0.682, v_num=0, train_loss_step=0.638]Epoch 0:  68%|██████▊   | 28/41 [00:05<00:02,  5.50it/s, loss=0.682, v_num=0, train_loss_step=0.638]Epoch 0:  68%|██████▊   | 28/41 [00:05<00:02,  5.50it/s, loss=0.68, v_num=0, train_loss_step=0.667] Epoch 0:  71%|███████   | 29/41 [00:05<00:02,  5.52it/s, loss=0.68, v_num=0, train_loss_step=0.667]Epoch 0:  71%|███████   | 29/41 [00:05<00:02,  5.52it/s, loss=0.677, v_num=0, train_loss_step=0.655]Epoch 0:  73%|███████▎  | 30/41 [00:05<00:01,  5.55it/s, loss=0.677, v_num=0, train_loss_step=0.655]Epoch 0:  73%|███████▎  | 30/41 [00:05<00:01,  5.55it/s, loss=0.673, v_num=0, train_loss_step=0.634]Epoch 0:  76%|███████▌  | 31/41 [00:05<00:01,  5.58it/s, loss=0.673, v_num=0, train_loss_step=0.634]Epoch 0:  76%|███████▌  | 31/41 [00:05<00:01,  5.58it/s, loss=0.672, v_num=0, train_loss_step=0.641]Epoch 0:  78%|███████▊  | 32/41 [00:05<00:01,  5.59it/s, loss=0.672, v_num=0, train_loss_step=0.641]Epoch 0:  78%|███████▊  | 32/41 [00:05<00:01,  5.59it/s, loss=0.672, v_num=0, train_loss_step=0.682]Epoch 0:  80%|████████  | 33/41 [00:06<00:01,  5.64it/s, loss=0.672, v_num=0, train_loss_step=0.682]Epoch 0:  80%|████████  | 33/41 [00:06<00:01,  5.64it/s, loss=0.666, v_num=0, train_loss_step=0.595]Epoch 0:  83%|████████▎ | 34/41 [00:06<00:01,  5.63it/s, loss=0.666, v_num=0, train_loss_step=0.595]Epoch 0:  83%|████████▎ | 34/41 [00:06<00:01,  5.62it/s, loss=0.661, v_num=0, train_loss_step=0.596]Epoch 0:  85%|████████▌ | 35/41 [00:06<00:01,  5.65it/s, loss=0.661, v_num=0, train_loss_step=0.596]Epoch 0:  85%|████████▌ | 35/41 [00:06<00:01,  5.65it/s, loss=0.659, v_num=0, train_loss_step=0.632]Epoch 0:  88%|████████▊ | 36/41 [00:06<00:00,  5.73it/s, loss=0.653, v_num=0, train_loss_step=0.574]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/5 [00:00<?, ?it/s][A
Validating:  20%|██        | 1/5 [00:00<00:01,  2.89it/s][AEpoch 0:  93%|█████████▎| 38/41 [00:06<00:00,  5.73it/s, loss=0.653, v_num=0, train_loss_step=0.574]
Validating:  40%|████      | 2/5 [00:00<00:01,  2.89it/s][A
Validating:  60%|██████    | 3/5 [00:01<00:00,  2.78it/s][A
Validating:  80%|████████  | 4/5 [00:01<00:00,  2.68it/s][AEpoch 0: 100%|██████████| 41/41 [00:07<00:00,  5.30it/s, loss=0.653, v_num=0, train_loss_step=0.574]
Validating: 100%|██████████| 5/5 [00:01<00:00,  2.57it/s][AEpoch 0: 100%|██████████| 41/41 [00:08<00:00,  5.03it/s, loss=0.653, v_num=0, train_loss_step=0.574]
                                                         [AEpoch 0: 100%|██████████| 41/41 [00:08<00:00,  4.96it/s, loss=0.653, v_num=0, train_loss_step=0.574]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(

Testing: 0it [00:00, ?it/s]Testing:   6%|▌         | 1/18 [00:00<00:03,  5.31it/s]Testing:  11%|█         | 2/18 [00:00<00:02,  5.35it/s]Testing:  17%|█▋        | 3/18 [00:00<00:02,  5.52it/s]Testing:  22%|██▏       | 4/18 [00:00<00:02,  5.55it/s]Testing:  28%|██▊       | 5/18 [00:00<00:02,  5.67it/s]Testing:  33%|███▎      | 6/18 [00:01<00:02,  5.63it/s]Testing:  39%|███▉      | 7/18 [00:01<00:01,  5.63it/s]Testing:  44%|████▍     | 8/18 [00:01<00:01,  5.69it/s]Testing:  50%|█████     | 9/18 [00:01<00:01,  5.52it/s]Testing:  56%|█████▌    | 10/18 [00:01<00:01,  5.51it/s]Testing:  61%|██████    | 11/18 [00:01<00:01,  5.50it/s]Testing:  67%|██████▋   | 12/18 [00:02<00:01,  5.50it/s]Testing:  72%|███████▏  | 13/18 [00:02<00:00,  5.64it/s]Testing:  78%|███████▊  | 14/18 [00:02<00:00,  5.71it/s]Testing:  83%|████████▎ | 15/18 [00:02<00:00,  5.77it/s]Testing:  89%|████████▉ | 16/18 [00:02<00:00,  5.87it/s]Testing:  94%|█████████▍| 17/18 [00:03<00:00,  5.91it/s]Testing: 100%|██████████| 18/18 [00:03<00:00,  5.68it/s]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'_mean_accuracy': 0.8209404349327087,
 '_standard_dev_accuracy': 0.11353100091218948,
 '_variance_accuracy': 0.012889288365840912,
 'test_acc': 0.8209404349327087,
 'test_dice_c1': 0.32984480261802673,
 'test_f2_c1': 0.4924103319644928,
 'test_loss': 0.6123462319374084,
 'test_mean_c1': 0.8806609511375427,
 'test_prec_c1': 0.22064216434955597,
 'test_sens_c1': 0.9601452350616455,
 'test_spec_c1': 0.8141460418701172}
--------------------------------------------------------------------------------
Testing: 100%|██████████| 18/18 [00:03<00:00,  5.63it/s]
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

  | Name       | Type             | Params
------------------------------------------------
0 | encoder1   | EncoderBlock     | 37.6 K
1 | encoder2   | EncoderBlock     | 221 K 
2 | bottleneck | ConvolutionBlock | 885 K 
3 | dropout    | Dropout2d        | 0     
4 | decoder1   | DecoderBlock     | 573 K 
5 | decoder2   | DecoderBlock     | 143 K 
6 | conv       | Conv2d           | 130   
7 | softmax    | Softmax2d        | 0     
------------------------------------------------
1.9 M     Trainable params
0         Non-trainable params
1.9 M     Total params
7.447     Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Validation sanity check:  50%|█████     | 1/2 [00:01<00:01,  1.78s/it]Validation sanity check: 100%|██████████| 2/2 [00:02<00:00,  1.07it/s]                                                                      /home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Training: -1it [00:00, ?it/s]Training:   0%|          | 0/11 [00:00<00:00, 26886.56it/s]Epoch 0:   0%|          | 0/11 [00:00<00:00, 4284.27it/s]  Epoch 0:   9%|▉         | 1/11 [00:00<00:02,  4.01it/s]  Epoch 0:   9%|▉         | 1/11 [00:00<00:02,  4.01it/s, loss=0.692, v_num=1, train_loss_step=0.692]Epoch 0:  18%|█▊        | 2/11 [00:00<00:02,  3.26it/s, loss=0.692, v_num=1, train_loss_step=0.692]Epoch 0:  18%|█▊        | 2/11 [00:00<00:02,  3.25it/s, loss=0.694, v_num=1, train_loss_step=0.697]Epoch 0:  27%|██▋       | 3/11 [00:01<00:02,  2.97it/s, loss=0.694, v_num=1, train_loss_step=0.697]Epoch 0:  27%|██▋       | 3/11 [00:01<00:02,  2.97it/s, loss=0.694, v_num=1, train_loss_step=0.694]Epoch 0:  36%|███▋      | 4/11 [00:01<00:02,  2.82it/s, loss=0.694, v_num=1, train_loss_step=0.694]Epoch 0:  36%|███▋      | 4/11 [00:01<00:02,  2.82it/s, loss=0.693, v_num=1, train_loss_step=0.690]Epoch 0:  45%|████▌     | 5/11 [00:02<00:02,  2.73it/s, loss=0.693, v_num=1, train_loss_step=0.690]Epoch 0:  45%|████▌     | 5/11 [00:02<00:02,  2.73it/s, loss=0.693, v_num=1, train_loss_step=0.691]Epoch 0:  55%|█████▍    | 6/11 [00:02<00:01,  2.67it/s, loss=0.693, v_num=1, train_loss_step=0.691]Epoch 0:  55%|█████▍    | 6/11 [00:02<00:01,  2.67it/s, loss=0.693, v_num=1, train_loss_step=0.697]Epoch 0:  64%|██████▎   | 7/11 [00:03<00:01,  2.63it/s, loss=0.693, v_num=1, train_loss_step=0.697]Epoch 0:  64%|██████▎   | 7/11 [00:03<00:01,  2.63it/s, loss=0.693, v_num=1, train_loss_step=0.688]Epoch 0:  73%|███████▎  | 8/11 [00:03<00:01,  2.60it/s, loss=0.693, v_num=1, train_loss_step=0.688]Epoch 0:  73%|███████▎  | 8/11 [00:03<00:01,  2.60it/s, loss=0.691, v_num=1, train_loss_step=0.682]Epoch 0:  82%|████████▏ | 9/11 [00:03<00:00,  2.62it/s, loss=0.691, v_num=1, train_loss_step=0.682]Epoch 0:  82%|████████▏ | 9/11 [00:03<00:00,  2.62it/s, loss=0.69, v_num=1, train_loss_step=0.685] 
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/2 [00:00<?, ?it/s][A
Validating:  50%|█████     | 1/2 [00:01<00:01,  1.52s/it][AEpoch 0: 100%|██████████| 11/11 [00:05<00:00,  2.24it/s, loss=0.69, v_num=1, train_loss_step=0.685]
Validating: 100%|██████████| 2/2 [00:01<00:00,  1.21it/s][AEpoch 0: 100%|██████████| 11/11 [00:05<00:00,  2.11it/s, loss=0.69, v_num=1, train_loss_step=0.685]
                                                         [AEpoch 0: 100%|██████████| 11/11 [00:05<00:00,  2.09it/s, loss=0.69, v_num=1, train_loss_step=0.685]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(

Testing: 0it [00:00, ?it/s]Testing:   6%|▌         | 1/18 [00:00<00:02,  5.81it/s]Testing:  11%|█         | 2/18 [00:00<00:02,  6.09it/s]Testing:  17%|█▋        | 3/18 [00:00<00:02,  6.23it/s]Testing:  22%|██▏       | 4/18 [00:00<00:02,  6.26it/s]Testing:  28%|██▊       | 5/18 [00:00<00:02,  6.32it/s]Testing:  33%|███▎      | 6/18 [00:00<00:01,  6.37it/s]Testing:  39%|███▉      | 7/18 [00:01<00:01,  6.35it/s]Testing:  44%|████▍     | 8/18 [00:01<00:01,  6.36it/s]Testing:  50%|█████     | 9/18 [00:01<00:01,  6.38it/s]Testing:  56%|█████▌    | 10/18 [00:01<00:01,  6.40it/s]Testing:  61%|██████    | 11/18 [00:01<00:01,  6.40it/s]Testing:  67%|██████▋   | 12/18 [00:01<00:00,  6.43it/s]Testing:  72%|███████▏  | 13/18 [00:02<00:00,  6.43it/s]Testing:  78%|███████▊  | 14/18 [00:02<00:00,  6.39it/s]Testing:  83%|████████▎ | 15/18 [00:02<00:00,  6.37it/s]Testing:  89%|████████▉ | 16/18 [00:02<00:00,  6.39it/s]Testing:  94%|█████████▍| 17/18 [00:02<00:00,  6.39it/s]Testing: 100%|██████████| 18/18 [00:02<00:00,  6.43it/s]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'_mean_accuracy': 0.9520778656005859,
 '_standard_dev_accuracy': 0.055123426020145416,
 '_variance_accuracy': 0.0030385919380933046,
 'test_acc': 0.9520778656005859,
 'test_dice_c1': 0.0,
 'test_f2_c1': 0.0,
 'test_loss': 0.6797571778297424,
 'test_mean_c1': 0.0,
 'test_prec_c1': 0.0,
 'test_sens_c1': 0.0,
 'test_spec_c1': 1.0}
--------------------------------------------------------------------------------
Testing: 100%|██████████| 18/18 [00:02<00:00,  6.35it/s]
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

  | Name       | Type             | Params
------------------------------------------------
0 | encoder1   | EncoderBlock     | 37.6 K
1 | encoder2   | EncoderBlock     | 221 K 
2 | bottleneck | ConvolutionBlock | 885 K 
3 | dropout    | Dropout2d        | 0     
4 | decoder1   | DecoderBlock     | 573 K 
5 | decoder2   | DecoderBlock     | 143 K 
6 | conv       | Conv2d           | 130   
7 | softmax    | Softmax2d        | 0     
------------------------------------------------
1.9 M     Trainable params
0         Non-trainable params
1.9 M     Total params
7.447     Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Validation sanity check:   0%|          | 0/1 [00:00<?, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Validation sanity check: 100%|██████████| 1/1 [00:02<00:00,  2.17s/it]                                                                      /home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Training: -1it [00:00, ?it/s]Training:   0%|          | 0/7 [00:00<00:00, 29746.84it/s]Epoch 0:   0%|          | 0/7 [00:00<00:00, 4198.50it/s]  Epoch 0:  14%|█▍        | 1/7 [00:00<00:02,  2.62it/s]  Epoch 0:  14%|█▍        | 1/7 [00:00<00:02,  2.62it/s, loss=0.693, v_num=2, train_loss_step=0.693]Epoch 0:  29%|██▊       | 2/7 [00:01<00:02,  2.11it/s, loss=0.693, v_num=2, train_loss_step=0.693]Epoch 0:  29%|██▊       | 2/7 [00:01<00:02,  2.11it/s, loss=0.693, v_num=2, train_loss_step=0.693]Epoch 0:  43%|████▎     | 3/7 [00:02<00:02,  1.93it/s, loss=0.693, v_num=2, train_loss_step=0.693]Epoch 0:  43%|████▎     | 3/7 [00:02<00:02,  1.93it/s, loss=0.693, v_num=2, train_loss_step=0.693]Epoch 0:  57%|█████▋    | 4/7 [00:02<00:01,  1.83it/s, loss=0.693, v_num=2, train_loss_step=0.693]Epoch 0:  57%|█████▋    | 4/7 [00:02<00:01,  1.83it/s, loss=0.692, v_num=2, train_loss_step=0.690]Epoch 0:  71%|███████▏  | 5/7 [00:03<00:01,  1.78it/s, loss=0.692, v_num=2, train_loss_step=0.690]Epoch 0:  71%|███████▏  | 5/7 [00:03<00:01,  1.78it/s, loss=0.692, v_num=2, train_loss_step=0.690]Epoch 0:  86%|████████▌ | 6/7 [00:03<00:00,  1.78it/s, loss=0.692, v_num=2, train_loss_step=0.690]Epoch 0:  86%|████████▌ | 6/7 [00:03<00:00,  1.78it/s, loss=0.691, v_num=2, train_loss_step=0.688]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/1 [00:00<?, ?it/s][A
Validating: 100%|██████████| 1/1 [00:01<00:00,  1.93s/it][AEpoch 0: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s, loss=0.691, v_num=2, train_loss_step=0.688]
                                                         [AEpoch 0: 100%|██████████| 7/7 [00:05<00:00,  1.34it/s, loss=0.691, v_num=2, train_loss_step=0.688]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(

Testing: 0it [00:00, ?it/s]Testing:   6%|▌         | 1/18 [00:00<00:02,  6.09it/s]Testing:  11%|█         | 2/18 [00:00<00:02,  6.20it/s]Testing:  17%|█▋        | 3/18 [00:00<00:02,  6.25it/s]Testing:  22%|██▏       | 4/18 [00:00<00:02,  6.26it/s]Testing:  28%|██▊       | 5/18 [00:00<00:02,  6.28it/s]Testing:  33%|███▎      | 6/18 [00:00<00:01,  6.35it/s]Testing:  39%|███▉      | 7/18 [00:01<00:01,  6.37it/s]Testing:  44%|████▍     | 8/18 [00:01<00:01,  6.39it/s]Testing:  50%|█████     | 9/18 [00:01<00:01,  6.37it/s]Testing:  56%|█████▌    | 10/18 [00:01<00:01,  6.38it/s]Testing:  61%|██████    | 11/18 [00:01<00:01,  6.39it/s]Testing:  67%|██████▋   | 12/18 [00:01<00:00,  6.36it/s]Testing:  72%|███████▏  | 13/18 [00:02<00:00,  6.36it/s]Testing:  78%|███████▊  | 14/18 [00:02<00:00,  6.38it/s]Testing:  83%|████████▎ | 15/18 [00:02<00:00,  6.37it/s]Testing:  89%|████████▉ | 16/18 [00:02<00:00,  6.38it/s]Testing:  94%|█████████▍| 17/18 [00:02<00:00,  6.38it/s]Testing: 100%|██████████| 18/18 [00:02<00:00,  6.39it/s]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'_mean_accuracy': 0.06972864270210266,
 '_standard_dev_accuracy': 0.06024389714002609,
 '_variance_accuracy': 0.0036293272860348225,
 'test_acc': 0.06972864270210266,
 'test_dice_c1': 0.12477566301822662,
 'test_f2_c1': 0.24241791665554047,
 'test_loss': 0.6917121410369873,
 'test_mean_c1': 0.0,
 'test_prec_c1': 0.06972864270210266,
 'test_sens_c1': 1.0,
 'test_spec_c1': 0.0}
--------------------------------------------------------------------------------
Testing: 100%|██████████| 18/18 [00:02<00:00,  6.34it/s]
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

  | Name       | Type             | Params
------------------------------------------------
0 | encoder1   | EncoderBlock     | 37.6 K
1 | encoder2   | EncoderBlock     | 221 K 
2 | bottleneck | ConvolutionBlock | 885 K 
3 | dropout    | Dropout2d        | 0     
4 | decoder1   | DecoderBlock     | 573 K 
5 | decoder2   | DecoderBlock     | 143 K 
6 | conv       | Conv2d           | 130   
7 | softmax    | Softmax2d        | 0     
------------------------------------------------
1.9 M     Trainable params
0         Non-trainable params
1.9 M     Total params
7.447     Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  2.04it/s]Validation sanity check: 100%|██████████| 2/2 [00:00<00:00,  2.72it/s]                                                                      /home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Training: -1it [00:00, ?it/s]Training:   0%|          | 0/41 [00:00<00:00, 27413.75it/s]Epoch 0:   0%|          | 0/41 [00:00<00:00, 4104.02it/s]  Epoch 0:   2%|▏         | 1/41 [00:00<00:02, 15.56it/s]  Epoch 0:   2%|▏         | 1/41 [00:00<00:02, 15.51it/s, loss=0.701, v_num=3, train_loss_step=0.701]Epoch 0:   5%|▍         | 2/41 [00:00<00:03, 12.76it/s, loss=0.701, v_num=3, train_loss_step=0.701]Epoch 0:   5%|▍         | 2/41 [00:00<00:03, 12.74it/s, loss=0.691, v_num=3, train_loss_step=0.681]Epoch 0:   7%|▋         | 3/41 [00:00<00:03, 11.69it/s, loss=0.691, v_num=3, train_loss_step=0.681]Epoch 0:   7%|▋         | 3/41 [00:00<00:03, 11.68it/s, loss=0.69, v_num=3, train_loss_step=0.688] Epoch 0:  10%|▉         | 4/41 [00:00<00:03, 11.07it/s, loss=0.69, v_num=3, train_loss_step=0.688]Epoch 0:  10%|▉         | 4/41 [00:00<00:03, 11.06it/s, loss=0.685, v_num=3, train_loss_step=0.669]Epoch 0:  12%|█▏        | 5/41 [00:00<00:03, 10.73it/s, loss=0.685, v_num=3, train_loss_step=0.669]Epoch 0:  12%|█▏        | 5/41 [00:00<00:03, 10.72it/s, loss=0.683, v_num=3, train_loss_step=0.675]Epoch 0:  15%|█▍        | 6/41 [00:00<00:03, 10.48it/s, loss=0.683, v_num=3, train_loss_step=0.675]Epoch 0:  15%|█▍        | 6/41 [00:00<00:03, 10.47it/s, loss=0.679, v_num=3, train_loss_step=0.659]Epoch 0:  17%|█▋        | 7/41 [00:00<00:03, 10.34it/s, loss=0.679, v_num=3, train_loss_step=0.659]Epoch 0:  17%|█▋        | 7/41 [00:00<00:03, 10.34it/s, loss=0.675, v_num=3, train_loss_step=0.650]Epoch 0:  20%|█▉        | 8/41 [00:00<00:03, 10.22it/s, loss=0.675, v_num=3, train_loss_step=0.650]Epoch 0:  20%|█▉        | 8/41 [00:00<00:03, 10.22it/s, loss=0.67, v_num=3, train_loss_step=0.634] Epoch 0:  22%|██▏       | 9/41 [00:00<00:03, 10.10it/s, loss=0.67, v_num=3, train_loss_step=0.634]Epoch 0:  22%|██▏       | 9/41 [00:00<00:03, 10.10it/s, loss=0.66, v_num=3, train_loss_step=0.582]Epoch 0:  24%|██▍       | 10/41 [00:01<00:03, 10.02it/s, loss=0.66, v_num=3, train_loss_step=0.582]Epoch 0:  24%|██▍       | 10/41 [00:01<00:03, 10.02it/s, loss=0.652, v_num=3, train_loss_step=0.582]Epoch 0:  27%|██▋       | 11/41 [00:01<00:03,  9.94it/s, loss=0.652, v_num=3, train_loss_step=0.582]Epoch 0:  27%|██▋       | 11/41 [00:01<00:03,  9.93it/s, loss=0.645, v_num=3, train_loss_step=0.570]Epoch 0:  29%|██▉       | 12/41 [00:01<00:02,  9.90it/s, loss=0.645, v_num=3, train_loss_step=0.570]Epoch 0:  29%|██▉       | 12/41 [00:01<00:02,  9.90it/s, loss=0.64, v_num=3, train_loss_step=0.583] Epoch 0:  32%|███▏      | 13/41 [00:01<00:02,  9.86it/s, loss=0.64, v_num=3, train_loss_step=0.583]Epoch 0:  32%|███▏      | 13/41 [00:01<00:02,  9.85it/s, loss=0.634, v_num=3, train_loss_step=0.573]Epoch 0:  34%|███▍      | 14/41 [00:01<00:02,  9.83it/s, loss=0.634, v_num=3, train_loss_step=0.573]Epoch 0:  34%|███▍      | 14/41 [00:01<00:02,  9.82it/s, loss=0.624, v_num=3, train_loss_step=0.491]Epoch 0:  37%|███▋      | 15/41 [00:01<00:02,  9.81it/s, loss=0.624, v_num=3, train_loss_step=0.491]Epoch 0:  37%|███▋      | 15/41 [00:01<00:02,  9.80it/s, loss=0.614, v_num=3, train_loss_step=0.466]Epoch 0:  39%|███▉      | 16/41 [00:01<00:02,  9.77it/s, loss=0.614, v_num=3, train_loss_step=0.466]Epoch 0:  39%|███▉      | 16/41 [00:01<00:02,  9.77it/s, loss=0.609, v_num=3, train_loss_step=0.536]Epoch 0:  41%|████▏     | 17/41 [00:01<00:02,  9.74it/s, loss=0.609, v_num=3, train_loss_step=0.536]Epoch 0:  41%|████▏     | 17/41 [00:01<00:02,  9.74it/s, loss=0.597, v_num=3, train_loss_step=0.414]Epoch 0:  44%|████▍     | 18/41 [00:01<00:02,  9.70it/s, loss=0.597, v_num=3, train_loss_step=0.414]Epoch 0:  44%|████▍     | 18/41 [00:01<00:02,  9.70it/s, loss=0.59, v_num=3, train_loss_step=0.463] Epoch 0:  46%|████▋     | 19/41 [00:02<00:02,  9.68it/s, loss=0.59, v_num=3, train_loss_step=0.463]Epoch 0:  46%|████▋     | 19/41 [00:02<00:02,  9.68it/s, loss=0.58, v_num=3, train_loss_step=0.395]Epoch 0:  49%|████▉     | 20/41 [00:02<00:02,  9.66it/s, loss=0.58, v_num=3, train_loss_step=0.395]Epoch 0:  49%|████▉     | 20/41 [00:02<00:02,  9.66it/s, loss=0.576, v_num=3, train_loss_step=0.513]Epoch 0:  51%|█████     | 21/41 [00:02<00:02,  9.64it/s, loss=0.576, v_num=3, train_loss_step=0.513]Epoch 0:  51%|█████     | 21/41 [00:02<00:02,  9.64it/s, loss=0.559, v_num=3, train_loss_step=0.364]Epoch 0:  54%|█████▎    | 22/41 [00:02<00:01,  9.62it/s, loss=0.559, v_num=3, train_loss_step=0.364]Epoch 0:  54%|█████▎    | 22/41 [00:02<00:01,  9.62it/s, loss=0.549, v_num=3, train_loss_step=0.479]Epoch 0:  56%|█████▌    | 23/41 [00:02<00:01,  9.61it/s, loss=0.549, v_num=3, train_loss_step=0.479]Epoch 0:  56%|█████▌    | 23/41 [00:02<00:01,  9.61it/s, loss=0.534, v_num=3, train_loss_step=0.373]Epoch 0:  59%|█████▊    | 24/41 [00:02<00:01,  9.60it/s, loss=0.534, v_num=3, train_loss_step=0.373]Epoch 0:  59%|█████▊    | 24/41 [00:02<00:01,  9.59it/s, loss=0.519, v_num=3, train_loss_step=0.383]Epoch 0:  61%|██████    | 25/41 [00:02<00:01,  9.58it/s, loss=0.519, v_num=3, train_loss_step=0.383]Epoch 0:  61%|██████    | 25/41 [00:02<00:01,  9.58it/s, loss=0.504, v_num=3, train_loss_step=0.363]Epoch 0:  63%|██████▎   | 26/41 [00:02<00:01,  9.57it/s, loss=0.504, v_num=3, train_loss_step=0.363]Epoch 0:  63%|██████▎   | 26/41 [00:02<00:01,  9.57it/s, loss=0.49, v_num=3, train_loss_step=0.379] Epoch 0:  66%|██████▌   | 27/41 [00:02<00:01,  9.56it/s, loss=0.49, v_num=3, train_loss_step=0.379]Epoch 0:  66%|██████▌   | 27/41 [00:02<00:01,  9.56it/s, loss=0.476, v_num=3, train_loss_step=0.372]Epoch 0:  68%|██████▊   | 28/41 [00:03<00:01,  9.55it/s, loss=0.476, v_num=3, train_loss_step=0.372]Epoch 0:  68%|██████▊   | 28/41 [00:03<00:01,  9.55it/s, loss=0.464, v_num=3, train_loss_step=0.402]Epoch 0:  71%|███████   | 29/41 [00:03<00:01,  9.54it/s, loss=0.464, v_num=3, train_loss_step=0.402]Epoch 0:  71%|███████   | 29/41 [00:03<00:01,  9.54it/s, loss=0.455, v_num=3, train_loss_step=0.403]Epoch 0:  73%|███████▎  | 30/41 [00:03<00:01,  9.53it/s, loss=0.455, v_num=3, train_loss_step=0.403]Epoch 0:  73%|███████▎  | 30/41 [00:03<00:01,  9.53it/s, loss=0.447, v_num=3, train_loss_step=0.424]Epoch 0:  76%|███████▌  | 31/41 [00:03<00:01,  9.53it/s, loss=0.447, v_num=3, train_loss_step=0.424]Epoch 0:  76%|███████▌  | 31/41 [00:03<00:01,  9.53it/s, loss=0.436, v_num=3, train_loss_step=0.350]Epoch 0:  78%|███████▊  | 32/41 [00:03<00:00,  9.52it/s, loss=0.436, v_num=3, train_loss_step=0.350]Epoch 0:  78%|███████▊  | 32/41 [00:03<00:00,  9.52it/s, loss=0.429, v_num=3, train_loss_step=0.441]Epoch 0:  80%|████████  | 33/41 [00:03<00:00,  9.51it/s, loss=0.429, v_num=3, train_loss_step=0.441]Epoch 0:  80%|████████  | 33/41 [00:03<00:00,  9.51it/s, loss=0.42, v_num=3, train_loss_step=0.381] Epoch 0:  83%|████████▎ | 34/41 [00:03<00:00,  9.51it/s, loss=0.42, v_num=3, train_loss_step=0.381]Epoch 0:  83%|████████▎ | 34/41 [00:03<00:00,  9.51it/s, loss=0.412, v_num=3, train_loss_step=0.347]Epoch 0:  85%|████████▌ | 35/41 [00:03<00:00,  9.50it/s, loss=0.412, v_num=3, train_loss_step=0.347]Epoch 0:  85%|████████▌ | 35/41 [00:03<00:00,  9.50it/s, loss=0.41, v_num=3, train_loss_step=0.417] Epoch 0:  88%|████████▊ | 36/41 [00:03<00:00,  9.54it/s, loss=0.405, v_num=3, train_loss_step=0.445]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/5 [00:00<?, ?it/s][A
Validating:  20%|██        | 1/5 [00:00<00:01,  3.49it/s][AEpoch 0:  93%|█████████▎| 38/41 [00:04<00:00,  9.35it/s, loss=0.405, v_num=3, train_loss_step=0.445]
Validating:  40%|████      | 2/5 [00:00<00:00,  3.54it/s][A
Validating:  60%|██████    | 3/5 [00:00<00:00,  3.55it/s][A
Validating:  80%|████████  | 4/5 [00:01<00:00,  3.55it/s][AEpoch 0: 100%|██████████| 41/41 [00:05<00:00,  8.38it/s, loss=0.405, v_num=3, train_loss_step=0.445]
Validating: 100%|██████████| 5/5 [00:01<00:00,  3.56it/s][AEpoch 0: 100%|██████████| 41/41 [00:05<00:00,  7.93it/s, loss=0.405, v_num=3, train_loss_step=0.445]
                                                         [AEpoch 0: 100%|██████████| 41/41 [00:05<00:00,  7.88it/s, loss=0.405, v_num=3, train_loss_step=0.445]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(

Testing: 0it [00:00, ?it/s]Testing:   6%|▌         | 1/18 [00:00<00:02,  7.40it/s]Testing:  11%|█         | 2/18 [00:00<00:02,  7.74it/s]Testing:  17%|█▋        | 3/18 [00:00<00:01,  7.79it/s]Testing:  22%|██▏       | 4/18 [00:00<00:01,  7.86it/s]Testing:  28%|██▊       | 5/18 [00:00<00:01,  7.79it/s]Testing:  33%|███▎      | 6/18 [00:00<00:01,  7.83it/s]Testing:  39%|███▉      | 7/18 [00:00<00:01,  7.82it/s]Testing:  44%|████▍     | 8/18 [00:01<00:01,  7.85it/s]Testing:  50%|█████     | 9/18 [00:01<00:01,  7.88it/s]Testing:  56%|█████▌    | 10/18 [00:01<00:01,  7.90it/s]Testing:  61%|██████    | 11/18 [00:01<00:00,  7.94it/s]Testing:  67%|██████▋   | 12/18 [00:01<00:00,  7.98it/s]Testing:  72%|███████▏  | 13/18 [00:01<00:00,  7.97it/s]Testing:  78%|███████▊  | 14/18 [00:01<00:00,  7.96it/s]Testing:  83%|████████▎ | 15/18 [00:01<00:00,  7.93it/s]Testing:  89%|████████▉ | 16/18 [00:02<00:00,  7.91it/s]Testing:  94%|█████████▍| 17/18 [00:02<00:00,  7.93it/s]Testing: 100%|██████████| 18/18 [00:02<00:00,  7.94it/s]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'_mean_accuracy': 0.8421639204025269,
 '_standard_dev_accuracy': 0.09174264967441559,
 '_variance_accuracy': 0.008416714146733284,
 'test_acc': 0.8421639204025269,
 'test_dice_c1': 0.39968815445899963,
 'test_f2_c1': 0.5537849068641663,
 'test_loss': 0.4277495741844177,
 'test_mean_c1': 0.8327350616455078,
 'test_prec_c1': 0.28448688983917236,
 'test_sens_c1': 0.8905670642852783,
 'test_spec_c1': 0.8338555693626404}
--------------------------------------------------------------------------------
Testing: 100%|██████████| 18/18 [00:02<00:00,  7.87it/s]
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

  | Name       | Type             | Params
------------------------------------------------
0 | encoder1   | EncoderBlock     | 37.6 K
1 | encoder2   | EncoderBlock     | 221 K 
2 | bottleneck | ConvolutionBlock | 885 K 
3 | dropout    | Dropout2d        | 0     
4 | decoder1   | DecoderBlock     | 573 K 
5 | decoder2   | DecoderBlock     | 143 K 
6 | conv       | Conv2d           | 130   
7 | softmax    | Softmax2d        | 0     
------------------------------------------------
1.9 M     Trainable params
0         Non-trainable params
1.9 M     Total params
7.447     Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Validation sanity check:  50%|█████     | 1/2 [00:01<00:01,  1.79s/it]Validation sanity check: 100%|██████████| 2/2 [00:02<00:00,  1.06it/s]                                                                      /home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Training: -1it [00:00, ?it/s]Training:   0%|          | 0/11 [00:00<00:00, 26546.23it/s]Epoch 0:   0%|          | 0/11 [00:00<00:00, 4310.69it/s]  Epoch 0:   9%|▉         | 1/11 [00:00<00:02,  3.92it/s]  Epoch 0:   9%|▉         | 1/11 [00:00<00:02,  3.92it/s, loss=0.693, v_num=4, train_loss_step=0.693]Epoch 0:  18%|█▊        | 2/11 [00:00<00:02,  3.21it/s, loss=0.693, v_num=4, train_loss_step=0.693]Epoch 0:  18%|█▊        | 2/11 [00:00<00:02,  3.21it/s, loss=0.692, v_num=4, train_loss_step=0.691]Epoch 0:  27%|██▋       | 3/11 [00:01<00:02,  2.95it/s, loss=0.692, v_num=4, train_loss_step=0.691]Epoch 0:  27%|██▋       | 3/11 [00:01<00:02,  2.95it/s, loss=0.69, v_num=4, train_loss_step=0.686] Epoch 0:  36%|███▋      | 4/11 [00:01<00:02,  2.81it/s, loss=0.69, v_num=4, train_loss_step=0.686]Epoch 0:  36%|███▋      | 4/11 [00:01<00:02,  2.81it/s, loss=0.688, v_num=4, train_loss_step=0.682]Epoch 0:  45%|████▌     | 5/11 [00:02<00:02,  2.73it/s, loss=0.688, v_num=4, train_loss_step=0.682]Epoch 0:  45%|████▌     | 5/11 [00:02<00:02,  2.73it/s, loss=0.685, v_num=4, train_loss_step=0.675]Epoch 0:  55%|█████▍    | 6/11 [00:02<00:01,  2.67it/s, loss=0.685, v_num=4, train_loss_step=0.675]Epoch 0:  55%|█████▍    | 6/11 [00:02<00:01,  2.67it/s, loss=0.682, v_num=4, train_loss_step=0.665]Epoch 0:  64%|██████▎   | 7/11 [00:03<00:01,  2.63it/s, loss=0.682, v_num=4, train_loss_step=0.665]Epoch 0:  64%|██████▎   | 7/11 [00:03<00:01,  2.63it/s, loss=0.678, v_num=4, train_loss_step=0.657]Epoch 0:  73%|███████▎  | 8/11 [00:03<00:01,  2.59it/s, loss=0.678, v_num=4, train_loss_step=0.657]Epoch 0:  73%|███████▎  | 8/11 [00:03<00:01,  2.59it/s, loss=0.672, v_num=4, train_loss_step=0.629]Epoch 0:  82%|████████▏ | 9/11 [00:03<00:00,  2.61it/s, loss=0.672, v_num=4, train_loss_step=0.629]Epoch 0:  82%|████████▏ | 9/11 [00:03<00:00,  2.61it/s, loss=0.664, v_num=4, train_loss_step=0.597]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/2 [00:00<?, ?it/s][A
Validating:  50%|█████     | 1/2 [00:01<00:01,  1.52s/it][AEpoch 0: 100%|██████████| 11/11 [00:05<00:00,  2.25it/s, loss=0.664, v_num=4, train_loss_step=0.597]
Validating: 100%|██████████| 2/2 [00:01<00:00,  1.20it/s][AEpoch 0: 100%|██████████| 11/11 [00:05<00:00,  2.11it/s, loss=0.664, v_num=4, train_loss_step=0.597]
                                                         [AEpoch 0: 100%|██████████| 11/11 [00:05<00:00,  2.08it/s, loss=0.664, v_num=4, train_loss_step=0.597]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(

Testing: 0it [00:00, ?it/s]Testing:   6%|▌         | 1/18 [00:00<00:02,  5.90it/s]Testing:  11%|█         | 2/18 [00:00<00:02,  6.14it/s]Testing:  17%|█▋        | 3/18 [00:00<00:02,  6.29it/s]Testing:  22%|██▏       | 4/18 [00:00<00:02,  6.36it/s]Testing:  28%|██▊       | 5/18 [00:00<00:02,  6.34it/s]Testing:  33%|███▎      | 6/18 [00:00<00:01,  6.35it/s]Testing:  39%|███▉      | 7/18 [00:01<00:01,  6.30it/s]Testing:  44%|████▍     | 8/18 [00:01<00:01,  6.32it/s]Testing:  50%|█████     | 9/18 [00:01<00:01,  6.33it/s]Testing:  56%|█████▌    | 10/18 [00:01<00:01,  6.36it/s]Testing:  61%|██████    | 11/18 [00:01<00:01,  6.39it/s]Testing:  67%|██████▋   | 12/18 [00:01<00:00,  6.38it/s]Testing:  72%|███████▏  | 13/18 [00:02<00:00,  6.38it/s]Testing:  78%|███████▊  | 14/18 [00:02<00:00,  6.36it/s]Testing:  83%|████████▎ | 15/18 [00:02<00:00,  6.34it/s]Testing:  89%|████████▉ | 16/18 [00:02<00:00,  6.37it/s]Testing:  94%|█████████▍| 17/18 [00:02<00:00,  6.38it/s]Testing: 100%|██████████| 18/18 [00:02<00:00,  6.38it/s]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'_mean_accuracy': 0.8285802006721497,
 '_standard_dev_accuracy': 0.08024624735116959,
 '_variance_accuracy': 0.006439460441470146,
 'test_acc': 0.8285802006721497,
 'test_dice_c1': 0.39365601539611816,
 'test_f2_c1': 0.5616674423217773,
 'test_loss': 0.5891689658164978,
 'test_mean_c1': 0.8846706748008728,
 'test_prec_c1': 0.2739483118057251,
 'test_sens_c1': 0.9599102735519409,
 'test_spec_c1': 0.8188140392303467}
--------------------------------------------------------------------------------
Testing: 100%|██████████| 18/18 [00:02<00:00,  6.33it/s]
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

  | Name       | Type             | Params
------------------------------------------------
0 | encoder1   | EncoderBlock     | 37.6 K
1 | encoder2   | EncoderBlock     | 221 K 
2 | bottleneck | ConvolutionBlock | 885 K 
3 | dropout    | Dropout2d        | 0     
4 | decoder1   | DecoderBlock     | 573 K 
5 | decoder2   | DecoderBlock     | 143 K 
6 | conv       | Conv2d           | 130   
7 | softmax    | Softmax2d        | 0     
------------------------------------------------
1.9 M     Trainable params
0         Non-trainable params
1.9 M     Total params
7.447     Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Validation sanity check:   0%|          | 0/1 [00:00<?, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Validation sanity check: 100%|██████████| 1/1 [00:01<00:00,  1.82s/it]                                                                      /home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Training: -1it [00:00, ?it/s]Training:   0%|          | 0/7 [00:00<00:00, 29959.31it/s]Epoch 0:   0%|          | 0/7 [00:00<00:00, 4355.46it/s]  Epoch 0:  14%|█▍        | 1/7 [00:00<00:02,  2.60it/s]  Epoch 0:  14%|█▍        | 1/7 [00:00<00:02,  2.60it/s, loss=0.69, v_num=5, train_loss_step=0.690]Epoch 0:  29%|██▊       | 2/7 [00:01<00:02,  2.10it/s, loss=0.69, v_num=5, train_loss_step=0.690]Epoch 0:  29%|██▊       | 2/7 [00:01<00:02,  2.10it/s, loss=0.689, v_num=5, train_loss_step=0.688]Epoch 0:  43%|████▎     | 3/7 [00:02<00:02,  1.92it/s, loss=0.689, v_num=5, train_loss_step=0.688]Epoch 0:  43%|████▎     | 3/7 [00:02<00:02,  1.92it/s, loss=0.687, v_num=5, train_loss_step=0.683]Epoch 0:  57%|█████▋    | 4/7 [00:02<00:01,  1.82it/s, loss=0.687, v_num=5, train_loss_step=0.683]Epoch 0:  57%|█████▋    | 4/7 [00:02<00:01,  1.82it/s, loss=0.684, v_num=5, train_loss_step=0.676]Epoch 0:  71%|███████▏  | 5/7 [00:03<00:01,  1.77it/s, loss=0.684, v_num=5, train_loss_step=0.676]Epoch 0:  71%|███████▏  | 5/7 [00:03<00:01,  1.77it/s, loss=0.682, v_num=5, train_loss_step=0.671]Epoch 0:  86%|████████▌ | 6/7 [00:03<00:00,  1.77it/s, loss=0.682, v_num=5, train_loss_step=0.671]Epoch 0:  86%|████████▌ | 6/7 [00:03<00:00,  1.77it/s, loss=0.677, v_num=5, train_loss_step=0.656]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/1 [00:00<?, ?it/s][A
Validating: 100%|██████████| 1/1 [00:01<00:00,  1.55s/it][AEpoch 0: 100%|██████████| 7/7 [00:05<00:00,  1.45it/s, loss=0.677, v_num=5, train_loss_step=0.656]
                                                         [AEpoch 0: 100%|██████████| 7/7 [00:05<00:00,  1.43it/s, loss=0.677, v_num=5, train_loss_step=0.656]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(

Testing: 0it [00:00, ?it/s]Testing:   6%|▌         | 1/18 [00:00<00:02,  7.23it/s]Testing:  11%|█         | 2/18 [00:00<00:02,  7.57it/s]Testing:  17%|█▋        | 3/18 [00:00<00:01,  7.72it/s]Testing:  22%|██▏       | 4/18 [00:00<00:01,  7.74it/s]Testing:  28%|██▊       | 5/18 [00:00<00:01,  7.83it/s]Testing:  33%|███▎      | 6/18 [00:00<00:01,  7.90it/s]Testing:  39%|███▉      | 7/18 [00:00<00:01,  7.89it/s]Testing:  44%|████▍     | 8/18 [00:01<00:01,  7.92it/s]Testing:  50%|█████     | 9/18 [00:01<00:01,  7.92it/s]Testing:  56%|█████▌    | 10/18 [00:01<00:01,  7.90it/s]Testing:  61%|██████    | 11/18 [00:01<00:00,  7.94it/s]Testing:  67%|██████▋   | 12/18 [00:01<00:00,  7.94it/s]Testing:  72%|███████▏  | 13/18 [00:01<00:00,  7.90it/s]Testing:  78%|███████▊  | 14/18 [00:01<00:00,  7.93it/s]Testing:  83%|████████▎ | 15/18 [00:01<00:00,  7.96it/s]Testing:  89%|████████▉ | 16/18 [00:02<00:00,  7.96it/s]Testing:  94%|█████████▍| 17/18 [00:02<00:00,  7.98it/s]Testing: 100%|██████████| 18/18 [00:02<00:00,  7.95it/s]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'_mean_accuracy': 0.8620961308479309,
 '_standard_dev_accuracy': 0.08426200598478317,
 '_variance_accuracy': 0.007100085262209177,
 'test_acc': 0.8620961308479309,
 'test_dice_c1': 0.48925521969795227,
 'test_f2_c1': 0.6508298516273499,
 'test_loss': 0.6428869962692261,
 'test_mean_c1': 0.882268488407135,
 'test_prec_c1': 0.3629400432109833,
 'test_sens_c1': 0.9175646901130676,
 'test_spec_c1': 0.8578681945800781}
--------------------------------------------------------------------------------
Testing: 100%|██████████| 18/18 [00:02<00:00,  7.87it/s]
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

  | Name       | Type             | Params
------------------------------------------------
0 | encoder1   | EncoderBlock     | 37.6 K
1 | encoder2   | EncoderBlock     | 221 K 
2 | bottleneck | ConvolutionBlock | 885 K 
3 | dropout    | Dropout2d        | 0     
4 | decoder1   | DecoderBlock     | 573 K 
5 | decoder2   | DecoderBlock     | 143 K 
6 | conv       | Conv2d           | 130   
7 | softmax    | Softmax2d        | 0     
------------------------------------------------
1.9 M     Trainable params
0         Non-trainable params
1.9 M     Total params
7.447     Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  1.78it/s]Validation sanity check: 100%|██████████| 2/2 [00:00<00:00,  2.25it/s]                                                                      /home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Training: -1it [00:00, ?it/s]Training:   0%|          | 0/41 [00:00<00:00, 27962.03it/s]Epoch 0:   0%|          | 0/41 [00:00<00:00, 4088.02it/s]  Epoch 0:   2%|▏         | 1/41 [00:00<00:02, 15.84it/s]  Epoch 0:   2%|▏         | 1/41 [00:00<00:02, 15.80it/s, loss=0.698, v_num=6, train_loss_step=0.698]Epoch 0:   5%|▍         | 2/41 [00:00<00:03, 12.69it/s, loss=0.698, v_num=6, train_loss_step=0.698]Epoch 0:   5%|▍         | 2/41 [00:00<00:03, 12.67it/s, loss=0.693, v_num=6, train_loss_step=0.689]Epoch 0:   7%|▋         | 3/41 [00:00<00:03, 11.67it/s, loss=0.693, v_num=6, train_loss_step=0.689]Epoch 0:   7%|▋         | 3/41 [00:00<00:03, 11.66it/s, loss=0.693, v_num=6, train_loss_step=0.691]Epoch 0:  10%|▉         | 4/41 [00:00<00:03, 11.05it/s, loss=0.693, v_num=6, train_loss_step=0.691]Epoch 0:  10%|▉         | 4/41 [00:00<00:03, 11.04it/s, loss=0.688, v_num=6, train_loss_step=0.675]Epoch 0:  12%|█▏        | 5/41 [00:00<00:03, 10.71it/s, loss=0.688, v_num=6, train_loss_step=0.675]Epoch 0:  12%|█▏        | 5/41 [00:00<00:03, 10.70it/s, loss=0.684, v_num=6, train_loss_step=0.665]Epoch 0:  15%|█▍        | 6/41 [00:00<00:03, 10.49it/s, loss=0.684, v_num=6, train_loss_step=0.665]Epoch 0:  15%|█▍        | 6/41 [00:00<00:03, 10.48it/s, loss=0.674, v_num=6, train_loss_step=0.624]Epoch 0:  17%|█▋        | 7/41 [00:00<00:03, 10.31it/s, loss=0.674, v_num=6, train_loss_step=0.624]Epoch 0:  17%|█▋        | 7/41 [00:00<00:03, 10.30it/s, loss=0.661, v_num=6, train_loss_step=0.587]Epoch 0:  20%|█▉        | 8/41 [00:00<00:03, 10.18it/s, loss=0.661, v_num=6, train_loss_step=0.587]Epoch 0:  20%|█▉        | 8/41 [00:00<00:03, 10.18it/s, loss=0.643, v_num=6, train_loss_step=0.514]Epoch 0:  22%|██▏       | 9/41 [00:00<00:03, 10.10it/s, loss=0.643, v_num=6, train_loss_step=0.514]Epoch 0:  22%|██▏       | 9/41 [00:00<00:03, 10.10it/s, loss=0.627, v_num=6, train_loss_step=0.499]Epoch 0:  24%|██▍       | 10/41 [00:01<00:03, 10.03it/s, loss=0.627, v_num=6, train_loss_step=0.499]Epoch 0:  24%|██▍       | 10/41 [00:01<00:03, 10.03it/s, loss=0.605, v_num=6, train_loss_step=0.406]Epoch 0:  27%|██▋       | 11/41 [00:01<00:03,  9.97it/s, loss=0.605, v_num=6, train_loss_step=0.406]Epoch 0:  27%|██▋       | 11/41 [00:01<00:03,  9.97it/s, loss=0.584, v_num=6, train_loss_step=0.376]Epoch 0:  29%|██▉       | 12/41 [00:01<00:02,  9.91it/s, loss=0.584, v_num=6, train_loss_step=0.376]Epoch 0:  29%|██▉       | 12/41 [00:01<00:02,  9.91it/s, loss=0.576, v_num=6, train_loss_step=0.486]Epoch 0:  32%|███▏      | 13/41 [00:01<00:02,  9.87it/s, loss=0.576, v_num=6, train_loss_step=0.486]Epoch 0:  32%|███▏      | 13/41 [00:01<00:02,  9.86it/s, loss=0.565, v_num=6, train_loss_step=0.432]Epoch 0:  34%|███▍      | 14/41 [00:01<00:02,  9.83it/s, loss=0.565, v_num=6, train_loss_step=0.432]Epoch 0:  34%|███▍      | 14/41 [00:01<00:02,  9.83it/s, loss=0.556, v_num=6, train_loss_step=0.441]Epoch 0:  37%|███▋      | 15/41 [00:01<00:02,  9.78it/s, loss=0.556, v_num=6, train_loss_step=0.441]Epoch 0:  37%|███▋      | 15/41 [00:01<00:02,  9.78it/s, loss=0.551, v_num=6, train_loss_step=0.476]Epoch 0:  39%|███▉      | 16/41 [00:01<00:02,  9.76it/s, loss=0.551, v_num=6, train_loss_step=0.476]Epoch 0:  39%|███▉      | 16/41 [00:01<00:02,  9.75it/s, loss=0.542, v_num=6, train_loss_step=0.416]Epoch 0:  41%|████▏     | 17/41 [00:01<00:02,  9.73it/s, loss=0.542, v_num=6, train_loss_step=0.416]Epoch 0:  41%|████▏     | 17/41 [00:01<00:02,  9.73it/s, loss=0.533, v_num=6, train_loss_step=0.387]Epoch 0:  44%|████▍     | 18/41 [00:01<00:02,  9.71it/s, loss=0.533, v_num=6, train_loss_step=0.387]Epoch 0:  44%|████▍     | 18/41 [00:01<00:02,  9.71it/s, loss=0.523, v_num=6, train_loss_step=0.359]Epoch 0:  46%|████▋     | 19/41 [00:02<00:02,  9.68it/s, loss=0.523, v_num=6, train_loss_step=0.359]Epoch 0:  46%|████▋     | 19/41 [00:02<00:02,  9.68it/s, loss=0.52, v_num=6, train_loss_step=0.461] Epoch 0:  49%|████▉     | 20/41 [00:02<00:02,  9.66it/s, loss=0.52, v_num=6, train_loss_step=0.461]Epoch 0:  49%|████▉     | 20/41 [00:02<00:02,  9.66it/s, loss=0.518, v_num=6, train_loss_step=0.483]Epoch 0:  51%|█████     | 21/41 [00:02<00:02,  9.65it/s, loss=0.518, v_num=6, train_loss_step=0.483]Epoch 0:  51%|█████     | 21/41 [00:02<00:02,  9.65it/s, loss=0.507, v_num=6, train_loss_step=0.482]Epoch 0:  54%|█████▎    | 22/41 [00:02<00:01,  9.63it/s, loss=0.507, v_num=6, train_loss_step=0.482]Epoch 0:  54%|█████▎    | 22/41 [00:02<00:01,  9.63it/s, loss=0.5, v_num=6, train_loss_step=0.532]  Epoch 0:  56%|█████▌    | 23/41 [00:02<00:01,  9.60it/s, loss=0.5, v_num=6, train_loss_step=0.532]Epoch 0:  56%|█████▌    | 23/41 [00:02<00:01,  9.60it/s, loss=0.486, v_num=6, train_loss_step=0.427]Epoch 0:  59%|█████▊    | 24/41 [00:02<00:01,  9.59it/s, loss=0.486, v_num=6, train_loss_step=0.427]Epoch 0:  59%|█████▊    | 24/41 [00:02<00:01,  9.59it/s, loss=0.473, v_num=6, train_loss_step=0.397]Epoch 0:  61%|██████    | 25/41 [00:02<00:01,  9.58it/s, loss=0.473, v_num=6, train_loss_step=0.397]Epoch 0:  61%|██████    | 25/41 [00:02<00:01,  9.58it/s, loss=0.463, v_num=6, train_loss_step=0.479]Epoch 0:  63%|██████▎   | 26/41 [00:02<00:01,  9.57it/s, loss=0.463, v_num=6, train_loss_step=0.479]Epoch 0:  63%|██████▎   | 26/41 [00:02<00:01,  9.56it/s, loss=0.454, v_num=6, train_loss_step=0.431]Epoch 0:  66%|██████▌   | 27/41 [00:02<00:01,  9.56it/s, loss=0.454, v_num=6, train_loss_step=0.431]Epoch 0:  66%|██████▌   | 27/41 [00:02<00:01,  9.56it/s, loss=0.442, v_num=6, train_loss_step=0.363]Epoch 0:  68%|██████▊   | 28/41 [00:03<00:01,  9.55it/s, loss=0.442, v_num=6, train_loss_step=0.363]Epoch 0:  68%|██████▊   | 28/41 [00:03<00:01,  9.55it/s, loss=0.433, v_num=6, train_loss_step=0.333]Epoch 0:  71%|███████   | 29/41 [00:03<00:01,  9.54it/s, loss=0.433, v_num=6, train_loss_step=0.333]Epoch 0:  71%|███████   | 29/41 [00:03<00:01,  9.54it/s, loss=0.431, v_num=6, train_loss_step=0.446]Epoch 0:  73%|███████▎  | 30/41 [00:03<00:01,  9.53it/s, loss=0.431, v_num=6, train_loss_step=0.446]Epoch 0:  73%|███████▎  | 30/41 [00:03<00:01,  9.53it/s, loss=0.43, v_num=6, train_loss_step=0.389] Epoch 0:  76%|███████▌  | 31/41 [00:03<00:01,  9.52it/s, loss=0.43, v_num=6, train_loss_step=0.389]Epoch 0:  76%|███████▌  | 31/41 [00:03<00:01,  9.52it/s, loss=0.43, v_num=6, train_loss_step=0.376]Epoch 0:  78%|███████▊  | 32/41 [00:03<00:00,  9.52it/s, loss=0.43, v_num=6, train_loss_step=0.376]Epoch 0:  78%|███████▊  | 32/41 [00:03<00:00,  9.52it/s, loss=0.431, v_num=6, train_loss_step=0.515]Epoch 0:  80%|████████  | 33/41 [00:03<00:00,  9.50it/s, loss=0.431, v_num=6, train_loss_step=0.515]Epoch 0:  80%|████████  | 33/41 [00:03<00:00,  9.50it/s, loss=0.427, v_num=6, train_loss_step=0.351]Epoch 0:  83%|████████▎ | 34/41 [00:03<00:00,  9.49it/s, loss=0.427, v_num=6, train_loss_step=0.351]Epoch 0:  83%|████████▎ | 34/41 [00:03<00:00,  9.49it/s, loss=0.427, v_num=6, train_loss_step=0.444]Epoch 0:  85%|████████▌ | 35/41 [00:03<00:00,  9.49it/s, loss=0.427, v_num=6, train_loss_step=0.444]Epoch 0:  85%|████████▌ | 35/41 [00:03<00:00,  9.49it/s, loss=0.426, v_num=6, train_loss_step=0.443]Epoch 0:  88%|████████▊ | 36/41 [00:03<00:00,  9.52it/s, loss=0.425, v_num=6, train_loss_step=0.400]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/5 [00:00<?, ?it/s][A
Validating:  20%|██        | 1/5 [00:00<00:01,  2.85it/s][AEpoch 0:  93%|█████████▎| 38/41 [00:04<00:00,  9.20it/s, loss=0.425, v_num=6, train_loss_step=0.400]
Validating:  40%|████      | 2/5 [00:00<00:01,  2.88it/s][A
Validating:  60%|██████    | 3/5 [00:01<00:00,  2.87it/s][A
Validating:  80%|████████  | 4/5 [00:01<00:00,  2.89it/s][AEpoch 0: 100%|██████████| 41/41 [00:05<00:00,  7.96it/s, loss=0.425, v_num=6, train_loss_step=0.400]
Validating: 100%|██████████| 5/5 [00:01<00:00,  2.89it/s][AEpoch 0: 100%|██████████| 41/41 [00:05<00:00,  7.47it/s, loss=0.425, v_num=6, train_loss_step=0.400]
                                                         [AEpoch 0: 100%|██████████| 41/41 [00:05<00:00,  7.41it/s, loss=0.425, v_num=6, train_loss_step=0.400]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(

Testing: 0it [00:00, ?it/s]Testing:   6%|▌         | 1/18 [00:00<00:02,  5.86it/s]Testing:  11%|█         | 2/18 [00:00<00:02,  6.14it/s]Testing:  17%|█▋        | 3/18 [00:00<00:02,  6.23it/s]Testing:  22%|██▏       | 4/18 [00:00<00:02,  6.30it/s]Testing:  28%|██▊       | 5/18 [00:00<00:02,  6.40it/s]Testing:  33%|███▎      | 6/18 [00:00<00:01,  6.44it/s]Testing:  39%|███▉      | 7/18 [00:01<00:01,  6.45it/s]Testing:  44%|████▍     | 8/18 [00:01<00:01,  6.43it/s]Testing:  50%|█████     | 9/18 [00:01<00:01,  6.36it/s]Testing:  56%|█████▌    | 10/18 [00:01<00:01,  6.33it/s]Testing:  61%|██████    | 11/18 [00:01<00:01,  6.37it/s]Testing:  67%|██████▋   | 12/18 [00:01<00:00,  6.38it/s]Testing:  72%|███████▏  | 13/18 [00:02<00:00,  6.40it/s]Testing:  78%|███████▊  | 14/18 [00:02<00:00,  6.38it/s]Testing:  83%|████████▎ | 15/18 [00:02<00:00,  6.36it/s]Testing:  89%|████████▉ | 16/18 [00:02<00:00,  6.38it/s]Testing:  94%|█████████▍| 17/18 [00:02<00:00,  6.36it/s]Testing: 100%|██████████| 18/18 [00:02<00:00,  6.35it/s]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'_mean_accuracy': 0.8901691436767578,
 '_standard_dev_accuracy': 0.09477829933166504,
 '_variance_accuracy': 0.008982925675809383,
 'test_acc': 0.8901691436767578,
 'test_dice_c1': 0.4582529067993164,
 'test_f2_c1': 0.6047011613845825,
 'test_loss': 0.4018854796886444,
 'test_mean_c1': 0.880518913269043,
 'test_prec_c1': 0.3449179530143738,
 'test_sens_c1': 0.8892170786857605,
 'test_spec_c1': 0.8864017128944397}
--------------------------------------------------------------------------------
Testing: 100%|██████████| 18/18 [00:02<00:00,  6.34it/s]
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

  | Name       | Type             | Params
------------------------------------------------
0 | encoder1   | EncoderBlock     | 37.6 K
1 | encoder2   | EncoderBlock     | 221 K 
2 | bottleneck | ConvolutionBlock | 885 K 
3 | dropout    | Dropout2d        | 0     
4 | decoder1   | DecoderBlock     | 573 K 
5 | decoder2   | DecoderBlock     | 143 K 
6 | conv       | Conv2d           | 130   
7 | softmax    | Softmax2d        | 0     
------------------------------------------------
1.9 M     Trainable params
0         Non-trainable params
1.9 M     Total params
7.447     Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Validation sanity check:  50%|█████     | 1/2 [00:01<00:01,  1.78s/it]Validation sanity check: 100%|██████████| 2/2 [00:02<00:00,  1.06it/s]                                                                      /home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Training: -1it [00:00, ?it/s]Training:   0%|          | 0/11 [00:00<00:00, 24528.09it/s]Epoch 0:   0%|          | 0/11 [00:00<00:00, 4165.15it/s]  Epoch 0:   9%|▉         | 1/11 [00:00<00:02,  3.96it/s]  Epoch 0:   9%|▉         | 1/11 [00:00<00:02,  3.96it/s, loss=0.691, v_num=7, train_loss_step=0.691]Epoch 0:  18%|█▊        | 2/11 [00:00<00:02,  3.22it/s, loss=0.691, v_num=7, train_loss_step=0.691]Epoch 0:  18%|█▊        | 2/11 [00:00<00:02,  3.22it/s, loss=0.691, v_num=7, train_loss_step=0.690]Epoch 0:  27%|██▋       | 3/11 [00:01<00:02,  2.95it/s, loss=0.691, v_num=7, train_loss_step=0.690]Epoch 0:  27%|██▋       | 3/11 [00:01<00:02,  2.95it/s, loss=0.686, v_num=7, train_loss_step=0.676]Epoch 0:  36%|███▋      | 4/11 [00:01<00:02,  2.81it/s, loss=0.686, v_num=7, train_loss_step=0.676]Epoch 0:  36%|███▋      | 4/11 [00:01<00:02,  2.81it/s, loss=0.682, v_num=7, train_loss_step=0.671]Epoch 0:  45%|████▌     | 5/11 [00:02<00:02,  2.72it/s, loss=0.682, v_num=7, train_loss_step=0.671]Epoch 0:  45%|████▌     | 5/11 [00:02<00:02,  2.72it/s, loss=0.671, v_num=7, train_loss_step=0.626]Epoch 0:  55%|█████▍    | 6/11 [00:02<00:01,  2.66it/s, loss=0.671, v_num=7, train_loss_step=0.626]Epoch 0:  55%|█████▍    | 6/11 [00:02<00:01,  2.66it/s, loss=0.66, v_num=7, train_loss_step=0.606] Epoch 0:  64%|██████▎   | 7/11 [00:03<00:01,  2.62it/s, loss=0.66, v_num=7, train_loss_step=0.606]Epoch 0:  64%|██████▎   | 7/11 [00:03<00:01,  2.62it/s, loss=0.644, v_num=7, train_loss_step=0.548]Epoch 0:  73%|███████▎  | 8/11 [00:03<00:01,  2.59it/s, loss=0.644, v_num=7, train_loss_step=0.548]Epoch 0:  73%|███████▎  | 8/11 [00:03<00:01,  2.59it/s, loss=0.633, v_num=7, train_loss_step=0.555]Epoch 0:  82%|████████▏ | 9/11 [00:03<00:00,  2.61it/s, loss=0.633, v_num=7, train_loss_step=0.555]Epoch 0:  82%|████████▏ | 9/11 [00:03<00:00,  2.61it/s, loss=0.618, v_num=7, train_loss_step=0.496]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/2 [00:00<?, ?it/s][A
Validating:  50%|█████     | 1/2 [00:01<00:01,  1.52s/it][AEpoch 0: 100%|██████████| 11/11 [00:05<00:00,  2.24it/s, loss=0.618, v_num=7, train_loss_step=0.496]
Validating: 100%|██████████| 2/2 [00:01<00:00,  1.20it/s][AEpoch 0: 100%|██████████| 11/11 [00:05<00:00,  2.10it/s, loss=0.618, v_num=7, train_loss_step=0.496]
                                                         [AEpoch 0: 100%|██████████| 11/11 [00:05<00:00,  2.08it/s, loss=0.618, v_num=7, train_loss_step=0.496]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(

Testing: 0it [00:00, ?it/s]Testing:   6%|▌         | 1/18 [00:00<00:02,  5.97it/s]Testing:  11%|█         | 2/18 [00:00<00:02,  6.15it/s]Testing:  17%|█▋        | 3/18 [00:00<00:02,  6.27it/s]Testing:  22%|██▏       | 4/18 [00:00<00:02,  6.35it/s]Testing:  28%|██▊       | 5/18 [00:00<00:02,  6.42it/s]Testing:  33%|███▎      | 6/18 [00:00<00:01,  6.40it/s]Testing:  39%|███▉      | 7/18 [00:01<00:01,  6.33it/s]Testing:  44%|████▍     | 8/18 [00:01<00:01,  6.31it/s]Testing:  50%|█████     | 9/18 [00:01<00:01,  6.32it/s]Testing:  56%|█████▌    | 10/18 [00:01<00:01,  6.34it/s]Testing:  61%|██████    | 11/18 [00:01<00:01,  6.36it/s]Testing:  67%|██████▋   | 12/18 [00:01<00:00,  6.39it/s]Testing:  72%|███████▏  | 13/18 [00:02<00:00,  6.39it/s]Testing:  78%|███████▊  | 14/18 [00:02<00:00,  6.38it/s]Testing:  83%|████████▎ | 15/18 [00:02<00:00,  6.37it/s]Testing:  89%|████████▉ | 16/18 [00:02<00:00,  6.37it/s]Testing:  94%|█████████▍| 17/18 [00:02<00:00,  6.39it/s]Testing: 100%|██████████| 18/18 [00:02<00:00,  6.41it/s]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'_mean_accuracy': 0.8622459769248962,
 '_standard_dev_accuracy': 0.07444148510694504,
 '_variance_accuracy': 0.005541535094380379,
 'test_acc': 0.8622459769248962,
 'test_dice_c1': 0.4991644620895386,
 'test_f2_c1': 0.6657017469406128,
 'test_loss': 0.5077835321426392,
 'test_mean_c1': 0.9064568281173706,
 'test_prec_c1': 0.3701484203338623,
 'test_sens_c1': 0.968647837638855,
 'test_spec_c1': 0.8512726426124573}
--------------------------------------------------------------------------------
Testing: 100%|██████████| 18/18 [00:02<00:00,  6.34it/s]
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

  | Name       | Type             | Params
------------------------------------------------
0 | encoder1   | EncoderBlock     | 37.6 K
1 | encoder2   | EncoderBlock     | 221 K 
2 | bottleneck | ConvolutionBlock | 885 K 
3 | dropout    | Dropout2d        | 0     
4 | decoder1   | DecoderBlock     | 573 K 
5 | decoder2   | DecoderBlock     | 143 K 
6 | conv       | Conv2d           | 130   
7 | softmax    | Softmax2d        | 0     
------------------------------------------------
1.9 M     Trainable params
0         Non-trainable params
1.9 M     Total params
7.447     Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Validation sanity check:   0%|          | 0/1 [00:00<?, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Validation sanity check: 100%|██████████| 1/1 [00:01<00:00,  1.84s/it]                                                                      /home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Training: -1it [00:00, ?it/s]Training:   0%|          | 0/7 [00:00<00:00, 27962.03it/s]Epoch 0:   0%|          | 0/7 [00:00<00:00, 4211.15it/s]  Epoch 0:  14%|█▍        | 1/7 [00:00<00:02,  2.63it/s]  Epoch 0:  14%|█▍        | 1/7 [00:00<00:02,  2.63it/s, loss=0.693, v_num=8, train_loss_step=0.693]Epoch 0:  29%|██▊       | 2/7 [00:01<00:02,  2.11it/s, loss=0.693, v_num=8, train_loss_step=0.693]Epoch 0:  29%|██▊       | 2/7 [00:01<00:02,  2.11it/s, loss=0.689, v_num=8, train_loss_step=0.684]Epoch 0:  43%|████▎     | 3/7 [00:02<00:02,  1.93it/s, loss=0.689, v_num=8, train_loss_step=0.684]Epoch 0:  43%|████▎     | 3/7 [00:02<00:02,  1.93it/s, loss=0.683, v_num=8, train_loss_step=0.673]Epoch 0:  57%|█████▋    | 4/7 [00:02<00:01,  1.83it/s, loss=0.683, v_num=8, train_loss_step=0.673]Epoch 0:  57%|█████▋    | 4/7 [00:02<00:01,  1.83it/s, loss=0.67, v_num=8, train_loss_step=0.631] Epoch 0:  71%|███████▏  | 5/7 [00:03<00:01,  1.77it/s, loss=0.67, v_num=8, train_loss_step=0.631]Epoch 0:  71%|███████▏  | 5/7 [00:03<00:01,  1.77it/s, loss=0.654, v_num=8, train_loss_step=0.590]Epoch 0:  86%|████████▌ | 6/7 [00:03<00:00,  1.77it/s, loss=0.654, v_num=8, train_loss_step=0.590]Epoch 0:  86%|████████▌ | 6/7 [00:03<00:00,  1.77it/s, loss=0.64, v_num=8, train_loss_step=0.571] 
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/1 [00:00<?, ?it/s][A
Validating: 100%|██████████| 1/1 [00:01<00:00,  1.57s/it][AEpoch 0: 100%|██████████| 7/7 [00:05<00:00,  1.45it/s, loss=0.64, v_num=8, train_loss_step=0.571]
                                                         [AEpoch 0: 100%|██████████| 7/7 [00:05<00:00,  1.43it/s, loss=0.64, v_num=8, train_loss_step=0.571]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(

Testing: 0it [00:00, ?it/s]Testing:   6%|▌         | 1/18 [00:00<00:02,  7.27it/s]Testing:  11%|█         | 2/18 [00:00<00:02,  7.55it/s]Testing:  17%|█▋        | 3/18 [00:00<00:01,  7.56it/s]Testing:  22%|██▏       | 4/18 [00:00<00:01,  7.72it/s]Testing:  28%|██▊       | 5/18 [00:00<00:01,  7.81it/s]Testing:  33%|███▎      | 6/18 [00:00<00:01,  7.91it/s]Testing:  39%|███▉      | 7/18 [00:00<00:01,  7.92it/s]Testing:  44%|████▍     | 8/18 [00:01<00:01,  7.97it/s]Testing:  50%|█████     | 9/18 [00:01<00:01,  7.94it/s]Testing:  56%|█████▌    | 10/18 [00:01<00:01,  7.89it/s]Testing:  61%|██████    | 11/18 [00:01<00:00,  7.90it/s]Testing:  67%|██████▋   | 12/18 [00:01<00:00,  7.86it/s]Testing:  72%|███████▏  | 13/18 [00:01<00:00,  7.91it/s]Testing:  78%|███████▊  | 14/18 [00:01<00:00,  7.93it/s]Testing:  83%|████████▎ | 15/18 [00:01<00:00,  7.95it/s]Testing:  89%|████████▉ | 16/18 [00:02<00:00,  7.95it/s]Testing:  94%|█████████▍| 17/18 [00:02<00:00,  7.96it/s]Testing: 100%|██████████| 18/18 [00:02<00:00,  7.95it/s]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'_mean_accuracy': 0.8143395185470581,
 '_standard_dev_accuracy': 0.10171610116958618,
 '_variance_accuracy': 0.010346165858209133,
 'test_acc': 0.8143395185470581,
 'test_dice_c1': 0.4335242807865143,
 'test_f2_c1': 0.5828773379325867,
 'test_loss': 0.5174998641014099,
 'test_mean_c1': 0.856711208820343,
 'test_prec_c1': 0.3245943784713745,
 'test_sens_c1': 0.9213727116584778,
 'test_spec_c1': 0.8093801736831665}
--------------------------------------------------------------------------------
Testing: 100%|██████████| 18/18 [00:02<00:00,  7.85it/s]
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

  | Name       | Type             | Params
------------------------------------------------
0 | encoder1   | EncoderBlock     | 37.6 K
1 | encoder2   | EncoderBlock     | 221 K 
2 | bottleneck | ConvolutionBlock | 885 K 
3 | dropout    | Dropout2d        | 0     
4 | decoder1   | DecoderBlock     | 573 K 
5 | decoder2   | DecoderBlock     | 143 K 
6 | conv       | Conv2d           | 130   
7 | softmax    | Softmax2d        | 0     
------------------------------------------------
1.9 M     Trainable params
0         Non-trainable params
1.9 M     Total params
7.447     Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  2.90it/s]Validation sanity check: 100%|██████████| 2/2 [00:00<00:00,  4.86it/s]                                                                      /home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Training: -1it [00:00, ?it/s]Training:   0%|          | 0/380 [00:00<00:00, 26379.27it/s]Epoch 0:   0%|          | 0/380 [00:00<00:00, 4040.76it/s]  Epoch 0:   0%|          | 1/380 [00:00<00:27, 13.58it/s]  Epoch 0:   0%|          | 1/380 [00:00<00:27, 13.55it/s, loss=0.676, v_num=9, train_loss_step=0.676]Epoch 0:   1%|          | 2/380 [00:00<00:29, 12.98it/s, loss=0.681, v_num=9, train_loss_step=0.685]Epoch 0:   1%|          | 3/380 [00:00<00:28, 13.35it/s, loss=0.681, v_num=9, train_loss_step=0.685]Epoch 0:   1%|          | 3/380 [00:00<00:28, 13.34it/s, loss=0.685, v_num=9, train_loss_step=0.695]Epoch 0:   1%|          | 4/380 [00:00<00:29, 12.94it/s, loss=0.683, v_num=9, train_loss_step=0.677]Epoch 0:   1%|▏         | 5/380 [00:00<00:28, 13.15it/s, loss=0.683, v_num=9, train_loss_step=0.677]Epoch 0:   1%|▏         | 5/380 [00:00<00:28, 13.14it/s, loss=0.681, v_num=9, train_loss_step=0.671]Epoch 0:   2%|▏         | 6/380 [00:00<00:29, 12.69it/s, loss=0.679, v_num=9, train_loss_step=0.669]Epoch 0:   2%|▏         | 7/380 [00:00<00:29, 12.58it/s, loss=0.679, v_num=9, train_loss_step=0.669]Epoch 0:   2%|▏         | 7/380 [00:00<00:29, 12.57it/s, loss=0.677, v_num=9, train_loss_step=0.668]Epoch 0:   2%|▏         | 8/380 [00:00<00:29, 12.51it/s, loss=0.676, v_num=9, train_loss_step=0.669]Epoch 0:   2%|▏         | 9/380 [00:00<00:30, 12.27it/s, loss=0.676, v_num=9, train_loss_step=0.669]Epoch 0:   2%|▏         | 9/380 [00:00<00:30, 12.27it/s, loss=0.675, v_num=9, train_loss_step=0.667]Epoch 0:   3%|▎         | 10/380 [00:00<00:30, 11.97it/s, loss=0.674, v_num=9, train_loss_step=0.664]Epoch 0:   3%|▎         | 11/380 [00:01<00:31, 11.69it/s, loss=0.674, v_num=9, train_loss_step=0.664]Epoch 0:   3%|▎         | 11/380 [00:01<00:31, 11.69it/s, loss=0.674, v_num=9, train_loss_step=0.673]Epoch 0:   3%|▎         | 12/380 [00:01<00:30, 11.93it/s, loss=0.673, v_num=9, train_loss_step=0.660]Epoch 0:   3%|▎         | 13/380 [00:01<00:30, 11.95it/s, loss=0.673, v_num=9, train_loss_step=0.660]Epoch 0:   3%|▎         | 13/380 [00:01<00:30, 11.95it/s, loss=0.672, v_num=9, train_loss_step=0.658]Epoch 0:   4%|▎         | 14/380 [00:01<00:30, 12.13it/s, loss=0.672, v_num=9, train_loss_step=0.672]Epoch 0:   4%|▍         | 15/380 [00:01<00:30, 12.14it/s, loss=0.672, v_num=9, train_loss_step=0.672]Epoch 0:   4%|▍         | 15/380 [00:01<00:30, 12.14it/s, loss=0.671, v_num=9, train_loss_step=0.654]Epoch 0:   4%|▍         | 16/380 [00:01<00:30, 11.94it/s, loss=0.67, v_num=9, train_loss_step=0.655] Epoch 0:   4%|▍         | 17/380 [00:01<00:30, 11.78it/s, loss=0.67, v_num=9, train_loss_step=0.655]Epoch 0:   4%|▍         | 17/380 [00:01<00:30, 11.78it/s, loss=0.668, v_num=9, train_loss_step=0.651]Epoch 0:   5%|▍         | 18/380 [00:01<00:30, 11.85it/s, loss=0.669, v_num=9, train_loss_step=0.679]Epoch 0:   5%|▌         | 19/380 [00:01<00:30, 11.66it/s, loss=0.669, v_num=9, train_loss_step=0.679]Epoch 0:   5%|▌         | 19/380 [00:01<00:30, 11.66it/s, loss=0.668, v_num=9, train_loss_step=0.653]Epoch 0:   5%|▌         | 20/380 [00:01<00:30, 11.72it/s, loss=0.669, v_num=9, train_loss_step=0.690]Epoch 0:   6%|▌         | 21/380 [00:01<00:30, 11.77it/s, loss=0.669, v_num=9, train_loss_step=0.690]Epoch 0:   6%|▌         | 21/380 [00:01<00:30, 11.77it/s, loss=0.667, v_num=9, train_loss_step=0.639]Epoch 0:   6%|▌         | 22/380 [00:01<00:30, 11.71it/s, loss=0.665, v_num=9, train_loss_step=0.641]Epoch 0:   6%|▌         | 23/380 [00:02<00:30, 11.70it/s, loss=0.665, v_num=9, train_loss_step=0.641]Epoch 0:   6%|▌         | 23/380 [00:02<00:30, 11.70it/s, loss=0.665, v_num=9, train_loss_step=0.688]Epoch 0:   6%|▋         | 24/380 [00:02<00:29, 11.87it/s, loss=0.663, v_num=9, train_loss_step=0.638]Epoch 0:   7%|▋         | 25/380 [00:02<00:29, 11.95it/s, loss=0.663, v_num=9, train_loss_step=0.638]Epoch 0:   7%|▋         | 25/380 [00:02<00:29, 11.95it/s, loss=0.661, v_num=9, train_loss_step=0.641]Epoch 0:   7%|▋         | 26/380 [00:02<00:29, 11.93it/s, loss=0.659, v_num=9, train_loss_step=0.616]Epoch 0:   7%|▋         | 27/380 [00:02<00:29, 12.01it/s, loss=0.659, v_num=9, train_loss_step=0.616]Epoch 0:   7%|▋         | 27/380 [00:02<00:29, 12.00it/s, loss=0.656, v_num=9, train_loss_step=0.620]Epoch 0:   7%|▋         | 28/380 [00:02<00:29, 12.02it/s, loss=0.653, v_num=9, train_loss_step=0.600]Epoch 0:   8%|▊         | 29/380 [00:02<00:28, 12.10it/s, loss=0.653, v_num=9, train_loss_step=0.600]Epoch 0:   8%|▊         | 29/380 [00:02<00:29, 12.10it/s, loss=0.65, v_num=9, train_loss_step=0.616] Epoch 0:   8%|▊         | 30/380 [00:02<00:28, 12.12it/s, loss=0.646, v_num=9, train_loss_step=0.577]Epoch 0:   8%|▊         | 31/380 [00:02<00:28, 12.10it/s, loss=0.646, v_num=9, train_loss_step=0.577]Epoch 0:   8%|▊         | 31/380 [00:02<00:28, 12.10it/s, loss=0.641, v_num=9, train_loss_step=0.578]Epoch 0:   8%|▊         | 32/380 [00:02<00:28, 12.12it/s, loss=0.636, v_num=9, train_loss_step=0.546]Epoch 0:   9%|▊         | 33/380 [00:02<00:28, 12.16it/s, loss=0.636, v_num=9, train_loss_step=0.546]Epoch 0:   9%|▊         | 33/380 [00:02<00:28, 12.16it/s, loss=0.635, v_num=9, train_loss_step=0.645]Epoch 0:   9%|▉         | 34/380 [00:02<00:28, 12.22it/s, loss=0.629, v_num=9, train_loss_step=0.550]Epoch 0:   9%|▉         | 35/380 [00:02<00:28, 12.32it/s, loss=0.629, v_num=9, train_loss_step=0.550]Epoch 0:   9%|▉         | 35/380 [00:02<00:28, 12.32it/s, loss=0.629, v_num=9, train_loss_step=0.669]Epoch 0:   9%|▉         | 36/380 [00:02<00:27, 12.37it/s, loss=0.619, v_num=9, train_loss_step=0.440]Epoch 0:  10%|▉         | 37/380 [00:03<00:27, 12.46it/s, loss=0.619, v_num=9, train_loss_step=0.440]Epoch 0:  10%|▉         | 37/380 [00:03<00:27, 12.46it/s, loss=0.615, v_num=9, train_loss_step=0.574]Epoch 0:  10%|█         | 38/380 [00:03<00:27, 12.58it/s, loss=0.619, v_num=9, train_loss_step=0.758]Epoch 0:  10%|█         | 39/380 [00:03<00:27, 12.61it/s, loss=0.619, v_num=9, train_loss_step=0.758]Epoch 0:  10%|█         | 39/380 [00:03<00:27, 12.61it/s, loss=0.613, v_num=9, train_loss_step=0.534]Epoch 0:  11%|█         | 40/380 [00:03<00:26, 12.66it/s, loss=0.6, v_num=9, train_loss_step=0.434]  Epoch 0:  11%|█         | 41/380 [00:03<00:26, 12.73it/s, loss=0.6, v_num=9, train_loss_step=0.434]Epoch 0:  11%|█         | 41/380 [00:03<00:26, 12.73it/s, loss=0.588, v_num=9, train_loss_step=0.401]Epoch 0:  11%|█         | 42/380 [00:03<00:26, 12.82it/s, loss=0.573, v_num=9, train_loss_step=0.340]Epoch 0:  11%|█▏        | 43/380 [00:03<00:26, 12.77it/s, loss=0.573, v_num=9, train_loss_step=0.340]Epoch 0:  11%|█▏        | 43/380 [00:03<00:26, 12.77it/s, loss=0.561, v_num=9, train_loss_step=0.437]Epoch 0:  12%|█▏        | 44/380 [00:03<00:26, 12.78it/s, loss=0.546, v_num=9, train_loss_step=0.349]Epoch 0:  12%|█▏        | 45/380 [00:03<00:26, 12.78it/s, loss=0.546, v_num=9, train_loss_step=0.349]Epoch 0:  12%|█▏        | 45/380 [00:03<00:26, 12.78it/s, loss=0.53, v_num=9, train_loss_step=0.320] Epoch 0:  12%|█▏        | 46/380 [00:03<00:25, 12.85it/s, loss=0.52, v_num=9, train_loss_step=0.420]Epoch 0:  12%|█▏        | 47/380 [00:03<00:25, 12.88it/s, loss=0.52, v_num=9, train_loss_step=0.420]Epoch 0:  12%|█▏        | 47/380 [00:03<00:25, 12.88it/s, loss=0.507, v_num=9, train_loss_step=0.360]Epoch 0:  13%|█▎        | 48/380 [00:03<00:25, 12.91it/s, loss=0.493, v_num=9, train_loss_step=0.315]Epoch 0:  13%|█▎        | 49/380 [00:03<00:25, 12.91it/s, loss=0.493, v_num=9, train_loss_step=0.315]Epoch 0:  13%|█▎        | 49/380 [00:03<00:25, 12.91it/s, loss=0.499, v_num=9, train_loss_step=0.732]Epoch 0:  13%|█▎        | 50/380 [00:03<00:25, 12.96it/s, loss=0.486, v_num=9, train_loss_step=0.314]Epoch 0:  13%|█▎        | 51/380 [00:04<00:25, 12.94it/s, loss=0.486, v_num=9, train_loss_step=0.314]Epoch 0:  13%|█▎        | 51/380 [00:04<00:25, 12.94it/s, loss=0.473, v_num=9, train_loss_step=0.314]Epoch 0:  14%|█▎        | 52/380 [00:04<00:25, 12.86it/s, loss=0.466, v_num=9, train_loss_step=0.407]Epoch 0:  14%|█▍        | 53/380 [00:04<00:25, 12.81it/s, loss=0.466, v_num=9, train_loss_step=0.407]Epoch 0:  14%|█▍        | 53/380 [00:04<00:25, 12.81it/s, loss=0.449, v_num=9, train_loss_step=0.316]Epoch 0:  14%|█▍        | 54/380 [00:04<00:25, 12.79it/s, loss=0.437, v_num=9, train_loss_step=0.314]Epoch 0:  14%|█▍        | 55/380 [00:04<00:25, 12.78it/s, loss=0.437, v_num=9, train_loss_step=0.314]Epoch 0:  14%|█▍        | 55/380 [00:04<00:25, 12.78it/s, loss=0.429, v_num=9, train_loss_step=0.507]Epoch 0:  15%|█▍        | 56/380 [00:04<00:25, 12.78it/s, loss=0.423, v_num=9, train_loss_step=0.315]Epoch 0:  15%|█▌        | 57/380 [00:04<00:25, 12.76it/s, loss=0.423, v_num=9, train_loss_step=0.315]Epoch 0:  15%|█▌        | 57/380 [00:04<00:25, 12.76it/s, loss=0.413, v_num=9, train_loss_step=0.374]Epoch 0:  15%|█▌        | 58/380 [00:04<00:25, 12.84it/s, loss=0.392, v_num=9, train_loss_step=0.336]Epoch 0:  16%|█▌        | 59/380 [00:04<00:25, 12.79it/s, loss=0.392, v_num=9, train_loss_step=0.336]Epoch 0:  16%|█▌        | 59/380 [00:04<00:25, 12.79it/s, loss=0.383, v_num=9, train_loss_step=0.359]Epoch 0:  16%|█▌        | 60/380 [00:04<00:25, 12.79it/s, loss=0.395, v_num=9, train_loss_step=0.669]Epoch 0:  16%|█▌        | 61/380 [00:04<00:24, 12.86it/s, loss=0.395, v_num=9, train_loss_step=0.669]Epoch 0:  16%|█▌        | 61/380 [00:04<00:24, 12.86it/s, loss=0.392, v_num=9, train_loss_step=0.338]Epoch 0:  16%|█▋        | 62/380 [00:04<00:24, 12.91it/s, loss=0.393, v_num=9, train_loss_step=0.358]Epoch 0:  17%|█▋        | 63/380 [00:04<00:24, 12.92it/s, loss=0.393, v_num=9, train_loss_step=0.358]Epoch 0:  17%|█▋        | 63/380 [00:04<00:24, 12.92it/s, loss=0.389, v_num=9, train_loss_step=0.371]Epoch 0:  17%|█▋        | 64/380 [00:05<00:24, 12.96it/s, loss=0.399, v_num=9, train_loss_step=0.534]Epoch 0:  17%|█▋        | 65/380 [00:05<00:24, 12.98it/s, loss=0.399, v_num=9, train_loss_step=0.534]Epoch 0:  17%|█▋        | 65/380 [00:05<00:24, 12.98it/s, loss=0.405, v_num=9, train_loss_step=0.455]Epoch 0:  17%|█▋        | 66/380 [00:05<00:24, 13.01it/s, loss=0.401, v_num=9, train_loss_step=0.324]Epoch 0:  18%|█▊        | 67/380 [00:05<00:24, 13.01it/s, loss=0.401, v_num=9, train_loss_step=0.324]Epoch 0:  18%|█▊        | 67/380 [00:05<00:24, 13.01it/s, loss=0.401, v_num=9, train_loss_step=0.359]Epoch 0:  18%|█▊        | 68/380 [00:05<00:23, 13.03it/s, loss=0.408, v_num=9, train_loss_step=0.464]Epoch 0:  18%|█▊        | 69/380 [00:05<00:23, 13.07it/s, loss=0.408, v_num=9, train_loss_step=0.464]Epoch 0:  18%|█▊        | 69/380 [00:05<00:23, 13.07it/s, loss=0.387, v_num=9, train_loss_step=0.314]Epoch 0:  18%|█▊        | 70/380 [00:05<00:23, 13.10it/s, loss=0.391, v_num=9, train_loss_step=0.383]Epoch 0:  19%|█▊        | 71/380 [00:05<00:23, 13.09it/s, loss=0.391, v_num=9, train_loss_step=0.383]Epoch 0:  19%|█▊        | 71/380 [00:05<00:23, 13.09it/s, loss=0.392, v_num=9, train_loss_step=0.334]Epoch 0:  19%|█▉        | 72/380 [00:05<00:23, 13.12it/s, loss=0.395, v_num=9, train_loss_step=0.472]Epoch 0:  19%|█▉        | 73/380 [00:05<00:23, 13.08it/s, loss=0.395, v_num=9, train_loss_step=0.472]Epoch 0:  19%|█▉        | 73/380 [00:05<00:23, 13.08it/s, loss=0.396, v_num=9, train_loss_step=0.345]Epoch 0:  19%|█▉        | 74/380 [00:05<00:23, 13.15it/s, loss=0.4, v_num=9, train_loss_step=0.389]  Epoch 0:  20%|█▉        | 75/380 [00:05<00:23, 13.15it/s, loss=0.4, v_num=9, train_loss_step=0.389]Epoch 0:  20%|█▉        | 75/380 [00:05<00:23, 13.15it/s, loss=0.397, v_num=9, train_loss_step=0.441]Epoch 0:  20%|██        | 76/380 [00:05<00:23, 13.20it/s, loss=0.399, v_num=9, train_loss_step=0.351]Epoch 0:  20%|██        | 77/380 [00:05<00:22, 13.20it/s, loss=0.399, v_num=9, train_loss_step=0.351]Epoch 0:  20%|██        | 77/380 [00:05<00:22, 13.20it/s, loss=0.399, v_num=9, train_loss_step=0.384]Epoch 0:  21%|██        | 78/380 [00:05<00:22, 13.22it/s, loss=0.405, v_num=9, train_loss_step=0.449]Epoch 0:  21%|██        | 79/380 [00:06<00:22, 13.21it/s, loss=0.405, v_num=9, train_loss_step=0.449]Epoch 0:  21%|██        | 79/380 [00:06<00:22, 13.21it/s, loss=0.405, v_num=9, train_loss_step=0.369]Epoch 0:  21%|██        | 80/380 [00:06<00:22, 13.18it/s, loss=0.391, v_num=9, train_loss_step=0.384]Epoch 0:  21%|██▏       | 81/380 [00:06<00:22, 13.18it/s, loss=0.391, v_num=9, train_loss_step=0.384]Epoch 0:  21%|██▏       | 81/380 [00:06<00:22, 13.18it/s, loss=0.392, v_num=9, train_loss_step=0.360]Epoch 0:  22%|██▏       | 82/380 [00:06<00:22, 13.20it/s, loss=0.39, v_num=9, train_loss_step=0.314] Epoch 0:  22%|██▏       | 83/380 [00:06<00:22, 13.20it/s, loss=0.39, v_num=9, train_loss_step=0.314]Epoch 0:  22%|██▏       | 83/380 [00:06<00:22, 13.20it/s, loss=0.388, v_num=9, train_loss_step=0.326]Epoch 0:  22%|██▏       | 84/380 [00:06<00:22, 13.20it/s, loss=0.377, v_num=9, train_loss_step=0.331]Epoch 0:  22%|██▏       | 85/380 [00:06<00:22, 13.24it/s, loss=0.377, v_num=9, train_loss_step=0.331]Epoch 0:  22%|██▏       | 85/380 [00:06<00:22, 13.24it/s, loss=0.374, v_num=9, train_loss_step=0.395]Epoch 0:  23%|██▎       | 86/380 [00:06<00:22, 13.29it/s, loss=0.384, v_num=9, train_loss_step=0.506]Epoch 0:  23%|██▎       | 87/380 [00:06<00:22, 13.24it/s, loss=0.384, v_num=9, train_loss_step=0.506]Epoch 0:  23%|██▎       | 87/380 [00:06<00:22, 13.24it/s, loss=0.395, v_num=9, train_loss_step=0.587]Epoch 0:  23%|██▎       | 88/380 [00:06<00:22, 13.19it/s, loss=0.39, v_num=9, train_loss_step=0.373] Epoch 0:  23%|██▎       | 89/380 [00:06<00:22, 13.16it/s, loss=0.39, v_num=9, train_loss_step=0.373]Epoch 0:  23%|██▎       | 89/380 [00:06<00:22, 13.16it/s, loss=0.398, v_num=9, train_loss_step=0.469]Epoch 0:  24%|██▎       | 90/380 [00:06<00:22, 13.17it/s, loss=0.397, v_num=9, train_loss_step=0.360]Epoch 0:  24%|██▍       | 91/380 [00:07<00:22, 13.12it/s, loss=0.397, v_num=9, train_loss_step=0.360]Epoch 0:  24%|██▍       | 91/380 [00:07<00:22, 13.12it/s, loss=0.397, v_num=9, train_loss_step=0.329]Epoch 0:  24%|██▍       | 92/380 [00:07<00:21, 13.16it/s, loss=0.396, v_num=9, train_loss_step=0.455]Epoch 0:  24%|██▍       | 93/380 [00:07<00:21, 13.14it/s, loss=0.396, v_num=9, train_loss_step=0.455]Epoch 0:  24%|██▍       | 93/380 [00:07<00:21, 13.14it/s, loss=0.396, v_num=9, train_loss_step=0.358]Epoch 0:  25%|██▍       | 94/380 [00:07<00:21, 13.13it/s, loss=0.397, v_num=9, train_loss_step=0.409]Epoch 0:  25%|██▌       | 95/380 [00:07<00:21, 13.17it/s, loss=0.397, v_num=9, train_loss_step=0.409]Epoch 0:  25%|██▌       | 95/380 [00:07<00:21, 13.17it/s, loss=0.391, v_num=9, train_loss_step=0.321]Epoch 0:  25%|██▌       | 96/380 [00:07<00:21, 13.23it/s, loss=0.394, v_num=9, train_loss_step=0.412]Epoch 0:  26%|██▌       | 97/380 [00:07<00:21, 13.21it/s, loss=0.394, v_num=9, train_loss_step=0.412]Epoch 0:  26%|██▌       | 97/380 [00:07<00:21, 13.21it/s, loss=0.391, v_num=9, train_loss_step=0.316]Epoch 0:  26%|██▌       | 98/380 [00:07<00:21, 13.25it/s, loss=0.392, v_num=9, train_loss_step=0.460]Epoch 0:  26%|██▌       | 99/380 [00:07<00:21, 13.28it/s, loss=0.392, v_num=9, train_loss_step=0.460]Epoch 0:  26%|██▌       | 99/380 [00:07<00:21, 13.28it/s, loss=0.393, v_num=9, train_loss_step=0.397]Epoch 0:  26%|██▋       | 100/380 [00:07<00:21, 13.28it/s, loss=0.392, v_num=9, train_loss_step=0.354]Epoch 0:  27%|██▋       | 101/380 [00:07<00:20, 13.31it/s, loss=0.392, v_num=9, train_loss_step=0.354]Epoch 0:  27%|██▋       | 101/380 [00:07<00:20, 13.31it/s, loss=0.392, v_num=9, train_loss_step=0.378]Epoch 0:  27%|██▋       | 102/380 [00:07<00:20, 13.36it/s, loss=0.395, v_num=9, train_loss_step=0.376]Epoch 0:  27%|██▋       | 103/380 [00:07<00:20, 13.39it/s, loss=0.395, v_num=9, train_loss_step=0.376]Epoch 0:  27%|██▋       | 103/380 [00:07<00:20, 13.39it/s, loss=0.399, v_num=9, train_loss_step=0.396]Epoch 0:  27%|██▋       | 104/380 [00:07<00:20, 13.40it/s, loss=0.402, v_num=9, train_loss_step=0.389]Epoch 0:  28%|██▊       | 105/380 [00:07<00:20, 13.43it/s, loss=0.402, v_num=9, train_loss_step=0.389]Epoch 0:  28%|██▊       | 105/380 [00:07<00:20, 13.43it/s, loss=0.404, v_num=9, train_loss_step=0.437]Epoch 0:  28%|██▊       | 106/380 [00:07<00:20, 13.43it/s, loss=0.397, v_num=9, train_loss_step=0.363]Epoch 0:  28%|██▊       | 107/380 [00:08<00:20, 13.41it/s, loss=0.397, v_num=9, train_loss_step=0.363]Epoch 0:  28%|██▊       | 107/380 [00:08<00:20, 13.41it/s, loss=0.388, v_num=9, train_loss_step=0.402]Epoch 0:  28%|██▊       | 108/380 [00:08<00:20, 13.46it/s, loss=0.389, v_num=9, train_loss_step=0.405]Epoch 0:  29%|██▊       | 109/380 [00:08<00:20, 13.49it/s, loss=0.383, v_num=9, train_loss_step=0.349]Epoch 0:  29%|██▉       | 110/380 [00:08<00:19, 13.52it/s, loss=0.383, v_num=9, train_loss_step=0.349]Epoch 0:  29%|██▉       | 110/380 [00:08<00:19, 13.52it/s, loss=0.384, v_num=9, train_loss_step=0.368]Epoch 0:  29%|██▉       | 111/380 [00:08<00:19, 13.53it/s, loss=0.391, v_num=9, train_loss_step=0.479]Epoch 0:  29%|██▉       | 112/380 [00:08<00:19, 13.56it/s, loss=0.386, v_num=9, train_loss_step=0.358]Epoch 0:  30%|██▉       | 113/380 [00:08<00:19, 13.51it/s, loss=0.386, v_num=9, train_loss_step=0.358]Epoch 0:  30%|██▉       | 113/380 [00:08<00:19, 13.51it/s, loss=0.385, v_num=9, train_loss_step=0.338]Epoch 0:  30%|███       | 114/380 [00:08<00:19, 13.54it/s, loss=0.39, v_num=9, train_loss_step=0.511] Epoch 0:  30%|███       | 115/380 [00:08<00:19, 13.53it/s, loss=0.393, v_num=9, train_loss_step=0.378]Epoch 0:  31%|███       | 116/380 [00:08<00:19, 13.59it/s, loss=0.393, v_num=9, train_loss_step=0.378]Epoch 0:  31%|███       | 116/380 [00:08<00:19, 13.58it/s, loss=0.39, v_num=9, train_loss_step=0.355] Epoch 0:  31%|███       | 117/380 [00:08<00:19, 13.58it/s, loss=0.391, v_num=9, train_loss_step=0.332]Epoch 0:  31%|███       | 118/380 [00:08<00:19, 13.62it/s, loss=0.384, v_num=9, train_loss_step=0.320]Epoch 0:  31%|███▏      | 119/380 [00:08<00:19, 13.66it/s, loss=0.384, v_num=9, train_loss_step=0.320]Epoch 0:  31%|███▏      | 119/380 [00:08<00:19, 13.66it/s, loss=0.38, v_num=9, train_loss_step=0.314] Epoch 0:  32%|███▏      | 120/380 [00:08<00:19, 13.65it/s, loss=0.384, v_num=9, train_loss_step=0.434]Epoch 0:  32%|███▏      | 121/380 [00:08<00:18, 13.67it/s, loss=0.39, v_num=9, train_loss_step=0.498] Epoch 0:  32%|███▏      | 122/380 [00:08<00:18, 13.68it/s, loss=0.39, v_num=9, train_loss_step=0.498]Epoch 0:  32%|███▏      | 122/380 [00:08<00:18, 13.68it/s, loss=0.393, v_num=9, train_loss_step=0.428]Epoch 0:  32%|███▏      | 123/380 [00:09<00:18, 13.69it/s, loss=0.392, v_num=9, train_loss_step=0.388]Epoch 0:  33%|███▎      | 124/380 [00:09<00:18, 13.71it/s, loss=0.393, v_num=9, train_loss_step=0.409]Epoch 0:  33%|███▎      | 125/380 [00:09<00:18, 13.67it/s, loss=0.393, v_num=9, train_loss_step=0.409]Epoch 0:  33%|███▎      | 125/380 [00:09<00:18, 13.67it/s, loss=0.39, v_num=9, train_loss_step=0.370] Epoch 0:  33%|███▎      | 126/380 [00:09<00:18, 13.68it/s, loss=0.393, v_num=9, train_loss_step=0.432]Epoch 0:  33%|███▎      | 127/380 [00:09<00:18, 13.68it/s, loss=0.394, v_num=9, train_loss_step=0.411]Epoch 0:  34%|███▎      | 128/380 [00:09<00:18, 13.69it/s, loss=0.394, v_num=9, train_loss_step=0.411]Epoch 0:  34%|███▎      | 128/380 [00:09<00:18, 13.69it/s, loss=0.391, v_num=9, train_loss_step=0.340]Epoch 0:  34%|███▍      | 129/380 [00:09<00:18, 13.65it/s, loss=0.395, v_num=9, train_loss_step=0.440]Epoch 0:  34%|███▍      | 130/380 [00:09<00:18, 13.63it/s, loss=0.4, v_num=9, train_loss_step=0.473]  Epoch 0:  34%|███▍      | 131/380 [00:09<00:18, 13.63it/s, loss=0.4, v_num=9, train_loss_step=0.473]Epoch 0:  34%|███▍      | 131/380 [00:09<00:18, 13.63it/s, loss=0.398, v_num=9, train_loss_step=0.428]Epoch 0:  35%|███▍      | 132/380 [00:09<00:18, 13.64it/s, loss=0.402, v_num=9, train_loss_step=0.439]Epoch 0:  35%|███▌      | 133/380 [00:09<00:18, 13.64it/s, loss=0.403, v_num=9, train_loss_step=0.371]Epoch 0:  35%|███▌      | 134/380 [00:09<00:17, 13.67it/s, loss=0.403, v_num=9, train_loss_step=0.371]Epoch 0:  35%|███▌      | 134/380 [00:09<00:17, 13.67it/s, loss=0.399, v_num=9, train_loss_step=0.419]Epoch 0:  36%|███▌      | 135/380 [00:09<00:17, 13.69it/s, loss=0.4, v_num=9, train_loss_step=0.403]  Epoch 0:  36%|███▌      | 136/380 [00:09<00:17, 13.73it/s, loss=0.398, v_num=9, train_loss_step=0.317]Epoch 0:  36%|███▌      | 137/380 [00:10<00:17, 13.70it/s, loss=0.398, v_num=9, train_loss_step=0.317]Epoch 0:  36%|███▌      | 137/380 [00:10<00:17, 13.70it/s, loss=0.403, v_num=9, train_loss_step=0.426]Epoch 0:  36%|███▋      | 138/380 [00:10<00:17, 13.69it/s, loss=0.405, v_num=9, train_loss_step=0.359]Epoch 0:  37%|███▋      | 139/380 [00:10<00:17, 13.71it/s, loss=0.409, v_num=9, train_loss_step=0.389]Epoch 0:  37%|███▋      | 140/380 [00:10<00:17, 13.74it/s, loss=0.409, v_num=9, train_loss_step=0.389]Epoch 0:  37%|███▋      | 140/380 [00:10<00:17, 13.74it/s, loss=0.407, v_num=9, train_loss_step=0.394]Epoch 0:  37%|███▋      | 141/380 [00:10<00:17, 13.73it/s, loss=0.399, v_num=9, train_loss_step=0.340]Epoch 0:  37%|███▋      | 142/380 [00:10<00:17, 13.74it/s, loss=0.395, v_num=9, train_loss_step=0.362]Epoch 0:  38%|███▊      | 143/380 [00:10<00:17, 13.78it/s, loss=0.395, v_num=9, train_loss_step=0.362]Epoch 0:  38%|███▊      | 143/380 [00:10<00:17, 13.78it/s, loss=0.395, v_num=9, train_loss_step=0.374]Epoch 0:  38%|███▊      | 144/380 [00:10<00:17, 13.77it/s, loss=0.396, v_num=9, train_loss_step=0.434]Epoch 0:  38%|███▊      | 145/380 [00:10<00:17, 13.80it/s, loss=0.393, v_num=9, train_loss_step=0.313]Epoch 0:  38%|███▊      | 146/380 [00:10<00:16, 13.83it/s, loss=0.393, v_num=9, train_loss_step=0.313]Epoch 0:  38%|███▊      | 146/380 [00:10<00:16, 13.83it/s, loss=0.389, v_num=9, train_loss_step=0.343]Epoch 0:  39%|███▊      | 147/380 [00:10<00:16, 13.87it/s, loss=0.384, v_num=9, train_loss_step=0.316]Epoch 0:  39%|███▉      | 148/380 [00:10<00:16, 13.90it/s, loss=0.383, v_num=9, train_loss_step=0.316]Epoch 0:  39%|███▉      | 149/380 [00:10<00:16, 13.92it/s, loss=0.383, v_num=9, train_loss_step=0.316]Epoch 0:  39%|███▉      | 149/380 [00:10<00:16, 13.92it/s, loss=0.377, v_num=9, train_loss_step=0.324]Epoch 0:  39%|███▉      | 150/380 [00:10<00:16, 13.92it/s, loss=0.375, v_num=9, train_loss_step=0.442]Epoch 0:  40%|███▉      | 151/380 [00:10<00:16, 13.94it/s, loss=0.37, v_num=9, train_loss_step=0.331] Epoch 0:  40%|████      | 152/380 [00:10<00:16, 13.96it/s, loss=0.37, v_num=9, train_loss_step=0.331]Epoch 0:  40%|████      | 152/380 [00:10<00:16, 13.96it/s, loss=0.364, v_num=9, train_loss_step=0.318]Epoch 0:  40%|████      | 153/380 [00:11<00:16, 13.95it/s, loss=0.373, v_num=9, train_loss_step=0.541]Epoch 0:  41%|████      | 154/380 [00:11<00:16, 13.94it/s, loss=0.368, v_num=9, train_loss_step=0.313]Epoch 0:  41%|████      | 155/380 [00:11<00:16, 13.97it/s, loss=0.368, v_num=9, train_loss_step=0.313]Epoch 0:  41%|████      | 155/380 [00:11<00:16, 13.97it/s, loss=0.377, v_num=9, train_loss_step=0.583]Epoch 0:  41%|████      | 156/380 [00:11<00:16, 13.98it/s, loss=0.377, v_num=9, train_loss_step=0.320]Epoch 0:  41%|████▏     | 157/380 [00:11<00:15, 14.00it/s, loss=0.372, v_num=9, train_loss_step=0.337]Epoch 0:  42%|████▏     | 158/380 [00:11<00:15, 14.02it/s, loss=0.372, v_num=9, train_loss_step=0.337]Epoch 0:  42%|████▏     | 158/380 [00:11<00:15, 14.02it/s, loss=0.373, v_num=9, train_loss_step=0.364]Epoch 0:  42%|████▏     | 159/380 [00:11<00:15, 14.03it/s, loss=0.371, v_num=9, train_loss_step=0.355]Epoch 0:  42%|████▏     | 160/380 [00:11<00:15, 14.04it/s, loss=0.37, v_num=9, train_loss_step=0.371] Epoch 0:  42%|████▏     | 161/380 [00:11<00:15, 14.06it/s, loss=0.37, v_num=9, train_loss_step=0.371]Epoch 0:  42%|████▏     | 161/380 [00:11<00:15, 14.06it/s, loss=0.373, v_num=9, train_loss_step=0.408]Epoch 0:  43%|████▎     | 162/380 [00:11<00:15, 14.06it/s, loss=0.374, v_num=9, train_loss_step=0.369]Epoch 0:  43%|████▎     | 163/380 [00:11<00:15, 14.10it/s, loss=0.373, v_num=9, train_loss_step=0.372]Epoch 0:  43%|████▎     | 164/380 [00:11<00:15, 14.07it/s, loss=0.373, v_num=9, train_loss_step=0.372]Epoch 0:  43%|████▎     | 164/380 [00:11<00:15, 14.07it/s, loss=0.37, v_num=9, train_loss_step=0.363] Epoch 0:  43%|████▎     | 165/380 [00:11<00:15, 14.05it/s, loss=0.371, v_num=9, train_loss_step=0.336]Epoch 0:  44%|████▎     | 166/380 [00:11<00:15, 14.07it/s, loss=0.374, v_num=9, train_loss_step=0.403]Epoch 0:  44%|████▍     | 167/380 [00:11<00:15, 14.08it/s, loss=0.374, v_num=9, train_loss_step=0.403]Epoch 0:  44%|████▍     | 167/380 [00:11<00:15, 14.08it/s, loss=0.378, v_num=9, train_loss_step=0.393]Epoch 0:  44%|████▍     | 168/380 [00:12<00:15, 14.08it/s, loss=0.38, v_num=9, train_loss_step=0.349] Epoch 0:  44%|████▍     | 169/380 [00:12<00:15, 14.06it/s, loss=0.385, v_num=9, train_loss_step=0.435]Epoch 0:  45%|████▍     | 170/380 [00:12<00:14, 14.07it/s, loss=0.385, v_num=9, train_loss_step=0.435]Epoch 0:  45%|████▍     | 170/380 [00:12<00:14, 14.07it/s, loss=0.38, v_num=9, train_loss_step=0.336] Epoch 0:  45%|████▌     | 171/380 [00:12<00:14, 14.08it/s, loss=0.381, v_num=9, train_loss_step=0.364]Epoch 0:  45%|████▌     | 172/380 [00:12<00:14, 14.09it/s, loss=0.384, v_num=9, train_loss_step=0.372]Epoch 0:  46%|████▌     | 173/380 [00:12<00:14, 14.09it/s, loss=0.384, v_num=9, train_loss_step=0.372]Epoch 0:  46%|████▌     | 173/380 [00:12<00:14, 14.09it/s, loss=0.377, v_num=9, train_loss_step=0.403]Epoch 0:  46%|████▌     | 174/380 [00:12<00:14, 14.13it/s, loss=0.378, v_num=9, train_loss_step=0.328]Epoch 0:  46%|████▌     | 175/380 [00:12<00:14, 14.13it/s, loss=0.366, v_num=9, train_loss_step=0.334]Epoch 0:  46%|████▋     | 176/380 [00:12<00:14, 14.13it/s, loss=0.366, v_num=9, train_loss_step=0.334]Epoch 0:  46%|████▋     | 176/380 [00:12<00:14, 14.13it/s, loss=0.366, v_num=9, train_loss_step=0.319]Epoch 0:  47%|████▋     | 177/380 [00:12<00:14, 14.15it/s, loss=0.364, v_num=9, train_loss_step=0.314]Epoch 0:  47%|████▋     | 178/380 [00:12<00:14, 14.14it/s, loss=0.364, v_num=9, train_loss_step=0.353]Epoch 0:  47%|████▋     | 179/380 [00:12<00:14, 14.16it/s, loss=0.364, v_num=9, train_loss_step=0.353]Epoch 0:  47%|████▋     | 179/380 [00:12<00:14, 14.16it/s, loss=0.369, v_num=9, train_loss_step=0.463]Epoch 0:  47%|████▋     | 180/380 [00:12<00:14, 14.18it/s, loss=0.368, v_num=9, train_loss_step=0.349]Epoch 0:  48%|████▊     | 181/380 [00:12<00:14, 14.19it/s, loss=0.365, v_num=9, train_loss_step=0.341]Epoch 0:  48%|████▊     | 182/380 [00:12<00:13, 14.21it/s, loss=0.365, v_num=9, train_loss_step=0.341]Epoch 0:  48%|████▊     | 182/380 [00:12<00:13, 14.21it/s, loss=0.366, v_num=9, train_loss_step=0.387]Epoch 0:  48%|████▊     | 183/380 [00:12<00:13, 14.23it/s, loss=0.363, v_num=9, train_loss_step=0.313]Epoch 0:  48%|████▊     | 184/380 [00:13<00:13, 14.23it/s, loss=0.361, v_num=9, train_loss_step=0.338]Epoch 0:  49%|████▊     | 185/380 [00:13<00:13, 14.21it/s, loss=0.361, v_num=9, train_loss_step=0.338]Epoch 0:  49%|████▊     | 185/380 [00:13<00:13, 14.21it/s, loss=0.364, v_num=9, train_loss_step=0.394]Epoch 0:  49%|████▉     | 186/380 [00:13<00:13, 14.20it/s, loss=0.364, v_num=9, train_loss_step=0.395]Epoch 0:  49%|████▉     | 187/380 [00:13<00:13, 14.19it/s, loss=0.362, v_num=9, train_loss_step=0.343]Epoch 0:  49%|████▉     | 188/380 [00:13<00:13, 14.17it/s, loss=0.362, v_num=9, train_loss_step=0.343]Epoch 0:  49%|████▉     | 188/380 [00:13<00:13, 14.17it/s, loss=0.362, v_num=9, train_loss_step=0.353]Epoch 0:  50%|████▉     | 189/380 [00:13<00:13, 14.18it/s, loss=0.357, v_num=9, train_loss_step=0.337]Epoch 0:  50%|█████     | 190/380 [00:13<00:13, 14.19it/s, loss=0.356, v_num=9, train_loss_step=0.326]Epoch 0:  50%|█████     | 191/380 [00:13<00:13, 14.18it/s, loss=0.356, v_num=9, train_loss_step=0.326]Epoch 0:  50%|█████     | 191/380 [00:13<00:13, 14.18it/s, loss=0.355, v_num=9, train_loss_step=0.344]Epoch 0:  51%|█████     | 192/380 [00:13<00:13, 14.18it/s, loss=0.354, v_num=9, train_loss_step=0.351]Epoch 0:  51%|█████     | 193/380 [00:13<00:13, 14.19it/s, loss=0.352, v_num=9, train_loss_step=0.349]Epoch 0:  51%|█████     | 194/380 [00:13<00:13, 14.22it/s, loss=0.352, v_num=9, train_loss_step=0.349]Epoch 0:  51%|█████     | 194/380 [00:13<00:13, 14.22it/s, loss=0.353, v_num=9, train_loss_step=0.351]Epoch 0:  51%|█████▏    | 195/380 [00:13<00:13, 14.22it/s, loss=0.355, v_num=9, train_loss_step=0.389]Epoch 0:  52%|█████▏    | 196/380 [00:13<00:12, 14.21it/s, loss=0.358, v_num=9, train_loss_step=0.362]Epoch 0:  52%|█████▏    | 197/380 [00:13<00:12, 14.20it/s, loss=0.358, v_num=9, train_loss_step=0.362]Epoch 0:  52%|█████▏    | 197/380 [00:13<00:12, 14.20it/s, loss=0.36, v_num=9, train_loss_step=0.369] Epoch 0:  52%|█████▏    | 198/380 [00:14<00:12, 14.18it/s, loss=0.359, v_num=9, train_loss_step=0.317]Epoch 0:  52%|█████▏    | 199/380 [00:14<00:12, 14.20it/s, loss=0.354, v_num=9, train_loss_step=0.375]Epoch 0:  53%|█████▎    | 200/380 [00:14<00:12, 14.18it/s, loss=0.354, v_num=9, train_loss_step=0.375]Epoch 0:  53%|█████▎    | 200/380 [00:14<00:12, 14.18it/s, loss=0.356, v_num=9, train_loss_step=0.383]Epoch 0:  53%|█████▎    | 201/380 [00:14<00:12, 14.19it/s, loss=0.355, v_num=9, train_loss_step=0.319]Epoch 0:  53%|█████▎    | 202/380 [00:14<00:12, 14.19it/s, loss=0.351, v_num=9, train_loss_step=0.316]Epoch 0:  53%|█████▎    | 203/380 [00:14<00:12, 14.20it/s, loss=0.351, v_num=9, train_loss_step=0.316]Epoch 0:  53%|█████▎    | 203/380 [00:14<00:12, 14.20it/s, loss=0.353, v_num=9, train_loss_step=0.348]Epoch 0:  54%|█████▎    | 204/380 [00:14<00:12, 14.19it/s, loss=0.353, v_num=9, train_loss_step=0.331]Epoch 0:  54%|█████▍    | 205/380 [00:14<00:12, 14.22it/s, loss=0.355, v_num=9, train_loss_step=0.446]Epoch 0:  54%|█████▍    | 206/380 [00:14<00:12, 14.22it/s, loss=0.355, v_num=9, train_loss_step=0.446]Epoch 0:  54%|█████▍    | 206/380 [00:14<00:12, 14.22it/s, loss=0.354, v_num=9, train_loss_step=0.367]Epoch 0:  54%|█████▍    | 207/380 [00:14<00:12, 14.22it/s, loss=0.354, v_num=9, train_loss_step=0.350]Epoch 0:  55%|█████▍    | 208/380 [00:14<00:12, 14.21it/s, loss=0.353, v_num=9, train_loss_step=0.335]Epoch 0:  55%|█████▌    | 209/380 [00:14<00:12, 14.23it/s, loss=0.353, v_num=9, train_loss_step=0.335]Epoch 0:  55%|█████▌    | 209/380 [00:14<00:12, 14.23it/s, loss=0.357, v_num=9, train_loss_step=0.411]Epoch 0:  55%|█████▌    | 210/380 [00:14<00:11, 14.26it/s, loss=0.358, v_num=9, train_loss_step=0.342]Epoch 0:  56%|█████▌    | 211/380 [00:14<00:11, 14.26it/s, loss=0.357, v_num=9, train_loss_step=0.321]Epoch 0:  56%|█████▌    | 212/380 [00:14<00:11, 14.26it/s, loss=0.357, v_num=9, train_loss_step=0.321]Epoch 0:  56%|█████▌    | 212/380 [00:14<00:11, 14.26it/s, loss=0.355, v_num=9, train_loss_step=0.327]Epoch 0:  56%|█████▌    | 213/380 [00:14<00:11, 14.29it/s, loss=0.354, v_num=9, train_loss_step=0.331]Epoch 0:  56%|█████▋    | 214/380 [00:15<00:11, 14.30it/s, loss=0.355, v_num=9, train_loss_step=0.361]Epoch 0:  57%|█████▋    | 215/380 [00:15<00:11, 14.30it/s, loss=0.355, v_num=9, train_loss_step=0.361]Epoch 0:  57%|█████▋    | 215/380 [00:15<00:11, 14.30it/s, loss=0.352, v_num=9, train_loss_step=0.338]Epoch 0:  57%|█████▋    | 216/380 [00:15<00:11, 14.27it/s, loss=0.352, v_num=9, train_loss_step=0.349]Epoch 0:  57%|█████▋    | 217/380 [00:15<00:11, 14.25it/s, loss=0.35, v_num=9, train_loss_step=0.333] Epoch 0:  57%|█████▋    | 218/380 [00:15<00:11, 14.28it/s, loss=0.35, v_num=9, train_loss_step=0.333]Epoch 0:  57%|█████▋    | 218/380 [00:15<00:11, 14.28it/s, loss=0.352, v_num=9, train_loss_step=0.350]Epoch 0:  58%|█████▊    | 219/380 [00:15<00:11, 14.24it/s, loss=0.349, v_num=9, train_loss_step=0.315]Epoch 0:  58%|█████▊    | 220/380 [00:15<00:11, 14.26it/s, loss=0.345, v_num=9, train_loss_step=0.315]Epoch 0:  58%|█████▊    | 221/380 [00:15<00:11, 14.26it/s, loss=0.345, v_num=9, train_loss_step=0.315]Epoch 0:  58%|█████▊    | 221/380 [00:15<00:11, 14.26it/s, loss=0.347, v_num=9, train_loss_step=0.359]Epoch 0:  58%|█████▊    | 222/380 [00:15<00:11, 14.28it/s, loss=0.348, v_num=9, train_loss_step=0.325]Epoch 0:  59%|█████▊    | 223/380 [00:15<00:11, 14.27it/s, loss=0.349, v_num=9, train_loss_step=0.383]Epoch 0:  59%|█████▉    | 224/380 [00:15<00:10, 14.27it/s, loss=0.349, v_num=9, train_loss_step=0.383]Epoch 0:  59%|█████▉    | 224/380 [00:15<00:10, 14.27it/s, loss=0.358, v_num=9, train_loss_step=0.504]Epoch 0:  59%|█████▉    | 225/380 [00:15<00:10, 14.28it/s, loss=0.352, v_num=9, train_loss_step=0.316]Epoch 0:  59%|█████▉    | 226/380 [00:15<00:10, 14.31it/s, loss=0.349, v_num=9, train_loss_step=0.313]Epoch 0:  60%|█████▉    | 227/380 [00:15<00:10, 14.31it/s, loss=0.349, v_num=9, train_loss_step=0.313]Epoch 0:  60%|█████▉    | 227/380 [00:15<00:10, 14.31it/s, loss=0.348, v_num=9, train_loss_step=0.324]Epoch 0:  60%|██████    | 228/380 [00:15<00:10, 14.33it/s, loss=0.347, v_num=9, train_loss_step=0.321]Epoch 0:  60%|██████    | 229/380 [00:16<00:10, 14.34it/s, loss=0.343, v_num=9, train_loss_step=0.324]Epoch 0:  61%|██████    | 230/380 [00:16<00:10, 14.35it/s, loss=0.343, v_num=9, train_loss_step=0.324]Epoch 0:  61%|██████    | 230/380 [00:16<00:10, 14.35it/s, loss=0.342, v_num=9, train_loss_step=0.336]Epoch 0:  61%|██████    | 231/380 [00:16<00:10, 14.35it/s, loss=0.343, v_num=9, train_loss_step=0.339]Epoch 0:  61%|██████    | 232/380 [00:16<00:10, 14.37it/s, loss=0.351, v_num=9, train_loss_step=0.484]Epoch 0:  61%|██████▏   | 233/380 [00:16<00:10, 14.37it/s, loss=0.351, v_num=9, train_loss_step=0.484]Epoch 0:  61%|██████▏   | 233/380 [00:16<00:10, 14.37it/s, loss=0.35, v_num=9, train_loss_step=0.313] Epoch 0:  62%|██████▏   | 234/380 [00:16<00:10, 14.37it/s, loss=0.353, v_num=9, train_loss_step=0.414]Epoch 0:  62%|██████▏   | 235/380 [00:16<00:10, 14.35it/s, loss=0.352, v_num=9, train_loss_step=0.314]Epoch 0:  62%|██████▏   | 236/380 [00:16<00:10, 14.35it/s, loss=0.352, v_num=9, train_loss_step=0.314]Epoch 0:  62%|██████▏   | 236/380 [00:16<00:10, 14.35it/s, loss=0.35, v_num=9, train_loss_step=0.313] Epoch 0:  62%|██████▏   | 237/380 [00:16<00:09, 14.38it/s, loss=0.35, v_num=9, train_loss_step=0.332]Epoch 0:  63%|██████▎   | 238/380 [00:16<00:09, 14.38it/s, loss=0.349, v_num=9, train_loss_step=0.323]Epoch 0:  63%|██████▎   | 239/380 [00:16<00:09, 14.39it/s, loss=0.349, v_num=9, train_loss_step=0.323]Epoch 0:  63%|██████▎   | 239/380 [00:16<00:09, 14.39it/s, loss=0.348, v_num=9, train_loss_step=0.314]Epoch 0:  63%|██████▎   | 240/380 [00:16<00:09, 14.40it/s, loss=0.349, v_num=9, train_loss_step=0.328]Epoch 0:  63%|██████▎   | 241/380 [00:16<00:09, 14.39it/s, loss=0.348, v_num=9, train_loss_step=0.328]Epoch 0:  64%|██████▎   | 242/380 [00:16<00:09, 14.40it/s, loss=0.348, v_num=9, train_loss_step=0.328]Epoch 0:  64%|██████▎   | 242/380 [00:16<00:09, 14.40it/s, loss=0.35, v_num=9, train_loss_step=0.367] Epoch 0:  64%|██████▍   | 243/380 [00:16<00:09, 14.39it/s, loss=0.346, v_num=9, train_loss_step=0.319]Epoch 0:  64%|██████▍   | 244/380 [00:16<00:09, 14.42it/s, loss=0.338, v_num=9, train_loss_step=0.336]Epoch 0:  64%|██████▍   | 245/380 [00:17<00:09, 14.41it/s, loss=0.338, v_num=9, train_loss_step=0.336]Epoch 0:  64%|██████▍   | 245/380 [00:17<00:09, 14.41it/s, loss=0.339, v_num=9, train_loss_step=0.326]Epoch 0:  65%|██████▍   | 246/380 [00:17<00:09, 14.40it/s, loss=0.341, v_num=9, train_loss_step=0.368]Epoch 0:  65%|██████▌   | 247/380 [00:17<00:09, 14.40it/s, loss=0.343, v_num=9, train_loss_step=0.359]Epoch 0:  65%|██████▌   | 248/380 [00:17<00:09, 14.42it/s, loss=0.343, v_num=9, train_loss_step=0.359]Epoch 0:  65%|██████▌   | 248/380 [00:17<00:09, 14.42it/s, loss=0.343, v_num=9, train_loss_step=0.326]Epoch 0:  66%|██████▌   | 249/380 [00:17<00:09, 14.42it/s, loss=0.343, v_num=9, train_loss_step=0.320]Epoch 0:  66%|██████▌   | 250/380 [00:17<00:08, 14.45it/s, loss=0.342, v_num=9, train_loss_step=0.317]Epoch 0:  66%|██████▌   | 251/380 [00:17<00:08, 14.44it/s, loss=0.342, v_num=9, train_loss_step=0.317]Epoch 0:  66%|██████▌   | 251/380 [00:17<00:08, 14.44it/s, loss=0.346, v_num=9, train_loss_step=0.422]Epoch 0:  66%|██████▋   | 252/380 [00:17<00:08, 14.45it/s, loss=0.339, v_num=9, train_loss_step=0.330]Epoch 0:  67%|██████▋   | 253/380 [00:17<00:08, 14.44it/s, loss=0.339, v_num=9, train_loss_step=0.325]Epoch 0:  67%|██████▋   | 254/380 [00:17<00:08, 14.44it/s, loss=0.339, v_num=9, train_loss_step=0.325]Epoch 0:  67%|██████▋   | 254/380 [00:17<00:08, 14.44it/s, loss=0.335, v_num=9, train_loss_step=0.338]Epoch 0:  67%|██████▋   | 255/380 [00:17<00:08, 14.43it/s, loss=0.341, v_num=9, train_loss_step=0.437]Epoch 0:  67%|██████▋   | 256/380 [00:17<00:08, 14.43it/s, loss=0.343, v_num=9, train_loss_step=0.340]Epoch 0:  68%|██████▊   | 257/380 [00:17<00:08, 14.43it/s, loss=0.343, v_num=9, train_loss_step=0.340]Epoch 0:  68%|██████▊   | 257/380 [00:17<00:08, 14.43it/s, loss=0.343, v_num=9, train_loss_step=0.346]Epoch 0:  68%|██████▊   | 258/380 [00:17<00:08, 14.44it/s, loss=0.345, v_num=9, train_loss_step=0.349]Epoch 0:  68%|██████▊   | 259/380 [00:18<00:08, 14.41it/s, loss=0.346, v_num=9, train_loss_step=0.330]Epoch 0:  68%|██████▊   | 260/380 [00:18<00:08, 14.42it/s, loss=0.346, v_num=9, train_loss_step=0.330]Epoch 0:  68%|██████▊   | 260/380 [00:18<00:08, 14.42it/s, loss=0.347, v_num=9, train_loss_step=0.361]Epoch 0:  69%|██████▊   | 261/380 [00:18<00:08, 14.42it/s, loss=0.348, v_num=9, train_loss_step=0.353]Epoch 0:  69%|██████▉   | 262/380 [00:18<00:08, 14.42it/s, loss=0.359, v_num=9, train_loss_step=0.571]Epoch 0:  69%|██████▉   | 263/380 [00:18<00:08, 14.40it/s, loss=0.359, v_num=9, train_loss_step=0.571]Epoch 0:  69%|██████▉   | 263/380 [00:18<00:08, 14.40it/s, loss=0.359, v_num=9, train_loss_step=0.325]Epoch 0:  69%|██████▉   | 264/380 [00:18<00:08, 14.39it/s, loss=0.36, v_num=9, train_loss_step=0.350] Epoch 0:  70%|██████▉   | 265/380 [00:18<00:07, 14.40it/s, loss=0.365, v_num=9, train_loss_step=0.437]Epoch 0:  70%|███████   | 266/380 [00:18<00:07, 14.42it/s, loss=0.365, v_num=9, train_loss_step=0.437]Epoch 0:  70%|███████   | 266/380 [00:18<00:07, 14.42it/s, loss=0.362, v_num=9, train_loss_step=0.313]Epoch 0:  70%|███████   | 267/380 [00:18<00:07, 14.43it/s, loss=0.361, v_num=9, train_loss_step=0.339]Epoch 0:  71%|███████   | 268/380 [00:18<00:07, 14.42it/s, loss=0.366, v_num=9, train_loss_step=0.418]Epoch 0:  71%|███████   | 269/380 [00:18<00:07, 14.42it/s, loss=0.366, v_num=9, train_loss_step=0.418]Epoch 0:  71%|███████   | 269/380 [00:18<00:07, 14.42it/s, loss=0.367, v_num=9, train_loss_step=0.345]Epoch 0:  71%|███████   | 270/380 [00:18<00:07, 14.44it/s, loss=0.371, v_num=9, train_loss_step=0.383]Epoch 0:  71%|███████▏  | 271/380 [00:18<00:07, 14.45it/s, loss=0.368, v_num=9, train_loss_step=0.372]Epoch 0:  72%|███████▏  | 272/380 [00:18<00:07, 14.45it/s, loss=0.368, v_num=9, train_loss_step=0.372]Epoch 0:  72%|███████▏  | 272/380 [00:18<00:07, 14.45it/s, loss=0.371, v_num=9, train_loss_step=0.394]Epoch 0:  72%|███████▏  | 273/380 [00:18<00:07, 14.46it/s, loss=0.371, v_num=9, train_loss_step=0.319]Epoch 0:  72%|███████▏  | 274/380 [00:19<00:07, 14.46it/s, loss=0.371, v_num=9, train_loss_step=0.341]Epoch 0:  72%|███████▏  | 275/380 [00:19<00:07, 14.47it/s, loss=0.371, v_num=9, train_loss_step=0.341]Epoch 0:  72%|███████▏  | 275/380 [00:19<00:07, 14.47it/s, loss=0.367, v_num=9, train_loss_step=0.345]Epoch 0:  73%|███████▎  | 276/380 [00:19<00:07, 14.46it/s, loss=0.366, v_num=9, train_loss_step=0.329]Epoch 0:  73%|███████▎  | 277/380 [00:19<00:07, 14.47it/s, loss=0.368, v_num=9, train_loss_step=0.378]Epoch 0:  73%|███████▎  | 278/380 [00:19<00:07, 14.48it/s, loss=0.368, v_num=9, train_loss_step=0.378]Epoch 0:  73%|███████▎  | 278/380 [00:19<00:07, 14.48it/s, loss=0.368, v_num=9, train_loss_step=0.352]Epoch 0:  73%|███████▎  | 279/380 [00:19<00:06, 14.47it/s, loss=0.368, v_num=9, train_loss_step=0.344]Epoch 0:  74%|███████▎  | 280/380 [00:19<00:06, 14.47it/s, loss=0.368, v_num=9, train_loss_step=0.344]Epoch 0:  74%|███████▍  | 281/380 [00:19<00:06, 14.47it/s, loss=0.368, v_num=9, train_loss_step=0.344]Epoch 0:  74%|███████▍  | 281/380 [00:19<00:06, 14.47it/s, loss=0.375, v_num=9, train_loss_step=0.511]Epoch 0:  74%|███████▍  | 282/380 [00:19<00:06, 14.48it/s, loss=0.367, v_num=9, train_loss_step=0.395]Epoch 0:  74%|███████▍  | 283/380 [00:19<00:06, 14.48it/s, loss=0.369, v_num=9, train_loss_step=0.378]Epoch 0:  75%|███████▍  | 284/380 [00:19<00:06, 14.46it/s, loss=0.369, v_num=9, train_loss_step=0.378]Epoch 0:  75%|███████▍  | 284/380 [00:19<00:06, 14.46it/s, loss=0.368, v_num=9, train_loss_step=0.321]Epoch 0:  75%|███████▌  | 285/380 [00:19<00:06, 14.45it/s, loss=0.362, v_num=9, train_loss_step=0.323]Epoch 0:  75%|███████▌  | 286/380 [00:19<00:06, 14.44it/s, loss=0.368, v_num=9, train_loss_step=0.431]Epoch 0:  76%|███████▌  | 287/380 [00:19<00:06, 14.44it/s, loss=0.368, v_num=9, train_loss_step=0.431]Epoch 0:  76%|███████▌  | 287/380 [00:19<00:06, 14.44it/s, loss=0.367, v_num=9, train_loss_step=0.321]Epoch 0:  76%|███████▌  | 288/380 [00:20<00:06, 14.45it/s, loss=0.366, v_num=9, train_loss_step=0.400]Epoch 0:  76%|███████▌  | 289/380 [00:20<00:06, 14.45it/s, loss=0.37, v_num=9, train_loss_step=0.411] Epoch 0:  76%|███████▋  | 290/380 [00:20<00:06, 14.46it/s, loss=0.37, v_num=9, train_loss_step=0.411]Epoch 0:  76%|███████▋  | 290/380 [00:20<00:06, 14.46it/s, loss=0.373, v_num=9, train_loss_step=0.449]Epoch 0:  77%|███████▋  | 291/380 [00:20<00:06, 14.47it/s, loss=0.375, v_num=9, train_loss_step=0.408]Epoch 0:  77%|███████▋  | 292/380 [00:20<00:06, 14.49it/s, loss=0.373, v_num=9, train_loss_step=0.369]Epoch 0:  77%|███████▋  | 293/380 [00:20<00:06, 14.49it/s, loss=0.373, v_num=9, train_loss_step=0.369]Epoch 0:  77%|███████▋  | 293/380 [00:20<00:06, 14.49it/s, loss=0.374, v_num=9, train_loss_step=0.326]Epoch 0:  77%|███████▋  | 294/380 [00:20<00:05, 14.48it/s, loss=0.38, v_num=9, train_loss_step=0.464] Epoch 0:  78%|███████▊  | 295/380 [00:20<00:05, 14.47it/s, loss=0.38, v_num=9, train_loss_step=0.352]Epoch 0:  78%|███████▊  | 296/380 [00:20<00:05, 14.48it/s, loss=0.38, v_num=9, train_loss_step=0.352]Epoch 0:  78%|███████▊  | 296/380 [00:20<00:05, 14.48it/s, loss=0.383, v_num=9, train_loss_step=0.385]Epoch 0:  78%|███████▊  | 297/380 [00:20<00:05, 14.49it/s, loss=0.383, v_num=9, train_loss_step=0.383]Epoch 0:  78%|███████▊  | 298/380 [00:20<00:05, 14.50it/s, loss=0.384, v_num=9, train_loss_step=0.363]Epoch 0:  79%|███████▊  | 299/380 [00:20<00:05, 14.50it/s, loss=0.384, v_num=9, train_loss_step=0.363]Epoch 0:  79%|███████▊  | 299/380 [00:20<00:05, 14.50it/s, loss=0.386, v_num=9, train_loss_step=0.391]Epoch 0:  79%|███████▉  | 300/380 [00:20<00:05, 14.50it/s, loss=0.392, v_num=9, train_loss_step=0.462]Epoch 0:  79%|███████▉  | 301/380 [00:20<00:05, 14.51it/s, loss=0.386, v_num=9, train_loss_step=0.379]Epoch 0:  79%|███████▉  | 302/380 [00:20<00:05, 14.54it/s, loss=0.386, v_num=9, train_loss_step=0.379]Epoch 0:  79%|███████▉  | 302/380 [00:20<00:05, 14.54it/s, loss=0.384, v_num=9, train_loss_step=0.375]Epoch 0:  80%|███████▉  | 303/380 [00:20<00:05, 14.55it/s, loss=0.384, v_num=9, train_loss_step=0.372]Epoch 0:  80%|████████  | 304/380 [00:20<00:05, 14.56it/s, loss=0.392, v_num=9, train_loss_step=0.474]Epoch 0:  80%|████████  | 305/380 [00:21<00:05, 14.55it/s, loss=0.392, v_num=9, train_loss_step=0.474]Epoch 0:  80%|████████  | 305/380 [00:21<00:05, 14.55it/s, loss=0.396, v_num=9, train_loss_step=0.405]Epoch 0:  81%|████████  | 306/380 [00:21<00:05, 14.56it/s, loss=0.392, v_num=9, train_loss_step=0.361]Epoch 0:  81%|████████  | 307/380 [00:21<00:05, 14.57it/s, loss=0.392, v_num=9, train_loss_step=0.315]Epoch 0:  81%|████████  | 308/380 [00:21<00:04, 14.59it/s, loss=0.392, v_num=9, train_loss_step=0.315]Epoch 0:  81%|████████  | 308/380 [00:21<00:04, 14.59it/s, loss=0.393, v_num=9, train_loss_step=0.415]Epoch 0:  81%|████████▏ | 309/380 [00:21<00:04, 14.61it/s, loss=0.391, v_num=9, train_loss_step=0.374]Epoch 0:  82%|████████▏ | 310/380 [00:21<00:04, 14.62it/s, loss=0.388, v_num=9, train_loss_step=0.385]Epoch 0:  82%|████████▏ | 311/380 [00:21<00:04, 14.63it/s, loss=0.388, v_num=9, train_loss_step=0.385]Epoch 0:  82%|████████▏ | 311/380 [00:21<00:04, 14.63it/s, loss=0.387, v_num=9, train_loss_step=0.395]Epoch 0:  82%|████████▏ | 312/380 [00:21<00:04, 14.64it/s, loss=0.387, v_num=9, train_loss_step=0.371]Epoch 0:  82%|████████▏ | 313/380 [00:21<00:04, 14.66it/s, loss=0.388, v_num=9, train_loss_step=0.344]Epoch 0:  83%|████████▎ | 314/380 [00:21<00:04, 14.67it/s, loss=0.388, v_num=9, train_loss_step=0.344]Epoch 0:  83%|████████▎ | 314/380 [00:21<00:04, 14.67it/s, loss=0.385, v_num=9, train_loss_step=0.400]Epoch 0:  83%|████████▎ | 315/380 [00:21<00:04, 14.69it/s, loss=0.383, v_num=9, train_loss_step=0.318]Epoch 0:  83%|████████▎ | 316/380 [00:21<00:04, 14.68it/s, loss=0.382, v_num=9, train_loss_step=0.365]Epoch 0:  83%|████████▎ | 317/380 [00:21<00:04, 14.68it/s, loss=0.382, v_num=9, train_loss_step=0.365]Epoch 0:  83%|████████▎ | 317/380 [00:21<00:04, 14.68it/s, loss=0.379, v_num=9, train_loss_step=0.317]Epoch 0:  84%|████████▎ | 318/380 [00:21<00:04, 14.70it/s, loss=0.377, v_num=9, train_loss_step=0.327]Epoch 0:  84%|████████▍ | 319/380 [00:21<00:04, 14.71it/s, loss=0.376, v_num=9, train_loss_step=0.360]Epoch 0:  84%|████████▍ | 320/380 [00:21<00:04, 14.71it/s, loss=0.376, v_num=9, train_loss_step=0.360]Epoch 0:  84%|████████▍ | 320/380 [00:21<00:04, 14.71it/s, loss=0.369, v_num=9, train_loss_step=0.332]Epoch 0:  84%|████████▍ | 321/380 [00:21<00:04, 14.72it/s, loss=0.367, v_num=9, train_loss_step=0.335]Epoch 0:  85%|████████▍ | 322/380 [00:21<00:03, 14.73it/s, loss=0.364, v_num=9, train_loss_step=0.314]Epoch 0:  85%|████████▌ | 323/380 [00:21<00:03, 14.75it/s, loss=0.364, v_num=9, train_loss_step=0.314]Epoch 0:  85%|████████▌ | 323/380 [00:21<00:03, 14.75it/s, loss=0.369, v_num=9, train_loss_step=0.471]Epoch 0:  85%|████████▌ | 324/380 [00:22<00:03, 14.75it/s, loss=0.362, v_num=9, train_loss_step=0.331]Epoch 0:  86%|████████▌ | 325/380 [00:22<00:03, 14.76it/s, loss=0.369, v_num=9, train_loss_step=0.544]Epoch 0:  86%|████████▌ | 326/380 [00:22<00:03, 14.75it/s, loss=0.369, v_num=9, train_loss_step=0.544]Epoch 0:  86%|████████▌ | 326/380 [00:22<00:03, 14.75it/s, loss=0.366, v_num=9, train_loss_step=0.313]Epoch 0:  86%|████████▌ | 327/380 [00:22<00:03, 14.76it/s, loss=0.367, v_num=9, train_loss_step=0.330]Epoch 0:  86%|████████▋ | 328/380 [00:22<00:03, 14.77it/s, loss=0.368, v_num=9, train_loss_step=0.439]Epoch 0:  87%|████████▋ | 329/380 [00:22<00:03, 14.77it/s, loss=0.368, v_num=9, train_loss_step=0.439]Epoch 0:  87%|████████▋ | 329/380 [00:22<00:03, 14.77it/s, loss=0.366, v_num=9, train_loss_step=0.322]Epoch 0:  87%|████████▋ | 330/380 [00:22<00:03, 14.78it/s, loss=0.362, v_num=9, train_loss_step=0.314]Epoch 0:  87%|████████▋ | 331/380 [00:22<00:03, 14.79it/s, loss=0.358, v_num=9, train_loss_step=0.320]Epoch 0:  87%|████████▋ | 332/380 [00:22<00:03, 14.76it/s, loss=0.358, v_num=9, train_loss_step=0.320]Epoch 0:  87%|████████▋ | 332/380 [00:22<00:03, 14.76it/s, loss=0.361, v_num=9, train_loss_step=0.413]Epoch 0:  88%|████████▊ | 333/380 [00:22<00:03, 14.77it/s, loss=0.36, v_num=9, train_loss_step=0.343] Epoch 0:  88%|████████▊ | 334/380 [00:22<00:03, 14.79it/s, loss=0.359, v_num=9, train_loss_step=0.370]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/46 [00:00<?, ?it/s][AEpoch 0:  88%|████████▊ | 336/380 [00:22<00:02, 14.83it/s, loss=0.359, v_num=9, train_loss_step=0.370]
Validating:   4%|▍         | 2/46 [00:00<00:03, 13.33it/s][A
Validating:   9%|▊         | 4/46 [00:00<00:04, 10.18it/s][AEpoch 0:  89%|████████▉ | 340/380 [00:23<00:02, 14.75it/s, loss=0.359, v_num=9, train_loss_step=0.370]
Validating:  13%|█▎        | 6/46 [00:00<00:03, 10.55it/s][A
Validating:  17%|█▋        | 8/46 [00:00<00:03, 10.08it/s][AEpoch 0:  91%|█████████ | 344/380 [00:23<00:02, 14.67it/s, loss=0.359, v_num=9, train_loss_step=0.370]
Validating:  22%|██▏       | 10/46 [00:00<00:03,  9.76it/s][A
Validating:  26%|██▌       | 12/46 [00:01<00:03, 10.09it/s][AEpoch 0:  92%|█████████▏| 348/380 [00:23<00:02, 14.60it/s, loss=0.359, v_num=9, train_loss_step=0.370]
Validating:  30%|███       | 14/46 [00:01<00:03, 10.44it/s][A
Validating:  35%|███▍      | 16/46 [00:01<00:03,  9.90it/s][AEpoch 0:  93%|█████████▎| 352/380 [00:24<00:01, 14.51it/s, loss=0.359, v_num=9, train_loss_step=0.370]
Validating:  39%|███▉      | 18/46 [00:01<00:02,  9.70it/s][A
Validating:  43%|████▎     | 20/46 [00:01<00:02,  9.88it/s][AEpoch 0:  94%|█████████▎| 356/380 [00:24<00:01, 14.45it/s, loss=0.359, v_num=9, train_loss_step=0.370]
Validating:  48%|████▊     | 22/46 [00:02<00:02, 10.24it/s][A
Validating:  52%|█████▏    | 24/46 [00:02<00:02, 10.19it/s][AEpoch 0:  95%|█████████▍| 360/380 [00:25<00:01, 14.38it/s, loss=0.359, v_num=9, train_loss_step=0.370]
Validating:  57%|█████▋    | 26/46 [00:02<00:01, 10.17it/s][A
Validating:  61%|██████    | 28/46 [00:02<00:01, 10.25it/s][AEpoch 0:  96%|█████████▌| 364/380 [00:25<00:01, 14.31it/s, loss=0.359, v_num=9, train_loss_step=0.370]
Validating:  65%|██████▌   | 30/46 [00:02<00:01,  9.73it/s][A
Validating:  67%|██████▋   | 31/46 [00:03<00:01,  9.66it/s][A
Validating:  72%|███████▏  | 33/46 [00:03<00:01, 10.19it/s][AEpoch 0:  97%|█████████▋| 368/380 [00:25<00:00, 14.24it/s, loss=0.359, v_num=9, train_loss_step=0.370]
Validating:  76%|███████▌  | 35/46 [00:03<00:01, 10.79it/s][A
Validating:  80%|████████  | 37/46 [00:03<00:00, 10.49it/s][AEpoch 0:  98%|█████████▊| 372/380 [00:26<00:00, 14.19it/s, loss=0.359, v_num=9, train_loss_step=0.370]
Validating:  85%|████████▍ | 39/46 [00:03<00:00, 10.79it/s][A
Validating:  89%|████████▉ | 41/46 [00:03<00:00, 10.71it/s][AEpoch 0:  99%|█████████▉| 376/380 [00:26<00:00, 14.15it/s, loss=0.359, v_num=9, train_loss_step=0.370]
Validating:  93%|█████████▎| 43/46 [00:04<00:00, 10.75it/s][A
Validating:  98%|█████████▊| 45/46 [00:04<00:00,  9.91it/s][AEpoch 0: 100%|██████████| 380/380 [00:27<00:00, 14.08it/s, loss=0.359, v_num=9, train_loss_step=0.370]Epoch 0: 100%|██████████| 380/380 [00:27<00:00, 14.04it/s, loss=0.359, v_num=9, train_loss_step=0.370]
                                                           [AEpoch 0: 100%|██████████| 380/380 [00:27<00:00, 14.01it/s, loss=0.359, v_num=9, train_loss_step=0.370]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(

Testing: 0it [00:00, ?it/s]Testing:   1%|          | 2/169 [00:00<00:10, 16.04it/s]Testing:   3%|▎         | 5/169 [00:00<00:08, 20.07it/s]Testing:   5%|▍         | 8/169 [00:00<00:08, 19.35it/s]Testing:   7%|▋         | 11/169 [00:00<00:08, 19.62it/s]Testing:   8%|▊         | 14/169 [00:00<00:07, 20.14it/s]Testing:  10%|█         | 17/169 [00:00<00:07, 20.92it/s]Testing:  12%|█▏        | 20/169 [00:00<00:07, 20.27it/s]Testing:  14%|█▎        | 23/169 [00:01<00:07, 20.54it/s]Testing:  15%|█▌        | 26/169 [00:01<00:06, 20.62it/s]Testing:  17%|█▋        | 29/169 [00:01<00:06, 22.21it/s]Testing:  19%|█▉        | 32/169 [00:01<00:06, 22.20it/s]Testing:  21%|██        | 35/169 [00:01<00:05, 22.61it/s]Testing:  22%|██▏       | 38/169 [00:01<00:05, 23.70it/s]Testing:  24%|██▍       | 41/169 [00:01<00:05, 22.79it/s]Testing:  26%|██▌       | 44/169 [00:02<00:05, 22.19it/s]Testing:  28%|██▊       | 47/169 [00:02<00:05, 23.11it/s]Testing:  30%|██▉       | 50/169 [00:02<00:05, 22.79it/s]Testing:  31%|███▏      | 53/169 [00:02<00:05, 21.24it/s]Testing:  33%|███▎      | 56/169 [00:02<00:05, 21.73it/s]Testing:  35%|███▍      | 59/169 [00:02<00:05, 21.39it/s]Testing:  37%|███▋      | 62/169 [00:02<00:04, 22.12it/s]Testing:  38%|███▊      | 65/169 [00:03<00:04, 21.94it/s]Testing:  40%|████      | 68/169 [00:03<00:04, 22.80it/s]Testing:  42%|████▏     | 71/169 [00:03<00:04, 22.78it/s]Testing:  44%|████▍     | 74/169 [00:03<00:04, 22.26it/s]Testing:  46%|████▌     | 77/169 [00:03<00:04, 22.43it/s]Testing:  47%|████▋     | 80/169 [00:03<00:03, 22.85it/s]Testing:  49%|████▉     | 83/169 [00:03<00:04, 20.61it/s]Testing:  51%|█████     | 86/169 [00:04<00:04, 20.09it/s]Testing:  53%|█████▎    | 89/169 [00:04<00:04, 19.90it/s]Testing:  54%|█████▍    | 92/169 [00:04<00:03, 19.97it/s]Testing:  56%|█████▌    | 95/169 [00:04<00:03, 19.42it/s]Testing:  58%|█████▊    | 98/169 [00:04<00:03, 20.41it/s]Testing:  60%|█████▉    | 101/169 [00:04<00:03, 20.16it/s]Testing:  62%|██████▏   | 104/169 [00:04<00:03, 20.89it/s]Testing:  63%|██████▎   | 107/169 [00:05<00:03, 20.24it/s]Testing:  65%|██████▌   | 110/169 [00:05<00:03, 18.79it/s]Testing:  67%|██████▋   | 113/169 [00:05<00:02, 19.65it/s]Testing:  68%|██████▊   | 115/169 [00:05<00:02, 19.28it/s]Testing:  69%|██████▉   | 117/169 [00:05<00:02, 19.33it/s]Testing:  71%|███████   | 120/169 [00:05<00:02, 20.76it/s]Testing:  73%|███████▎  | 123/169 [00:05<00:02, 20.77it/s]Testing:  75%|███████▍  | 126/169 [00:05<00:02, 21.14it/s]Testing:  76%|███████▋  | 129/169 [00:06<00:01, 21.07it/s]Testing:  78%|███████▊  | 132/169 [00:06<00:01, 22.32it/s]Testing:  80%|███████▉  | 135/169 [00:06<00:01, 21.96it/s]Testing:  82%|████████▏ | 138/169 [00:06<00:01, 22.03it/s]Testing:  83%|████████▎ | 141/169 [00:06<00:01, 21.63it/s]Testing:  85%|████████▌ | 144/169 [00:06<00:01, 21.98it/s]Testing:  87%|████████▋ | 147/169 [00:06<00:00, 22.65it/s]Testing:  89%|████████▉ | 150/169 [00:07<00:00, 23.65it/s]Testing:  91%|█████████ | 153/169 [00:07<00:00, 22.71it/s]Testing:  92%|█████████▏| 156/169 [00:07<00:00, 23.71it/s]Testing:  94%|█████████▍| 159/169 [00:07<00:00, 23.37it/s]Testing:  96%|█████████▌| 162/169 [00:07<00:00, 21.58it/s]Testing:  98%|█████████▊| 165/169 [00:07<00:00, 22.42it/s]Testing:  99%|█████████▉| 168/169 [00:07<00:00, 22.42it/s]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'_mean_accuracy': 0.9844397306442261,
 '_standard_dev_accuracy': 0.01880313828587532,
 '_variance_accuracy': 0.0003535579890012741,
 'test_acc': 0.9844397306442261,
 'test_dice_c1': 0.26004502177238464,
 'test_f2_c1': 0.298213392496109,
 'test_loss': 0.3607591986656189,
 'test_mean_c1': 0.4078366756439209,
 'test_prec_c1': 0.25873351097106934,
 'test_sens_c1': 0.3622758090496063,
 'test_spec_c1': 0.989592969417572}
--------------------------------------------------------------------------------
Testing: 100%|██████████| 169/169 [00:07<00:00, 21.40it/s]
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

  | Name       | Type             | Params
------------------------------------------------
0 | encoder1   | EncoderBlock     | 37.6 K
1 | encoder2   | EncoderBlock     | 221 K 
2 | bottleneck | ConvolutionBlock | 885 K 
3 | dropout    | Dropout2d        | 0     
4 | decoder1   | DecoderBlock     | 573 K 
5 | decoder2   | DecoderBlock     | 143 K 
6 | conv       | Conv2d           | 130   
7 | softmax    | Softmax2d        | 0     
------------------------------------------------
1.9 M     Trainable params
0         Non-trainable params
1.9 M     Total params
7.447     Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  2.00it/s]Validation sanity check: 100%|██████████| 2/2 [00:00<00:00,  2.67it/s]                                                                      /home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Training: -1it [00:00, ?it/s]Training:   0%|          | 0/96 [00:00<00:00, 28339.89it/s]Epoch 0:   0%|          | 0/96 [00:00<00:00, 4120.14it/s]  Epoch 0:   1%|          | 1/96 [00:00<00:06, 14.74it/s]  Epoch 0:   1%|          | 1/96 [00:00<00:06, 14.70it/s, loss=0.666, v_num=10, train_loss_step=0.666]Epoch 0:   2%|▏         | 2/96 [00:00<00:07, 12.19it/s, loss=0.666, v_num=10, train_loss_step=0.666]Epoch 0:   2%|▏         | 2/96 [00:00<00:07, 12.17it/s, loss=0.671, v_num=10, train_loss_step=0.676]Epoch 0:   3%|▎         | 3/96 [00:00<00:08, 11.29it/s, loss=0.671, v_num=10, train_loss_step=0.676]Epoch 0:   3%|▎         | 3/96 [00:00<00:08, 11.28it/s, loss=0.67, v_num=10, train_loss_step=0.669] Epoch 0:   4%|▍         | 4/96 [00:00<00:08, 10.87it/s, loss=0.67, v_num=10, train_loss_step=0.669]Epoch 0:   4%|▍         | 4/96 [00:00<00:08, 10.86it/s, loss=0.667, v_num=10, train_loss_step=0.657]Epoch 0:   5%|▌         | 5/96 [00:00<00:08, 10.65it/s, loss=0.667, v_num=10, train_loss_step=0.657]Epoch 0:   5%|▌         | 5/96 [00:00<00:08, 10.64it/s, loss=0.67, v_num=10, train_loss_step=0.680] Epoch 0:   6%|▋         | 6/96 [00:00<00:08, 10.47it/s, loss=0.67, v_num=10, train_loss_step=0.680]Epoch 0:   6%|▋         | 6/96 [00:00<00:08, 10.46it/s, loss=0.668, v_num=10, train_loss_step=0.658]Epoch 0:   7%|▋         | 7/96 [00:00<00:08, 10.35it/s, loss=0.668, v_num=10, train_loss_step=0.658]Epoch 0:   7%|▋         | 7/96 [00:00<00:08, 10.35it/s, loss=0.666, v_num=10, train_loss_step=0.655]Epoch 0:   8%|▊         | 8/96 [00:00<00:08, 10.26it/s, loss=0.666, v_num=10, train_loss_step=0.655]Epoch 0:   8%|▊         | 8/96 [00:00<00:08, 10.26it/s, loss=0.665, v_num=10, train_loss_step=0.661]Epoch 0:   9%|▉         | 9/96 [00:00<00:08, 10.20it/s, loss=0.665, v_num=10, train_loss_step=0.661]Epoch 0:   9%|▉         | 9/96 [00:00<00:08, 10.19it/s, loss=0.664, v_num=10, train_loss_step=0.653]Epoch 0:  10%|█         | 10/96 [00:01<00:08, 10.15it/s, loss=0.664, v_num=10, train_loss_step=0.653]Epoch 0:  10%|█         | 10/96 [00:01<00:08, 10.14it/s, loss=0.663, v_num=10, train_loss_step=0.650]Epoch 0:  11%|█▏        | 11/96 [00:01<00:08, 10.11it/s, loss=0.663, v_num=10, train_loss_step=0.650]Epoch 0:  11%|█▏        | 11/96 [00:01<00:08, 10.10it/s, loss=0.661, v_num=10, train_loss_step=0.651]Epoch 0:  12%|█▎        | 12/96 [00:01<00:08, 10.06it/s, loss=0.661, v_num=10, train_loss_step=0.651]Epoch 0:  12%|█▎        | 12/96 [00:01<00:08, 10.06it/s, loss=0.66, v_num=10, train_loss_step=0.645] Epoch 0:  14%|█▎        | 13/96 [00:01<00:08, 10.03it/s, loss=0.66, v_num=10, train_loss_step=0.645]Epoch 0:  14%|█▎        | 13/96 [00:01<00:08, 10.02it/s, loss=0.661, v_num=10, train_loss_step=0.671]Epoch 0:  15%|█▍        | 14/96 [00:01<00:08, 10.00it/s, loss=0.661, v_num=10, train_loss_step=0.671]Epoch 0:  15%|█▍        | 14/96 [00:01<00:08, 10.00it/s, loss=0.661, v_num=10, train_loss_step=0.663]Epoch 0:  16%|█▌        | 15/96 [00:01<00:08,  9.97it/s, loss=0.661, v_num=10, train_loss_step=0.663]Epoch 0:  16%|█▌        | 15/96 [00:01<00:08,  9.97it/s, loss=0.66, v_num=10, train_loss_step=0.642] Epoch 0:  17%|█▋        | 16/96 [00:01<00:08,  9.95it/s, loss=0.66, v_num=10, train_loss_step=0.642]Epoch 0:  17%|█▋        | 16/96 [00:01<00:08,  9.95it/s, loss=0.659, v_num=10, train_loss_step=0.653]Epoch 0:  18%|█▊        | 17/96 [00:01<00:07,  9.93it/s, loss=0.659, v_num=10, train_loss_step=0.653]Epoch 0:  18%|█▊        | 17/96 [00:01<00:07,  9.93it/s, loss=0.659, v_num=10, train_loss_step=0.654]Epoch 0:  19%|█▉        | 18/96 [00:01<00:07,  9.92it/s, loss=0.659, v_num=10, train_loss_step=0.654]Epoch 0:  19%|█▉        | 18/96 [00:01<00:07,  9.91it/s, loss=0.658, v_num=10, train_loss_step=0.640]Epoch 0:  20%|█▉        | 19/96 [00:02<00:07,  9.90it/s, loss=0.658, v_num=10, train_loss_step=0.640]Epoch 0:  20%|█▉        | 19/96 [00:02<00:07,  9.90it/s, loss=0.657, v_num=10, train_loss_step=0.647]Epoch 0:  21%|██        | 20/96 [00:02<00:07,  9.90it/s, loss=0.657, v_num=10, train_loss_step=0.647]Epoch 0:  21%|██        | 20/96 [00:02<00:07,  9.89it/s, loss=0.657, v_num=10, train_loss_step=0.650]Epoch 0:  22%|██▏       | 21/96 [00:02<00:07,  9.89it/s, loss=0.657, v_num=10, train_loss_step=0.650]Epoch 0:  22%|██▏       | 21/96 [00:02<00:07,  9.89it/s, loss=0.656, v_num=10, train_loss_step=0.636]Epoch 0:  23%|██▎       | 22/96 [00:02<00:07,  9.88it/s, loss=0.656, v_num=10, train_loss_step=0.636]Epoch 0:  23%|██▎       | 22/96 [00:02<00:07,  9.88it/s, loss=0.654, v_num=10, train_loss_step=0.645]Epoch 0:  24%|██▍       | 23/96 [00:02<00:07,  9.87it/s, loss=0.654, v_num=10, train_loss_step=0.645]Epoch 0:  24%|██▍       | 23/96 [00:02<00:07,  9.87it/s, loss=0.652, v_num=10, train_loss_step=0.638]Epoch 0:  25%|██▌       | 24/96 [00:02<00:07,  9.86it/s, loss=0.652, v_num=10, train_loss_step=0.638]Epoch 0:  25%|██▌       | 24/96 [00:02<00:07,  9.86it/s, loss=0.653, v_num=10, train_loss_step=0.666]Epoch 0:  26%|██▌       | 25/96 [00:02<00:07,  9.85it/s, loss=0.653, v_num=10, train_loss_step=0.666]Epoch 0:  26%|██▌       | 25/96 [00:02<00:07,  9.84it/s, loss=0.651, v_num=10, train_loss_step=0.634]Epoch 0:  27%|██▋       | 26/96 [00:02<00:07,  9.84it/s, loss=0.651, v_num=10, train_loss_step=0.634]Epoch 0:  27%|██▋       | 26/96 [00:02<00:07,  9.84it/s, loss=0.65, v_num=10, train_loss_step=0.639] Epoch 0:  28%|██▊       | 27/96 [00:02<00:07,  9.83it/s, loss=0.65, v_num=10, train_loss_step=0.639]Epoch 0:  28%|██▊       | 27/96 [00:02<00:07,  9.83it/s, loss=0.648, v_num=10, train_loss_step=0.621]Epoch 0:  29%|██▉       | 28/96 [00:02<00:06,  9.82it/s, loss=0.648, v_num=10, train_loss_step=0.621]Epoch 0:  29%|██▉       | 28/96 [00:02<00:06,  9.82it/s, loss=0.647, v_num=10, train_loss_step=0.638]Epoch 0:  30%|███       | 29/96 [00:03<00:06,  9.81it/s, loss=0.647, v_num=10, train_loss_step=0.638]Epoch 0:  30%|███       | 29/96 [00:03<00:06,  9.81it/s, loss=0.648, v_num=10, train_loss_step=0.669]Epoch 0:  31%|███▏      | 30/96 [00:03<00:06,  9.81it/s, loss=0.648, v_num=10, train_loss_step=0.669]Epoch 0:  31%|███▏      | 30/96 [00:03<00:06,  9.80it/s, loss=0.647, v_num=10, train_loss_step=0.636]Epoch 0:  32%|███▏      | 31/96 [00:03<00:06,  9.80it/s, loss=0.647, v_num=10, train_loss_step=0.636]Epoch 0:  32%|███▏      | 31/96 [00:03<00:06,  9.80it/s, loss=0.644, v_num=10, train_loss_step=0.594]Epoch 0:  33%|███▎      | 32/96 [00:03<00:06,  9.80it/s, loss=0.644, v_num=10, train_loss_step=0.594]Epoch 0:  33%|███▎      | 32/96 [00:03<00:06,  9.80it/s, loss=0.644, v_num=10, train_loss_step=0.641]Epoch 0:  34%|███▍      | 33/96 [00:03<00:06,  9.79it/s, loss=0.644, v_num=10, train_loss_step=0.641]Epoch 0:  34%|███▍      | 33/96 [00:03<00:06,  9.79it/s, loss=0.638, v_num=10, train_loss_step=0.548]Epoch 0:  35%|███▌      | 34/96 [00:03<00:06,  9.79it/s, loss=0.638, v_num=10, train_loss_step=0.548]Epoch 0:  35%|███▌      | 34/96 [00:03<00:06,  9.79it/s, loss=0.634, v_num=10, train_loss_step=0.595]Epoch 0:  36%|███▋      | 35/96 [00:03<00:06,  9.78it/s, loss=0.634, v_num=10, train_loss_step=0.595]Epoch 0:  36%|███▋      | 35/96 [00:03<00:06,  9.78it/s, loss=0.627, v_num=10, train_loss_step=0.505]Epoch 0:  38%|███▊      | 36/96 [00:03<00:06,  9.78it/s, loss=0.627, v_num=10, train_loss_step=0.505]Epoch 0:  38%|███▊      | 36/96 [00:03<00:06,  9.78it/s, loss=0.621, v_num=10, train_loss_step=0.528]Epoch 0:  39%|███▊      | 37/96 [00:03<00:06,  9.78it/s, loss=0.621, v_num=10, train_loss_step=0.528]Epoch 0:  39%|███▊      | 37/96 [00:03<00:06,  9.78it/s, loss=0.609, v_num=10, train_loss_step=0.417]Epoch 0:  40%|███▉      | 38/96 [00:03<00:05,  9.77it/s, loss=0.609, v_num=10, train_loss_step=0.417]Epoch 0:  40%|███▉      | 38/96 [00:03<00:05,  9.77it/s, loss=0.598, v_num=10, train_loss_step=0.421]Epoch 0:  41%|████      | 39/96 [00:04<00:05,  9.77it/s, loss=0.598, v_num=10, train_loss_step=0.421]Epoch 0:  41%|████      | 39/96 [00:04<00:05,  9.77it/s, loss=0.593, v_num=10, train_loss_step=0.538]Epoch 0:  42%|████▏     | 40/96 [00:04<00:05,  9.77it/s, loss=0.593, v_num=10, train_loss_step=0.538]Epoch 0:  42%|████▏     | 40/96 [00:04<00:05,  9.77it/s, loss=0.589, v_num=10, train_loss_step=0.573]Epoch 0:  43%|████▎     | 41/96 [00:04<00:05,  9.76it/s, loss=0.589, v_num=10, train_loss_step=0.573]Epoch 0:  43%|████▎     | 41/96 [00:04<00:05,  9.76it/s, loss=0.578, v_num=10, train_loss_step=0.418]Epoch 0:  44%|████▍     | 42/96 [00:04<00:05,  9.76it/s, loss=0.578, v_num=10, train_loss_step=0.418]Epoch 0:  44%|████▍     | 42/96 [00:04<00:05,  9.76it/s, loss=0.574, v_num=10, train_loss_step=0.559]Epoch 0:  45%|████▍     | 43/96 [00:04<00:05,  9.76it/s, loss=0.574, v_num=10, train_loss_step=0.559]Epoch 0:  45%|████▍     | 43/96 [00:04<00:05,  9.76it/s, loss=0.572, v_num=10, train_loss_step=0.601]Epoch 0:  46%|████▌     | 44/96 [00:04<00:05,  9.75it/s, loss=0.572, v_num=10, train_loss_step=0.601]Epoch 0:  46%|████▌     | 44/96 [00:04<00:05,  9.75it/s, loss=0.559, v_num=10, train_loss_step=0.415]Epoch 0:  47%|████▋     | 45/96 [00:04<00:05,  9.75it/s, loss=0.559, v_num=10, train_loss_step=0.415]Epoch 0:  47%|████▋     | 45/96 [00:04<00:05,  9.75it/s, loss=0.545, v_num=10, train_loss_step=0.342]Epoch 0:  48%|████▊     | 46/96 [00:04<00:05,  9.75it/s, loss=0.545, v_num=10, train_loss_step=0.342]Epoch 0:  48%|████▊     | 46/96 [00:04<00:05,  9.75it/s, loss=0.548, v_num=10, train_loss_step=0.701]Epoch 0:  49%|████▉     | 47/96 [00:04<00:05,  9.75it/s, loss=0.548, v_num=10, train_loss_step=0.701]Epoch 0:  49%|████▉     | 47/96 [00:04<00:05,  9.75it/s, loss=0.537, v_num=10, train_loss_step=0.399]Epoch 0:  50%|█████     | 48/96 [00:05<00:04,  9.74it/s, loss=0.537, v_num=10, train_loss_step=0.399]Epoch 0:  50%|█████     | 48/96 [00:05<00:04,  9.74it/s, loss=0.535, v_num=10, train_loss_step=0.606]Epoch 0:  51%|█████     | 49/96 [00:05<00:04,  9.74it/s, loss=0.535, v_num=10, train_loss_step=0.606]Epoch 0:  51%|█████     | 49/96 [00:05<00:04,  9.74it/s, loss=0.528, v_num=10, train_loss_step=0.526]Epoch 0:  52%|█████▏    | 50/96 [00:05<00:04,  9.74it/s, loss=0.528, v_num=10, train_loss_step=0.526]Epoch 0:  52%|█████▏    | 50/96 [00:05<00:04,  9.74it/s, loss=0.518, v_num=10, train_loss_step=0.439]Epoch 0:  53%|█████▎    | 51/96 [00:05<00:04,  9.74it/s, loss=0.518, v_num=10, train_loss_step=0.439]Epoch 0:  53%|█████▎    | 51/96 [00:05<00:04,  9.74it/s, loss=0.506, v_num=10, train_loss_step=0.359]Epoch 0:  54%|█████▍    | 52/96 [00:05<00:04,  9.74it/s, loss=0.506, v_num=10, train_loss_step=0.359]Epoch 0:  54%|█████▍    | 52/96 [00:05<00:04,  9.74it/s, loss=0.495, v_num=10, train_loss_step=0.410]Epoch 0:  55%|█████▌    | 53/96 [00:05<00:04,  9.73it/s, loss=0.495, v_num=10, train_loss_step=0.410]Epoch 0:  55%|█████▌    | 53/96 [00:05<00:04,  9.73it/s, loss=0.488, v_num=10, train_loss_step=0.413]Epoch 0:  56%|█████▋    | 54/96 [00:05<00:04,  9.73it/s, loss=0.488, v_num=10, train_loss_step=0.413]Epoch 0:  56%|█████▋    | 54/96 [00:05<00:04,  9.73it/s, loss=0.481, v_num=10, train_loss_step=0.454]Epoch 0:  57%|█████▋    | 55/96 [00:05<00:04,  9.73it/s, loss=0.481, v_num=10, train_loss_step=0.454]Epoch 0:  57%|█████▋    | 55/96 [00:05<00:04,  9.73it/s, loss=0.474, v_num=10, train_loss_step=0.354]Epoch 0:  58%|█████▊    | 56/96 [00:05<00:04,  9.73it/s, loss=0.474, v_num=10, train_loss_step=0.354]Epoch 0:  58%|█████▊    | 56/96 [00:05<00:04,  9.73it/s, loss=0.466, v_num=10, train_loss_step=0.367]Epoch 0:  59%|█████▉    | 57/96 [00:05<00:04,  9.72it/s, loss=0.466, v_num=10, train_loss_step=0.367]Epoch 0:  59%|█████▉    | 57/96 [00:05<00:04,  9.72it/s, loss=0.463, v_num=10, train_loss_step=0.372]Epoch 0:  60%|██████    | 58/96 [00:06<00:03,  9.72it/s, loss=0.463, v_num=10, train_loss_step=0.372]Epoch 0:  60%|██████    | 58/96 [00:06<00:03,  9.72it/s, loss=0.462, v_num=10, train_loss_step=0.397]Epoch 0:  61%|██████▏   | 59/96 [00:06<00:03,  9.71it/s, loss=0.462, v_num=10, train_loss_step=0.397]Epoch 0:  61%|██████▏   | 59/96 [00:06<00:03,  9.71it/s, loss=0.456, v_num=10, train_loss_step=0.420]Epoch 0:  62%|██████▎   | 60/96 [00:06<00:03,  9.71it/s, loss=0.456, v_num=10, train_loss_step=0.420]Epoch 0:  62%|██████▎   | 60/96 [00:06<00:03,  9.71it/s, loss=0.448, v_num=10, train_loss_step=0.399]Epoch 0:  64%|██████▎   | 61/96 [00:06<00:03,  9.71it/s, loss=0.448, v_num=10, train_loss_step=0.399]Epoch 0:  64%|██████▎   | 61/96 [00:06<00:03,  9.71it/s, loss=0.444, v_num=10, train_loss_step=0.351]Epoch 0:  65%|██████▍   | 62/96 [00:06<00:03,  9.70it/s, loss=0.444, v_num=10, train_loss_step=0.351]Epoch 0:  65%|██████▍   | 62/96 [00:06<00:03,  9.70it/s, loss=0.439, v_num=10, train_loss_step=0.449]Epoch 0:  66%|██████▌   | 63/96 [00:06<00:03,  9.70it/s, loss=0.439, v_num=10, train_loss_step=0.449]Epoch 0:  66%|██████▌   | 63/96 [00:06<00:03,  9.70it/s, loss=0.429, v_num=10, train_loss_step=0.399]Epoch 0:  67%|██████▋   | 64/96 [00:06<00:03,  9.70it/s, loss=0.429, v_num=10, train_loss_step=0.399]Epoch 0:  67%|██████▋   | 64/96 [00:06<00:03,  9.70it/s, loss=0.427, v_num=10, train_loss_step=0.392]Epoch 0:  68%|██████▊   | 65/96 [00:06<00:03,  9.70it/s, loss=0.427, v_num=10, train_loss_step=0.392]Epoch 0:  68%|██████▊   | 65/96 [00:06<00:03,  9.70it/s, loss=0.431, v_num=10, train_loss_step=0.411]Epoch 0:  69%|██████▉   | 66/96 [00:06<00:03,  9.70it/s, loss=0.431, v_num=10, train_loss_step=0.411]Epoch 0:  69%|██████▉   | 66/96 [00:06<00:03,  9.70it/s, loss=0.42, v_num=10, train_loss_step=0.476] Epoch 0:  70%|██████▉   | 67/96 [00:07<00:02,  9.70it/s, loss=0.42, v_num=10, train_loss_step=0.476]Epoch 0:  70%|██████▉   | 67/96 [00:07<00:02,  9.70it/s, loss=0.419, v_num=10, train_loss_step=0.379]Epoch 0:  71%|███████   | 68/96 [00:07<00:02,  9.70it/s, loss=0.419, v_num=10, train_loss_step=0.379]Epoch 0:  71%|███████   | 68/96 [00:07<00:02,  9.70it/s, loss=0.407, v_num=10, train_loss_step=0.364]Epoch 0:  72%|███████▏  | 69/96 [00:07<00:02,  9.70it/s, loss=0.407, v_num=10, train_loss_step=0.364]Epoch 0:  72%|███████▏  | 69/96 [00:07<00:02,  9.70it/s, loss=0.4, v_num=10, train_loss_step=0.399]  Epoch 0:  73%|███████▎  | 70/96 [00:07<00:02,  9.70it/s, loss=0.4, v_num=10, train_loss_step=0.399]Epoch 0:  73%|███████▎  | 70/96 [00:07<00:02,  9.70it/s, loss=0.397, v_num=10, train_loss_step=0.370]Epoch 0:  74%|███████▍  | 71/96 [00:07<00:02,  9.69it/s, loss=0.397, v_num=10, train_loss_step=0.370]Epoch 0:  74%|███████▍  | 71/96 [00:07<00:02,  9.69it/s, loss=0.397, v_num=10, train_loss_step=0.354]Epoch 0:  75%|███████▌  | 72/96 [00:07<00:02,  9.69it/s, loss=0.397, v_num=10, train_loss_step=0.354]Epoch 0:  75%|███████▌  | 72/96 [00:07<00:02,  9.69it/s, loss=0.399, v_num=10, train_loss_step=0.468]Epoch 0:  76%|███████▌  | 73/96 [00:07<00:02,  9.68it/s, loss=0.399, v_num=10, train_loss_step=0.468]Epoch 0:  76%|███████▌  | 73/96 [00:07<00:02,  9.68it/s, loss=0.397, v_num=10, train_loss_step=0.372]Epoch 0:  77%|███████▋  | 74/96 [00:07<00:02,  9.68it/s, loss=0.397, v_num=10, train_loss_step=0.372]Epoch 0:  77%|███████▋  | 74/96 [00:07<00:02,  9.68it/s, loss=0.395, v_num=10, train_loss_step=0.409]Epoch 0:  78%|███████▊  | 75/96 [00:07<00:02,  9.68it/s, loss=0.395, v_num=10, train_loss_step=0.409]Epoch 0:  78%|███████▊  | 75/96 [00:07<00:02,  9.68it/s, loss=0.4, v_num=10, train_loss_step=0.445]  Epoch 0:  79%|███████▉  | 76/96 [00:07<00:02,  9.68it/s, loss=0.4, v_num=10, train_loss_step=0.445]Epoch 0:  79%|███████▉  | 76/96 [00:07<00:02,  9.68it/s, loss=0.401, v_num=10, train_loss_step=0.383]Epoch 0:  80%|████████  | 77/96 [00:08<00:01,  9.68it/s, loss=0.401, v_num=10, train_loss_step=0.383]Epoch 0:  80%|████████  | 77/96 [00:08<00:01,  9.68it/s, loss=0.404, v_num=10, train_loss_step=0.440]Epoch 0:  81%|████████▏ | 78/96 [00:08<00:01,  9.68it/s, loss=0.404, v_num=10, train_loss_step=0.440]Epoch 0:  81%|████████▏ | 78/96 [00:08<00:01,  9.68it/s, loss=0.404, v_num=10, train_loss_step=0.400]Epoch 0:  82%|████████▏ | 79/96 [00:08<00:01,  9.68it/s, loss=0.404, v_num=10, train_loss_step=0.400]Epoch 0:  82%|████████▏ | 79/96 [00:08<00:01,  9.68it/s, loss=0.402, v_num=10, train_loss_step=0.382]Epoch 0:  83%|████████▎ | 80/96 [00:08<00:01,  9.68it/s, loss=0.402, v_num=10, train_loss_step=0.382]Epoch 0:  83%|████████▎ | 80/96 [00:08<00:01,  9.68it/s, loss=0.401, v_num=10, train_loss_step=0.380]Epoch 0:  84%|████████▍ | 81/96 [00:08<00:01,  9.68it/s, loss=0.401, v_num=10, train_loss_step=0.380]Epoch 0:  84%|████████▍ | 81/96 [00:08<00:01,  9.68it/s, loss=0.403, v_num=10, train_loss_step=0.377]Epoch 0:  85%|████████▌ | 82/96 [00:08<00:01,  9.68it/s, loss=0.403, v_num=10, train_loss_step=0.377]Epoch 0:  85%|████████▌ | 82/96 [00:08<00:01,  9.68it/s, loss=0.4, v_num=10, train_loss_step=0.405]  Epoch 0:  86%|████████▋ | 83/96 [00:08<00:01,  9.68it/s, loss=0.398, v_num=10, train_loss_step=0.343]Epoch 0:  88%|████████▊ | 84/96 [00:08<00:01,  9.75it/s, loss=0.398, v_num=10, train_loss_step=0.343]Epoch 0:  88%|████████▊ | 84/96 [00:08<00:01,  9.75it/s, loss=0.399, v_num=10, train_loss_step=0.428]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/12 [00:00<?, ?it/s][A
Validating:   8%|▊         | 1/12 [00:00<00:03,  3.47it/s][AEpoch 0:  90%|████████▉ | 86/96 [00:09<00:01,  9.65it/s, loss=0.399, v_num=10, train_loss_step=0.428]
Validating:  17%|█▋        | 2/12 [00:00<00:02,  3.53it/s][A
Validating:  25%|██▌       | 3/12 [00:00<00:02,  3.52it/s][AEpoch 0:  92%|█████████▏| 88/96 [00:09<00:00,  9.29it/s, loss=0.399, v_num=10, train_loss_step=0.428]
Validating:  33%|███▎      | 4/12 [00:01<00:02,  3.55it/s][A
Validating:  42%|████▏     | 5/12 [00:01<00:01,  3.57it/s][AEpoch 0:  94%|█████████▍| 90/96 [00:10<00:00,  8.98it/s, loss=0.399, v_num=10, train_loss_step=0.428]
Validating:  50%|█████     | 6/12 [00:01<00:01,  3.57it/s][A
Validating:  58%|█████▊    | 7/12 [00:01<00:01,  3.58it/s][AEpoch 0:  96%|█████████▌| 92/96 [00:10<00:00,  8.70it/s, loss=0.399, v_num=10, train_loss_step=0.428]
Validating:  67%|██████▋   | 8/12 [00:02<00:01,  3.58it/s][A
Validating:  75%|███████▌  | 9/12 [00:02<00:00,  3.58it/s][AEpoch 0:  98%|█████████▊| 94/96 [00:11<00:00,  8.44it/s, loss=0.399, v_num=10, train_loss_step=0.428]
Validating:  83%|████████▎ | 10/12 [00:02<00:00,  3.57it/s][A
Validating:  92%|█████████▏| 11/12 [00:03<00:00,  3.57it/s][AEpoch 0: 100%|██████████| 96/96 [00:11<00:00,  8.21it/s, loss=0.399, v_num=10, train_loss_step=0.428]
Validating: 100%|██████████| 12/12 [00:03<00:00,  4.21it/s][AEpoch 0: 100%|██████████| 96/96 [00:11<00:00,  8.11it/s, loss=0.399, v_num=10, train_loss_step=0.428]
                                                           [AEpoch 0: 100%|██████████| 96/96 [00:11<00:00,  8.08it/s, loss=0.399, v_num=10, train_loss_step=0.428]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(

Testing: 0it [00:00, ?it/s]Testing:   2%|▏         | 3/169 [00:00<00:06, 26.30it/s]Testing:   4%|▎         | 6/169 [00:00<00:05, 28.03it/s]Testing:   5%|▌         | 9/169 [00:00<00:05, 28.58it/s]Testing:   7%|▋         | 12/169 [00:00<00:05, 28.80it/s]Testing:   9%|▉         | 15/169 [00:00<00:05, 29.10it/s]Testing:  11%|█         | 18/169 [00:00<00:05, 29.12it/s]Testing:  12%|█▏        | 21/169 [00:00<00:05, 29.23it/s]Testing:  14%|█▍        | 24/169 [00:00<00:04, 29.20it/s]Testing:  16%|█▌        | 27/169 [00:00<00:04, 29.26it/s]Testing:  18%|█▊        | 30/169 [00:01<00:04, 29.34it/s]Testing:  20%|█▉        | 33/169 [00:01<00:04, 29.28it/s]Testing:  21%|██▏       | 36/169 [00:01<00:04, 29.39it/s]Testing:  24%|██▎       | 40/169 [00:01<00:04, 29.55it/s]Testing:  25%|██▌       | 43/169 [00:01<00:04, 29.49it/s]Testing:  27%|██▋       | 46/169 [00:01<00:04, 29.35it/s]Testing:  29%|██▉       | 49/169 [00:01<00:04, 29.48it/s]Testing:  31%|███       | 52/169 [00:01<00:03, 29.46it/s]Testing:  33%|███▎      | 55/169 [00:01<00:03, 29.39it/s]Testing:  34%|███▍      | 58/169 [00:01<00:03, 29.38it/s]Testing:  36%|███▌      | 61/169 [00:02<00:03, 29.41it/s]Testing:  38%|███▊      | 64/169 [00:02<00:03, 29.35it/s]Testing:  40%|███▉      | 67/169 [00:02<00:03, 29.30it/s]Testing:  41%|████▏     | 70/169 [00:02<00:03, 29.34it/s]Testing:  43%|████▎     | 73/169 [00:02<00:03, 29.33it/s]Testing:  45%|████▍     | 76/169 [00:02<00:03, 29.43it/s]Testing:  47%|████▋     | 79/169 [00:02<00:03, 29.42it/s]Testing:  49%|████▊     | 82/169 [00:02<00:02, 29.46it/s]Testing:  50%|█████     | 85/169 [00:02<00:02, 29.33it/s]Testing:  52%|█████▏    | 88/169 [00:03<00:02, 29.31it/s]Testing:  54%|█████▍    | 91/169 [00:03<00:02, 29.34it/s]Testing:  56%|█████▌    | 94/169 [00:03<00:02, 29.39it/s]Testing:  57%|█████▋    | 97/169 [00:03<00:02, 29.34it/s]Testing:  59%|█████▉    | 100/169 [00:03<00:02, 29.43it/s]Testing:  61%|██████    | 103/169 [00:03<00:02, 29.34it/s]Testing:  63%|██████▎   | 106/169 [00:03<00:02, 29.42it/s]Testing:  64%|██████▍   | 109/169 [00:03<00:02, 29.41it/s]Testing:  66%|██████▋   | 112/169 [00:03<00:01, 29.49it/s]Testing:  68%|██████▊   | 115/169 [00:03<00:01, 29.42it/s]Testing:  70%|██████▉   | 118/169 [00:04<00:01, 29.46it/s]Testing:  72%|███████▏  | 121/169 [00:04<00:01, 29.28it/s]Testing:  73%|███████▎  | 124/169 [00:04<00:01, 29.25it/s]Testing:  75%|███████▌  | 127/169 [00:04<00:01, 29.38it/s]Testing:  77%|███████▋  | 130/169 [00:04<00:01, 29.14it/s]Testing:  79%|███████▊  | 133/169 [00:04<00:01, 29.20it/s]Testing:  80%|████████  | 136/169 [00:04<00:01, 29.24it/s]Testing:  82%|████████▏ | 139/169 [00:04<00:01, 29.34it/s]Testing:  84%|████████▍ | 142/169 [00:04<00:00, 29.28it/s]Testing:  86%|████████▌ | 145/169 [00:04<00:00, 29.26it/s]Testing:  88%|████████▊ | 148/169 [00:05<00:00, 29.33it/s]Testing:  89%|████████▉ | 151/169 [00:05<00:00, 29.34it/s]Testing:  91%|█████████ | 154/169 [00:05<00:00, 29.28it/s]Testing:  93%|█████████▎| 157/169 [00:05<00:00, 29.10it/s]Testing:  95%|█████████▍| 160/169 [00:05<00:00, 29.22it/s]Testing:  96%|█████████▋| 163/169 [00:05<00:00, 29.30it/s]Testing:  98%|█████████▊| 166/169 [00:05<00:00, 29.38it/s]Testing: 100%|██████████| 169/169 [00:05<00:00, 29.38it/s]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'_mean_accuracy': 0.9084919691085815,
 '_standard_dev_accuracy': 0.07684639096260071,
 '_variance_accuracy': 0.005905367434024811,
 'test_acc': 0.9084919691085815,
 'test_dice_c1': 0.14764437079429626,
 'test_f2_c1': 0.213848277926445,
 'test_loss': 0.384781152009964,
 'test_mean_c1': 0.45754504203796387,
 'test_prec_c1': 0.11010638624429703,
 'test_sens_c1': 0.47540372610092163,
 'test_spec_c1': 0.9075987935066223}
--------------------------------------------------------------------------------
Testing: 100%|██████████| 169/169 [00:05<00:00, 29.26it/s]
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

  | Name       | Type             | Params
------------------------------------------------
0 | encoder1   | EncoderBlock     | 37.6 K
1 | encoder2   | EncoderBlock     | 221 K 
2 | bottleneck | ConvolutionBlock | 885 K 
3 | dropout    | Dropout2d        | 0     
4 | decoder1   | DecoderBlock     | 573 K 
5 | decoder2   | DecoderBlock     | 143 K 
6 | conv       | Conv2d           | 130   
7 | softmax    | Softmax2d        | 0     
------------------------------------------------
1.9 M     Trainable params
0         Non-trainable params
1.9 M     Total params
7.447     Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  1.33it/s]Validation sanity check: 100%|██████████| 2/2 [00:01<00:00,  1.62it/s]                                                                      /home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Training: -1it [00:00, ?it/s]Training:   0%|          | 0/64 [00:00<00:00, 26886.56it/s]Epoch 0:   0%|          | 0/64 [00:00<00:00, 3927.25it/s]  Epoch 0:   2%|▏         | 1/64 [00:00<00:05, 10.55it/s]  Epoch 0:   2%|▏         | 1/64 [00:00<00:05, 10.53it/s, loss=0.679, v_num=11, train_loss_step=0.679]Epoch 0:   3%|▎         | 2/64 [00:00<00:07,  8.66it/s, loss=0.679, v_num=11, train_loss_step=0.679]Epoch 0:   3%|▎         | 2/64 [00:00<00:07,  8.65it/s, loss=0.68, v_num=11, train_loss_step=0.681] Epoch 0:   5%|▍         | 3/64 [00:00<00:07,  7.93it/s, loss=0.68, v_num=11, train_loss_step=0.681]Epoch 0:   5%|▍         | 3/64 [00:00<00:07,  7.92it/s, loss=0.678, v_num=11, train_loss_step=0.673]Epoch 0:   6%|▋         | 4/64 [00:00<00:07,  7.55it/s, loss=0.678, v_num=11, train_loss_step=0.673]Epoch 0:   6%|▋         | 4/64 [00:00<00:07,  7.55it/s, loss=0.675, v_num=11, train_loss_step=0.669]Epoch 0:   8%|▊         | 5/64 [00:00<00:08,  7.33it/s, loss=0.675, v_num=11, train_loss_step=0.669]Epoch 0:   8%|▊         | 5/64 [00:00<00:08,  7.32it/s, loss=0.674, v_num=11, train_loss_step=0.671]Epoch 0:   9%|▉         | 6/64 [00:00<00:08,  7.17it/s, loss=0.674, v_num=11, train_loss_step=0.671]Epoch 0:   9%|▉         | 6/64 [00:00<00:08,  7.17it/s, loss=0.674, v_num=11, train_loss_step=0.671]Epoch 0:  11%|█         | 7/64 [00:01<00:08,  7.07it/s, loss=0.674, v_num=11, train_loss_step=0.671]Epoch 0:  11%|█         | 7/64 [00:01<00:08,  7.06it/s, loss=0.673, v_num=11, train_loss_step=0.664]Epoch 0:  12%|█▎        | 8/64 [00:01<00:08,  6.97it/s, loss=0.673, v_num=11, train_loss_step=0.664]Epoch 0:  12%|█▎        | 8/64 [00:01<00:08,  6.97it/s, loss=0.674, v_num=11, train_loss_step=0.681]Epoch 0:  14%|█▍        | 9/64 [00:01<00:07,  6.90it/s, loss=0.674, v_num=11, train_loss_step=0.681]Epoch 0:  14%|█▍        | 9/64 [00:01<00:07,  6.90it/s, loss=0.674, v_num=11, train_loss_step=0.681]Epoch 0:  16%|█▌        | 10/64 [00:01<00:07,  6.85it/s, loss=0.674, v_num=11, train_loss_step=0.681]Epoch 0:  16%|█▌        | 10/64 [00:01<00:07,  6.85it/s, loss=0.674, v_num=11, train_loss_step=0.672]Epoch 0:  17%|█▋        | 11/64 [00:01<00:07,  6.80it/s, loss=0.674, v_num=11, train_loss_step=0.672]Epoch 0:  17%|█▋        | 11/64 [00:01<00:07,  6.80it/s, loss=0.673, v_num=11, train_loss_step=0.664]Epoch 0:  19%|█▉        | 12/64 [00:01<00:07,  6.76it/s, loss=0.673, v_num=11, train_loss_step=0.664]Epoch 0:  19%|█▉        | 12/64 [00:01<00:07,  6.76it/s, loss=0.672, v_num=11, train_loss_step=0.656]Epoch 0:  20%|██        | 13/64 [00:02<00:07,  6.74it/s, loss=0.672, v_num=11, train_loss_step=0.656]Epoch 0:  20%|██        | 13/64 [00:02<00:07,  6.74it/s, loss=0.671, v_num=11, train_loss_step=0.662]Epoch 0:  22%|██▏       | 14/64 [00:02<00:07,  6.71it/s, loss=0.671, v_num=11, train_loss_step=0.662]Epoch 0:  22%|██▏       | 14/64 [00:02<00:07,  6.71it/s, loss=0.669, v_num=11, train_loss_step=0.650]Epoch 0:  23%|██▎       | 15/64 [00:02<00:07,  6.69it/s, loss=0.669, v_num=11, train_loss_step=0.650]Epoch 0:  23%|██▎       | 15/64 [00:02<00:07,  6.69it/s, loss=0.668, v_num=11, train_loss_step=0.654]Epoch 0:  25%|██▌       | 16/64 [00:02<00:07,  6.67it/s, loss=0.668, v_num=11, train_loss_step=0.654]Epoch 0:  25%|██▌       | 16/64 [00:02<00:07,  6.66it/s, loss=0.668, v_num=11, train_loss_step=0.659]Epoch 0:  27%|██▋       | 17/64 [00:02<00:07,  6.65it/s, loss=0.668, v_num=11, train_loss_step=0.659]Epoch 0:  27%|██▋       | 17/64 [00:02<00:07,  6.65it/s, loss=0.667, v_num=11, train_loss_step=0.658]Epoch 0:  28%|██▊       | 18/64 [00:02<00:06,  6.63it/s, loss=0.667, v_num=11, train_loss_step=0.658]Epoch 0:  28%|██▊       | 18/64 [00:02<00:06,  6.63it/s, loss=0.667, v_num=11, train_loss_step=0.657]Epoch 0:  30%|██▉       | 19/64 [00:03<00:06,  6.62it/s, loss=0.667, v_num=11, train_loss_step=0.657]Epoch 0:  30%|██▉       | 19/64 [00:03<00:06,  6.62it/s, loss=0.666, v_num=11, train_loss_step=0.648]Epoch 0:  31%|███▏      | 20/64 [00:03<00:06,  6.61it/s, loss=0.666, v_num=11, train_loss_step=0.648]Epoch 0:  31%|███▏      | 20/64 [00:03<00:06,  6.61it/s, loss=0.664, v_num=11, train_loss_step=0.631]Epoch 0:  33%|███▎      | 21/64 [00:03<00:06,  6.60it/s, loss=0.664, v_num=11, train_loss_step=0.631]Epoch 0:  33%|███▎      | 21/64 [00:03<00:06,  6.60it/s, loss=0.662, v_num=11, train_loss_step=0.632]Epoch 0:  34%|███▍      | 22/64 [00:03<00:06,  6.58it/s, loss=0.662, v_num=11, train_loss_step=0.632]Epoch 0:  34%|███▍      | 22/64 [00:03<00:06,  6.58it/s, loss=0.66, v_num=11, train_loss_step=0.652] Epoch 0:  36%|███▌      | 23/64 [00:03<00:06,  6.57it/s, loss=0.66, v_num=11, train_loss_step=0.652]Epoch 0:  36%|███▌      | 23/64 [00:03<00:06,  6.57it/s, loss=0.659, v_num=11, train_loss_step=0.652]Epoch 0:  38%|███▊      | 24/64 [00:03<00:06,  6.57it/s, loss=0.659, v_num=11, train_loss_step=0.652]Epoch 0:  38%|███▊      | 24/64 [00:03<00:06,  6.57it/s, loss=0.657, v_num=11, train_loss_step=0.618]Epoch 0:  39%|███▉      | 25/64 [00:03<00:05,  6.56it/s, loss=0.657, v_num=11, train_loss_step=0.618]Epoch 0:  39%|███▉      | 25/64 [00:03<00:05,  6.56it/s, loss=0.654, v_num=11, train_loss_step=0.624]Epoch 0:  41%|████      | 26/64 [00:04<00:05,  6.55it/s, loss=0.654, v_num=11, train_loss_step=0.624]Epoch 0:  41%|████      | 26/64 [00:04<00:05,  6.55it/s, loss=0.65, v_num=11, train_loss_step=0.583] Epoch 0:  42%|████▏     | 27/64 [00:04<00:05,  6.54it/s, loss=0.65, v_num=11, train_loss_step=0.583]Epoch 0:  42%|████▏     | 27/64 [00:04<00:05,  6.54it/s, loss=0.646, v_num=11, train_loss_step=0.595]Epoch 0:  44%|████▍     | 28/64 [00:04<00:05,  6.53it/s, loss=0.646, v_num=11, train_loss_step=0.595]Epoch 0:  44%|████▍     | 28/64 [00:04<00:05,  6.53it/s, loss=0.641, v_num=11, train_loss_step=0.577]Epoch 0:  45%|████▌     | 29/64 [00:04<00:05,  6.52it/s, loss=0.641, v_num=11, train_loss_step=0.577]Epoch 0:  45%|████▌     | 29/64 [00:04<00:05,  6.52it/s, loss=0.634, v_num=11, train_loss_step=0.534]Epoch 0:  47%|████▋     | 30/64 [00:04<00:05,  6.52it/s, loss=0.634, v_num=11, train_loss_step=0.534]Epoch 0:  47%|████▋     | 30/64 [00:04<00:05,  6.52it/s, loss=0.626, v_num=11, train_loss_step=0.519]Epoch 0:  48%|████▊     | 31/64 [00:04<00:05,  6.51it/s, loss=0.626, v_num=11, train_loss_step=0.519]Epoch 0:  48%|████▊     | 31/64 [00:04<00:05,  6.51it/s, loss=0.617, v_num=11, train_loss_step=0.483]Epoch 0:  50%|█████     | 32/64 [00:05<00:04,  6.51it/s, loss=0.617, v_num=11, train_loss_step=0.483]Epoch 0:  50%|█████     | 32/64 [00:05<00:04,  6.51it/s, loss=0.607, v_num=11, train_loss_step=0.458]Epoch 0:  52%|█████▏    | 33/64 [00:05<00:04,  6.50it/s, loss=0.607, v_num=11, train_loss_step=0.458]Epoch 0:  52%|█████▏    | 33/64 [00:05<00:04,  6.50it/s, loss=0.598, v_num=11, train_loss_step=0.480]Epoch 0:  53%|█████▎    | 34/64 [00:05<00:04,  6.49it/s, loss=0.598, v_num=11, train_loss_step=0.480]Epoch 0:  53%|█████▎    | 34/64 [00:05<00:04,  6.49it/s, loss=0.585, v_num=11, train_loss_step=0.382]Epoch 0:  55%|█████▍    | 35/64 [00:05<00:04,  6.49it/s, loss=0.585, v_num=11, train_loss_step=0.382]Epoch 0:  55%|█████▍    | 35/64 [00:05<00:04,  6.49it/s, loss=0.575, v_num=11, train_loss_step=0.465]Epoch 0:  56%|█████▋    | 36/64 [00:05<00:04,  6.48it/s, loss=0.575, v_num=11, train_loss_step=0.465]Epoch 0:  56%|█████▋    | 36/64 [00:05<00:04,  6.48it/s, loss=0.564, v_num=11, train_loss_step=0.441]Epoch 0:  58%|█████▊    | 37/64 [00:05<00:04,  6.47it/s, loss=0.564, v_num=11, train_loss_step=0.441]Epoch 0:  58%|█████▊    | 37/64 [00:05<00:04,  6.47it/s, loss=0.549, v_num=11, train_loss_step=0.347]Epoch 0:  59%|█████▉    | 38/64 [00:06<00:04,  6.47it/s, loss=0.549, v_num=11, train_loss_step=0.347]Epoch 0:  59%|█████▉    | 38/64 [00:06<00:04,  6.47it/s, loss=0.537, v_num=11, train_loss_step=0.421]Epoch 0:  61%|██████    | 39/64 [00:06<00:03,  6.46it/s, loss=0.537, v_num=11, train_loss_step=0.421]Epoch 0:  61%|██████    | 39/64 [00:06<00:03,  6.46it/s, loss=0.529, v_num=11, train_loss_step=0.480]Epoch 0:  62%|██████▎   | 40/64 [00:06<00:03,  6.46it/s, loss=0.529, v_num=11, train_loss_step=0.480]Epoch 0:  62%|██████▎   | 40/64 [00:06<00:03,  6.46it/s, loss=0.516, v_num=11, train_loss_step=0.384]Epoch 0:  64%|██████▍   | 41/64 [00:06<00:03,  6.45it/s, loss=0.516, v_num=11, train_loss_step=0.384]Epoch 0:  64%|██████▍   | 41/64 [00:06<00:03,  6.45it/s, loss=0.509, v_num=11, train_loss_step=0.477]Epoch 0:  66%|██████▌   | 42/64 [00:06<00:03,  6.45it/s, loss=0.509, v_num=11, train_loss_step=0.477]Epoch 0:  66%|██████▌   | 42/64 [00:06<00:03,  6.45it/s, loss=0.499, v_num=11, train_loss_step=0.458]Epoch 0:  67%|██████▋   | 43/64 [00:06<00:03,  6.45it/s, loss=0.499, v_num=11, train_loss_step=0.458]Epoch 0:  67%|██████▋   | 43/64 [00:06<00:03,  6.45it/s, loss=0.487, v_num=11, train_loss_step=0.417]Epoch 0:  69%|██████▉   | 44/64 [00:06<00:03,  6.44it/s, loss=0.487, v_num=11, train_loss_step=0.417]Epoch 0:  69%|██████▉   | 44/64 [00:06<00:03,  6.44it/s, loss=0.478, v_num=11, train_loss_step=0.445]Epoch 0:  70%|███████   | 45/64 [00:07<00:02,  6.44it/s, loss=0.478, v_num=11, train_loss_step=0.445]Epoch 0:  70%|███████   | 45/64 [00:07<00:02,  6.44it/s, loss=0.467, v_num=11, train_loss_step=0.398]Epoch 0:  72%|███████▏  | 46/64 [00:07<00:02,  6.43it/s, loss=0.467, v_num=11, train_loss_step=0.398]Epoch 0:  72%|███████▏  | 46/64 [00:07<00:02,  6.43it/s, loss=0.459, v_num=11, train_loss_step=0.413]Epoch 0:  73%|███████▎  | 47/64 [00:07<00:02,  6.43it/s, loss=0.459, v_num=11, train_loss_step=0.413]Epoch 0:  73%|███████▎  | 47/64 [00:07<00:02,  6.43it/s, loss=0.45, v_num=11, train_loss_step=0.418] Epoch 0:  75%|███████▌  | 48/64 [00:07<00:02,  6.43it/s, loss=0.45, v_num=11, train_loss_step=0.418]Epoch 0:  75%|███████▌  | 48/64 [00:07<00:02,  6.43it/s, loss=0.443, v_num=11, train_loss_step=0.446]Epoch 0:  77%|███████▋  | 49/64 [00:07<00:02,  6.43it/s, loss=0.443, v_num=11, train_loss_step=0.446]Epoch 0:  77%|███████▋  | 49/64 [00:07<00:02,  6.43it/s, loss=0.438, v_num=11, train_loss_step=0.439]Epoch 0:  78%|███████▊  | 50/64 [00:07<00:02,  6.43it/s, loss=0.438, v_num=11, train_loss_step=0.439]Epoch 0:  78%|███████▊  | 50/64 [00:07<00:02,  6.43it/s, loss=0.431, v_num=11, train_loss_step=0.371]Epoch 0:  80%|███████▉  | 51/64 [00:08<00:02,  6.42it/s, loss=0.431, v_num=11, train_loss_step=0.371]Epoch 0:  80%|███████▉  | 51/64 [00:08<00:02,  6.42it/s, loss=0.429, v_num=11, train_loss_step=0.431]Epoch 0:  81%|████████▏ | 52/64 [00:08<00:01,  6.42it/s, loss=0.429, v_num=11, train_loss_step=0.431]Epoch 0:  81%|████████▏ | 52/64 [00:08<00:01,  6.42it/s, loss=0.425, v_num=11, train_loss_step=0.395]Epoch 0:  83%|████████▎ | 53/64 [00:08<00:01,  6.42it/s, loss=0.425, v_num=11, train_loss_step=0.395]Epoch 0:  83%|████████▎ | 53/64 [00:08<00:01,  6.42it/s, loss=0.42, v_num=11, train_loss_step=0.370] Epoch 0:  84%|████████▍ | 54/64 [00:08<00:01,  6.42it/s, loss=0.42, v_num=11, train_loss_step=0.370]Epoch 0:  84%|████████▍ | 54/64 [00:08<00:01,  6.42it/s, loss=0.421, v_num=11, train_loss_step=0.398]Epoch 0:  86%|████████▌ | 55/64 [00:08<00:01,  6.42it/s, loss=0.421, v_num=11, train_loss_step=0.398]Epoch 0:  86%|████████▌ | 55/64 [00:08<00:01,  6.42it/s, loss=0.417, v_num=11, train_loss_step=0.385]Epoch 0:  88%|████████▊ | 56/64 [00:08<00:01,  6.47it/s, loss=0.413, v_num=11, train_loss_step=0.373]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/8 [00:00<?, ?it/s][A
Validating:  12%|█▎        | 1/8 [00:00<00:03,  1.90it/s][AEpoch 0:  91%|█████████ | 58/64 [00:09<00:00,  6.32it/s, loss=0.413, v_num=11, train_loss_step=0.373]
Validating:  25%|██▌       | 2/8 [00:01<00:03,  1.91it/s][A
Validating:  38%|███▊      | 3/8 [00:01<00:02,  1.92it/s][A
Validating:  50%|█████     | 4/8 [00:02<00:02,  1.92it/s][AEpoch 0:  95%|█████████▌| 61/64 [00:10<00:00,  5.69it/s, loss=0.413, v_num=11, train_loss_step=0.373]
Validating:  62%|██████▎   | 5/8 [00:02<00:01,  1.92it/s][A
Validating:  75%|███████▌  | 6/8 [00:03<00:01,  1.92it/s][A
Validating:  88%|████████▊ | 7/8 [00:03<00:00,  1.92it/s][AEpoch 0: 100%|██████████| 64/64 [00:12<00:00,  5.22it/s, loss=0.413, v_num=11, train_loss_step=0.373]
Validating: 100%|██████████| 8/8 [00:03<00:00,  2.15it/s][AEpoch 0: 100%|██████████| 64/64 [00:12<00:00,  5.08it/s, loss=0.413, v_num=11, train_loss_step=0.373]
                                                         [AEpoch 0: 100%|██████████| 64/64 [00:12<00:00,  5.06it/s, loss=0.413, v_num=11, train_loss_step=0.373]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(

Testing: 0it [00:00, ?it/s]Testing:   2%|▏         | 3/169 [00:00<00:07, 22.12it/s]Testing:   4%|▎         | 6/169 [00:00<00:07, 23.03it/s]Testing:   5%|▌         | 9/169 [00:00<00:06, 23.49it/s]Testing:   7%|▋         | 12/169 [00:00<00:06, 23.70it/s]Testing:   9%|▉         | 15/169 [00:00<00:06, 23.81it/s]Testing:  11%|█         | 18/169 [00:00<00:06, 23.83it/s]Testing:  12%|█▏        | 21/169 [00:00<00:06, 24.03it/s]Testing:  14%|█▍        | 24/169 [00:01<00:06, 23.95it/s]Testing:  16%|█▌        | 27/169 [00:01<00:05, 23.92it/s]Testing:  18%|█▊        | 30/169 [00:01<00:05, 23.90it/s]Testing:  20%|█▉        | 33/169 [00:01<00:05, 23.86it/s]Testing:  21%|██▏       | 36/169 [00:01<00:05, 23.77it/s]Testing:  23%|██▎       | 39/169 [00:01<00:05, 23.80it/s]Testing:  25%|██▍       | 42/169 [00:01<00:05, 23.89it/s]Testing:  27%|██▋       | 45/169 [00:01<00:05, 23.98it/s]Testing:  28%|██▊       | 48/169 [00:02<00:05, 23.98it/s]Testing:  30%|███       | 51/169 [00:02<00:04, 23.97it/s]Testing:  32%|███▏      | 54/169 [00:02<00:04, 23.96it/s]Testing:  34%|███▎      | 57/169 [00:02<00:04, 23.96it/s]Testing:  36%|███▌      | 60/169 [00:02<00:04, 23.96it/s]Testing:  37%|███▋      | 63/169 [00:02<00:04, 23.95it/s]Testing:  39%|███▉      | 66/169 [00:02<00:04, 23.78it/s]Testing:  41%|████      | 69/169 [00:02<00:04, 23.83it/s]Testing:  43%|████▎     | 72/169 [00:03<00:04, 23.74it/s]Testing:  44%|████▍     | 75/169 [00:03<00:03, 23.62it/s]Testing:  46%|████▌     | 78/169 [00:03<00:03, 23.58it/s]Testing:  48%|████▊     | 81/169 [00:03<00:03, 23.67it/s]Testing:  50%|████▉     | 84/169 [00:03<00:03, 23.60it/s]Testing:  51%|█████▏    | 87/169 [00:03<00:03, 23.69it/s]Testing:  53%|█████▎    | 90/169 [00:03<00:03, 23.71it/s]Testing:  55%|█████▌    | 93/169 [00:03<00:03, 23.61it/s]Testing:  57%|█████▋    | 96/169 [00:04<00:03, 23.49it/s]Testing:  59%|█████▊    | 99/169 [00:04<00:02, 23.54it/s]Testing:  60%|██████    | 102/169 [00:04<00:02, 23.57it/s]Testing:  62%|██████▏   | 105/169 [00:04<00:02, 23.67it/s]Testing:  64%|██████▍   | 108/169 [00:04<00:02, 23.70it/s]Testing:  66%|██████▌   | 111/169 [00:04<00:02, 23.65it/s]Testing:  67%|██████▋   | 114/169 [00:04<00:02, 23.70it/s]Testing:  69%|██████▉   | 117/169 [00:04<00:02, 23.82it/s]Testing:  71%|███████   | 120/169 [00:05<00:02, 23.77it/s]Testing:  73%|███████▎  | 123/169 [00:05<00:01, 23.74it/s]Testing:  75%|███████▍  | 126/169 [00:05<00:01, 23.70it/s]Testing:  76%|███████▋  | 129/169 [00:05<00:01, 23.35it/s]Testing:  78%|███████▊  | 132/169 [00:05<00:01, 23.32it/s]Testing:  80%|███████▉  | 135/169 [00:05<00:01, 23.44it/s]Testing:  82%|████████▏ | 138/169 [00:05<00:01, 23.54it/s]Testing:  83%|████████▎ | 141/169 [00:05<00:01, 23.61it/s]Testing:  85%|████████▌ | 144/169 [00:06<00:01, 23.70it/s]Testing:  87%|████████▋ | 147/169 [00:06<00:00, 23.68it/s]Testing:  89%|████████▉ | 150/169 [00:06<00:00, 23.64it/s]Testing:  91%|█████████ | 153/169 [00:06<00:00, 23.69it/s]Testing:  92%|█████████▏| 156/169 [00:06<00:00, 23.71it/s]Testing:  94%|█████████▍| 159/169 [00:06<00:00, 23.68it/s]Testing:  96%|█████████▌| 162/169 [00:06<00:00, 23.71it/s]Testing:  98%|█████████▊| 165/169 [00:06<00:00, 23.65it/s]Testing:  99%|█████████▉| 168/169 [00:07<00:00, 23.58it/s]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'_mean_accuracy': 0.9269372224807739,
 '_standard_dev_accuracy': 0.06453360617160797,
 '_variance_accuracy': 0.004164586309343576,
 'test_acc': 0.9269372224807739,
 'test_dice_c1': 0.14108243584632874,
 'test_f2_c1': 0.19437968730926514,
 'test_loss': 0.37781864404678345,
 'test_mean_c1': 0.40861958265304565,
 'test_prec_c1': 0.10868360102176666,
 'test_sens_c1': 0.4006851613521576,
 'test_spec_c1': 0.9271843433380127}
--------------------------------------------------------------------------------
Testing: 100%|██████████| 169/169 [00:07<00:00, 23.68it/s]
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

  | Name       | Type             | Params
------------------------------------------------
0 | encoder1   | EncoderBlock     | 37.6 K
1 | encoder2   | EncoderBlock     | 221 K 
2 | bottleneck | ConvolutionBlock | 885 K 
3 | dropout    | Dropout2d        | 0     
4 | decoder1   | DecoderBlock     | 573 K 
5 | decoder2   | DecoderBlock     | 143 K 
6 | conv       | Conv2d           | 130   
7 | softmax    | Softmax2d        | 0     
------------------------------------------------
1.9 M     Trainable params
0         Non-trainable params
1.9 M     Total params
7.447     Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  3.70it/s]                                                                      /home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Training: -1it [00:00, ?it/s]Training:   0%|          | 0/380 [00:00<00:00, 27594.11it/s]Epoch 0:   0%|          | 0/380 [00:00<00:00, 3795.75it/s]  Epoch 0:   0%|          | 1/380 [00:00<00:08, 46.82it/s, loss=0.652, v_num=12, train_loss_step=0.652]Epoch 0:   1%|          | 2/380 [00:00<00:09, 38.77it/s, loss=0.663, v_num=12, train_loss_step=0.674]Epoch 0:   1%|          | 3/380 [00:00<00:10, 35.76it/s, loss=0.663, v_num=12, train_loss_step=0.674]Epoch 0:   1%|          | 3/380 [00:00<00:10, 35.68it/s, loss=0.664, v_num=12, train_loss_step=0.666]Epoch 0:   1%|          | 4/380 [00:00<00:11, 34.14it/s, loss=0.666, v_num=12, train_loss_step=0.671]Epoch 0:   1%|▏         | 5/380 [00:00<00:11, 33.25it/s, loss=0.661, v_num=12, train_loss_step=0.642]Epoch 0:   2%|▏         | 6/380 [00:00<00:11, 32.79it/s, loss=0.661, v_num=12, train_loss_step=0.642]Epoch 0:   2%|▏         | 6/380 [00:00<00:11, 32.74it/s, loss=0.655, v_num=12, train_loss_step=0.622]Epoch 0:   2%|▏         | 7/380 [00:00<00:11, 32.60it/s, loss=0.648, v_num=12, train_loss_step=0.608]Epoch 0:   2%|▏         | 8/380 [00:00<00:11, 32.45it/s, loss=0.641, v_num=12, train_loss_step=0.595]Epoch 0:   2%|▏         | 9/380 [00:00<00:11, 32.36it/s, loss=0.64, v_num=12, train_loss_step=0.632] Epoch 0:   3%|▎         | 10/380 [00:00<00:11, 32.25it/s, loss=0.64, v_num=12, train_loss_step=0.632]Epoch 0:   3%|▎         | 10/380 [00:00<00:11, 32.22it/s, loss=0.624, v_num=12, train_loss_step=0.472]Epoch 0:   3%|▎         | 11/380 [00:00<00:11, 32.15it/s, loss=0.61, v_num=12, train_loss_step=0.473] Epoch 0:   3%|▎         | 12/380 [00:00<00:11, 32.14it/s, loss=0.586, v_num=12, train_loss_step=0.320]Epoch 0:   3%|▎         | 13/380 [00:00<00:11, 32.18it/s, loss=0.579, v_num=12, train_loss_step=0.505]Epoch 0:   4%|▎         | 14/380 [00:00<00:11, 32.20it/s, loss=0.579, v_num=12, train_loss_step=0.505]Epoch 0:   4%|▎         | 14/380 [00:00<00:11, 32.19it/s, loss=0.561, v_num=12, train_loss_step=0.324]Epoch 0:   4%|▍         | 15/380 [00:00<00:11, 32.21it/s, loss=0.547, v_num=12, train_loss_step=0.346]Epoch 0:   4%|▍         | 16/380 [00:00<00:11, 32.22it/s, loss=0.54, v_num=12, train_loss_step=0.440] Epoch 0:   4%|▍         | 17/380 [00:00<00:11, 32.25it/s, loss=0.527, v_num=12, train_loss_step=0.313]Epoch 0:   5%|▍         | 18/380 [00:00<00:11, 32.28it/s, loss=0.527, v_num=12, train_loss_step=0.313]Epoch 0:   5%|▍         | 18/380 [00:00<00:11, 32.26it/s, loss=0.526, v_num=12, train_loss_step=0.514]Epoch 0:   5%|▌         | 19/380 [00:00<00:11, 32.28it/s, loss=0.515, v_num=12, train_loss_step=0.313]Epoch 0:   5%|▌         | 20/380 [00:00<00:11, 32.28it/s, loss=0.508, v_num=12, train_loss_step=0.368]Epoch 0:   6%|▌         | 21/380 [00:00<00:11, 32.29it/s, loss=0.493, v_num=12, train_loss_step=0.359]Epoch 0:   6%|▌         | 22/380 [00:00<00:11, 32.32it/s, loss=0.493, v_num=12, train_loss_step=0.359]Epoch 0:   6%|▌         | 22/380 [00:00<00:11, 32.30it/s, loss=0.49, v_num=12, train_loss_step=0.610] Epoch 0:   6%|▌         | 23/380 [00:00<00:11, 32.33it/s, loss=0.491, v_num=12, train_loss_step=0.695]Epoch 0:   6%|▋         | 24/380 [00:00<00:11, 32.34it/s, loss=0.473, v_num=12, train_loss_step=0.313]Epoch 0:   7%|▋         | 25/380 [00:00<00:10, 32.31it/s, loss=0.457, v_num=12, train_loss_step=0.313]Epoch 0:   7%|▋         | 26/380 [00:00<00:10, 32.30it/s, loss=0.457, v_num=12, train_loss_step=0.313]Epoch 0:   7%|▋         | 26/380 [00:00<00:10, 32.29it/s, loss=0.454, v_num=12, train_loss_step=0.558]Epoch 0:   7%|▋         | 27/380 [00:00<00:10, 32.30it/s, loss=0.469, v_num=12, train_loss_step=0.913]Epoch 0:   7%|▋         | 28/380 [00:00<00:10, 32.30it/s, loss=0.457, v_num=12, train_loss_step=0.367]Epoch 0:   8%|▊         | 29/380 [00:00<00:10, 32.31it/s, loss=0.475, v_num=12, train_loss_step=0.981]Epoch 0:   8%|▊         | 30/380 [00:00<00:10, 32.30it/s, loss=0.475, v_num=12, train_loss_step=0.981]Epoch 0:   8%|▊         | 30/380 [00:00<00:10, 32.29it/s, loss=0.471, v_num=12, train_loss_step=0.389]Epoch 0:   8%|▊         | 31/380 [00:00<00:10, 32.31it/s, loss=0.465, v_num=12, train_loss_step=0.351]Epoch 0:   8%|▊         | 32/380 [00:01<00:10, 32.31it/s, loss=0.467, v_num=12, train_loss_step=0.369]Epoch 0:   9%|▊         | 33/380 [00:01<00:10, 32.31it/s, loss=0.465, v_num=12, train_loss_step=0.457]Epoch 0:   9%|▉         | 34/380 [00:01<00:10, 32.34it/s, loss=0.465, v_num=12, train_loss_step=0.457]Epoch 0:   9%|▉         | 34/380 [00:01<00:10, 32.33it/s, loss=0.464, v_num=12, train_loss_step=0.315]Epoch 0:   9%|▉         | 35/380 [00:01<00:10, 32.29it/s, loss=0.467, v_num=12, train_loss_step=0.403]Epoch 0:   9%|▉         | 36/380 [00:01<00:10, 32.29it/s, loss=0.464, v_num=12, train_loss_step=0.380]Epoch 0:  10%|▉         | 37/380 [00:01<00:10, 32.29it/s, loss=0.465, v_num=12, train_loss_step=0.323]Epoch 0:  10%|█         | 38/380 [00:01<00:10, 32.31it/s, loss=0.465, v_num=12, train_loss_step=0.323]Epoch 0:  10%|█         | 38/380 [00:01<00:10, 32.30it/s, loss=0.484, v_num=12, train_loss_step=0.895]Epoch 0:  10%|█         | 39/380 [00:01<00:10, 32.29it/s, loss=0.484, v_num=12, train_loss_step=0.313]Epoch 0:  11%|█         | 40/380 [00:01<00:10, 32.30it/s, loss=0.481, v_num=12, train_loss_step=0.313]Epoch 0:  11%|█         | 41/380 [00:01<00:10, 32.30it/s, loss=0.479, v_num=12, train_loss_step=0.315]Epoch 0:  11%|█         | 42/380 [00:01<00:10, 32.32it/s, loss=0.479, v_num=12, train_loss_step=0.315]Epoch 0:  11%|█         | 42/380 [00:01<00:10, 32.31it/s, loss=0.477, v_num=12, train_loss_step=0.584]Epoch 0:  11%|█▏        | 43/380 [00:01<00:10, 32.31it/s, loss=0.458, v_num=12, train_loss_step=0.313]Epoch 0:  12%|█▏        | 44/380 [00:01<00:10, 32.32it/s, loss=0.465, v_num=12, train_loss_step=0.440]Epoch 0:  12%|█▏        | 45/380 [00:01<00:10, 32.31it/s, loss=0.465, v_num=12, train_loss_step=0.313]Epoch 0:  12%|█▏        | 46/380 [00:01<00:10, 32.32it/s, loss=0.465, v_num=12, train_loss_step=0.313]Epoch 0:  12%|█▏        | 46/380 [00:01<00:10, 32.31it/s, loss=0.46, v_num=12, train_loss_step=0.457] Epoch 0:  12%|█▏        | 47/380 [00:01<00:10, 32.33it/s, loss=0.436, v_num=12, train_loss_step=0.440]Epoch 0:  13%|█▎        | 48/380 [00:01<00:10, 32.33it/s, loss=0.443, v_num=12, train_loss_step=0.513]Epoch 0:  13%|█▎        | 49/380 [00:01<00:10, 32.35it/s, loss=0.41, v_num=12, train_loss_step=0.313] Epoch 0:  13%|█▎        | 50/380 [00:01<00:10, 32.36it/s, loss=0.41, v_num=12, train_loss_step=0.313]Epoch 0:  13%|█▎        | 50/380 [00:01<00:10, 32.35it/s, loss=0.409, v_num=12, train_loss_step=0.372]Epoch 0:  13%|█▎        | 51/380 [00:01<00:10, 32.35it/s, loss=0.409, v_num=12, train_loss_step=0.343]Epoch 0:  14%|█▎        | 52/380 [00:01<00:10, 32.36it/s, loss=0.432, v_num=12, train_loss_step=0.833]Epoch 0:  14%|█▍        | 53/380 [00:01<00:10, 32.36it/s, loss=0.426, v_num=12, train_loss_step=0.332]Epoch 0:  14%|█▍        | 54/380 [00:01<00:10, 32.37it/s, loss=0.426, v_num=12, train_loss_step=0.332]Epoch 0:  14%|█▍        | 54/380 [00:01<00:10, 32.36it/s, loss=0.426, v_num=12, train_loss_step=0.313]Epoch 0:  14%|█▍        | 55/380 [00:01<00:10, 32.36it/s, loss=0.432, v_num=12, train_loss_step=0.534]Epoch 0:  15%|█▍        | 56/380 [00:01<00:10, 32.37it/s, loss=0.433, v_num=12, train_loss_step=0.390]Epoch 0:  15%|█▌        | 57/380 [00:01<00:09, 32.37it/s, loss=0.437, v_num=12, train_loss_step=0.418]Epoch 0:  15%|█▌        | 58/380 [00:01<00:09, 32.38it/s, loss=0.437, v_num=12, train_loss_step=0.418]Epoch 0:  15%|█▌        | 58/380 [00:01<00:09, 32.37it/s, loss=0.415, v_num=12, train_loss_step=0.445]Epoch 0:  16%|█▌        | 59/380 [00:01<00:09, 32.38it/s, loss=0.418, v_num=12, train_loss_step=0.367]Epoch 0:  16%|█▌        | 60/380 [00:01<00:09, 32.38it/s, loss=0.446, v_num=12, train_loss_step=0.887]Epoch 0:  16%|█▌        | 61/380 [00:01<00:09, 32.39it/s, loss=0.449, v_num=12, train_loss_step=0.370]Epoch 0:  16%|█▋        | 62/380 [00:01<00:09, 32.39it/s, loss=0.449, v_num=12, train_loss_step=0.370]Epoch 0:  16%|█▋        | 62/380 [00:01<00:09, 32.39it/s, loss=0.436, v_num=12, train_loss_step=0.313]Epoch 0:  17%|█▋        | 63/380 [00:01<00:09, 32.40it/s, loss=0.437, v_num=12, train_loss_step=0.353]Epoch 0:  17%|█▋        | 64/380 [00:02<00:09, 32.39it/s, loss=0.432, v_num=12, train_loss_step=0.323]Epoch 0:  17%|█▋        | 65/380 [00:02<00:09, 32.40it/s, loss=0.448, v_num=12, train_loss_step=0.643]Epoch 0:  17%|█▋        | 66/380 [00:02<00:09, 32.41it/s, loss=0.448, v_num=12, train_loss_step=0.643]Epoch 0:  17%|█▋        | 66/380 [00:02<00:09, 32.40it/s, loss=0.447, v_num=12, train_loss_step=0.426]Epoch 0:  18%|█▊        | 67/380 [00:02<00:09, 32.41it/s, loss=0.453, v_num=12, train_loss_step=0.575]Epoch 0:  18%|█▊        | 68/380 [00:02<00:09, 32.41it/s, loss=0.443, v_num=12, train_loss_step=0.313]Epoch 0:  18%|█▊        | 69/380 [00:02<00:09, 32.41it/s, loss=0.45, v_num=12, train_loss_step=0.446] Epoch 0:  18%|█▊        | 70/380 [00:02<00:09, 32.41it/s, loss=0.45, v_num=12, train_loss_step=0.446]Epoch 0:  18%|█▊        | 70/380 [00:02<00:09, 32.41it/s, loss=0.45, v_num=12, train_loss_step=0.380]Epoch 0:  19%|█▊        | 71/380 [00:02<00:09, 32.41it/s, loss=0.464, v_num=12, train_loss_step=0.616]Epoch 0:  19%|█▉        | 72/380 [00:02<00:09, 32.39it/s, loss=0.441, v_num=12, train_loss_step=0.365]Epoch 0:  19%|█▉        | 73/380 [00:02<00:09, 32.39it/s, loss=0.44, v_num=12, train_loss_step=0.313] Epoch 0:  19%|█▉        | 74/380 [00:02<00:09, 32.39it/s, loss=0.44, v_num=12, train_loss_step=0.313]Epoch 0:  19%|█▉        | 74/380 [00:02<00:09, 32.39it/s, loss=0.458, v_num=12, train_loss_step=0.678]Epoch 0:  20%|█▉        | 75/380 [00:02<00:09, 32.39it/s, loss=0.465, v_num=12, train_loss_step=0.674]Epoch 0:  20%|██        | 76/380 [00:02<00:09, 32.40it/s, loss=0.461, v_num=12, train_loss_step=0.319]Epoch 0:  20%|██        | 77/380 [00:02<00:09, 32.40it/s, loss=0.459, v_num=12, train_loss_step=0.380]Epoch 0:  21%|██        | 78/380 [00:02<00:09, 32.41it/s, loss=0.459, v_num=12, train_loss_step=0.380]Epoch 0:  21%|██        | 78/380 [00:02<00:09, 32.40it/s, loss=0.458, v_num=12, train_loss_step=0.411]Epoch 0:  21%|██        | 79/380 [00:02<00:09, 32.40it/s, loss=0.455, v_num=12, train_loss_step=0.313]Epoch 0:  21%|██        | 80/380 [00:02<00:09, 32.41it/s, loss=0.445, v_num=12, train_loss_step=0.693]Epoch 0:  21%|██▏       | 81/380 [00:02<00:09, 32.42it/s, loss=0.442, v_num=12, train_loss_step=0.313]Epoch 0:  22%|██▏       | 82/380 [00:02<00:09, 32.42it/s, loss=0.442, v_num=12, train_loss_step=0.313]Epoch 0:  22%|██▏       | 82/380 [00:02<00:09, 32.42it/s, loss=0.442, v_num=12, train_loss_step=0.313]Epoch 0:  22%|██▏       | 83/380 [00:02<00:09, 32.43it/s, loss=0.44, v_num=12, train_loss_step=0.313] Epoch 0:  22%|██▏       | 84/380 [00:02<00:09, 32.42it/s, loss=0.442, v_num=12, train_loss_step=0.349]Epoch 0:  22%|██▏       | 85/380 [00:02<00:09, 32.42it/s, loss=0.427, v_num=12, train_loss_step=0.352]Epoch 0:  23%|██▎       | 86/380 [00:02<00:09, 32.43it/s, loss=0.427, v_num=12, train_loss_step=0.352]Epoch 0:  23%|██▎       | 86/380 [00:02<00:09, 32.43it/s, loss=0.429, v_num=12, train_loss_step=0.454]Epoch 0:  23%|██▎       | 87/380 [00:02<00:09, 32.43it/s, loss=0.418, v_num=12, train_loss_step=0.365]Epoch 0:  23%|██▎       | 88/380 [00:02<00:09, 32.43it/s, loss=0.42, v_num=12, train_loss_step=0.354] Epoch 0:  23%|██▎       | 89/380 [00:02<00:08, 32.43it/s, loss=0.415, v_num=12, train_loss_step=0.337]Epoch 0:  24%|██▎       | 90/380 [00:02<00:08, 32.44it/s, loss=0.415, v_num=12, train_loss_step=0.337]Epoch 0:  24%|██▎       | 90/380 [00:02<00:08, 32.43it/s, loss=0.411, v_num=12, train_loss_step=0.313]Epoch 0:  24%|██▍       | 91/380 [00:02<00:08, 32.43it/s, loss=0.4, v_num=12, train_loss_step=0.380]  Epoch 0:  24%|██▍       | 92/380 [00:02<00:08, 32.44it/s, loss=0.398, v_num=12, train_loss_step=0.334]Epoch 0:  24%|██▍       | 93/380 [00:02<00:08, 32.44it/s, loss=0.404, v_num=12, train_loss_step=0.427]Epoch 0:  25%|██▍       | 94/380 [00:02<00:08, 32.44it/s, loss=0.404, v_num=12, train_loss_step=0.427]Epoch 0:  25%|██▍       | 94/380 [00:02<00:08, 32.44it/s, loss=0.394, v_num=12, train_loss_step=0.473]Epoch 0:  25%|██▌       | 95/380 [00:02<00:08, 32.44it/s, loss=0.378, v_num=12, train_loss_step=0.358]Epoch 0:  25%|██▌       | 96/380 [00:02<00:08, 32.44it/s, loss=0.392, v_num=12, train_loss_step=0.600]Epoch 0:  26%|██▌       | 97/380 [00:03<00:08, 32.43it/s, loss=0.388, v_num=12, train_loss_step=0.313]Epoch 0:  26%|██▌       | 98/380 [00:03<00:08, 32.44it/s, loss=0.388, v_num=12, train_loss_step=0.313]Epoch 0:  26%|██▌       | 98/380 [00:03<00:08, 32.44it/s, loss=0.392, v_num=12, train_loss_step=0.480]Epoch 0:  26%|██▌       | 99/380 [00:03<00:08, 32.44it/s, loss=0.41, v_num=12, train_loss_step=0.670] Epoch 0:  26%|██▋       | 100/380 [00:03<00:08, 32.44it/s, loss=0.394, v_num=12, train_loss_step=0.377]Epoch 0:  27%|██▋       | 101/380 [00:03<00:08, 32.44it/s, loss=0.394, v_num=12, train_loss_step=0.313]Epoch 0:  27%|██▋       | 102/380 [00:03<00:08, 32.44it/s, loss=0.394, v_num=12, train_loss_step=0.313]Epoch 0:  27%|██▋       | 102/380 [00:03<00:08, 32.44it/s, loss=0.394, v_num=12, train_loss_step=0.324]Epoch 0:  27%|██▋       | 103/380 [00:03<00:08, 32.44it/s, loss=0.394, v_num=12, train_loss_step=0.313]Epoch 0:  27%|██▋       | 104/380 [00:03<00:08, 32.44it/s, loss=0.401, v_num=12, train_loss_step=0.479]Epoch 0:  28%|██▊       | 105/380 [00:03<00:08, 32.44it/s, loss=0.413, v_num=12, train_loss_step=0.588]Epoch 0:  28%|██▊       | 106/380 [00:03<00:08, 32.45it/s, loss=0.413, v_num=12, train_loss_step=0.588]Epoch 0:  28%|██▊       | 106/380 [00:03<00:08, 32.44it/s, loss=0.422, v_num=12, train_loss_step=0.647]Epoch 0:  28%|██▊       | 107/380 [00:03<00:08, 32.45it/s, loss=0.42, v_num=12, train_loss_step=0.313] Epoch 0:  28%|██▊       | 108/380 [00:03<00:08, 32.45it/s, loss=0.423, v_num=12, train_loss_step=0.428]Epoch 0:  29%|██▊       | 109/380 [00:03<00:08, 32.45it/s, loss=0.422, v_num=12, train_loss_step=0.313]Epoch 0:  29%|██▉       | 110/380 [00:03<00:08, 32.46it/s, loss=0.422, v_num=12, train_loss_step=0.313]Epoch 0:  29%|██▉       | 110/380 [00:03<00:08, 32.45it/s, loss=0.422, v_num=12, train_loss_step=0.313]Epoch 0:  29%|██▉       | 111/380 [00:03<00:08, 32.45it/s, loss=0.42, v_num=12, train_loss_step=0.329] Epoch 0:  29%|██▉       | 112/380 [00:03<00:08, 32.45it/s, loss=0.428, v_num=12, train_loss_step=0.506]Epoch 0:  30%|██▉       | 113/380 [00:03<00:08, 32.45it/s, loss=0.427, v_num=12, train_loss_step=0.396]Epoch 0:  30%|███       | 114/380 [00:03<00:08, 32.45it/s, loss=0.427, v_num=12, train_loss_step=0.396]Epoch 0:  30%|███       | 114/380 [00:03<00:08, 32.45it/s, loss=0.419, v_num=12, train_loss_step=0.313]Epoch 0:  30%|███       | 115/380 [00:03<00:08, 32.45it/s, loss=0.428, v_num=12, train_loss_step=0.543]Epoch 0:  31%|███       | 116/380 [00:03<00:08, 32.46it/s, loss=0.414, v_num=12, train_loss_step=0.320]Epoch 0:  31%|███       | 117/380 [00:03<00:08, 32.46it/s, loss=0.414, v_num=12, train_loss_step=0.313]Epoch 0:  31%|███       | 118/380 [00:03<00:08, 32.46it/s, loss=0.414, v_num=12, train_loss_step=0.313]Epoch 0:  31%|███       | 118/380 [00:03<00:08, 32.46it/s, loss=0.406, v_num=12, train_loss_step=0.321]Epoch 0:  31%|███▏      | 119/380 [00:03<00:08, 32.46it/s, loss=0.401, v_num=12, train_loss_step=0.563]Epoch 0:  32%|███▏      | 120/380 [00:03<00:08, 32.47it/s, loss=0.397, v_num=12, train_loss_step=0.313]Epoch 0:  32%|███▏      | 121/380 [00:03<00:07, 32.47it/s, loss=0.397, v_num=12, train_loss_step=0.313]Epoch 0:  32%|███▏      | 122/380 [00:03<00:07, 32.47it/s, loss=0.397, v_num=12, train_loss_step=0.313]Epoch 0:  32%|███▏      | 122/380 [00:03<00:07, 32.47it/s, loss=0.397, v_num=12, train_loss_step=0.321]Epoch 0:  32%|███▏      | 123/380 [00:03<00:07, 32.48it/s, loss=0.407, v_num=12, train_loss_step=0.507]Epoch 0:  33%|███▎      | 124/380 [00:03<00:07, 32.47it/s, loss=0.399, v_num=12, train_loss_step=0.313]Epoch 0:  33%|███▎      | 125/380 [00:03<00:07, 32.48it/s, loss=0.408, v_num=12, train_loss_step=0.780]Epoch 0:  33%|███▎      | 126/380 [00:03<00:07, 32.48it/s, loss=0.408, v_num=12, train_loss_step=0.780]Epoch 0:  33%|███▎      | 126/380 [00:03<00:07, 32.48it/s, loss=0.394, v_num=12, train_loss_step=0.354]Epoch 0:  33%|███▎      | 127/380 [00:03<00:07, 32.48it/s, loss=0.396, v_num=12, train_loss_step=0.363]Epoch 0:  34%|███▎      | 128/380 [00:03<00:07, 32.48it/s, loss=0.39, v_num=12, train_loss_step=0.313] Epoch 0:  34%|███▍      | 129/380 [00:04<00:07, 32.48it/s, loss=0.398, v_num=12, train_loss_step=0.459]Epoch 0:  34%|███▍      | 130/380 [00:04<00:07, 32.49it/s, loss=0.398, v_num=12, train_loss_step=0.459]Epoch 0:  34%|███▍      | 130/380 [00:04<00:07, 32.48it/s, loss=0.401, v_num=12, train_loss_step=0.384]Epoch 0:  34%|███▍      | 131/380 [00:04<00:07, 32.48it/s, loss=0.405, v_num=12, train_loss_step=0.400]Epoch 0:  35%|███▍      | 132/380 [00:04<00:07, 32.48it/s, loss=0.421, v_num=12, train_loss_step=0.839]Epoch 0:  35%|███▌      | 133/380 [00:04<00:07, 32.48it/s, loss=0.42, v_num=12, train_loss_step=0.359] Epoch 0:  35%|███▌      | 134/380 [00:04<00:07, 32.48it/s, loss=0.42, v_num=12, train_loss_step=0.359]Epoch 0:  35%|███▌      | 134/380 [00:04<00:07, 32.48it/s, loss=0.42, v_num=12, train_loss_step=0.320]Epoch 0:  36%|███▌      | 135/380 [00:04<00:07, 32.48it/s, loss=0.411, v_num=12, train_loss_step=0.368]Epoch 0:  36%|███▌      | 136/380 [00:04<00:07, 32.47it/s, loss=0.411, v_num=12, train_loss_step=0.313]Epoch 0:  36%|███▌      | 137/380 [00:04<00:07, 32.48it/s, loss=0.426, v_num=12, train_loss_step=0.616]Epoch 0:  36%|███▋      | 138/380 [00:04<00:07, 32.47it/s, loss=0.426, v_num=12, train_loss_step=0.616]Epoch 0:  36%|███▋      | 138/380 [00:04<00:07, 32.47it/s, loss=0.426, v_num=12, train_loss_step=0.313]Epoch 0:  37%|███▋      | 139/380 [00:04<00:07, 32.47it/s, loss=0.433, v_num=12, train_loss_step=0.710]Epoch 0:  37%|███▋      | 140/380 [00:04<00:07, 32.47it/s, loss=0.448, v_num=12, train_loss_step=0.618]Epoch 0:  37%|███▋      | 141/380 [00:04<00:07, 32.47it/s, loss=0.451, v_num=12, train_loss_step=0.361]Epoch 0:  37%|███▋      | 142/380 [00:04<00:07, 32.47it/s, loss=0.451, v_num=12, train_loss_step=0.361]Epoch 0:  37%|███▋      | 142/380 [00:04<00:07, 32.47it/s, loss=0.45, v_num=12, train_loss_step=0.313] Epoch 0:  38%|███▊      | 143/380 [00:04<00:07, 32.47it/s, loss=0.453, v_num=12, train_loss_step=0.557]Epoch 0:  38%|███▊      | 144/380 [00:04<00:07, 32.47it/s, loss=0.453, v_num=12, train_loss_step=0.313]Epoch 0:  38%|███▊      | 145/380 [00:04<00:07, 32.47it/s, loss=0.433, v_num=12, train_loss_step=0.378]Epoch 0:  38%|███▊      | 146/380 [00:04<00:07, 32.47it/s, loss=0.433, v_num=12, train_loss_step=0.378]Epoch 0:  38%|███▊      | 146/380 [00:04<00:07, 32.47it/s, loss=0.436, v_num=12, train_loss_step=0.422]Epoch 0:  39%|███▊      | 147/380 [00:04<00:07, 32.47it/s, loss=0.434, v_num=12, train_loss_step=0.313]Epoch 0:  39%|███▉      | 148/380 [00:04<00:07, 32.47it/s, loss=0.436, v_num=12, train_loss_step=0.366]Epoch 0:  39%|███▉      | 149/380 [00:04<00:07, 32.48it/s, loss=0.432, v_num=12, train_loss_step=0.366]Epoch 0:  39%|███▉      | 150/380 [00:04<00:07, 32.48it/s, loss=0.432, v_num=12, train_loss_step=0.366]Epoch 0:  39%|███▉      | 150/380 [00:04<00:07, 32.48it/s, loss=0.428, v_num=12, train_loss_step=0.313]Epoch 0:  40%|███▉      | 151/380 [00:04<00:07, 32.48it/s, loss=0.425, v_num=12, train_loss_step=0.349]Epoch 0:  40%|████      | 152/380 [00:04<00:07, 32.48it/s, loss=0.399, v_num=12, train_loss_step=0.313]Epoch 0:  40%|████      | 153/380 [00:04<00:06, 32.48it/s, loss=0.403, v_num=12, train_loss_step=0.439]Epoch 0:  41%|████      | 154/380 [00:04<00:06, 32.48it/s, loss=0.403, v_num=12, train_loss_step=0.439]Epoch 0:  41%|████      | 154/380 [00:04<00:06, 32.48it/s, loss=0.403, v_num=12, train_loss_step=0.318]Epoch 0:  41%|████      | 155/380 [00:04<00:06, 32.48it/s, loss=0.422, v_num=12, train_loss_step=0.737]Epoch 0:  41%|████      | 156/380 [00:04<00:06, 32.48it/s, loss=0.445, v_num=12, train_loss_step=0.783]Epoch 0:  41%|████▏     | 157/380 [00:04<00:06, 32.47it/s, loss=0.433, v_num=12, train_loss_step=0.372]Epoch 0:  42%|████▏     | 158/380 [00:04<00:06, 32.48it/s, loss=0.433, v_num=12, train_loss_step=0.372]Epoch 0:  42%|████▏     | 158/380 [00:04<00:06, 32.47it/s, loss=0.465, v_num=12, train_loss_step=0.955]Epoch 0:  42%|████▏     | 159/380 [00:04<00:06, 32.48it/s, loss=0.445, v_num=12, train_loss_step=0.316]Epoch 0:  42%|████▏     | 160/380 [00:04<00:06, 32.47it/s, loss=0.435, v_num=12, train_loss_step=0.414]Epoch 0:  42%|████▏     | 161/380 [00:04<00:06, 32.48it/s, loss=0.433, v_num=12, train_loss_step=0.313]Epoch 0:  43%|████▎     | 162/380 [00:05<00:06, 32.48it/s, loss=0.433, v_num=12, train_loss_step=0.313]Epoch 0:  43%|████▎     | 162/380 [00:05<00:06, 32.48it/s, loss=0.433, v_num=12, train_loss_step=0.318]Epoch 0:  43%|████▎     | 163/380 [00:05<00:06, 32.48it/s, loss=0.421, v_num=12, train_loss_step=0.324]Epoch 0:  43%|████▎     | 164/380 [00:05<00:06, 32.48it/s, loss=0.425, v_num=12, train_loss_step=0.395]Epoch 0:  43%|████▎     | 165/380 [00:05<00:06, 32.48it/s, loss=0.448, v_num=12, train_loss_step=0.826]Epoch 0:  44%|████▎     | 166/380 [00:05<00:06, 32.48it/s, loss=0.448, v_num=12, train_loss_step=0.826]Epoch 0:  44%|████▎     | 166/380 [00:05<00:06, 32.48it/s, loss=0.442, v_num=12, train_loss_step=0.313]Epoch 0:  44%|████▍     | 167/380 [00:05<00:06, 32.48it/s, loss=0.451, v_num=12, train_loss_step=0.481]Epoch 0:  44%|████▍     | 168/380 [00:05<00:06, 32.48it/s, loss=0.448, v_num=12, train_loss_step=0.313]Epoch 0:  44%|████▍     | 169/380 [00:05<00:06, 32.48it/s, loss=0.445, v_num=12, train_loss_step=0.313]Epoch 0:  45%|████▍     | 170/380 [00:05<00:06, 32.49it/s, loss=0.445, v_num=12, train_loss_step=0.313]Epoch 0:  45%|████▍     | 170/380 [00:05<00:06, 32.48it/s, loss=0.458, v_num=12, train_loss_step=0.568]Epoch 0:  45%|████▌     | 171/380 [00:05<00:06, 32.48it/s, loss=0.456, v_num=12, train_loss_step=0.313]Epoch 0:  45%|████▌     | 172/380 [00:05<00:06, 32.47it/s, loss=0.48, v_num=12, train_loss_step=0.785] Epoch 0:  46%|████▌     | 173/380 [00:05<00:06, 32.47it/s, loss=0.488, v_num=12, train_loss_step=0.599]Epoch 0:  46%|████▌     | 174/380 [00:05<00:06, 32.48it/s, loss=0.488, v_num=12, train_loss_step=0.599]Epoch 0:  46%|████▌     | 174/380 [00:05<00:06, 32.47it/s, loss=0.491, v_num=12, train_loss_step=0.382]Epoch 0:  46%|████▌     | 175/380 [00:05<00:06, 32.48it/s, loss=0.477, v_num=12, train_loss_step=0.446]Epoch 0:  46%|████▋     | 176/380 [00:05<00:06, 32.47it/s, loss=0.453, v_num=12, train_loss_step=0.313]Epoch 0:  47%|████▋     | 177/380 [00:05<00:06, 32.48it/s, loss=0.471, v_num=12, train_loss_step=0.730]Epoch 0:  47%|████▋     | 178/380 [00:05<00:06, 32.47it/s, loss=0.471, v_num=12, train_loss_step=0.730]Epoch 0:  47%|████▋     | 178/380 [00:05<00:06, 32.47it/s, loss=0.441, v_num=12, train_loss_step=0.358]Epoch 0:  47%|████▋     | 179/380 [00:05<00:06, 32.47it/s, loss=0.466, v_num=12, train_loss_step=0.823]Epoch 0:  47%|████▋     | 180/380 [00:05<00:06, 32.47it/s, loss=0.462, v_num=12, train_loss_step=0.326]Epoch 0:  48%|████▊     | 181/380 [00:05<00:06, 32.46it/s, loss=0.469, v_num=12, train_loss_step=0.462]Epoch 0:  48%|████▊     | 182/380 [00:05<00:06, 32.46it/s, loss=0.469, v_num=12, train_loss_step=0.462]Epoch 0:  48%|████▊     | 182/380 [00:05<00:06, 32.46it/s, loss=0.471, v_num=12, train_loss_step=0.350]Epoch 0:  48%|████▊     | 183/380 [00:05<00:06, 32.47it/s, loss=0.471, v_num=12, train_loss_step=0.322]Epoch 0:  48%|████▊     | 184/380 [00:05<00:06, 32.46it/s, loss=0.472, v_num=12, train_loss_step=0.418]Epoch 0:  49%|████▊     | 185/380 [00:05<00:06, 32.46it/s, loss=0.464, v_num=12, train_loss_step=0.659]Epoch 0:  49%|████▉     | 186/380 [00:05<00:05, 32.46it/s, loss=0.464, v_num=12, train_loss_step=0.659]Epoch 0:  49%|████▉     | 186/380 [00:05<00:05, 32.46it/s, loss=0.481, v_num=12, train_loss_step=0.664]Epoch 0:  49%|████▉     | 187/380 [00:05<00:05, 32.46it/s, loss=0.473, v_num=12, train_loss_step=0.313]Epoch 0:  49%|████▉     | 188/380 [00:05<00:05, 32.46it/s, loss=0.479, v_num=12, train_loss_step=0.445]Epoch 0:  50%|████▉     | 189/380 [00:05<00:05, 32.46it/s, loss=0.486, v_num=12, train_loss_step=0.436]Epoch 0:  50%|█████     | 190/380 [00:05<00:05, 32.46it/s, loss=0.486, v_num=12, train_loss_step=0.436]Epoch 0:  50%|█████     | 190/380 [00:05<00:05, 32.46it/s, loss=0.49, v_num=12, train_loss_step=0.659] Epoch 0:  50%|█████     | 191/380 [00:05<00:05, 32.46it/s, loss=0.51, v_num=12, train_loss_step=0.705]Epoch 0:  51%|█████     | 192/380 [00:05<00:05, 32.46it/s, loss=0.505, v_num=12, train_loss_step=0.700]Epoch 0:  51%|█████     | 193/380 [00:05<00:05, 32.46it/s, loss=0.494, v_num=12, train_loss_step=0.377]Epoch 0:  51%|█████     | 194/380 [00:06<00:05, 32.46it/s, loss=0.494, v_num=12, train_loss_step=0.377]Epoch 0:  51%|█████     | 194/380 [00:06<00:05, 32.46it/s, loss=0.51, v_num=12, train_loss_step=0.691] Epoch 0:  51%|█████▏    | 195/380 [00:06<00:05, 32.46it/s, loss=0.503, v_num=12, train_loss_step=0.313]Epoch 0:  52%|█████▏    | 196/380 [00:06<00:05, 32.46it/s, loss=0.512, v_num=12, train_loss_step=0.496]Epoch 0:  52%|█████▏    | 197/380 [00:06<00:05, 32.46it/s, loss=0.497, v_num=12, train_loss_step=0.419]Epoch 0:  52%|█████▏    | 198/380 [00:06<00:05, 32.46it/s, loss=0.497, v_num=12, train_loss_step=0.419]Epoch 0:  52%|█████▏    | 198/380 [00:06<00:05, 32.46it/s, loss=0.498, v_num=12, train_loss_step=0.384]Epoch 0:  52%|█████▏    | 199/380 [00:06<00:05, 32.46it/s, loss=0.475, v_num=12, train_loss_step=0.362]Epoch 0:  53%|█████▎    | 200/380 [00:06<00:05, 32.46it/s, loss=0.478, v_num=12, train_loss_step=0.389]Epoch 0:  53%|█████▎    | 201/380 [00:06<00:05, 32.46it/s, loss=0.473, v_num=12, train_loss_step=0.354]Epoch 0:  53%|█████▎    | 202/380 [00:06<00:05, 32.46it/s, loss=0.473, v_num=12, train_loss_step=0.354]Epoch 0:  53%|█████▎    | 202/380 [00:06<00:05, 32.46it/s, loss=0.477, v_num=12, train_loss_step=0.438]Epoch 0:  53%|█████▎    | 203/380 [00:06<00:05, 32.47it/s, loss=0.491, v_num=12, train_loss_step=0.592]Epoch 0:  54%|█████▎    | 204/380 [00:06<00:05, 32.47it/s, loss=0.485, v_num=12, train_loss_step=0.313]Epoch 0:  54%|█████▍    | 205/380 [00:06<00:05, 32.47it/s, loss=0.482, v_num=12, train_loss_step=0.595]Epoch 0:  54%|█████▍    | 206/380 [00:06<00:05, 32.47it/s, loss=0.482, v_num=12, train_loss_step=0.595]Epoch 0:  54%|█████▍    | 206/380 [00:06<00:05, 32.47it/s, loss=0.465, v_num=12, train_loss_step=0.313]Epoch 0:  54%|█████▍    | 207/380 [00:06<00:05, 32.47it/s, loss=0.483, v_num=12, train_loss_step=0.679]Epoch 0:  55%|█████▍    | 208/380 [00:06<00:05, 32.47it/s, loss=0.476, v_num=12, train_loss_step=0.313]Epoch 0:  55%|█████▌    | 209/380 [00:06<00:05, 32.47it/s, loss=0.471, v_num=12, train_loss_step=0.323]Epoch 0:  55%|█████▌    | 210/380 [00:06<00:05, 32.47it/s, loss=0.471, v_num=12, train_loss_step=0.323]Epoch 0:  55%|█████▌    | 210/380 [00:06<00:05, 32.47it/s, loss=0.477, v_num=12, train_loss_step=0.793]Epoch 0:  56%|█████▌    | 211/380 [00:06<00:05, 32.47it/s, loss=0.461, v_num=12, train_loss_step=0.369]Epoch 0:  56%|█████▌    | 212/380 [00:06<00:05, 32.47it/s, loss=0.455, v_num=12, train_loss_step=0.582]Epoch 0:  56%|█████▌    | 213/380 [00:06<00:05, 32.47it/s, loss=0.456, v_num=12, train_loss_step=0.408]Epoch 0:  56%|█████▋    | 214/380 [00:06<00:05, 32.47it/s, loss=0.456, v_num=12, train_loss_step=0.408]Epoch 0:  56%|█████▋    | 214/380 [00:06<00:05, 32.47it/s, loss=0.441, v_num=12, train_loss_step=0.378]Epoch 0:  57%|█████▋    | 215/380 [00:06<00:05, 32.47it/s, loss=0.45, v_num=12, train_loss_step=0.490] Epoch 0:  57%|█████▋    | 216/380 [00:06<00:05, 32.47it/s, loss=0.467, v_num=12, train_loss_step=0.844]Epoch 0:  57%|█████▋    | 217/380 [00:06<00:05, 32.47it/s, loss=0.462, v_num=12, train_loss_step=0.313]Epoch 0:  57%|█████▋    | 218/380 [00:06<00:04, 32.46it/s, loss=0.462, v_num=12, train_loss_step=0.313]Epoch 0:  57%|█████▋    | 218/380 [00:06<00:04, 32.46it/s, loss=0.466, v_num=12, train_loss_step=0.474]Epoch 0:  58%|█████▊    | 219/380 [00:06<00:04, 32.46it/s, loss=0.475, v_num=12, train_loss_step=0.530]Epoch 0:  58%|█████▊    | 220/380 [00:06<00:04, 32.46it/s, loss=0.473, v_num=12, train_loss_step=0.355]Epoch 0:  58%|█████▊    | 221/380 [00:06<00:04, 32.46it/s, loss=0.472, v_num=12, train_loss_step=0.342]Epoch 0:  58%|█████▊    | 222/380 [00:06<00:04, 32.46it/s, loss=0.472, v_num=12, train_loss_step=0.342]Epoch 0:  58%|█████▊    | 222/380 [00:06<00:04, 32.46it/s, loss=0.471, v_num=12, train_loss_step=0.406]Epoch 0:  59%|█████▊    | 223/380 [00:06<00:04, 32.46it/s, loss=0.465, v_num=12, train_loss_step=0.477]Epoch 0:  59%|█████▉    | 224/380 [00:06<00:04, 32.46it/s, loss=0.465, v_num=12, train_loss_step=0.313]Epoch 0:  59%|█████▉    | 225/380 [00:06<00:04, 32.46it/s, loss=0.451, v_num=12, train_loss_step=0.313]Epoch 0:  59%|█████▉    | 226/380 [00:06<00:04, 32.46it/s, loss=0.451, v_num=12, train_loss_step=0.313]Epoch 0:  59%|█████▉    | 226/380 [00:06<00:04, 32.46it/s, loss=0.451, v_num=12, train_loss_step=0.313]Epoch 0:  60%|█████▉    | 227/380 [00:07<00:04, 32.46it/s, loss=0.45, v_num=12, train_loss_step=0.669] Epoch 0:  60%|██████    | 228/380 [00:07<00:04, 32.46it/s, loss=0.454, v_num=12, train_loss_step=0.382]Epoch 0:  60%|██████    | 229/380 [00:07<00:04, 32.46it/s, loss=0.474, v_num=12, train_loss_step=0.727]Epoch 0:  61%|██████    | 230/380 [00:07<00:04, 32.46it/s, loss=0.474, v_num=12, train_loss_step=0.727]Epoch 0:  61%|██████    | 230/380 [00:07<00:04, 32.46it/s, loss=0.45, v_num=12, train_loss_step=0.313] Epoch 0:  61%|██████    | 231/380 [00:07<00:04, 32.46it/s, loss=0.47, v_num=12, train_loss_step=0.777]Epoch 0:  61%|██████    | 232/380 [00:07<00:04, 32.46it/s, loss=0.476, v_num=12, train_loss_step=0.687]Epoch 0:  61%|██████▏   | 233/380 [00:07<00:04, 32.46it/s, loss=0.479, v_num=12, train_loss_step=0.467]Epoch 0:  62%|██████▏   | 234/380 [00:07<00:04, 32.46it/s, loss=0.479, v_num=12, train_loss_step=0.467]Epoch 0:  62%|██████▏   | 234/380 [00:07<00:04, 32.46it/s, loss=0.495, v_num=12, train_loss_step=0.697]Epoch 0:  62%|██████▏   | 235/380 [00:07<00:04, 32.46it/s, loss=0.493, v_num=12, train_loss_step=0.451]Epoch 0:  62%|██████▏   | 236/380 [00:07<00:04, 32.47it/s, loss=0.466, v_num=12, train_loss_step=0.313]Epoch 0:  62%|██████▏   | 237/380 [00:07<00:04, 32.47it/s, loss=0.466, v_num=12, train_loss_step=0.313]Epoch 0:  63%|██████▎   | 238/380 [00:07<00:04, 32.47it/s, loss=0.466, v_num=12, train_loss_step=0.313]Epoch 0:  63%|██████▎   | 238/380 [00:07<00:04, 32.47it/s, loss=0.458, v_num=12, train_loss_step=0.313]Epoch 0:  63%|██████▎   | 239/380 [00:07<00:04, 32.46it/s, loss=0.45, v_num=12, train_loss_step=0.368] Epoch 0:  63%|██████▎   | 240/380 [00:07<00:04, 32.47it/s, loss=0.469, v_num=12, train_loss_step=0.728]Epoch 0:  63%|██████▎   | 241/380 [00:07<00:04, 32.47it/s, loss=0.467, v_num=12, train_loss_step=0.313]Epoch 0:  64%|██████▎   | 242/380 [00:07<00:04, 32.47it/s, loss=0.467, v_num=12, train_loss_step=0.313]Epoch 0:  64%|██████▎   | 242/380 [00:07<00:04, 32.47it/s, loss=0.483, v_num=12, train_loss_step=0.722]Epoch 0:  64%|██████▍   | 243/380 [00:07<00:04, 32.47it/s, loss=0.476, v_num=12, train_loss_step=0.340]Epoch 0:  64%|██████▍   | 244/380 [00:07<00:04, 32.47it/s, loss=0.477, v_num=12, train_loss_step=0.341]Epoch 0:  64%|██████▍   | 245/380 [00:07<00:04, 32.47it/s, loss=0.478, v_num=12, train_loss_step=0.322]Epoch 0:  65%|██████▍   | 246/380 [00:07<00:04, 32.47it/s, loss=0.478, v_num=12, train_loss_step=0.322]Epoch 0:  65%|██████▍   | 246/380 [00:07<00:04, 32.47it/s, loss=0.484, v_num=12, train_loss_step=0.444]Epoch 0:  65%|██████▌   | 247/380 [00:07<00:04, 32.47it/s, loss=0.475, v_num=12, train_loss_step=0.476]Epoch 0:  65%|██████▌   | 248/380 [00:07<00:04, 32.47it/s, loss=0.474, v_num=12, train_loss_step=0.375]Epoch 0:  66%|██████▌   | 249/380 [00:07<00:04, 32.47it/s, loss=0.454, v_num=12, train_loss_step=0.313]Epoch 0:  66%|██████▌   | 250/380 [00:07<00:04, 32.47it/s, loss=0.454, v_num=12, train_loss_step=0.313]Epoch 0:  66%|██████▌   | 250/380 [00:07<00:04, 32.47it/s, loss=0.455, v_num=12, train_loss_step=0.335]Epoch 0:  66%|██████▌   | 251/380 [00:07<00:03, 32.47it/s, loss=0.442, v_num=12, train_loss_step=0.518]Epoch 0:  66%|██████▋   | 252/380 [00:07<00:03, 32.47it/s, loss=0.441, v_num=12, train_loss_step=0.672]Epoch 0:  67%|██████▋   | 253/380 [00:07<00:03, 32.47it/s, loss=0.445, v_num=12, train_loss_step=0.546]Epoch 0:  67%|██████▋   | 254/380 [00:07<00:03, 32.47it/s, loss=0.445, v_num=12, train_loss_step=0.546]Epoch 0:  67%|██████▋   | 254/380 [00:07<00:03, 32.47it/s, loss=0.433, v_num=12, train_loss_step=0.459]Epoch 0:  67%|██████▋   | 255/380 [00:07<00:03, 32.47it/s, loss=0.428, v_num=12, train_loss_step=0.348]Epoch 0:  67%|██████▋   | 256/380 [00:07<00:03, 32.47it/s, loss=0.431, v_num=12, train_loss_step=0.366]Epoch 0:  68%|██████▊   | 257/380 [00:07<00:03, 32.47it/s, loss=0.434, v_num=12, train_loss_step=0.380]Epoch 0:  68%|██████▊   | 258/380 [00:07<00:03, 32.47it/s, loss=0.434, v_num=12, train_loss_step=0.380]Epoch 0:  68%|██████▊   | 258/380 [00:07<00:03, 32.47it/s, loss=0.438, v_num=12, train_loss_step=0.387]Epoch 0:  68%|██████▊   | 259/380 [00:08<00:03, 32.45it/s, loss=0.444, v_num=12, train_loss_step=0.495]Epoch 0:  68%|██████▊   | 260/380 [00:08<00:03, 32.45it/s, loss=0.426, v_num=12, train_loss_step=0.372]Epoch 0:  69%|██████▊   | 261/380 [00:08<00:03, 32.45it/s, loss=0.426, v_num=12, train_loss_step=0.313]Epoch 0:  69%|██████▉   | 262/380 [00:08<00:03, 32.45it/s, loss=0.426, v_num=12, train_loss_step=0.313]Epoch 0:  69%|██████▉   | 262/380 [00:08<00:03, 32.45it/s, loss=0.406, v_num=12, train_loss_step=0.313]Epoch 0:  69%|██████▉   | 263/380 [00:08<00:03, 32.45it/s, loss=0.404, v_num=12, train_loss_step=0.313]Epoch 0:  69%|██████▉   | 264/380 [00:08<00:03, 32.45it/s, loss=0.404, v_num=12, train_loss_step=0.333]Epoch 0:  70%|██████▉   | 265/380 [00:08<00:03, 32.45it/s, loss=0.408, v_num=12, train_loss_step=0.392]Epoch 0:  70%|███████   | 266/380 [00:08<00:03, 32.46it/s, loss=0.408, v_num=12, train_loss_step=0.392]Epoch 0:  70%|███████   | 266/380 [00:08<00:03, 32.45it/s, loss=0.403, v_num=12, train_loss_step=0.347]Epoch 0:  70%|███████   | 267/380 [00:08<00:03, 32.46it/s, loss=0.395, v_num=12, train_loss_step=0.313]Epoch 0:  71%|███████   | 268/380 [00:08<00:03, 32.46it/s, loss=0.392, v_num=12, train_loss_step=0.313]Epoch 0:  71%|███████   | 269/380 [00:08<00:03, 32.46it/s, loss=0.392, v_num=12, train_loss_step=0.313]Epoch 0:  71%|███████   | 270/380 [00:08<00:03, 32.46it/s, loss=0.392, v_num=12, train_loss_step=0.313]Epoch 0:  71%|███████   | 270/380 [00:08<00:03, 32.46it/s, loss=0.39, v_num=12, train_loss_step=0.313] Epoch 0:  71%|███████▏  | 271/380 [00:08<00:03, 32.46it/s, loss=0.392, v_num=12, train_loss_step=0.547]Epoch 0:  72%|███████▏  | 272/380 [00:08<00:03, 32.46it/s, loss=0.375, v_num=12, train_loss_step=0.324]Epoch 0:  72%|███████▏  | 273/380 [00:08<00:03, 32.46it/s, loss=0.367, v_num=12, train_loss_step=0.399]Epoch 0:  72%|███████▏  | 274/380 [00:08<00:03, 32.46it/s, loss=0.367, v_num=12, train_loss_step=0.399]Epoch 0:  72%|███████▏  | 274/380 [00:08<00:03, 32.46it/s, loss=0.378, v_num=12, train_loss_step=0.683]Epoch 0:  72%|███████▏  | 275/380 [00:08<00:03, 32.46it/s, loss=0.383, v_num=12, train_loss_step=0.442]Epoch 0:  73%|███████▎  | 276/380 [00:08<00:03, 32.46it/s, loss=0.385, v_num=12, train_loss_step=0.403]Epoch 0:  73%|███████▎  | 277/380 [00:08<00:03, 32.46it/s, loss=0.403, v_num=12, train_loss_step=0.734]Epoch 0:  73%|███████▎  | 278/380 [00:08<00:03, 32.46it/s, loss=0.403, v_num=12, train_loss_step=0.734]Epoch 0:  73%|███████▎  | 278/380 [00:08<00:03, 32.46it/s, loss=0.408, v_num=12, train_loss_step=0.495]Epoch 0:  73%|███████▎  | 279/380 [00:08<00:03, 32.46it/s, loss=0.403, v_num=12, train_loss_step=0.393]Epoch 0:  74%|███████▎  | 280/380 [00:08<00:03, 32.46it/s, loss=0.427, v_num=12, train_loss_step=0.864]Epoch 0:  74%|███████▍  | 281/380 [00:08<00:03, 32.46it/s, loss=0.428, v_num=12, train_loss_step=0.332]Epoch 0:  74%|███████▍  | 282/380 [00:08<00:03, 32.46it/s, loss=0.428, v_num=12, train_loss_step=0.332]Epoch 0:  74%|███████▍  | 282/380 [00:08<00:03, 32.46it/s, loss=0.429, v_num=12, train_loss_step=0.325]Epoch 0:  74%|███████▍  | 283/380 [00:08<00:02, 32.46it/s, loss=0.429, v_num=12, train_loss_step=0.313]Epoch 0:  75%|███████▍  | 284/380 [00:08<00:02, 32.46it/s, loss=0.428, v_num=12, train_loss_step=0.313]Epoch 0:  75%|███████▌  | 285/380 [00:08<00:02, 32.46it/s, loss=0.429, v_num=12, train_loss_step=0.410]Epoch 0:  75%|███████▌  | 286/380 [00:08<00:02, 32.46it/s, loss=0.429, v_num=12, train_loss_step=0.410]Epoch 0:  75%|███████▌  | 286/380 [00:08<00:02, 32.46it/s, loss=0.448, v_num=12, train_loss_step=0.737]Epoch 0:  76%|███████▌  | 287/380 [00:08<00:02, 32.46it/s, loss=0.448, v_num=12, train_loss_step=0.313]Epoch 0:  76%|███████▌  | 288/380 [00:08<00:02, 32.46it/s, loss=0.453, v_num=12, train_loss_step=0.411]Epoch 0:  76%|███████▌  | 289/380 [00:08<00:02, 32.46it/s, loss=0.455, v_num=12, train_loss_step=0.346]Epoch 0:  76%|███████▋  | 290/380 [00:08<00:02, 32.46it/s, loss=0.455, v_num=12, train_loss_step=0.346]Epoch 0:  76%|███████▋  | 290/380 [00:08<00:02, 32.46it/s, loss=0.459, v_num=12, train_loss_step=0.384]Epoch 0:  77%|███████▋  | 291/380 [00:08<00:02, 32.46it/s, loss=0.45, v_num=12, train_loss_step=0.381] Epoch 0:  77%|███████▋  | 292/380 [00:09<00:02, 32.46it/s, loss=0.452, v_num=12, train_loss_step=0.358]Epoch 0:  77%|███████▋  | 293/380 [00:09<00:02, 32.46it/s, loss=0.451, v_num=12, train_loss_step=0.390]Epoch 0:  77%|███████▋  | 294/380 [00:09<00:02, 32.46it/s, loss=0.451, v_num=12, train_loss_step=0.390]Epoch 0:  77%|███████▋  | 294/380 [00:09<00:02, 32.46it/s, loss=0.433, v_num=12, train_loss_step=0.324]Epoch 0:  78%|███████▊  | 295/380 [00:09<00:02, 32.46it/s, loss=0.427, v_num=12, train_loss_step=0.313]Epoch 0:  78%|███████▊  | 296/380 [00:09<00:02, 32.46it/s, loss=0.423, v_num=12, train_loss_step=0.329]Epoch 0:  78%|███████▊  | 297/380 [00:09<00:02, 32.46it/s, loss=0.403, v_num=12, train_loss_step=0.322]Epoch 0:  78%|███████▊  | 298/380 [00:09<00:02, 32.46it/s, loss=0.403, v_num=12, train_loss_step=0.322]Epoch 0:  78%|███████▊  | 298/380 [00:09<00:02, 32.46it/s, loss=0.395, v_num=12, train_loss_step=0.342]Epoch 0:  79%|███████▊  | 299/380 [00:09<00:02, 32.46it/s, loss=0.392, v_num=12, train_loss_step=0.342]Epoch 0:  79%|███████▉  | 300/380 [00:09<00:02, 32.46it/s, loss=0.367, v_num=12, train_loss_step=0.362]Epoch 0:  79%|███████▉  | 301/380 [00:09<00:02, 32.46it/s, loss=0.367, v_num=12, train_loss_step=0.335]Epoch 0:  79%|███████▉  | 302/380 [00:09<00:02, 32.46it/s, loss=0.367, v_num=12, train_loss_step=0.335]Epoch 0:  79%|███████▉  | 302/380 [00:09<00:02, 32.46it/s, loss=0.39, v_num=12, train_loss_step=0.784] Epoch 0:  80%|███████▉  | 303/380 [00:09<00:02, 32.45it/s, loss=0.405, v_num=12, train_loss_step=0.602]Epoch 0:  80%|████████  | 304/380 [00:09<00:02, 32.45it/s, loss=0.426, v_num=12, train_loss_step=0.738]Epoch 0:  80%|████████  | 305/380 [00:09<00:02, 32.45it/s, loss=0.432, v_num=12, train_loss_step=0.519]Epoch 0:  81%|████████  | 306/380 [00:09<00:02, 32.45it/s, loss=0.432, v_num=12, train_loss_step=0.519]Epoch 0:  81%|████████  | 306/380 [00:09<00:02, 32.45it/s, loss=0.413, v_num=12, train_loss_step=0.358]Epoch 0:  81%|████████  | 307/380 [00:09<00:02, 32.45it/s, loss=0.446, v_num=12, train_loss_step=0.977]Epoch 0:  81%|████████  | 308/380 [00:09<00:02, 32.45it/s, loss=0.449, v_num=12, train_loss_step=0.471]Epoch 0:  81%|████████▏ | 309/380 [00:09<00:02, 32.45it/s, loss=0.447, v_num=12, train_loss_step=0.313]Epoch 0:  82%|████████▏ | 310/380 [00:09<00:02, 32.45it/s, loss=0.447, v_num=12, train_loss_step=0.313]Epoch 0:  82%|████████▏ | 310/380 [00:09<00:02, 32.45it/s, loss=0.444, v_num=12, train_loss_step=0.313]Epoch 0:  82%|████████▏ | 311/380 [00:09<00:02, 32.45it/s, loss=0.443, v_num=12, train_loss_step=0.378]Epoch 0:  82%|████████▏ | 312/380 [00:09<00:02, 32.45it/s, loss=0.443, v_num=12, train_loss_step=0.350]Epoch 0:  82%|████████▏ | 313/380 [00:09<00:02, 32.45it/s, loss=0.439, v_num=12, train_loss_step=0.313]Epoch 0:  83%|████████▎ | 314/380 [00:09<00:02, 32.45it/s, loss=0.439, v_num=12, train_loss_step=0.313]Epoch 0:  83%|████████▎ | 314/380 [00:09<00:02, 32.45it/s, loss=0.454, v_num=12, train_loss_step=0.628]Epoch 0:  83%|████████▎ | 315/380 [00:09<00:02, 32.45it/s, loss=0.455, v_num=12, train_loss_step=0.319]Epoch 0:  83%|████████▎ | 316/380 [00:09<00:01, 32.45it/s, loss=0.457, v_num=12, train_loss_step=0.376]Epoch 0:  83%|████████▎ | 317/380 [00:09<00:01, 32.45it/s, loss=0.462, v_num=12, train_loss_step=0.415]Epoch 0:  84%|████████▎ | 318/380 [00:09<00:01, 32.45it/s, loss=0.462, v_num=12, train_loss_step=0.415]Epoch 0:  84%|████████▎ | 318/380 [00:09<00:01, 32.45it/s, loss=0.474, v_num=12, train_loss_step=0.581]Epoch 0:  84%|████████▍ | 319/380 [00:09<00:01, 32.45it/s, loss=0.492, v_num=12, train_loss_step=0.708]Epoch 0:  84%|████████▍ | 320/380 [00:09<00:01, 32.45it/s, loss=0.491, v_num=12, train_loss_step=0.333]Epoch 0:  84%|████████▍ | 321/380 [00:09<00:01, 32.45it/s, loss=0.496, v_num=12, train_loss_step=0.438]Epoch 0:  85%|████████▍ | 322/380 [00:09<00:01, 32.45it/s, loss=0.496, v_num=12, train_loss_step=0.438]Epoch 0:  85%|████████▍ | 322/380 [00:09<00:01, 32.45it/s, loss=0.472, v_num=12, train_loss_step=0.313]Epoch 0:  85%|████████▌ | 323/380 [00:09<00:01, 32.45it/s, loss=0.462, v_num=12, train_loss_step=0.395]Epoch 0:  85%|████████▌ | 324/380 [00:10<00:01, 32.45it/s, loss=0.47, v_num=12, train_loss_step=0.902] Epoch 0:  86%|████████▌ | 325/380 [00:10<00:01, 32.45it/s, loss=0.462, v_num=12, train_loss_step=0.367]Epoch 0:  86%|████████▌ | 326/380 [00:10<00:01, 32.45it/s, loss=0.462, v_num=12, train_loss_step=0.367]Epoch 0:  86%|████████▌ | 326/380 [00:10<00:01, 32.45it/s, loss=0.484, v_num=12, train_loss_step=0.790]Epoch 0:  86%|████████▌ | 327/380 [00:10<00:01, 32.45it/s, loss=0.454, v_num=12, train_loss_step=0.370]Epoch 0:  86%|████████▋ | 328/380 [00:10<00:01, 32.45it/s, loss=0.448, v_num=12, train_loss_step=0.357]Epoch 0:  87%|████████▋ | 329/380 [00:10<00:01, 32.45it/s, loss=0.467, v_num=12, train_loss_step=0.691]Epoch 0:  87%|████████▋ | 330/380 [00:10<00:01, 32.45it/s, loss=0.467, v_num=12, train_loss_step=0.691]Epoch 0:  87%|████████▋ | 330/380 [00:10<00:01, 32.45it/s, loss=0.48, v_num=12, train_loss_step=0.565] Epoch 0:  87%|████████▋ | 331/380 [00:10<00:01, 32.45it/s, loss=0.476, v_num=12, train_loss_step=0.313]Epoch 0:  87%|████████▋ | 332/380 [00:10<00:01, 32.45it/s, loss=0.476, v_num=12, train_loss_step=0.344]Epoch 0:  88%|████████▊ | 333/380 [00:10<00:01, 32.45it/s, loss=0.477, v_num=12, train_loss_step=0.323]Epoch 0:  88%|████████▊ | 334/380 [00:10<00:01, 32.46it/s, loss=0.477, v_num=12, train_loss_step=0.323]Epoch 0:  88%|████████▊ | 334/380 [00:10<00:01, 32.46it/s, loss=0.474, v_num=12, train_loss_step=0.574]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/46 [00:00<?, ?it/s][A
Validating:   4%|▍         | 2/46 [00:00<00:03, 13.70it/s][AEpoch 0:  89%|████████▉ | 338/380 [00:10<00:01, 32.16it/s, loss=0.474, v_num=12, train_loss_step=0.574]
Validating:   9%|▊         | 4/46 [00:00<00:03, 13.69it/s][A
Validating:  13%|█▎        | 6/46 [00:00<00:02, 13.72it/s][AEpoch 0:  90%|█████████ | 342/380 [00:10<00:01, 31.66it/s, loss=0.474, v_num=12, train_loss_step=0.574]
Validating:  17%|█▋        | 8/46 [00:00<00:02, 13.74it/s][A
Validating:  22%|██▏       | 10/46 [00:00<00:02, 13.79it/s][AEpoch 0:  91%|█████████ | 346/380 [00:11<00:01, 31.20it/s, loss=0.474, v_num=12, train_loss_step=0.574]
Validating:  26%|██▌       | 12/46 [00:00<00:02, 13.74it/s][A
Validating:  30%|███       | 14/46 [00:01<00:02, 13.78it/s][AEpoch 0:  92%|█████████▏| 350/380 [00:11<00:00, 30.76it/s, loss=0.474, v_num=12, train_loss_step=0.574]
Validating:  35%|███▍      | 16/46 [00:01<00:02, 13.75it/s][A
Validating:  39%|███▉      | 18/46 [00:01<00:02, 13.72it/s][AEpoch 0:  93%|█████████▎| 354/380 [00:11<00:00, 30.33it/s, loss=0.474, v_num=12, train_loss_step=0.574]
Validating:  43%|████▎     | 20/46 [00:01<00:01, 13.73it/s][A
Validating:  48%|████▊     | 22/46 [00:01<00:01, 13.72it/s][AEpoch 0:  94%|█████████▍| 358/380 [00:11<00:00, 29.92it/s, loss=0.474, v_num=12, train_loss_step=0.574]
Validating:  52%|█████▏    | 24/46 [00:01<00:01, 13.72it/s][A
Validating:  57%|█████▋    | 26/46 [00:01<00:01, 13.76it/s][AEpoch 0:  95%|█████████▌| 362/380 [00:12<00:00, 29.54it/s, loss=0.474, v_num=12, train_loss_step=0.574]
Validating:  61%|██████    | 28/46 [00:02<00:01, 13.72it/s][A
Validating:  65%|██████▌   | 30/46 [00:02<00:01, 13.75it/s][AEpoch 0:  96%|█████████▋| 366/380 [00:12<00:00, 29.18it/s, loss=0.474, v_num=12, train_loss_step=0.574]
Validating:  70%|██████▉   | 32/46 [00:02<00:01, 13.77it/s][A
Validating:  74%|███████▍  | 34/46 [00:02<00:00, 13.81it/s][AEpoch 0:  97%|█████████▋| 370/380 [00:12<00:00, 28.83it/s, loss=0.474, v_num=12, train_loss_step=0.574]
Validating:  78%|███████▊  | 36/46 [00:02<00:00, 13.82it/s][A
Validating:  83%|████████▎ | 38/46 [00:02<00:00, 13.81it/s][AEpoch 0:  98%|█████████▊| 374/380 [00:13<00:00, 28.50it/s, loss=0.474, v_num=12, train_loss_step=0.574]
Validating:  87%|████████▋ | 40/46 [00:02<00:00, 13.74it/s][A
Validating:  91%|█████████▏| 42/46 [00:03<00:00, 13.73it/s][AEpoch 0:  99%|█████████▉| 378/380 [00:13<00:00, 28.18it/s, loss=0.474, v_num=12, train_loss_step=0.574]
Validating:  96%|█████████▌| 44/46 [00:03<00:00, 13.71it/s][A
Validating: 100%|██████████| 46/46 [00:03<00:00, 13.70it/s][AEpoch 0: 100%|██████████| 380/380 [00:13<00:00, 27.87it/s, loss=0.474, v_num=12, train_loss_step=0.574]
                                                           [AEpoch 0: 100%|██████████| 380/380 [00:13<00:00, 27.77it/s, loss=0.474, v_num=12, train_loss_step=0.574]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(

Testing: 0it [00:00, ?it/s]Testing:   2%|▏         | 3/169 [00:00<00:05, 28.02it/s]Testing:   4%|▎         | 6/169 [00:00<00:05, 28.91it/s]Testing:   5%|▌         | 9/169 [00:00<00:05, 29.15it/s]Testing:   7%|▋         | 12/169 [00:00<00:05, 29.27it/s]Testing:   9%|▉         | 15/169 [00:00<00:05, 29.28it/s]Testing:  11%|█         | 18/169 [00:00<00:05, 29.28it/s]Testing:  12%|█▏        | 21/169 [00:00<00:05, 29.20it/s]Testing:  14%|█▍        | 24/169 [00:00<00:04, 29.24it/s]Testing:  16%|█▌        | 27/169 [00:00<00:04, 29.26it/s]Testing:  18%|█▊        | 30/169 [00:01<00:04, 29.33it/s]Testing:  20%|█▉        | 33/169 [00:01<00:04, 29.37it/s]Testing:  21%|██▏       | 36/169 [00:01<00:04, 29.29it/s]Testing:  23%|██▎       | 39/169 [00:01<00:04, 29.32it/s]Testing:  25%|██▍       | 42/169 [00:01<00:04, 29.37it/s]Testing:  27%|██▋       | 45/169 [00:01<00:04, 29.43it/s]Testing:  28%|██▊       | 48/169 [00:01<00:04, 29.40it/s]Testing:  30%|███       | 51/169 [00:01<00:04, 29.30it/s]Testing:  32%|███▏      | 54/169 [00:01<00:03, 28.79it/s]Testing:  34%|███▎      | 57/169 [00:01<00:03, 28.85it/s]Testing:  36%|███▌      | 60/169 [00:02<00:03, 28.93it/s]Testing:  37%|███▋      | 63/169 [00:02<00:03, 29.08it/s]Testing:  39%|███▉      | 66/169 [00:02<00:03, 29.10it/s]Testing:  41%|████      | 69/169 [00:02<00:03, 29.24it/s]Testing:  43%|████▎     | 72/169 [00:02<00:03, 29.31it/s]Testing:  44%|████▍     | 75/169 [00:02<00:03, 29.34it/s]Testing:  46%|████▌     | 78/169 [00:02<00:03, 29.35it/s]Testing:  48%|████▊     | 81/169 [00:02<00:02, 29.39it/s]Testing:  50%|████▉     | 84/169 [00:02<00:02, 29.38it/s]Testing:  51%|█████▏    | 87/169 [00:02<00:02, 29.43it/s]Testing:  53%|█████▎    | 90/169 [00:03<00:02, 29.44it/s]Testing:  55%|█████▌    | 93/169 [00:03<00:02, 29.37it/s]Testing:  57%|█████▋    | 96/169 [00:03<00:02, 29.50it/s]Testing:  59%|█████▊    | 99/169 [00:03<00:02, 29.45it/s]Testing:  60%|██████    | 102/169 [00:03<00:02, 29.44it/s]Testing:  62%|██████▏   | 105/169 [00:03<00:02, 29.35it/s]Testing:  64%|██████▍   | 108/169 [00:03<00:02, 29.41it/s]Testing:  66%|██████▌   | 111/169 [00:03<00:01, 29.44it/s]Testing:  67%|██████▋   | 114/169 [00:03<00:01, 29.32it/s]Testing:  69%|██████▉   | 117/169 [00:03<00:01, 29.32it/s]Testing:  71%|███████   | 120/169 [00:04<00:01, 29.37it/s]Testing:  73%|███████▎  | 123/169 [00:04<00:01, 29.33it/s]Testing:  75%|███████▍  | 126/169 [00:04<00:01, 29.38it/s]Testing:  76%|███████▋  | 129/169 [00:04<00:01, 29.14it/s]Testing:  78%|███████▊  | 132/169 [00:04<00:01, 29.14it/s]Testing:  80%|███████▉  | 135/169 [00:04<00:01, 29.25it/s]Testing:  82%|████████▏ | 138/169 [00:04<00:01, 29.35it/s]Testing:  83%|████████▎ | 141/169 [00:04<00:00, 29.35it/s]Testing:  85%|████████▌ | 144/169 [00:04<00:00, 29.24it/s]Testing:  87%|████████▋ | 147/169 [00:05<00:00, 29.30it/s]Testing:  89%|████████▉ | 150/169 [00:05<00:00, 29.42it/s]Testing:  91%|█████████ | 153/169 [00:05<00:00, 29.46it/s]Testing:  92%|█████████▏| 156/169 [00:05<00:00, 29.40it/s]Testing:  94%|█████████▍| 159/169 [00:05<00:00, 29.42it/s]Testing:  96%|█████████▌| 162/169 [00:05<00:00, 29.31it/s]Testing:  98%|█████████▊| 165/169 [00:05<00:00, 29.23it/s]Testing:  99%|█████████▉| 168/169 [00:05<00:00, 29.21it/s]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'_mean_accuracy': 0.984501302242279,
 '_standard_dev_accuracy': 0.03214376047253609,
 '_variance_accuracy': 0.00103322125505656,
 'test_acc': 0.984501302242279,
 'test_dice_c1': 0.0,
 'test_f2_c1': 0.0,
 'test_loss': 0.4280335605144501,
 'test_mean_c1': 0.0,
 'test_prec_c1': 0.0,
 'test_sens_c1': 0.0,
 'test_spec_c1': 1.0}
--------------------------------------------------------------------------------
Testing: 100%|██████████| 169/169 [00:05<00:00, 29.26it/s]
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

  | Name       | Type             | Params
------------------------------------------------
0 | encoder1   | EncoderBlock     | 37.6 K
1 | encoder2   | EncoderBlock     | 221 K 
2 | bottleneck | ConvolutionBlock | 885 K 
3 | dropout    | Dropout2d        | 0     
4 | decoder1   | DecoderBlock     | 573 K 
5 | decoder2   | DecoderBlock     | 143 K 
6 | conv       | Conv2d           | 130   
7 | softmax    | Softmax2d        | 0     
------------------------------------------------
1.9 M     Trainable params
0         Non-trainable params
1.9 M     Total params
7.447     Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  2.00it/s]Validation sanity check: 100%|██████████| 2/2 [00:00<00:00,  2.68it/s]                                                                      /home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Training: -1it [00:00, ?it/s]Training:   0%|          | 0/96 [00:00<00:00, 26546.23it/s]Epoch 0:   0%|          | 0/96 [00:00<00:00, 4021.38it/s]  Epoch 0:   1%|          | 1/96 [00:00<00:05, 15.95it/s]  Epoch 0:   1%|          | 1/96 [00:00<00:05, 15.90it/s, loss=0.683, v_num=13, train_loss_step=0.683]Epoch 0:   2%|▏         | 2/96 [00:00<00:07, 13.08it/s, loss=0.683, v_num=13, train_loss_step=0.683]Epoch 0:   2%|▏         | 2/96 [00:00<00:07, 13.06it/s, loss=0.682, v_num=13, train_loss_step=0.680]Epoch 0:   3%|▎         | 3/96 [00:00<00:07, 11.97it/s, loss=0.682, v_num=13, train_loss_step=0.680]Epoch 0:   3%|▎         | 3/96 [00:00<00:07, 11.95it/s, loss=0.675, v_num=13, train_loss_step=0.661]Epoch 0:   4%|▍         | 4/96 [00:00<00:08, 11.37it/s, loss=0.675, v_num=13, train_loss_step=0.661]Epoch 0:   4%|▍         | 4/96 [00:00<00:08, 11.36it/s, loss=0.672, v_num=13, train_loss_step=0.663]Epoch 0:   5%|▌         | 5/96 [00:00<00:08, 11.04it/s, loss=0.672, v_num=13, train_loss_step=0.663]Epoch 0:   5%|▌         | 5/96 [00:00<00:08, 11.03it/s, loss=0.671, v_num=13, train_loss_step=0.667]Epoch 0:   6%|▋         | 6/96 [00:00<00:08, 10.83it/s, loss=0.671, v_num=13, train_loss_step=0.667]Epoch 0:   6%|▋         | 6/96 [00:00<00:08, 10.82it/s, loss=0.661, v_num=13, train_loss_step=0.611]Epoch 0:   7%|▋         | 7/96 [00:00<00:08, 10.63it/s, loss=0.661, v_num=13, train_loss_step=0.611]Epoch 0:   7%|▋         | 7/96 [00:00<00:08, 10.62it/s, loss=0.649, v_num=13, train_loss_step=0.579]Epoch 0:   8%|▊         | 8/96 [00:00<00:08, 10.52it/s, loss=0.649, v_num=13, train_loss_step=0.579]Epoch 0:   8%|▊         | 8/96 [00:00<00:08, 10.51it/s, loss=0.641, v_num=13, train_loss_step=0.580]Epoch 0:   9%|▉         | 9/96 [00:00<00:08, 10.43it/s, loss=0.641, v_num=13, train_loss_step=0.580]Epoch 0:   9%|▉         | 9/96 [00:00<00:08, 10.42it/s, loss=0.631, v_num=13, train_loss_step=0.552]Epoch 0:  10%|█         | 10/96 [00:01<00:08, 10.36it/s, loss=0.631, v_num=13, train_loss_step=0.552]Epoch 0:  10%|█         | 10/96 [00:01<00:08, 10.35it/s, loss=0.611, v_num=13, train_loss_step=0.436]Epoch 0:  11%|█▏        | 11/96 [00:01<00:08, 10.30it/s, loss=0.611, v_num=13, train_loss_step=0.436]Epoch 0:  11%|█▏        | 11/96 [00:01<00:08, 10.29it/s, loss=0.592, v_num=13, train_loss_step=0.393]Epoch 0:  12%|█▎        | 12/96 [00:01<00:08, 10.24it/s, loss=0.592, v_num=13, train_loss_step=0.393]Epoch 0:  12%|█▎        | 12/96 [00:01<00:08, 10.24it/s, loss=0.576, v_num=13, train_loss_step=0.407]Epoch 0:  14%|█▎        | 13/96 [00:01<00:08, 10.20it/s, loss=0.576, v_num=13, train_loss_step=0.407]Epoch 0:  14%|█▎        | 13/96 [00:01<00:08, 10.20it/s, loss=0.566, v_num=13, train_loss_step=0.443]Epoch 0:  15%|█▍        | 14/96 [00:01<00:08, 10.16it/s, loss=0.566, v_num=13, train_loss_step=0.443]Epoch 0:  15%|█▍        | 14/96 [00:01<00:08, 10.16it/s, loss=0.553, v_num=13, train_loss_step=0.378]Epoch 0:  16%|█▌        | 15/96 [00:01<00:07, 10.13it/s, loss=0.553, v_num=13, train_loss_step=0.378]Epoch 0:  16%|█▌        | 15/96 [00:01<00:08, 10.12it/s, loss=0.544, v_num=13, train_loss_step=0.419]Epoch 0:  17%|█▋        | 16/96 [00:01<00:07, 10.09it/s, loss=0.544, v_num=13, train_loss_step=0.419]Epoch 0:  17%|█▋        | 16/96 [00:01<00:07, 10.09it/s, loss=0.536, v_num=13, train_loss_step=0.417]Epoch 0:  18%|█▊        | 17/96 [00:01<00:07, 10.06it/s, loss=0.536, v_num=13, train_loss_step=0.417]Epoch 0:  18%|█▊        | 17/96 [00:01<00:07, 10.06it/s, loss=0.527, v_num=13, train_loss_step=0.384]Epoch 0:  19%|█▉        | 18/96 [00:01<00:07, 10.03it/s, loss=0.527, v_num=13, train_loss_step=0.384]Epoch 0:  19%|█▉        | 18/96 [00:01<00:07, 10.03it/s, loss=0.521, v_num=13, train_loss_step=0.421]Epoch 0:  20%|█▉        | 19/96 [00:01<00:07, 10.02it/s, loss=0.521, v_num=13, train_loss_step=0.421]Epoch 0:  20%|█▉        | 19/96 [00:01<00:07, 10.01it/s, loss=0.515, v_num=13, train_loss_step=0.404]Epoch 0:  21%|██        | 20/96 [00:02<00:07,  9.99it/s, loss=0.515, v_num=13, train_loss_step=0.404]Epoch 0:  21%|██        | 20/96 [00:02<00:07,  9.99it/s, loss=0.508, v_num=13, train_loss_step=0.372]Epoch 0:  22%|██▏       | 21/96 [00:02<00:07,  9.98it/s, loss=0.508, v_num=13, train_loss_step=0.372]Epoch 0:  22%|██▏       | 21/96 [00:02<00:07,  9.98it/s, loss=0.495, v_num=13, train_loss_step=0.430]Epoch 0:  23%|██▎       | 22/96 [00:02<00:07,  9.96it/s, loss=0.495, v_num=13, train_loss_step=0.430]Epoch 0:  23%|██▎       | 22/96 [00:02<00:07,  9.96it/s, loss=0.479, v_num=13, train_loss_step=0.369]Epoch 0:  24%|██▍       | 23/96 [00:02<00:07,  9.95it/s, loss=0.479, v_num=13, train_loss_step=0.369]Epoch 0:  24%|██▍       | 23/96 [00:02<00:07,  9.95it/s, loss=0.465, v_num=13, train_loss_step=0.378]Epoch 0:  25%|██▌       | 24/96 [00:02<00:07,  9.93it/s, loss=0.465, v_num=13, train_loss_step=0.378]Epoch 0:  25%|██▌       | 24/96 [00:02<00:07,  9.93it/s, loss=0.45, v_num=13, train_loss_step=0.358] Epoch 0:  26%|██▌       | 25/96 [00:02<00:07,  9.92it/s, loss=0.45, v_num=13, train_loss_step=0.358]Epoch 0:  26%|██▌       | 25/96 [00:02<00:07,  9.92it/s, loss=0.435, v_num=13, train_loss_step=0.370]Epoch 0:  27%|██▋       | 26/96 [00:02<00:07,  9.91it/s, loss=0.435, v_num=13, train_loss_step=0.370]Epoch 0:  27%|██▋       | 26/96 [00:02<00:07,  9.91it/s, loss=0.424, v_num=13, train_loss_step=0.390]Epoch 0:  28%|██▊       | 27/96 [00:02<00:06,  9.89it/s, loss=0.424, v_num=13, train_loss_step=0.390]Epoch 0:  28%|██▊       | 27/96 [00:02<00:06,  9.89it/s, loss=0.415, v_num=13, train_loss_step=0.391]Epoch 0:  29%|██▉       | 28/96 [00:02<00:06,  9.89it/s, loss=0.415, v_num=13, train_loss_step=0.391]Epoch 0:  29%|██▉       | 28/96 [00:02<00:06,  9.88it/s, loss=0.408, v_num=13, train_loss_step=0.456]Epoch 0:  30%|███       | 29/96 [00:03<00:06,  9.88it/s, loss=0.408, v_num=13, train_loss_step=0.456]Epoch 0:  30%|███       | 29/96 [00:03<00:06,  9.88it/s, loss=0.401, v_num=13, train_loss_step=0.394]Epoch 0:  31%|███▏      | 30/96 [00:03<00:06,  9.87it/s, loss=0.401, v_num=13, train_loss_step=0.394]Epoch 0:  31%|███▏      | 30/96 [00:03<00:06,  9.87it/s, loss=0.399, v_num=13, train_loss_step=0.403]Epoch 0:  32%|███▏      | 31/96 [00:03<00:06,  9.86it/s, loss=0.399, v_num=13, train_loss_step=0.403]Epoch 0:  32%|███▏      | 31/96 [00:03<00:06,  9.86it/s, loss=0.399, v_num=13, train_loss_step=0.396]Epoch 0:  33%|███▎      | 32/96 [00:03<00:06,  9.85it/s, loss=0.399, v_num=13, train_loss_step=0.396]Epoch 0:  33%|███▎      | 32/96 [00:03<00:06,  9.85it/s, loss=0.397, v_num=13, train_loss_step=0.370]Epoch 0:  34%|███▍      | 33/96 [00:03<00:06,  9.85it/s, loss=0.397, v_num=13, train_loss_step=0.370]Epoch 0:  34%|███▍      | 33/96 [00:03<00:06,  9.85it/s, loss=0.395, v_num=13, train_loss_step=0.400]Epoch 0:  35%|███▌      | 34/96 [00:03<00:06,  9.84it/s, loss=0.395, v_num=13, train_loss_step=0.400]Epoch 0:  35%|███▌      | 34/96 [00:03<00:06,  9.83it/s, loss=0.396, v_num=13, train_loss_step=0.398]Epoch 0:  36%|███▋      | 35/96 [00:03<00:06,  9.83it/s, loss=0.396, v_num=13, train_loss_step=0.398]Epoch 0:  36%|███▋      | 35/96 [00:03<00:06,  9.83it/s, loss=0.394, v_num=13, train_loss_step=0.380]Epoch 0:  38%|███▊      | 36/96 [00:03<00:06,  9.82it/s, loss=0.394, v_num=13, train_loss_step=0.380]Epoch 0:  38%|███▊      | 36/96 [00:03<00:06,  9.82it/s, loss=0.393, v_num=13, train_loss_step=0.391]Epoch 0:  39%|███▊      | 37/96 [00:03<00:06,  9.82it/s, loss=0.393, v_num=13, train_loss_step=0.391]Epoch 0:  39%|███▊      | 37/96 [00:03<00:06,  9.82it/s, loss=0.392, v_num=13, train_loss_step=0.371]Epoch 0:  40%|███▉      | 38/96 [00:03<00:05,  9.81it/s, loss=0.392, v_num=13, train_loss_step=0.371]Epoch 0:  40%|███▉      | 38/96 [00:03<00:05,  9.81it/s, loss=0.39, v_num=13, train_loss_step=0.388] Epoch 0:  41%|████      | 39/96 [00:04<00:05,  9.80it/s, loss=0.39, v_num=13, train_loss_step=0.388]Epoch 0:  41%|████      | 39/96 [00:04<00:05,  9.80it/s, loss=0.388, v_num=13, train_loss_step=0.351]Epoch 0:  42%|████▏     | 40/96 [00:04<00:05,  9.79it/s, loss=0.388, v_num=13, train_loss_step=0.351]Epoch 0:  42%|████▏     | 40/96 [00:04<00:05,  9.79it/s, loss=0.39, v_num=13, train_loss_step=0.413] Epoch 0:  43%|████▎     | 41/96 [00:04<00:05,  9.79it/s, loss=0.39, v_num=13, train_loss_step=0.413]Epoch 0:  43%|████▎     | 41/96 [00:04<00:05,  9.79it/s, loss=0.387, v_num=13, train_loss_step=0.377]Epoch 0:  44%|████▍     | 42/96 [00:04<00:05,  9.78it/s, loss=0.387, v_num=13, train_loss_step=0.377]Epoch 0:  44%|████▍     | 42/96 [00:04<00:05,  9.78it/s, loss=0.387, v_num=13, train_loss_step=0.357]Epoch 0:  45%|████▍     | 43/96 [00:04<00:05,  9.78it/s, loss=0.387, v_num=13, train_loss_step=0.357]Epoch 0:  45%|████▍     | 43/96 [00:04<00:05,  9.78it/s, loss=0.386, v_num=13, train_loss_step=0.368]Epoch 0:  46%|████▌     | 44/96 [00:04<00:05,  9.77it/s, loss=0.386, v_num=13, train_loss_step=0.368]Epoch 0:  46%|████▌     | 44/96 [00:04<00:05,  9.77it/s, loss=0.387, v_num=13, train_loss_step=0.386]Epoch 0:  47%|████▋     | 45/96 [00:04<00:05,  9.77it/s, loss=0.387, v_num=13, train_loss_step=0.386]Epoch 0:  47%|████▋     | 45/96 [00:04<00:05,  9.77it/s, loss=0.387, v_num=13, train_loss_step=0.353]Epoch 0:  48%|████▊     | 46/96 [00:04<00:05,  9.76it/s, loss=0.387, v_num=13, train_loss_step=0.353]Epoch 0:  48%|████▊     | 46/96 [00:04<00:05,  9.76it/s, loss=0.386, v_num=13, train_loss_step=0.385]Epoch 0:  49%|████▉     | 47/96 [00:04<00:05,  9.76it/s, loss=0.386, v_num=13, train_loss_step=0.385]Epoch 0:  49%|████▉     | 47/96 [00:04<00:05,  9.76it/s, loss=0.385, v_num=13, train_loss_step=0.370]Epoch 0:  50%|█████     | 48/96 [00:05<00:04,  9.76it/s, loss=0.385, v_num=13, train_loss_step=0.370]Epoch 0:  50%|█████     | 48/96 [00:05<00:04,  9.75it/s, loss=0.381, v_num=13, train_loss_step=0.375]Epoch 0:  51%|█████     | 49/96 [00:05<00:04,  9.75it/s, loss=0.381, v_num=13, train_loss_step=0.375]Epoch 0:  51%|█████     | 49/96 [00:05<00:04,  9.75it/s, loss=0.382, v_num=13, train_loss_step=0.411]Epoch 0:  52%|█████▏    | 50/96 [00:05<00:04,  9.75it/s, loss=0.382, v_num=13, train_loss_step=0.411]Epoch 0:  52%|█████▏    | 50/96 [00:05<00:04,  9.75it/s, loss=0.38, v_num=13, train_loss_step=0.355] Epoch 0:  53%|█████▎    | 51/96 [00:05<00:04,  9.75it/s, loss=0.38, v_num=13, train_loss_step=0.355]Epoch 0:  53%|█████▎    | 51/96 [00:05<00:04,  9.74it/s, loss=0.379, v_num=13, train_loss_step=0.384]Epoch 0:  54%|█████▍    | 52/96 [00:05<00:04,  9.74it/s, loss=0.379, v_num=13, train_loss_step=0.384]Epoch 0:  54%|█████▍    | 52/96 [00:05<00:04,  9.74it/s, loss=0.379, v_num=13, train_loss_step=0.375]Epoch 0:  55%|█████▌    | 53/96 [00:05<00:04,  9.74it/s, loss=0.379, v_num=13, train_loss_step=0.375]Epoch 0:  55%|█████▌    | 53/96 [00:05<00:04,  9.73it/s, loss=0.378, v_num=13, train_loss_step=0.364]Epoch 0:  56%|█████▋    | 54/96 [00:05<00:04,  9.73it/s, loss=0.378, v_num=13, train_loss_step=0.364]Epoch 0:  56%|█████▋    | 54/96 [00:05<00:04,  9.73it/s, loss=0.379, v_num=13, train_loss_step=0.422]Epoch 0:  57%|█████▋    | 55/96 [00:05<00:04,  9.73it/s, loss=0.379, v_num=13, train_loss_step=0.422]Epoch 0:  57%|█████▋    | 55/96 [00:05<00:04,  9.73it/s, loss=0.378, v_num=13, train_loss_step=0.356]Epoch 0:  58%|█████▊    | 56/96 [00:05<00:04,  9.73it/s, loss=0.378, v_num=13, train_loss_step=0.356]Epoch 0:  58%|█████▊    | 56/96 [00:05<00:04,  9.73it/s, loss=0.376, v_num=13, train_loss_step=0.358]Epoch 0:  59%|█████▉    | 57/96 [00:05<00:04,  9.73it/s, loss=0.376, v_num=13, train_loss_step=0.358]Epoch 0:  59%|█████▉    | 57/96 [00:05<00:04,  9.73it/s, loss=0.376, v_num=13, train_loss_step=0.380]Epoch 0:  60%|██████    | 58/96 [00:06<00:03,  9.73it/s, loss=0.376, v_num=13, train_loss_step=0.380]Epoch 0:  60%|██████    | 58/96 [00:06<00:03,  9.73it/s, loss=0.375, v_num=13, train_loss_step=0.358]Epoch 0:  61%|██████▏   | 59/96 [00:06<00:03,  9.72it/s, loss=0.375, v_num=13, train_loss_step=0.358]Epoch 0:  61%|██████▏   | 59/96 [00:06<00:03,  9.72it/s, loss=0.378, v_num=13, train_loss_step=0.404]Epoch 0:  62%|██████▎   | 60/96 [00:06<00:03,  9.71it/s, loss=0.378, v_num=13, train_loss_step=0.404]Epoch 0:  62%|██████▎   | 60/96 [00:06<00:03,  9.71it/s, loss=0.374, v_num=13, train_loss_step=0.341]Epoch 0:  64%|██████▎   | 61/96 [00:06<00:03,  9.71it/s, loss=0.374, v_num=13, train_loss_step=0.341]Epoch 0:  64%|██████▎   | 61/96 [00:06<00:03,  9.71it/s, loss=0.373, v_num=13, train_loss_step=0.362]Epoch 0:  65%|██████▍   | 62/96 [00:06<00:03,  9.71it/s, loss=0.373, v_num=13, train_loss_step=0.362]Epoch 0:  65%|██████▍   | 62/96 [00:06<00:03,  9.71it/s, loss=0.374, v_num=13, train_loss_step=0.377]Epoch 0:  66%|██████▌   | 63/96 [00:06<00:03,  9.70it/s, loss=0.374, v_num=13, train_loss_step=0.377]Epoch 0:  66%|██████▌   | 63/96 [00:06<00:03,  9.70it/s, loss=0.374, v_num=13, train_loss_step=0.357]Epoch 0:  67%|██████▋   | 64/96 [00:06<00:03,  9.70it/s, loss=0.374, v_num=13, train_loss_step=0.357]Epoch 0:  67%|██████▋   | 64/96 [00:06<00:03,  9.70it/s, loss=0.373, v_num=13, train_loss_step=0.377]Epoch 0:  68%|██████▊   | 65/96 [00:06<00:03,  9.70it/s, loss=0.373, v_num=13, train_loss_step=0.377]Epoch 0:  68%|██████▊   | 65/96 [00:06<00:03,  9.70it/s, loss=0.374, v_num=13, train_loss_step=0.369]Epoch 0:  69%|██████▉   | 66/96 [00:06<00:03,  9.70it/s, loss=0.374, v_num=13, train_loss_step=0.369]Epoch 0:  69%|██████▉   | 66/96 [00:06<00:03,  9.70it/s, loss=0.373, v_num=13, train_loss_step=0.365]Epoch 0:  70%|██████▉   | 67/96 [00:07<00:02,  9.70it/s, loss=0.373, v_num=13, train_loss_step=0.365]Epoch 0:  70%|██████▉   | 67/96 [00:07<00:02,  9.70it/s, loss=0.373, v_num=13, train_loss_step=0.364]Epoch 0:  71%|███████   | 68/96 [00:07<00:02,  9.70it/s, loss=0.373, v_num=13, train_loss_step=0.364]Epoch 0:  71%|███████   | 68/96 [00:07<00:02,  9.70it/s, loss=0.372, v_num=13, train_loss_step=0.360]Epoch 0:  72%|███████▏  | 69/96 [00:07<00:02,  9.70it/s, loss=0.372, v_num=13, train_loss_step=0.360]Epoch 0:  72%|███████▏  | 69/96 [00:07<00:02,  9.70it/s, loss=0.37, v_num=13, train_loss_step=0.364] Epoch 0:  73%|███████▎  | 70/96 [00:07<00:02,  9.69it/s, loss=0.37, v_num=13, train_loss_step=0.364]Epoch 0:  73%|███████▎  | 70/96 [00:07<00:02,  9.69it/s, loss=0.369, v_num=13, train_loss_step=0.352]Epoch 0:  74%|███████▍  | 71/96 [00:07<00:02,  9.69it/s, loss=0.369, v_num=13, train_loss_step=0.352]Epoch 0:  74%|███████▍  | 71/96 [00:07<00:02,  9.69it/s, loss=0.367, v_num=13, train_loss_step=0.341]Epoch 0:  75%|███████▌  | 72/96 [00:07<00:02,  9.68it/s, loss=0.367, v_num=13, train_loss_step=0.341]Epoch 0:  75%|███████▌  | 72/96 [00:07<00:02,  9.68it/s, loss=0.365, v_num=13, train_loss_step=0.332]Epoch 0:  76%|███████▌  | 73/96 [00:07<00:02,  9.68it/s, loss=0.365, v_num=13, train_loss_step=0.332]Epoch 0:  76%|███████▌  | 73/96 [00:07<00:02,  9.68it/s, loss=0.367, v_num=13, train_loss_step=0.404]Epoch 0:  77%|███████▋  | 74/96 [00:07<00:02,  9.68it/s, loss=0.367, v_num=13, train_loss_step=0.404]Epoch 0:  77%|███████▋  | 74/96 [00:07<00:02,  9.68it/s, loss=0.365, v_num=13, train_loss_step=0.373]Epoch 0:  78%|███████▊  | 75/96 [00:07<00:02,  9.68it/s, loss=0.365, v_num=13, train_loss_step=0.373]Epoch 0:  78%|███████▊  | 75/96 [00:07<00:02,  9.68it/s, loss=0.366, v_num=13, train_loss_step=0.381]Epoch 0:  79%|███████▉  | 76/96 [00:07<00:02,  9.68it/s, loss=0.366, v_num=13, train_loss_step=0.381]Epoch 0:  79%|███████▉  | 76/96 [00:07<00:02,  9.68it/s, loss=0.365, v_num=13, train_loss_step=0.334]Epoch 0:  80%|████████  | 77/96 [00:08<00:01,  9.68it/s, loss=0.365, v_num=13, train_loss_step=0.334]Epoch 0:  80%|████████  | 77/96 [00:08<00:01,  9.68it/s, loss=0.365, v_num=13, train_loss_step=0.388]Epoch 0:  81%|████████▏ | 78/96 [00:08<00:01,  9.68it/s, loss=0.365, v_num=13, train_loss_step=0.388]Epoch 0:  81%|████████▏ | 78/96 [00:08<00:01,  9.68it/s, loss=0.364, v_num=13, train_loss_step=0.331]Epoch 0:  82%|████████▏ | 79/96 [00:08<00:01,  9.68it/s, loss=0.364, v_num=13, train_loss_step=0.331]Epoch 0:  82%|████████▏ | 79/96 [00:08<00:01,  9.68it/s, loss=0.36, v_num=13, train_loss_step=0.338] Epoch 0:  83%|████████▎ | 80/96 [00:08<00:01,  9.68it/s, loss=0.36, v_num=13, train_loss_step=0.338]Epoch 0:  83%|████████▎ | 80/96 [00:08<00:01,  9.68it/s, loss=0.362, v_num=13, train_loss_step=0.376]Epoch 0:  84%|████████▍ | 81/96 [00:08<00:01,  9.68it/s, loss=0.362, v_num=13, train_loss_step=0.376]Epoch 0:  84%|████████▍ | 81/96 [00:08<00:01,  9.68it/s, loss=0.361, v_num=13, train_loss_step=0.343]Epoch 0:  85%|████████▌ | 82/96 [00:08<00:01,  9.68it/s, loss=0.361, v_num=13, train_loss_step=0.343]Epoch 0:  85%|████████▌ | 82/96 [00:08<00:01,  9.68it/s, loss=0.362, v_num=13, train_loss_step=0.387]Epoch 0:  86%|████████▋ | 83/96 [00:08<00:01,  9.69it/s, loss=0.361, v_num=13, train_loss_step=0.349]Epoch 0:  88%|████████▊ | 84/96 [00:08<00:01,  9.75it/s, loss=0.361, v_num=13, train_loss_step=0.349]Epoch 0:  88%|████████▊ | 84/96 [00:08<00:01,  9.75it/s, loss=0.359, v_num=13, train_loss_step=0.331]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/12 [00:00<?, ?it/s][A
Validating:   8%|▊         | 1/12 [00:00<00:03,  3.46it/s][AEpoch 0:  90%|████████▉ | 86/96 [00:09<00:01,  9.65it/s, loss=0.359, v_num=13, train_loss_step=0.331]
Validating:  17%|█▋        | 2/12 [00:00<00:02,  3.50it/s][A
Validating:  25%|██▌       | 3/12 [00:00<00:02,  3.54it/s][AEpoch 0:  92%|█████████▏| 88/96 [00:09<00:00,  9.30it/s, loss=0.359, v_num=13, train_loss_step=0.331]
Validating:  33%|███▎      | 4/12 [00:01<00:02,  3.55it/s][A
Validating:  42%|████▏     | 5/12 [00:01<00:01,  3.54it/s][AEpoch 0:  94%|█████████▍| 90/96 [00:10<00:00,  8.98it/s, loss=0.359, v_num=13, train_loss_step=0.331]
Validating:  50%|█████     | 6/12 [00:01<00:01,  3.55it/s][A
Validating:  58%|█████▊    | 7/12 [00:01<00:01,  3.56it/s][AEpoch 0:  96%|█████████▌| 92/96 [00:10<00:00,  8.69it/s, loss=0.359, v_num=13, train_loss_step=0.331]
Validating:  67%|██████▋   | 8/12 [00:02<00:01,  3.56it/s][A
Validating:  75%|███████▌  | 9/12 [00:02<00:00,  3.55it/s][AEpoch 0:  98%|█████████▊| 94/96 [00:11<00:00,  8.44it/s, loss=0.359, v_num=13, train_loss_step=0.331]
Validating:  83%|████████▎ | 10/12 [00:02<00:00,  3.54it/s][A
Validating:  92%|█████████▏| 11/12 [00:03<00:00,  3.55it/s][AEpoch 0: 100%|██████████| 96/96 [00:11<00:00,  8.20it/s, loss=0.359, v_num=13, train_loss_step=0.331]
Validating: 100%|██████████| 12/12 [00:03<00:00,  4.18it/s][AEpoch 0: 100%|██████████| 96/96 [00:11<00:00,  8.10it/s, loss=0.359, v_num=13, train_loss_step=0.331]
                                                           [AEpoch 0: 100%|██████████| 96/96 [00:12<00:00,  8.08it/s, loss=0.359, v_num=13, train_loss_step=0.331]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(

Testing: 0it [00:00, ?it/s]Testing:   2%|▏         | 3/169 [00:00<00:06, 26.03it/s]Testing:   4%|▎         | 6/169 [00:00<00:05, 27.95it/s]Testing:   5%|▌         | 9/169 [00:00<00:05, 28.62it/s]Testing:   7%|▋         | 12/169 [00:00<00:05, 28.58it/s]Testing:   9%|▉         | 15/169 [00:00<00:05, 28.85it/s]Testing:  11%|█         | 18/169 [00:00<00:05, 29.11it/s]Testing:  12%|█▏        | 21/169 [00:00<00:05, 29.22it/s]Testing:  14%|█▍        | 24/169 [00:00<00:04, 29.33it/s]Testing:  16%|█▌        | 27/169 [00:00<00:04, 29.34it/s]Testing:  18%|█▊        | 30/169 [00:01<00:04, 29.31it/s]Testing:  20%|█▉        | 33/169 [00:01<00:04, 29.39it/s]Testing:  21%|██▏       | 36/169 [00:01<00:04, 29.40it/s]Testing:  23%|██▎       | 39/169 [00:01<00:04, 29.38it/s]Testing:  25%|██▍       | 42/169 [00:01<00:04, 29.29it/s]Testing:  27%|██▋       | 45/169 [00:01<00:04, 29.36it/s]Testing:  28%|██▊       | 48/169 [00:01<00:04, 29.23it/s]Testing:  30%|███       | 51/169 [00:01<00:04, 29.18it/s]Testing:  32%|███▏      | 54/169 [00:01<00:03, 29.33it/s]Testing:  34%|███▎      | 57/169 [00:01<00:03, 29.35it/s]Testing:  36%|███▌      | 60/169 [00:02<00:03, 29.44it/s]Testing:  37%|███▋      | 63/169 [00:02<00:03, 29.40it/s]Testing:  39%|███▉      | 66/169 [00:02<00:03, 29.34it/s]Testing:  41%|████      | 69/169 [00:02<00:03, 29.37it/s]Testing:  43%|████▎     | 72/169 [00:02<00:03, 29.39it/s]Testing:  44%|████▍     | 75/169 [00:02<00:03, 29.29it/s]Testing:  46%|████▌     | 78/169 [00:02<00:03, 29.31it/s]Testing:  48%|████▊     | 81/169 [00:02<00:03, 29.25it/s]Testing:  50%|████▉     | 84/169 [00:02<00:02, 29.09it/s]Testing:  51%|█████▏    | 87/169 [00:02<00:02, 29.07it/s]Testing:  53%|█████▎    | 90/169 [00:03<00:02, 28.98it/s]Testing:  55%|█████▌    | 93/169 [00:03<00:02, 29.05it/s]Testing:  57%|█████▋    | 96/169 [00:03<00:02, 29.03it/s]Testing:  59%|█████▊    | 99/169 [00:03<00:02, 28.97it/s]Testing:  60%|██████    | 102/169 [00:03<00:02, 28.98it/s]Testing:  62%|██████▏   | 105/169 [00:03<00:02, 28.88it/s]Testing:  64%|██████▍   | 108/169 [00:03<00:02, 28.91it/s]Testing:  66%|██████▌   | 111/169 [00:03<00:02, 28.82it/s]Testing:  67%|██████▋   | 114/169 [00:03<00:01, 28.99it/s]Testing:  69%|██████▉   | 117/169 [00:04<00:01, 28.96it/s]Testing:  71%|███████   | 120/169 [00:04<00:01, 28.86it/s]Testing:  73%|███████▎  | 123/169 [00:04<00:01, 28.85it/s]Testing:  75%|███████▍  | 126/169 [00:04<00:01, 28.81it/s]Testing:  76%|███████▋  | 129/169 [00:04<00:01, 28.73it/s]Testing:  78%|███████▊  | 132/169 [00:04<00:01, 28.87it/s]Testing:  80%|███████▉  | 135/169 [00:04<00:01, 28.91it/s]Testing:  82%|████████▏ | 138/169 [00:04<00:01, 28.93it/s]Testing:  83%|████████▎ | 141/169 [00:04<00:00, 28.99it/s]Testing:  85%|████████▌ | 144/169 [00:04<00:00, 29.03it/s]Testing:  87%|████████▋ | 147/169 [00:05<00:00, 29.01it/s]Testing:  89%|████████▉ | 150/169 [00:05<00:00, 28.97it/s]Testing:  91%|█████████ | 153/169 [00:05<00:00, 29.05it/s]Testing:  92%|█████████▏| 156/169 [00:05<00:00, 28.77it/s]Testing:  94%|█████████▍| 159/169 [00:05<00:00, 28.89it/s]Testing:  96%|█████████▌| 162/169 [00:05<00:00, 28.91it/s]Testing:  98%|█████████▊| 165/169 [00:05<00:00, 28.98it/s]Testing:  99%|█████████▉| 168/169 [00:05<00:00, 28.90it/s]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'_mean_accuracy': 0.9634290337562561,
 '_standard_dev_accuracy': 0.03662344440817833,
 '_variance_accuracy': 0.0013412765692919493,
 'test_acc': 0.9634290337562561,
 'test_dice_c1': 0.22916245460510254,
 'test_f2_c1': 0.2827591001987457,
 'test_loss': 0.3575444519519806,
 'test_mean_c1': 0.4434959292411804,
 'test_prec_c1': 0.19809293746948242,
 'test_sens_c1': 0.42166560888290405,
 'test_spec_c1': 0.9653062224388123}
--------------------------------------------------------------------------------
Testing: 100%|██████████| 169/169 [00:05<00:00, 29.02it/s]
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

  | Name       | Type             | Params
------------------------------------------------
0 | encoder1   | EncoderBlock     | 37.6 K
1 | encoder2   | EncoderBlock     | 221 K 
2 | bottleneck | ConvolutionBlock | 885 K 
3 | dropout    | Dropout2d        | 0     
4 | decoder1   | DecoderBlock     | 573 K 
5 | decoder2   | DecoderBlock     | 143 K 
6 | conv       | Conv2d           | 130   
7 | softmax    | Softmax2d        | 0     
------------------------------------------------
1.9 M     Trainable params
0         Non-trainable params
1.9 M     Total params
7.447     Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  1.53it/s]Validation sanity check: 100%|██████████| 2/2 [00:01<00:00,  1.92it/s]                                                                      /home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Training: -1it [00:00, ?it/s]Training:   0%|          | 0/64 [00:00<00:00, 27235.74it/s]Epoch 0:   0%|          | 0/64 [00:00<00:00, 4112.06it/s]  Epoch 0:   2%|▏         | 1/64 [00:00<00:06,  9.76it/s]  Epoch 0:   2%|▏         | 1/64 [00:00<00:06,  9.74it/s, loss=0.689, v_num=14, train_loss_step=0.689]Epoch 0:   3%|▎         | 2/64 [00:00<00:07,  8.13it/s, loss=0.689, v_num=14, train_loss_step=0.689]Epoch 0:   3%|▎         | 2/64 [00:00<00:07,  8.12it/s, loss=0.686, v_num=14, train_loss_step=0.684]Epoch 0:   5%|▍         | 3/64 [00:00<00:08,  7.58it/s, loss=0.686, v_num=14, train_loss_step=0.684]Epoch 0:   5%|▍         | 3/64 [00:00<00:08,  7.57it/s, loss=0.683, v_num=14, train_loss_step=0.675]Epoch 0:   6%|▋         | 4/64 [00:00<00:08,  7.30it/s, loss=0.683, v_num=14, train_loss_step=0.675]Epoch 0:   6%|▋         | 4/64 [00:00<00:08,  7.29it/s, loss=0.68, v_num=14, train_loss_step=0.671] Epoch 0:   8%|▊         | 5/64 [00:00<00:08,  7.12it/s, loss=0.68, v_num=14, train_loss_step=0.671]Epoch 0:   8%|▊         | 5/64 [00:00<00:08,  7.12it/s, loss=0.674, v_num=14, train_loss_step=0.653]Epoch 0:   9%|▉         | 6/64 [00:00<00:08,  7.01it/s, loss=0.674, v_num=14, train_loss_step=0.653]Epoch 0:   9%|▉         | 6/64 [00:00<00:08,  7.01it/s, loss=0.67, v_num=14, train_loss_step=0.647] Epoch 0:  11%|█         | 7/64 [00:01<00:08,  6.93it/s, loss=0.67, v_num=14, train_loss_step=0.647]Epoch 0:  11%|█         | 7/64 [00:01<00:08,  6.93it/s, loss=0.662, v_num=14, train_loss_step=0.617]Epoch 0:  12%|█▎        | 8/64 [00:01<00:08,  6.85it/s, loss=0.662, v_num=14, train_loss_step=0.617]Epoch 0:  12%|█▎        | 8/64 [00:01<00:08,  6.85it/s, loss=0.652, v_num=14, train_loss_step=0.579]Epoch 0:  14%|█▍        | 9/64 [00:01<00:08,  6.80it/s, loss=0.652, v_num=14, train_loss_step=0.579]Epoch 0:  14%|█▍        | 9/64 [00:01<00:08,  6.79it/s, loss=0.643, v_num=14, train_loss_step=0.568]Epoch 0:  16%|█▌        | 10/64 [00:01<00:07,  6.76it/s, loss=0.643, v_num=14, train_loss_step=0.568]Epoch 0:  16%|█▌        | 10/64 [00:01<00:07,  6.76it/s, loss=0.626, v_num=14, train_loss_step=0.479]Epoch 0:  17%|█▋        | 11/64 [00:01<00:07,  6.72it/s, loss=0.626, v_num=14, train_loss_step=0.479]Epoch 0:  17%|█▋        | 11/64 [00:01<00:07,  6.72it/s, loss=0.604, v_num=14, train_loss_step=0.382]Epoch 0:  19%|█▉        | 12/64 [00:01<00:07,  6.69it/s, loss=0.604, v_num=14, train_loss_step=0.382]Epoch 0:  19%|█▉        | 12/64 [00:01<00:07,  6.69it/s, loss=0.59, v_num=14, train_loss_step=0.435] Epoch 0:  20%|██        | 13/64 [00:02<00:07,  6.66it/s, loss=0.59, v_num=14, train_loss_step=0.435]Epoch 0:  20%|██        | 13/64 [00:02<00:07,  6.66it/s, loss=0.572, v_num=14, train_loss_step=0.354]Epoch 0:  22%|██▏       | 14/64 [00:02<00:07,  6.63it/s, loss=0.572, v_num=14, train_loss_step=0.354]Epoch 0:  22%|██▏       | 14/64 [00:02<00:07,  6.63it/s, loss=0.56, v_num=14, train_loss_step=0.404] Epoch 0:  23%|██▎       | 15/64 [00:02<00:07,  6.61it/s, loss=0.56, v_num=14, train_loss_step=0.404]Epoch 0:  23%|██▎       | 15/64 [00:02<00:07,  6.61it/s, loss=0.548, v_num=14, train_loss_step=0.387]Epoch 0:  25%|██▌       | 16/64 [00:02<00:07,  6.59it/s, loss=0.548, v_num=14, train_loss_step=0.387]Epoch 0:  25%|██▌       | 16/64 [00:02<00:07,  6.59it/s, loss=0.538, v_num=14, train_loss_step=0.379]Epoch 0:  27%|██▋       | 17/64 [00:02<00:07,  6.57it/s, loss=0.538, v_num=14, train_loss_step=0.379]Epoch 0:  27%|██▋       | 17/64 [00:02<00:07,  6.57it/s, loss=0.529, v_num=14, train_loss_step=0.389]Epoch 0:  28%|██▊       | 18/64 [00:02<00:07,  6.56it/s, loss=0.529, v_num=14, train_loss_step=0.389]Epoch 0:  28%|██▊       | 18/64 [00:02<00:07,  6.56it/s, loss=0.521, v_num=14, train_loss_step=0.394]Epoch 0:  30%|██▉       | 19/64 [00:03<00:06,  6.55it/s, loss=0.521, v_num=14, train_loss_step=0.394]Epoch 0:  30%|██▉       | 19/64 [00:03<00:06,  6.55it/s, loss=0.515, v_num=14, train_loss_step=0.389]Epoch 0:  31%|███▏      | 20/64 [00:03<00:06,  6.54it/s, loss=0.515, v_num=14, train_loss_step=0.389]Epoch 0:  31%|███▏      | 20/64 [00:03<00:06,  6.54it/s, loss=0.508, v_num=14, train_loss_step=0.385]Epoch 0:  33%|███▎      | 21/64 [00:03<00:06,  6.53it/s, loss=0.508, v_num=14, train_loss_step=0.385]Epoch 0:  33%|███▎      | 21/64 [00:03<00:06,  6.53it/s, loss=0.493, v_num=14, train_loss_step=0.390]Epoch 0:  34%|███▍      | 22/64 [00:03<00:06,  6.52it/s, loss=0.493, v_num=14, train_loss_step=0.390]Epoch 0:  34%|███▍      | 22/64 [00:03<00:06,  6.52it/s, loss=0.478, v_num=14, train_loss_step=0.380]Epoch 0:  36%|███▌      | 23/64 [00:03<00:06,  6.51it/s, loss=0.478, v_num=14, train_loss_step=0.380]Epoch 0:  36%|███▌      | 23/64 [00:03<00:06,  6.50it/s, loss=0.463, v_num=14, train_loss_step=0.388]Epoch 0:  38%|███▊      | 24/64 [00:03<00:06,  6.50it/s, loss=0.463, v_num=14, train_loss_step=0.388]Epoch 0:  38%|███▊      | 24/64 [00:03<00:06,  6.50it/s, loss=0.449, v_num=14, train_loss_step=0.388]Epoch 0:  39%|███▉      | 25/64 [00:04<00:06,  6.49it/s, loss=0.449, v_num=14, train_loss_step=0.388]Epoch 0:  39%|███▉      | 25/64 [00:04<00:06,  6.49it/s, loss=0.436, v_num=14, train_loss_step=0.389]Epoch 0:  41%|████      | 26/64 [00:04<00:05,  6.48it/s, loss=0.436, v_num=14, train_loss_step=0.389]Epoch 0:  41%|████      | 26/64 [00:04<00:05,  6.48it/s, loss=0.422, v_num=14, train_loss_step=0.355]Epoch 0:  42%|████▏     | 27/64 [00:04<00:05,  6.47it/s, loss=0.422, v_num=14, train_loss_step=0.355]Epoch 0:  42%|████▏     | 27/64 [00:04<00:05,  6.47it/s, loss=0.412, v_num=14, train_loss_step=0.422]Epoch 0:  44%|████▍     | 28/64 [00:04<00:05,  6.47it/s, loss=0.412, v_num=14, train_loss_step=0.422]Epoch 0:  44%|████▍     | 28/64 [00:04<00:05,  6.47it/s, loss=0.403, v_num=14, train_loss_step=0.404]Epoch 0:  45%|████▌     | 29/64 [00:04<00:05,  6.46it/s, loss=0.403, v_num=14, train_loss_step=0.404]Epoch 0:  45%|████▌     | 29/64 [00:04<00:05,  6.46it/s, loss=0.393, v_num=14, train_loss_step=0.363]Epoch 0:  47%|████▋     | 30/64 [00:04<00:05,  6.46it/s, loss=0.393, v_num=14, train_loss_step=0.363]Epoch 0:  47%|████▋     | 30/64 [00:04<00:05,  6.46it/s, loss=0.388, v_num=14, train_loss_step=0.387]Epoch 0:  48%|████▊     | 31/64 [00:04<00:05,  6.45it/s, loss=0.388, v_num=14, train_loss_step=0.387]Epoch 0:  48%|████▊     | 31/64 [00:04<00:05,  6.45it/s, loss=0.388, v_num=14, train_loss_step=0.386]Epoch 0:  50%|█████     | 32/64 [00:05<00:04,  6.44it/s, loss=0.388, v_num=14, train_loss_step=0.386]Epoch 0:  50%|█████     | 32/64 [00:05<00:04,  6.44it/s, loss=0.387, v_num=14, train_loss_step=0.399]Epoch 0:  52%|█████▏    | 33/64 [00:05<00:04,  6.44it/s, loss=0.387, v_num=14, train_loss_step=0.399]Epoch 0:  52%|█████▏    | 33/64 [00:05<00:04,  6.44it/s, loss=0.388, v_num=14, train_loss_step=0.390]Epoch 0:  53%|█████▎    | 34/64 [00:05<00:04,  6.44it/s, loss=0.388, v_num=14, train_loss_step=0.390]Epoch 0:  53%|█████▎    | 34/64 [00:05<00:04,  6.44it/s, loss=0.387, v_num=14, train_loss_step=0.372]Epoch 0:  55%|█████▍    | 35/64 [00:05<00:04,  6.43it/s, loss=0.387, v_num=14, train_loss_step=0.372]Epoch 0:  55%|█████▍    | 35/64 [00:05<00:04,  6.43it/s, loss=0.388, v_num=14, train_loss_step=0.409]Epoch 0:  56%|█████▋    | 36/64 [00:05<00:04,  6.43it/s, loss=0.388, v_num=14, train_loss_step=0.409]Epoch 0:  56%|█████▋    | 36/64 [00:05<00:04,  6.43it/s, loss=0.387, v_num=14, train_loss_step=0.358]Epoch 0:  58%|█████▊    | 37/64 [00:05<00:04,  6.42it/s, loss=0.387, v_num=14, train_loss_step=0.358]Epoch 0:  58%|█████▊    | 37/64 [00:05<00:04,  6.42it/s, loss=0.39, v_num=14, train_loss_step=0.454] Epoch 0:  59%|█████▉    | 38/64 [00:06<00:04,  6.41it/s, loss=0.39, v_num=14, train_loss_step=0.454]Epoch 0:  59%|█████▉    | 38/64 [00:06<00:04,  6.41it/s, loss=0.388, v_num=14, train_loss_step=0.354]Epoch 0:  61%|██████    | 39/64 [00:06<00:03,  6.41it/s, loss=0.388, v_num=14, train_loss_step=0.354]Epoch 0:  61%|██████    | 39/64 [00:06<00:03,  6.41it/s, loss=0.387, v_num=14, train_loss_step=0.369]Epoch 0:  62%|██████▎   | 40/64 [00:06<00:03,  6.41it/s, loss=0.387, v_num=14, train_loss_step=0.369]Epoch 0:  62%|██████▎   | 40/64 [00:06<00:03,  6.41it/s, loss=0.387, v_num=14, train_loss_step=0.376]Epoch 0:  64%|██████▍   | 41/64 [00:06<00:03,  6.40it/s, loss=0.387, v_num=14, train_loss_step=0.376]Epoch 0:  64%|██████▍   | 41/64 [00:06<00:03,  6.40it/s, loss=0.386, v_num=14, train_loss_step=0.376]Epoch 0:  66%|██████▌   | 42/64 [00:06<00:03,  6.40it/s, loss=0.386, v_num=14, train_loss_step=0.376]Epoch 0:  66%|██████▌   | 42/64 [00:06<00:03,  6.40it/s, loss=0.387, v_num=14, train_loss_step=0.390]Epoch 0:  67%|██████▋   | 43/64 [00:06<00:03,  6.40it/s, loss=0.387, v_num=14, train_loss_step=0.390]Epoch 0:  67%|██████▋   | 43/64 [00:06<00:03,  6.40it/s, loss=0.385, v_num=14, train_loss_step=0.363]Epoch 0:  69%|██████▉   | 44/64 [00:07<00:03,  6.40it/s, loss=0.385, v_num=14, train_loss_step=0.363]Epoch 0:  69%|██████▉   | 44/64 [00:07<00:03,  6.40it/s, loss=0.385, v_num=14, train_loss_step=0.378]Epoch 0:  70%|███████   | 45/64 [00:07<00:02,  6.40it/s, loss=0.385, v_num=14, train_loss_step=0.378]Epoch 0:  70%|███████   | 45/64 [00:07<00:02,  6.39it/s, loss=0.384, v_num=14, train_loss_step=0.380]Epoch 0:  72%|███████▏  | 46/64 [00:07<00:02,  6.39it/s, loss=0.384, v_num=14, train_loss_step=0.380]Epoch 0:  72%|███████▏  | 46/64 [00:07<00:02,  6.39it/s, loss=0.385, v_num=14, train_loss_step=0.375]Epoch 0:  73%|███████▎  | 47/64 [00:07<00:02,  6.39it/s, loss=0.385, v_num=14, train_loss_step=0.375]Epoch 0:  73%|███████▎  | 47/64 [00:07<00:02,  6.39it/s, loss=0.385, v_num=14, train_loss_step=0.408]Epoch 0:  75%|███████▌  | 48/64 [00:07<00:02,  6.39it/s, loss=0.385, v_num=14, train_loss_step=0.408]Epoch 0:  75%|███████▌  | 48/64 [00:07<00:02,  6.39it/s, loss=0.382, v_num=14, train_loss_step=0.348]Epoch 0:  77%|███████▋  | 49/64 [00:07<00:02,  6.39it/s, loss=0.382, v_num=14, train_loss_step=0.348]Epoch 0:  77%|███████▋  | 49/64 [00:07<00:02,  6.39it/s, loss=0.381, v_num=14, train_loss_step=0.357]Epoch 0:  78%|███████▊  | 50/64 [00:07<00:02,  6.39it/s, loss=0.381, v_num=14, train_loss_step=0.357]Epoch 0:  78%|███████▊  | 50/64 [00:07<00:02,  6.39it/s, loss=0.38, v_num=14, train_loss_step=0.352] Epoch 0:  80%|███████▉  | 51/64 [00:08<00:02,  6.39it/s, loss=0.38, v_num=14, train_loss_step=0.352]Epoch 0:  80%|███████▉  | 51/64 [00:08<00:02,  6.39it/s, loss=0.377, v_num=14, train_loss_step=0.329]Epoch 0:  81%|████████▏ | 52/64 [00:08<00:01,  6.39it/s, loss=0.377, v_num=14, train_loss_step=0.329]Epoch 0:  81%|████████▏ | 52/64 [00:08<00:01,  6.38it/s, loss=0.375, v_num=14, train_loss_step=0.359]Epoch 0:  83%|████████▎ | 53/64 [00:08<00:01,  6.38it/s, loss=0.375, v_num=14, train_loss_step=0.359]Epoch 0:  83%|████████▎ | 53/64 [00:08<00:01,  6.38it/s, loss=0.374, v_num=14, train_loss_step=0.381]Epoch 0:  84%|████████▍ | 54/64 [00:08<00:01,  6.38it/s, loss=0.374, v_num=14, train_loss_step=0.381]Epoch 0:  84%|████████▍ | 54/64 [00:08<00:01,  6.38it/s, loss=0.374, v_num=14, train_loss_step=0.364]Epoch 0:  86%|████████▌ | 55/64 [00:08<00:01,  6.39it/s, loss=0.374, v_num=14, train_loss_step=0.364]Epoch 0:  86%|████████▌ | 55/64 [00:08<00:01,  6.39it/s, loss=0.373, v_num=14, train_loss_step=0.384]Epoch 0:  88%|████████▊ | 56/64 [00:08<00:01,  6.44it/s, loss=0.374, v_num=14, train_loss_step=0.385]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/8 [00:00<?, ?it/s][A
Validating:  12%|█▎        | 1/8 [00:00<00:03,  2.32it/s][AEpoch 0:  91%|█████████ | 58/64 [00:09<00:00,  6.35it/s, loss=0.374, v_num=14, train_loss_step=0.385]
Validating:  25%|██▌       | 2/8 [00:00<00:02,  2.32it/s][A
Validating:  38%|███▊      | 3/8 [00:01<00:02,  2.34it/s][A
Validating:  50%|█████     | 4/8 [00:01<00:01,  2.34it/s][AEpoch 0:  95%|█████████▌| 61/64 [00:10<00:00,  5.87it/s, loss=0.374, v_num=14, train_loss_step=0.385]
Validating:  62%|██████▎   | 5/8 [00:02<00:01,  2.35it/s][A
Validating:  75%|███████▌  | 6/8 [00:02<00:00,  2.36it/s][A
Validating:  88%|████████▊ | 7/8 [00:02<00:00,  2.36it/s][AEpoch 0: 100%|██████████| 64/64 [00:11<00:00,  5.49it/s, loss=0.374, v_num=14, train_loss_step=0.385]
Validating: 100%|██████████| 8/8 [00:03<00:00,  2.65it/s][AEpoch 0: 100%|██████████| 64/64 [00:12<00:00,  5.37it/s, loss=0.374, v_num=14, train_loss_step=0.385]
                                                         [AEpoch 0: 100%|██████████| 64/64 [00:12<00:00,  5.34it/s, loss=0.374, v_num=14, train_loss_step=0.385]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(

Testing: 0it [00:00, ?it/s]Testing:   2%|▏         | 3/169 [00:00<00:06, 25.91it/s]Testing:   4%|▎         | 6/169 [00:00<00:05, 27.79it/s]Testing:   5%|▌         | 9/169 [00:00<00:05, 28.42it/s]Testing:   7%|▋         | 12/169 [00:00<00:05, 28.83it/s]Testing:   9%|▉         | 15/169 [00:00<00:05, 28.96it/s]Testing:  11%|█         | 18/169 [00:00<00:05, 29.12it/s]Testing:  12%|█▏        | 21/169 [00:00<00:05, 29.14it/s]Testing:  14%|█▍        | 24/169 [00:00<00:04, 29.20it/s]Testing:  16%|█▌        | 27/169 [00:00<00:04, 29.31it/s]Testing:  18%|█▊        | 30/169 [00:01<00:04, 29.20it/s]Testing:  20%|█▉        | 33/169 [00:01<00:04, 29.08it/s]Testing:  21%|██▏       | 36/169 [00:01<00:04, 29.19it/s]Testing:  23%|██▎       | 39/169 [00:01<00:04, 29.29it/s]Testing:  25%|██▍       | 42/169 [00:01<00:04, 29.28it/s]Testing:  27%|██▋       | 45/169 [00:01<00:04, 29.30it/s]Testing:  28%|██▊       | 48/169 [00:01<00:04, 29.25it/s]Testing:  30%|███       | 51/169 [00:01<00:04, 29.28it/s]Testing:  32%|███▏      | 54/169 [00:01<00:03, 29.36it/s]Testing:  34%|███▎      | 57/169 [00:01<00:03, 29.35it/s]Testing:  36%|███▌      | 60/169 [00:02<00:03, 29.30it/s]Testing:  37%|███▋      | 63/169 [00:02<00:03, 29.35it/s]Testing:  39%|███▉      | 66/169 [00:02<00:03, 29.23it/s]Testing:  41%|████      | 69/169 [00:02<00:03, 29.22it/s]Testing:  43%|████▎     | 72/169 [00:02<00:03, 29.23it/s]Testing:  44%|████▍     | 75/169 [00:02<00:03, 29.13it/s]Testing:  46%|████▌     | 78/169 [00:02<00:03, 29.10it/s]Testing:  48%|████▊     | 81/169 [00:02<00:03, 29.24it/s]Testing:  50%|████▉     | 84/169 [00:02<00:02, 29.26it/s]Testing:  51%|█████▏    | 87/169 [00:02<00:02, 29.27it/s]Testing:  53%|█████▎    | 90/169 [00:03<00:02, 29.36it/s]Testing:  55%|█████▌    | 93/169 [00:03<00:02, 29.37it/s]Testing:  57%|█████▋    | 96/169 [00:03<00:02, 29.35it/s]Testing:  59%|█████▊    | 99/169 [00:03<00:02, 29.33it/s]Testing:  60%|██████    | 102/169 [00:03<00:02, 29.26it/s]Testing:  62%|██████▏   | 105/169 [00:03<00:02, 29.13it/s]Testing:  64%|██████▍   | 108/169 [00:03<00:02, 29.03it/s]Testing:  66%|██████▌   | 111/169 [00:03<00:01, 29.14it/s]Testing:  67%|██████▋   | 114/169 [00:03<00:01, 29.22it/s]Testing:  69%|██████▉   | 117/169 [00:04<00:01, 29.27it/s]Testing:  71%|███████   | 120/169 [00:04<00:01, 29.22it/s]Testing:  73%|███████▎  | 123/169 [00:04<00:01, 29.23it/s]Testing:  75%|███████▍  | 126/169 [00:04<00:01, 29.23it/s]Testing:  76%|███████▋  | 129/169 [00:04<00:01, 29.21it/s]Testing:  78%|███████▊  | 132/169 [00:04<00:01, 29.14it/s]Testing:  80%|███████▉  | 135/169 [00:04<00:01, 29.16it/s]Testing:  82%|████████▏ | 138/169 [00:04<00:01, 29.21it/s]Testing:  83%|████████▎ | 141/169 [00:04<00:00, 29.02it/s]Testing:  85%|████████▌ | 144/169 [00:04<00:00, 29.02it/s]Testing:  87%|████████▋ | 147/169 [00:05<00:00, 28.99it/s]Testing:  89%|████████▉ | 150/169 [00:05<00:00, 29.09it/s]Testing:  91%|█████████ | 153/169 [00:05<00:00, 29.20it/s]Testing:  92%|█████████▏| 156/169 [00:05<00:00, 29.15it/s]Testing:  94%|█████████▍| 159/169 [00:05<00:00, 29.21it/s]Testing:  96%|█████████▌| 162/169 [00:05<00:00, 29.09it/s]Testing:  98%|█████████▊| 165/169 [00:05<00:00, 29.07it/s]Testing:  99%|█████████▉| 168/169 [00:05<00:00, 29.15it/s]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'_mean_accuracy': 0.9520095586776733,
 '_standard_dev_accuracy': 0.04606882482767105,
 '_variance_accuracy': 0.002122336532920599,
 'test_acc': 0.9520095586776733,
 'test_dice_c1': 0.19243109226226807,
 'test_f2_c1': 0.2616327404975891,
 'test_loss': 0.3612164855003357,
 'test_mean_c1': 0.467658132314682,
 'test_prec_c1': 0.14885775744915009,
 'test_sens_c1': 0.4582831859588623,
 'test_spec_c1': 0.9524681568145752}
--------------------------------------------------------------------------------
Testing: 100%|██████████| 169/169 [00:05<00:00, 29.13it/s]
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

  | Name       | Type             | Params
------------------------------------------------
0 | encoder1   | EncoderBlock     | 37.6 K
1 | encoder2   | EncoderBlock     | 221 K 
2 | bottleneck | ConvolutionBlock | 885 K 
3 | dropout    | Dropout2d        | 0     
4 | decoder1   | DecoderBlock     | 573 K 
5 | decoder2   | DecoderBlock     | 143 K 
6 | conv       | Conv2d           | 130   
7 | softmax    | Softmax2d        | 0     
------------------------------------------------
1.9 M     Trainable params
0         Non-trainable params
1.9 M     Total params
7.447     Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  3.73it/s]                                                                      /home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Training: -1it [00:00, ?it/s]Training:   0%|          | 0/380 [00:00<00:00, 26886.56it/s]Epoch 0:   0%|          | 0/380 [00:00<00:00, 4088.02it/s]  Epoch 0:   0%|          | 1/380 [00:00<00:07, 49.30it/s, loss=0.68, v_num=15, train_loss_step=0.680]Epoch 0:   1%|          | 2/380 [00:00<00:09, 41.54it/s, loss=0.673, v_num=15, train_loss_step=0.665]Epoch 0:   1%|          | 3/380 [00:00<00:09, 38.72it/s, loss=0.673, v_num=15, train_loss_step=0.665]Epoch 0:   1%|          | 3/380 [00:00<00:09, 38.61it/s, loss=0.677, v_num=15, train_loss_step=0.684]Epoch 0:   1%|          | 4/380 [00:00<00:10, 37.13it/s, loss=0.679, v_num=15, train_loss_step=0.685]Epoch 0:   1%|▏         | 5/380 [00:00<00:10, 36.33it/s, loss=0.656, v_num=15, train_loss_step=0.566]Epoch 0:   2%|▏         | 6/380 [00:00<00:10, 35.80it/s, loss=0.625, v_num=15, train_loss_step=0.471]Epoch 0:   2%|▏         | 7/380 [00:00<00:10, 35.32it/s, loss=0.625, v_num=15, train_loss_step=0.471]Epoch 0:   2%|▏         | 7/380 [00:00<00:10, 35.28it/s, loss=0.584, v_num=15, train_loss_step=0.338]Epoch 0:   2%|▏         | 8/380 [00:00<00:10, 35.00it/s, loss=0.57, v_num=15, train_loss_step=0.471] Epoch 0:   2%|▏         | 9/380 [00:00<00:10, 34.72it/s, loss=0.55, v_num=15, train_loss_step=0.385]Epoch 0:   3%|▎         | 10/380 [00:00<00:10, 34.40it/s, loss=0.541, v_num=15, train_loss_step=0.462]Epoch 0:   3%|▎         | 11/380 [00:00<00:10, 34.24it/s, loss=0.541, v_num=15, train_loss_step=0.462]Epoch 0:   3%|▎         | 11/380 [00:00<00:10, 34.21it/s, loss=0.556, v_num=15, train_loss_step=0.709]Epoch 0:   3%|▎         | 12/380 [00:00<00:10, 34.10it/s, loss=0.547, v_num=15, train_loss_step=0.445]Epoch 0:   3%|▎         | 13/380 [00:00<00:10, 33.95it/s, loss=0.529, v_num=15, train_loss_step=0.322]Epoch 0:   4%|▎         | 14/380 [00:00<00:10, 33.90it/s, loss=0.515, v_num=15, train_loss_step=0.324]Epoch 0:   4%|▍         | 15/380 [00:00<00:10, 33.84it/s, loss=0.515, v_num=15, train_loss_step=0.324]Epoch 0:   4%|▍         | 15/380 [00:00<00:10, 33.81it/s, loss=0.501, v_num=15, train_loss_step=0.313]Epoch 0:   4%|▍         | 16/380 [00:00<00:10, 33.73it/s, loss=0.491, v_num=15, train_loss_step=0.333]Epoch 0:   4%|▍         | 17/380 [00:00<00:10, 33.66it/s, loss=0.483, v_num=15, train_loss_step=0.366]Epoch 0:   5%|▍         | 18/380 [00:00<00:10, 33.61it/s, loss=0.474, v_num=15, train_loss_step=0.313]Epoch 0:   5%|▌         | 19/380 [00:00<00:10, 33.58it/s, loss=0.474, v_num=15, train_loss_step=0.313]Epoch 0:   5%|▌         | 19/380 [00:00<00:10, 33.57it/s, loss=0.466, v_num=15, train_loss_step=0.313]Epoch 0:   5%|▌         | 20/380 [00:00<00:10, 33.51it/s, loss=0.458, v_num=15, train_loss_step=0.313]Epoch 0:   6%|▌         | 21/380 [00:00<00:10, 33.46it/s, loss=0.445, v_num=15, train_loss_step=0.415]Epoch 0:   6%|▌         | 22/380 [00:00<00:10, 33.41it/s, loss=0.428, v_num=15, train_loss_step=0.333]Epoch 0:   6%|▌         | 23/380 [00:00<00:10, 33.34it/s, loss=0.428, v_num=15, train_loss_step=0.333]Epoch 0:   6%|▌         | 23/380 [00:00<00:10, 33.33it/s, loss=0.424, v_num=15, train_loss_step=0.607]Epoch 0:   6%|▋         | 24/380 [00:00<00:10, 33.29it/s, loss=0.424, v_num=15, train_loss_step=0.680]Epoch 0:   7%|▋         | 25/380 [00:00<00:10, 33.21it/s, loss=0.42, v_num=15, train_loss_step=0.484] Epoch 0:   7%|▋         | 26/380 [00:00<00:10, 33.16it/s, loss=0.416, v_num=15, train_loss_step=0.393]Epoch 0:   7%|▋         | 27/380 [00:00<00:10, 33.15it/s, loss=0.416, v_num=15, train_loss_step=0.393]Epoch 0:   7%|▋         | 27/380 [00:00<00:10, 33.14it/s, loss=0.416, v_num=15, train_loss_step=0.344]Epoch 0:   7%|▋         | 28/380 [00:00<00:10, 33.12it/s, loss=0.414, v_num=15, train_loss_step=0.426]Epoch 0:   8%|▊         | 29/380 [00:00<00:10, 33.11it/s, loss=0.413, v_num=15, train_loss_step=0.355]Epoch 0:   8%|▊         | 30/380 [00:00<00:10, 33.08it/s, loss=0.405, v_num=15, train_loss_step=0.313]Epoch 0:   8%|▊         | 31/380 [00:00<00:10, 33.07it/s, loss=0.405, v_num=15, train_loss_step=0.313]Epoch 0:   8%|▊         | 31/380 [00:00<00:10, 33.06it/s, loss=0.4, v_num=15, train_loss_step=0.598]  Epoch 0:   8%|▊         | 32/380 [00:00<00:10, 33.04it/s, loss=0.396, v_num=15, train_loss_step=0.374]Epoch 0:   9%|▊         | 33/380 [00:01<00:10, 33.03it/s, loss=0.4, v_num=15, train_loss_step=0.397]  Epoch 0:   9%|▉         | 34/380 [00:01<00:10, 33.00it/s, loss=0.409, v_num=15, train_loss_step=0.507]Epoch 0:   9%|▉         | 35/380 [00:01<00:10, 32.98it/s, loss=0.409, v_num=15, train_loss_step=0.507]Epoch 0:   9%|▉         | 35/380 [00:01<00:10, 32.97it/s, loss=0.433, v_num=15, train_loss_step=0.795]Epoch 0:   9%|▉         | 36/380 [00:01<00:10, 32.96it/s, loss=0.436, v_num=15, train_loss_step=0.400]Epoch 0:  10%|▉         | 37/380 [00:01<00:10, 32.96it/s, loss=0.448, v_num=15, train_loss_step=0.604]Epoch 0:  10%|█         | 38/380 [00:01<00:10, 32.94it/s, loss=0.448, v_num=15, train_loss_step=0.313]Epoch 0:  10%|█         | 39/380 [00:01<00:10, 32.93it/s, loss=0.448, v_num=15, train_loss_step=0.313]Epoch 0:  10%|█         | 39/380 [00:01<00:10, 32.92it/s, loss=0.45, v_num=15, train_loss_step=0.347] Epoch 0:  11%|█         | 40/380 [00:01<00:10, 32.92it/s, loss=0.466, v_num=15, train_loss_step=0.636]Epoch 0:  11%|█         | 41/380 [00:01<00:10, 32.90it/s, loss=0.479, v_num=15, train_loss_step=0.679]Epoch 0:  11%|█         | 42/380 [00:01<00:10, 32.90it/s, loss=0.485, v_num=15, train_loss_step=0.442]Epoch 0:  11%|█▏        | 43/380 [00:01<00:10, 32.91it/s, loss=0.485, v_num=15, train_loss_step=0.442]Epoch 0:  11%|█▏        | 43/380 [00:01<00:10, 32.90it/s, loss=0.47, v_num=15, train_loss_step=0.313] Epoch 0:  12%|█▏        | 44/380 [00:01<00:10, 32.89it/s, loss=0.455, v_num=15, train_loss_step=0.372]Epoch 0:  12%|█▏        | 45/380 [00:01<00:10, 32.88it/s, loss=0.463, v_num=15, train_loss_step=0.652]Epoch 0:  12%|█▏        | 46/380 [00:01<00:10, 32.88it/s, loss=0.461, v_num=15, train_loss_step=0.358]Epoch 0:  12%|█▏        | 47/380 [00:01<00:10, 32.87it/s, loss=0.461, v_num=15, train_loss_step=0.358]Epoch 0:  12%|█▏        | 47/380 [00:01<00:10, 32.87it/s, loss=0.46, v_num=15, train_loss_step=0.326] Epoch 0:  13%|█▎        | 48/380 [00:01<00:10, 32.86it/s, loss=0.455, v_num=15, train_loss_step=0.313]Epoch 0:  13%|█▎        | 49/380 [00:01<00:10, 32.86it/s, loss=0.454, v_num=15, train_loss_step=0.346]Epoch 0:  13%|█▎        | 50/380 [00:01<00:10, 32.85it/s, loss=0.455, v_num=15, train_loss_step=0.335]Epoch 0:  13%|█▎        | 51/380 [00:01<00:10, 32.85it/s, loss=0.455, v_num=15, train_loss_step=0.335]Epoch 0:  13%|█▎        | 51/380 [00:01<00:10, 32.84it/s, loss=0.441, v_num=15, train_loss_step=0.313]Epoch 0:  14%|█▎        | 52/380 [00:01<00:09, 32.85it/s, loss=0.446, v_num=15, train_loss_step=0.472]Epoch 0:  14%|█▍        | 53/380 [00:01<00:09, 32.82it/s, loss=0.442, v_num=15, train_loss_step=0.313]Epoch 0:  14%|█▍        | 54/380 [00:01<00:09, 32.82it/s, loss=0.455, v_num=15, train_loss_step=0.768]Epoch 0:  14%|█▍        | 55/380 [00:01<00:09, 32.81it/s, loss=0.455, v_num=15, train_loss_step=0.768]Epoch 0:  14%|█▍        | 55/380 [00:01<00:09, 32.81it/s, loss=0.434, v_num=15, train_loss_step=0.381]Epoch 0:  15%|█▍        | 56/380 [00:01<00:09, 32.80it/s, loss=0.439, v_num=15, train_loss_step=0.498]Epoch 0:  15%|█▌        | 57/380 [00:01<00:09, 32.80it/s, loss=0.428, v_num=15, train_loss_step=0.388]Epoch 0:  15%|█▌        | 58/380 [00:01<00:09, 32.80it/s, loss=0.429, v_num=15, train_loss_step=0.320]Epoch 0:  16%|█▌        | 59/380 [00:01<00:09, 32.80it/s, loss=0.429, v_num=15, train_loss_step=0.320]Epoch 0:  16%|█▌        | 59/380 [00:01<00:09, 32.80it/s, loss=0.446, v_num=15, train_loss_step=0.684]Epoch 0:  16%|█▌        | 60/380 [00:01<00:09, 32.79it/s, loss=0.432, v_num=15, train_loss_step=0.371]Epoch 0:  16%|█▌        | 61/380 [00:01<00:09, 32.79it/s, loss=0.424, v_num=15, train_loss_step=0.519]Epoch 0:  16%|█▋        | 62/380 [00:01<00:09, 32.77it/s, loss=0.424, v_num=15, train_loss_step=0.438]Epoch 0:  17%|█▋        | 63/380 [00:01<00:09, 32.77it/s, loss=0.424, v_num=15, train_loss_step=0.438]Epoch 0:  17%|█▋        | 63/380 [00:01<00:09, 32.77it/s, loss=0.429, v_num=15, train_loss_step=0.415]Epoch 0:  17%|█▋        | 64/380 [00:01<00:09, 32.77it/s, loss=0.428, v_num=15, train_loss_step=0.354]Epoch 0:  17%|█▋        | 65/380 [00:02<00:09, 32.77it/s, loss=0.412, v_num=15, train_loss_step=0.326]Epoch 0:  17%|█▋        | 66/380 [00:02<00:09, 32.76it/s, loss=0.421, v_num=15, train_loss_step=0.546]Epoch 0:  18%|█▊        | 67/380 [00:02<00:09, 32.76it/s, loss=0.421, v_num=15, train_loss_step=0.546]Epoch 0:  18%|█▊        | 67/380 [00:02<00:09, 32.75it/s, loss=0.423, v_num=15, train_loss_step=0.366]Epoch 0:  18%|█▊        | 68/380 [00:02<00:09, 32.75it/s, loss=0.453, v_num=15, train_loss_step=0.902]Epoch 0:  18%|█▊        | 69/380 [00:02<00:09, 32.74it/s, loss=0.455, v_num=15, train_loss_step=0.382]Epoch 0:  18%|█▊        | 70/380 [00:02<00:09, 32.74it/s, loss=0.454, v_num=15, train_loss_step=0.313]Epoch 0:  19%|█▊        | 71/380 [00:02<00:09, 32.75it/s, loss=0.454, v_num=15, train_loss_step=0.313]Epoch 0:  19%|█▊        | 71/380 [00:02<00:09, 32.74it/s, loss=0.455, v_num=15, train_loss_step=0.347]Epoch 0:  19%|█▉        | 72/380 [00:02<00:09, 32.74it/s, loss=0.447, v_num=15, train_loss_step=0.313]Epoch 0:  19%|█▉        | 73/380 [00:02<00:09, 32.74it/s, loss=0.454, v_num=15, train_loss_step=0.441]Epoch 0:  19%|█▉        | 74/380 [00:02<00:09, 32.73it/s, loss=0.442, v_num=15, train_loss_step=0.529]Epoch 0:  20%|█▉        | 75/380 [00:02<00:09, 32.73it/s, loss=0.442, v_num=15, train_loss_step=0.529]Epoch 0:  20%|█▉        | 75/380 [00:02<00:09, 32.73it/s, loss=0.443, v_num=15, train_loss_step=0.410]Epoch 0:  20%|██        | 76/380 [00:02<00:09, 32.73it/s, loss=0.434, v_num=15, train_loss_step=0.315]Epoch 0:  20%|██        | 77/380 [00:02<00:09, 32.72it/s, loss=0.446, v_num=15, train_loss_step=0.624]Epoch 0:  21%|██        | 78/380 [00:02<00:09, 32.72it/s, loss=0.448, v_num=15, train_loss_step=0.367]Epoch 0:  21%|██        | 79/380 [00:02<00:09, 32.72it/s, loss=0.448, v_num=15, train_loss_step=0.367]Epoch 0:  21%|██        | 79/380 [00:02<00:09, 32.71it/s, loss=0.43, v_num=15, train_loss_step=0.320] Epoch 0:  21%|██        | 80/380 [00:02<00:09, 32.71it/s, loss=0.427, v_num=15, train_loss_step=0.313]Epoch 0:  21%|██▏       | 81/380 [00:02<00:09, 32.71it/s, loss=0.42, v_num=15, train_loss_step=0.373] Epoch 0:  22%|██▏       | 82/380 [00:02<00:09, 32.71it/s, loss=0.414, v_num=15, train_loss_step=0.313]Epoch 0:  22%|██▏       | 83/380 [00:02<00:09, 32.71it/s, loss=0.414, v_num=15, train_loss_step=0.313]Epoch 0:  22%|██▏       | 83/380 [00:02<00:09, 32.70it/s, loss=0.414, v_num=15, train_loss_step=0.415]Epoch 0:  22%|██▏       | 84/380 [00:02<00:09, 32.69it/s, loss=0.412, v_num=15, train_loss_step=0.313]Epoch 0:  22%|██▏       | 85/380 [00:02<00:09, 32.69it/s, loss=0.436, v_num=15, train_loss_step=0.823]Epoch 0:  23%|██▎       | 86/380 [00:02<00:08, 32.69it/s, loss=0.43, v_num=15, train_loss_step=0.409] Epoch 0:  23%|██▎       | 87/380 [00:02<00:08, 32.68it/s, loss=0.43, v_num=15, train_loss_step=0.409]Epoch 0:  23%|██▎       | 87/380 [00:02<00:08, 32.68it/s, loss=0.428, v_num=15, train_loss_step=0.335]Epoch 0:  23%|██▎       | 88/380 [00:02<00:08, 32.68it/s, loss=0.401, v_num=15, train_loss_step=0.352]Epoch 0:  23%|██▎       | 89/380 [00:02<00:08, 32.68it/s, loss=0.417, v_num=15, train_loss_step=0.710]Epoch 0:  24%|██▎       | 90/380 [00:02<00:08, 32.68it/s, loss=0.417, v_num=15, train_loss_step=0.313]Epoch 0:  24%|██▍       | 91/380 [00:02<00:08, 32.68it/s, loss=0.417, v_num=15, train_loss_step=0.313]Epoch 0:  24%|██▍       | 91/380 [00:02<00:08, 32.68it/s, loss=0.415, v_num=15, train_loss_step=0.313]Epoch 0:  24%|██▍       | 92/380 [00:02<00:08, 32.68it/s, loss=0.427, v_num=15, train_loss_step=0.539]Epoch 0:  24%|██▍       | 93/380 [00:02<00:08, 32.68it/s, loss=0.422, v_num=15, train_loss_step=0.360]Epoch 0:  25%|██▍       | 94/380 [00:02<00:08, 32.68it/s, loss=0.431, v_num=15, train_loss_step=0.692]Epoch 0:  25%|██▌       | 95/380 [00:02<00:08, 32.68it/s, loss=0.431, v_num=15, train_loss_step=0.692]Epoch 0:  25%|██▌       | 95/380 [00:02<00:08, 32.68it/s, loss=0.426, v_num=15, train_loss_step=0.313]Epoch 0:  25%|██▌       | 96/380 [00:02<00:08, 32.68it/s, loss=0.426, v_num=15, train_loss_step=0.313]Epoch 0:  26%|██▌       | 97/380 [00:02<00:08, 32.68it/s, loss=0.412, v_num=15, train_loss_step=0.348]Epoch 0:  26%|██▌       | 98/380 [00:03<00:08, 32.68it/s, loss=0.409, v_num=15, train_loss_step=0.313]Epoch 0:  26%|██▌       | 99/380 [00:03<00:08, 32.67it/s, loss=0.409, v_num=15, train_loss_step=0.313]Epoch 0:  26%|██▌       | 99/380 [00:03<00:08, 32.67it/s, loss=0.415, v_num=15, train_loss_step=0.436]Epoch 0:  26%|██▋       | 100/380 [00:03<00:08, 32.66it/s, loss=0.416, v_num=15, train_loss_step=0.339]Epoch 0:  27%|██▋       | 101/380 [00:03<00:08, 32.66it/s, loss=0.415, v_num=15, train_loss_step=0.344]Epoch 0:  27%|██▋       | 102/380 [00:03<00:08, 32.66it/s, loss=0.422, v_num=15, train_loss_step=0.450]Epoch 0:  27%|██▋       | 103/380 [00:03<00:08, 32.66it/s, loss=0.422, v_num=15, train_loss_step=0.450]Epoch 0:  27%|██▋       | 103/380 [00:03<00:08, 32.66it/s, loss=0.417, v_num=15, train_loss_step=0.313]Epoch 0:  27%|██▋       | 104/380 [00:03<00:08, 32.65it/s, loss=0.42, v_num=15, train_loss_step=0.381] Epoch 0:  28%|██▊       | 105/380 [00:03<00:08, 32.64it/s, loss=0.42, v_num=15, train_loss_step=0.826]Epoch 0:  28%|██▊       | 106/380 [00:03<00:08, 32.65it/s, loss=0.437, v_num=15, train_loss_step=0.748]Epoch 0:  28%|██▊       | 107/380 [00:03<00:08, 32.65it/s, loss=0.437, v_num=15, train_loss_step=0.748]Epoch 0:  28%|██▊       | 107/380 [00:03<00:08, 32.65it/s, loss=0.436, v_num=15, train_loss_step=0.313]Epoch 0:  28%|██▊       | 108/380 [00:03<00:08, 32.64it/s, loss=0.436, v_num=15, train_loss_step=0.354]Epoch 0:  29%|██▊       | 109/380 [00:03<00:08, 32.63it/s, loss=0.445, v_num=15, train_loss_step=0.889]Epoch 0:  29%|██▉       | 110/380 [00:03<00:08, 32.63it/s, loss=0.469, v_num=15, train_loss_step=0.800]Epoch 0:  29%|██▉       | 111/380 [00:03<00:08, 32.63it/s, loss=0.469, v_num=15, train_loss_step=0.800]Epoch 0:  29%|██▉       | 111/380 [00:03<00:08, 32.63it/s, loss=0.469, v_num=15, train_loss_step=0.313]Epoch 0:  29%|██▉       | 112/380 [00:03<00:08, 32.62it/s, loss=0.458, v_num=15, train_loss_step=0.313]Epoch 0:  30%|██▉       | 113/380 [00:03<00:08, 32.62it/s, loss=0.47, v_num=15, train_loss_step=0.599] Epoch 0:  30%|███       | 114/380 [00:03<00:08, 32.62it/s, loss=0.454, v_num=15, train_loss_step=0.373]Epoch 0:  30%|███       | 115/380 [00:03<00:08, 32.62it/s, loss=0.454, v_num=15, train_loss_step=0.373]Epoch 0:  30%|███       | 115/380 [00:03<00:08, 32.62it/s, loss=0.457, v_num=15, train_loss_step=0.376]Epoch 0:  31%|███       | 116/380 [00:03<00:08, 32.62it/s, loss=0.464, v_num=15, train_loss_step=0.458]Epoch 0:  31%|███       | 117/380 [00:03<00:08, 32.62it/s, loss=0.463, v_num=15, train_loss_step=0.313]Epoch 0:  31%|███       | 118/380 [00:03<00:08, 32.62it/s, loss=0.467, v_num=15, train_loss_step=0.399]Epoch 0:  31%|███▏      | 119/380 [00:03<00:08, 32.62it/s, loss=0.467, v_num=15, train_loss_step=0.399]Epoch 0:  31%|███▏      | 119/380 [00:03<00:08, 32.62it/s, loss=0.472, v_num=15, train_loss_step=0.546]Epoch 0:  32%|███▏      | 120/380 [00:03<00:07, 32.62it/s, loss=0.474, v_num=15, train_loss_step=0.382]Epoch 0:  32%|███▏      | 121/380 [00:03<00:07, 32.61it/s, loss=0.48, v_num=15, train_loss_step=0.463] Epoch 0:  32%|███▏      | 122/380 [00:03<00:07, 32.61it/s, loss=0.492, v_num=15, train_loss_step=0.672]Epoch 0:  32%|███▏      | 123/380 [00:03<00:07, 32.61it/s, loss=0.492, v_num=15, train_loss_step=0.672]Epoch 0:  32%|███▏      | 123/380 [00:03<00:07, 32.61it/s, loss=0.5, v_num=15, train_loss_step=0.483]  Epoch 0:  33%|███▎      | 124/380 [00:03<00:07, 32.61it/s, loss=0.497, v_num=15, train_loss_step=0.327]Epoch 0:  33%|███▎      | 125/380 [00:03<00:07, 32.61it/s, loss=0.49, v_num=15, train_loss_step=0.673] Epoch 0:  33%|███▎      | 126/380 [00:03<00:07, 32.61it/s, loss=0.469, v_num=15, train_loss_step=0.343]Epoch 0:  33%|███▎      | 127/380 [00:03<00:07, 32.61it/s, loss=0.469, v_num=15, train_loss_step=0.343]Epoch 0:  33%|███▎      | 127/380 [00:03<00:07, 32.61it/s, loss=0.5, v_num=15, train_loss_step=0.915]  Epoch 0:  34%|███▎      | 128/380 [00:03<00:07, 32.61it/s, loss=0.497, v_num=15, train_loss_step=0.313]Epoch 0:  34%|███▍      | 129/380 [00:03<00:07, 32.60it/s, loss=0.469, v_num=15, train_loss_step=0.313]Epoch 0:  34%|███▍      | 130/380 [00:04<00:07, 32.60it/s, loss=0.449, v_num=15, train_loss_step=0.409]Epoch 0:  34%|███▍      | 131/380 [00:04<00:07, 32.60it/s, loss=0.449, v_num=15, train_loss_step=0.409]Epoch 0:  34%|███▍      | 131/380 [00:04<00:07, 32.60it/s, loss=0.457, v_num=15, train_loss_step=0.479]Epoch 0:  35%|███▍      | 132/380 [00:04<00:07, 32.59it/s, loss=0.472, v_num=15, train_loss_step=0.601]Epoch 0:  35%|███▌      | 133/380 [00:04<00:07, 32.59it/s, loss=0.473, v_num=15, train_loss_step=0.625]Epoch 0:  35%|███▌      | 134/380 [00:04<00:07, 32.60it/s, loss=0.488, v_num=15, train_loss_step=0.673]Epoch 0:  36%|███▌      | 135/380 [00:04<00:07, 32.59it/s, loss=0.488, v_num=15, train_loss_step=0.673]Epoch 0:  36%|███▌      | 135/380 [00:04<00:07, 32.59it/s, loss=0.485, v_num=15, train_loss_step=0.313]Epoch 0:  36%|███▌      | 136/380 [00:04<00:07, 32.59it/s, loss=0.482, v_num=15, train_loss_step=0.404]Epoch 0:  36%|███▌      | 137/380 [00:04<00:07, 32.59it/s, loss=0.484, v_num=15, train_loss_step=0.347]Epoch 0:  36%|███▋      | 138/380 [00:04<00:07, 32.59it/s, loss=0.49, v_num=15, train_loss_step=0.513] Epoch 0:  37%|███▋      | 139/380 [00:04<00:07, 32.59it/s, loss=0.49, v_num=15, train_loss_step=0.513]Epoch 0:  37%|███▋      | 139/380 [00:04<00:07, 32.58it/s, loss=0.483, v_num=15, train_loss_step=0.413]Epoch 0:  37%|███▋      | 140/380 [00:04<00:07, 32.58it/s, loss=0.499, v_num=15, train_loss_step=0.692]Epoch 0:  37%|███▋      | 141/380 [00:04<00:07, 32.58it/s, loss=0.51, v_num=15, train_loss_step=0.688] Epoch 0:  37%|███▋      | 142/380 [00:04<00:07, 32.58it/s, loss=0.497, v_num=15, train_loss_step=0.406]Epoch 0:  38%|███▊      | 143/380 [00:04<00:07, 32.58it/s, loss=0.497, v_num=15, train_loss_step=0.406]Epoch 0:  38%|███▊      | 143/380 [00:04<00:07, 32.58it/s, loss=0.488, v_num=15, train_loss_step=0.313]Epoch 0:  38%|███▊      | 144/380 [00:04<00:07, 32.58it/s, loss=0.496, v_num=15, train_loss_step=0.476]Epoch 0:  38%|███▊      | 145/380 [00:04<00:07, 32.58it/s, loss=0.478, v_num=15, train_loss_step=0.313]Epoch 0:  38%|███▊      | 146/380 [00:04<00:07, 32.58it/s, loss=0.48, v_num=15, train_loss_step=0.395] Epoch 0:  39%|███▊      | 147/380 [00:04<00:07, 32.58it/s, loss=0.48, v_num=15, train_loss_step=0.395]Epoch 0:  39%|███▊      | 147/380 [00:04<00:07, 32.58it/s, loss=0.462, v_num=15, train_loss_step=0.553]Epoch 0:  39%|███▉      | 148/380 [00:04<00:07, 32.58it/s, loss=0.468, v_num=15, train_loss_step=0.425]Epoch 0:  39%|███▉      | 149/380 [00:04<00:07, 32.58it/s, loss=0.468, v_num=15, train_loss_step=0.313]Epoch 0:  39%|███▉      | 150/380 [00:04<00:07, 32.58it/s, loss=0.463, v_num=15, train_loss_step=0.316]Epoch 0:  40%|███▉      | 151/380 [00:04<00:07, 32.58it/s, loss=0.463, v_num=15, train_loss_step=0.316]Epoch 0:  40%|███▉      | 151/380 [00:04<00:07, 32.58it/s, loss=0.462, v_num=15, train_loss_step=0.457]Epoch 0:  40%|████      | 152/380 [00:04<00:06, 32.58it/s, loss=0.468, v_num=15, train_loss_step=0.729]Epoch 0:  40%|████      | 153/380 [00:04<00:06, 32.58it/s, loss=0.453, v_num=15, train_loss_step=0.313]Epoch 0:  41%|████      | 154/380 [00:04<00:06, 32.58it/s, loss=0.452, v_num=15, train_loss_step=0.667]Epoch 0:  41%|████      | 155/380 [00:04<00:06, 32.58it/s, loss=0.452, v_num=15, train_loss_step=0.667]Epoch 0:  41%|████      | 155/380 [00:04<00:06, 32.58it/s, loss=0.452, v_num=15, train_loss_step=0.313]Epoch 0:  41%|████      | 156/380 [00:04<00:06, 32.58it/s, loss=0.45, v_num=15, train_loss_step=0.344] Epoch 0:  41%|████▏     | 157/380 [00:04<00:06, 32.58it/s, loss=0.448, v_num=15, train_loss_step=0.313]Epoch 0:  42%|████▏     | 158/380 [00:04<00:06, 32.58it/s, loss=0.438, v_num=15, train_loss_step=0.313]Epoch 0:  42%|████▏     | 159/380 [00:04<00:06, 32.58it/s, loss=0.438, v_num=15, train_loss_step=0.313]Epoch 0:  42%|████▏     | 159/380 [00:04<00:06, 32.58it/s, loss=0.435, v_num=15, train_loss_step=0.353]Epoch 0:  42%|████▏     | 160/380 [00:04<00:06, 32.58it/s, loss=0.419, v_num=15, train_loss_step=0.378]Epoch 0:  42%|████▏     | 161/380 [00:04<00:06, 32.58it/s, loss=0.403, v_num=15, train_loss_step=0.368]Epoch 0:  43%|████▎     | 162/380 [00:05<00:06, 32.58it/s, loss=0.399, v_num=15, train_loss_step=0.313]Epoch 0:  43%|████▎     | 163/380 [00:05<00:06, 32.58it/s, loss=0.399, v_num=15, train_loss_step=0.313]Epoch 0:  43%|████▎     | 163/380 [00:05<00:06, 32.58it/s, loss=0.416, v_num=15, train_loss_step=0.670]Epoch 0:  43%|████▎     | 164/380 [00:05<00:06, 32.58it/s, loss=0.425, v_num=15, train_loss_step=0.642]Epoch 0:  43%|████▎     | 165/380 [00:05<00:06, 32.58it/s, loss=0.425, v_num=15, train_loss_step=0.313]Epoch 0:  44%|████▎     | 166/380 [00:05<00:06, 32.58it/s, loss=0.431, v_num=15, train_loss_step=0.532]Epoch 0:  44%|████▍     | 167/380 [00:05<00:06, 32.58it/s, loss=0.431, v_num=15, train_loss_step=0.532]Epoch 0:  44%|████▍     | 167/380 [00:05<00:06, 32.58it/s, loss=0.419, v_num=15, train_loss_step=0.313]Epoch 0:  44%|████▍     | 168/380 [00:05<00:06, 32.58it/s, loss=0.417, v_num=15, train_loss_step=0.376]Epoch 0:  44%|████▍     | 169/380 [00:05<00:06, 32.57it/s, loss=0.421, v_num=15, train_loss_step=0.394]Epoch 0:  45%|████▍     | 170/380 [00:05<00:06, 32.57it/s, loss=0.429, v_num=15, train_loss_step=0.480]Epoch 0:  45%|████▌     | 171/380 [00:05<00:06, 32.58it/s, loss=0.429, v_num=15, train_loss_step=0.480]Epoch 0:  45%|████▌     | 171/380 [00:05<00:06, 32.57it/s, loss=0.424, v_num=15, train_loss_step=0.346]Epoch 0:  45%|████▌     | 172/380 [00:05<00:06, 32.57it/s, loss=0.403, v_num=15, train_loss_step=0.313]Epoch 0:  46%|████▌     | 173/380 [00:05<00:06, 32.57it/s, loss=0.403, v_num=15, train_loss_step=0.313]Epoch 0:  46%|████▌     | 174/380 [00:05<00:06, 32.57it/s, loss=0.39, v_num=15, train_loss_step=0.412] Epoch 0:  46%|████▌     | 175/380 [00:05<00:06, 32.57it/s, loss=0.39, v_num=15, train_loss_step=0.412]Epoch 0:  46%|████▌     | 175/380 [00:05<00:06, 32.57it/s, loss=0.408, v_num=15, train_loss_step=0.668]Epoch 0:  46%|████▋     | 176/380 [00:05<00:06, 32.57it/s, loss=0.411, v_num=15, train_loss_step=0.417]Epoch 0:  47%|████▋     | 177/380 [00:05<00:06, 32.57it/s, loss=0.414, v_num=15, train_loss_step=0.355]Epoch 0:  47%|████▋     | 178/380 [00:05<00:06, 32.57it/s, loss=0.414, v_num=15, train_loss_step=0.313]Epoch 0:  47%|████▋     | 179/380 [00:05<00:06, 32.57it/s, loss=0.414, v_num=15, train_loss_step=0.313]Epoch 0:  47%|████▋     | 179/380 [00:05<00:06, 32.56it/s, loss=0.426, v_num=15, train_loss_step=0.602]Epoch 0:  47%|████▋     | 180/380 [00:05<00:06, 32.57it/s, loss=0.429, v_num=15, train_loss_step=0.449]Epoch 0:  48%|████▊     | 181/380 [00:05<00:06, 32.57it/s, loss=0.43, v_num=15, train_loss_step=0.387] Epoch 0:  48%|████▊     | 182/380 [00:05<00:06, 32.56it/s, loss=0.43, v_num=15, train_loss_step=0.313]Epoch 0:  48%|████▊     | 183/380 [00:05<00:06, 32.56it/s, loss=0.43, v_num=15, train_loss_step=0.313]Epoch 0:  48%|████▊     | 183/380 [00:05<00:06, 32.56it/s, loss=0.436, v_num=15, train_loss_step=0.783]Epoch 0:  48%|████▊     | 184/380 [00:05<00:06, 32.56it/s, loss=0.424, v_num=15, train_loss_step=0.408]Epoch 0:  49%|████▊     | 185/380 [00:05<00:05, 32.56it/s, loss=0.457, v_num=15, train_loss_step=0.957]Epoch 0:  49%|████▉     | 186/380 [00:05<00:05, 32.56it/s, loss=0.446, v_num=15, train_loss_step=0.313]Epoch 0:  49%|████▉     | 187/380 [00:05<00:05, 32.56it/s, loss=0.446, v_num=15, train_loss_step=0.313]Epoch 0:  49%|████▉     | 187/380 [00:05<00:05, 32.55it/s, loss=0.456, v_num=15, train_loss_step=0.526]Epoch 0:  49%|████▉     | 188/380 [00:05<00:05, 32.55it/s, loss=0.453, v_num=15, train_loss_step=0.313]Epoch 0:  50%|████▉     | 189/380 [00:05<00:05, 32.55it/s, loss=0.454, v_num=15, train_loss_step=0.419]Epoch 0:  50%|█████     | 190/380 [00:05<00:05, 32.55it/s, loss=0.45, v_num=15, train_loss_step=0.401] Epoch 0:  50%|█████     | 191/380 [00:05<00:05, 32.55it/s, loss=0.45, v_num=15, train_loss_step=0.401]Epoch 0:  50%|█████     | 191/380 [00:05<00:05, 32.55it/s, loss=0.461, v_num=15, train_loss_step=0.557]Epoch 0:  51%|█████     | 192/380 [00:05<00:05, 32.55it/s, loss=0.471, v_num=15, train_loss_step=0.513]Epoch 0:  51%|█████     | 193/380 [00:05<00:05, 32.55it/s, loss=0.475, v_num=15, train_loss_step=0.390]Epoch 0:  51%|█████     | 194/380 [00:05<00:05, 32.55it/s, loss=0.487, v_num=15, train_loss_step=0.664]Epoch 0:  51%|█████▏    | 195/380 [00:06<00:05, 32.55it/s, loss=0.487, v_num=15, train_loss_step=0.664]Epoch 0:  51%|█████▏    | 195/380 [00:06<00:05, 32.55it/s, loss=0.497, v_num=15, train_loss_step=0.864]Epoch 0:  52%|█████▏    | 196/380 [00:06<00:05, 32.54it/s, loss=0.492, v_num=15, train_loss_step=0.313]Epoch 0:  52%|█████▏    | 197/380 [00:06<00:05, 32.54it/s, loss=0.504, v_num=15, train_loss_step=0.600]Epoch 0:  52%|█████▏    | 198/380 [00:06<00:05, 32.54it/s, loss=0.512, v_num=15, train_loss_step=0.472]Epoch 0:  52%|█████▏    | 199/380 [00:06<00:05, 32.54it/s, loss=0.512, v_num=15, train_loss_step=0.472]Epoch 0:  52%|█████▏    | 199/380 [00:06<00:05, 32.54it/s, loss=0.506, v_num=15, train_loss_step=0.476]Epoch 0:  53%|█████▎    | 200/380 [00:06<00:05, 32.54it/s, loss=0.5, v_num=15, train_loss_step=0.321]  Epoch 0:  53%|█████▎    | 201/380 [00:06<00:05, 32.54it/s, loss=0.503, v_num=15, train_loss_step=0.448]Epoch 0:  53%|█████▎    | 202/380 [00:06<00:05, 32.53it/s, loss=0.524, v_num=15, train_loss_step=0.746]Epoch 0:  53%|█████▎    | 203/380 [00:06<00:05, 32.54it/s, loss=0.524, v_num=15, train_loss_step=0.746]Epoch 0:  53%|█████▎    | 203/380 [00:06<00:05, 32.54it/s, loss=0.519, v_num=15, train_loss_step=0.675]Epoch 0:  54%|█████▎    | 204/380 [00:06<00:05, 32.54it/s, loss=0.514, v_num=15, train_loss_step=0.313]Epoch 0:  54%|█████▍    | 205/380 [00:06<00:05, 32.53it/s, loss=0.498, v_num=15, train_loss_step=0.627]Epoch 0:  54%|█████▍    | 206/380 [00:06<00:05, 32.53it/s, loss=0.498, v_num=15, train_loss_step=0.319]Epoch 0:  54%|█████▍    | 207/380 [00:06<00:05, 32.53it/s, loss=0.498, v_num=15, train_loss_step=0.319]Epoch 0:  54%|█████▍    | 207/380 [00:06<00:05, 32.53it/s, loss=0.493, v_num=15, train_loss_step=0.419]Epoch 0:  55%|█████▍    | 208/380 [00:06<00:05, 32.53it/s, loss=0.496, v_num=15, train_loss_step=0.389]Epoch 0:  55%|█████▌    | 209/380 [00:06<00:05, 32.53it/s, loss=0.51, v_num=15, train_loss_step=0.684] Epoch 0:  55%|█████▌    | 210/380 [00:06<00:05, 32.53it/s, loss=0.505, v_num=15, train_loss_step=0.315]Epoch 0:  56%|█████▌    | 211/380 [00:06<00:05, 32.53it/s, loss=0.505, v_num=15, train_loss_step=0.315]Epoch 0:  56%|█████▌    | 211/380 [00:06<00:05, 32.52it/s, loss=0.512, v_num=15, train_loss_step=0.701]Epoch 0:  56%|█████▌    | 212/380 [00:06<00:05, 32.53it/s, loss=0.517, v_num=15, train_loss_step=0.600]Epoch 0:  56%|█████▌    | 213/380 [00:06<00:05, 32.53it/s, loss=0.514, v_num=15, train_loss_step=0.341]Epoch 0:  56%|█████▋    | 214/380 [00:06<00:05, 32.53it/s, loss=0.499, v_num=15, train_loss_step=0.364]Epoch 0:  57%|█████▋    | 215/380 [00:06<00:05, 32.53it/s, loss=0.499, v_num=15, train_loss_step=0.364]Epoch 0:  57%|█████▋    | 215/380 [00:06<00:05, 32.53it/s, loss=0.472, v_num=15, train_loss_step=0.320]Epoch 0:  57%|█████▋    | 216/380 [00:06<00:05, 32.53it/s, loss=0.472, v_num=15, train_loss_step=0.313]Epoch 0:  57%|█████▋    | 217/380 [00:06<00:05, 32.53it/s, loss=0.462, v_num=15, train_loss_step=0.391]Epoch 0:  57%|█████▋    | 218/380 [00:06<00:04, 32.53it/s, loss=0.454, v_num=15, train_loss_step=0.313]Epoch 0:  58%|█████▊    | 219/380 [00:06<00:04, 32.52it/s, loss=0.454, v_num=15, train_loss_step=0.313]Epoch 0:  58%|█████▊    | 219/380 [00:06<00:04, 32.52it/s, loss=0.446, v_num=15, train_loss_step=0.321]Epoch 0:  58%|█████▊    | 220/380 [00:06<00:04, 32.52it/s, loss=0.469, v_num=15, train_loss_step=0.784]Epoch 0:  58%|█████▊    | 221/380 [00:06<00:04, 32.52it/s, loss=0.467, v_num=15, train_loss_step=0.409]Epoch 0:  58%|█████▊    | 222/380 [00:06<00:04, 32.52it/s, loss=0.446, v_num=15, train_loss_step=0.313]Epoch 0:  59%|█████▊    | 223/380 [00:06<00:04, 32.52it/s, loss=0.446, v_num=15, train_loss_step=0.313]Epoch 0:  59%|█████▊    | 223/380 [00:06<00:04, 32.52it/s, loss=0.433, v_num=15, train_loss_step=0.418]Epoch 0:  59%|█████▉    | 224/380 [00:06<00:04, 32.52it/s, loss=0.441, v_num=15, train_loss_step=0.466]Epoch 0:  59%|█████▉    | 225/380 [00:06<00:04, 32.52it/s, loss=0.425, v_num=15, train_loss_step=0.313]Epoch 0:  59%|█████▉    | 226/380 [00:06<00:04, 32.52it/s, loss=0.444, v_num=15, train_loss_step=0.710]Epoch 0:  60%|█████▉    | 227/380 [00:07<00:04, 32.52it/s, loss=0.444, v_num=15, train_loss_step=0.710]Epoch 0:  60%|█████▉    | 227/380 [00:07<00:04, 32.52it/s, loss=0.452, v_num=15, train_loss_step=0.570]Epoch 0:  60%|██████    | 228/380 [00:07<00:04, 32.52it/s, loss=0.466, v_num=15, train_loss_step=0.674]Epoch 0:  60%|██████    | 229/380 [00:07<00:04, 32.52it/s, loss=0.448, v_num=15, train_loss_step=0.313]Epoch 0:  61%|██████    | 230/380 [00:07<00:04, 32.52it/s, loss=0.465, v_num=15, train_loss_step=0.669]Epoch 0:  61%|██████    | 231/380 [00:07<00:04, 32.52it/s, loss=0.465, v_num=15, train_loss_step=0.669]Epoch 0:  61%|██████    | 231/380 [00:07<00:04, 32.52it/s, loss=0.46, v_num=15, train_loss_step=0.593] Epoch 0:  61%|██████    | 232/380 [00:07<00:04, 32.51it/s, loss=0.467, v_num=15, train_loss_step=0.748]Epoch 0:  61%|██████▏   | 233/380 [00:07<00:04, 32.51it/s, loss=0.476, v_num=15, train_loss_step=0.509]Epoch 0:  62%|██████▏   | 234/380 [00:07<00:04, 32.51it/s, loss=0.482, v_num=15, train_loss_step=0.495]Epoch 0:  62%|██████▏   | 235/380 [00:07<00:04, 32.51it/s, loss=0.482, v_num=15, train_loss_step=0.495]Epoch 0:  62%|██████▏   | 235/380 [00:07<00:04, 32.51it/s, loss=0.502, v_num=15, train_loss_step=0.715]Epoch 0:  62%|██████▏   | 236/380 [00:07<00:04, 32.51it/s, loss=0.502, v_num=15, train_loss_step=0.313]Epoch 0:  62%|██████▏   | 237/380 [00:07<00:04, 32.51it/s, loss=0.499, v_num=15, train_loss_step=0.336]Epoch 0:  63%|██████▎   | 238/380 [00:07<00:04, 32.51it/s, loss=0.512, v_num=15, train_loss_step=0.574]Epoch 0:  63%|██████▎   | 239/380 [00:07<00:04, 32.51it/s, loss=0.512, v_num=15, train_loss_step=0.574]Epoch 0:  63%|██████▎   | 239/380 [00:07<00:04, 32.51it/s, loss=0.513, v_num=15, train_loss_step=0.338]Epoch 0:  63%|██████▎   | 240/380 [00:07<00:04, 32.51it/s, loss=0.49, v_num=15, train_loss_step=0.313] Epoch 0:  63%|██████▎   | 241/380 [00:07<00:04, 32.51it/s, loss=0.485, v_num=15, train_loss_step=0.326]Epoch 0:  64%|██████▎   | 242/380 [00:07<00:04, 32.51it/s, loss=0.498, v_num=15, train_loss_step=0.565]Epoch 0:  64%|██████▍   | 243/380 [00:07<00:04, 32.51it/s, loss=0.498, v_num=15, train_loss_step=0.565]Epoch 0:  64%|██████▍   | 243/380 [00:07<00:04, 32.51it/s, loss=0.526, v_num=15, train_loss_step=0.977]Epoch 0:  64%|██████▍   | 244/380 [00:07<00:04, 32.51it/s, loss=0.518, v_num=15, train_loss_step=0.313]Epoch 0:  64%|██████▍   | 245/380 [00:07<00:04, 32.50it/s, loss=0.526, v_num=15, train_loss_step=0.462]Epoch 0:  65%|██████▍   | 246/380 [00:07<00:04, 32.50it/s, loss=0.518, v_num=15, train_loss_step=0.556]Epoch 0:  65%|██████▌   | 247/380 [00:07<00:04, 32.50it/s, loss=0.518, v_num=15, train_loss_step=0.556]Epoch 0:  65%|██████▌   | 247/380 [00:07<00:04, 32.50it/s, loss=0.525, v_num=15, train_loss_step=0.717]Epoch 0:  65%|██████▌   | 248/380 [00:07<00:04, 32.50it/s, loss=0.51, v_num=15, train_loss_step=0.372] Epoch 0:  66%|██████▌   | 249/380 [00:07<00:04, 32.50it/s, loss=0.52, v_num=15, train_loss_step=0.500]Epoch 0:  66%|██████▌   | 250/380 [00:07<00:03, 32.50it/s, loss=0.503, v_num=15, train_loss_step=0.338]Epoch 0:  66%|██████▌   | 251/380 [00:07<00:03, 32.50it/s, loss=0.503, v_num=15, train_loss_step=0.338]Epoch 0:  66%|██████▌   | 251/380 [00:07<00:03, 32.50it/s, loss=0.491, v_num=15, train_loss_step=0.347]Epoch 0:  66%|██████▋   | 252/380 [00:07<00:03, 32.50it/s, loss=0.475, v_num=15, train_loss_step=0.430]Epoch 0:  67%|██████▋   | 253/380 [00:07<00:03, 32.50it/s, loss=0.465, v_num=15, train_loss_step=0.318]Epoch 0:  67%|██████▋   | 254/380 [00:07<00:03, 32.50it/s, loss=0.456, v_num=15, train_loss_step=0.313]Epoch 0:  67%|██████▋   | 255/380 [00:07<00:03, 32.50it/s, loss=0.456, v_num=15, train_loss_step=0.313]Epoch 0:  67%|██████▋   | 255/380 [00:07<00:03, 32.50it/s, loss=0.436, v_num=15, train_loss_step=0.313]Epoch 0:  67%|██████▋   | 256/380 [00:07<00:03, 32.50it/s, loss=0.437, v_num=15, train_loss_step=0.329]Epoch 0:  68%|██████▊   | 257/380 [00:07<00:03, 32.50it/s, loss=0.439, v_num=15, train_loss_step=0.372]Epoch 0:  68%|██████▊   | 258/380 [00:07<00:03, 32.50it/s, loss=0.426, v_num=15, train_loss_step=0.313]Epoch 0:  68%|██████▊   | 259/380 [00:07<00:03, 32.50it/s, loss=0.426, v_num=15, train_loss_step=0.313]Epoch 0:  68%|██████▊   | 259/380 [00:07<00:03, 32.50it/s, loss=0.424, v_num=15, train_loss_step=0.313]Epoch 0:  68%|██████▊   | 260/380 [00:08<00:03, 32.48it/s, loss=0.425, v_num=15, train_loss_step=0.322]Epoch 0:  69%|██████▊   | 261/380 [00:08<00:03, 32.48it/s, loss=0.424, v_num=15, train_loss_step=0.313]Epoch 0:  69%|██████▉   | 262/380 [00:08<00:03, 32.48it/s, loss=0.412, v_num=15, train_loss_step=0.313]Epoch 0:  69%|██████▉   | 263/380 [00:08<00:03, 32.48it/s, loss=0.412, v_num=15, train_loss_step=0.313]Epoch 0:  69%|██████▉   | 263/380 [00:08<00:03, 32.48it/s, loss=0.381, v_num=15, train_loss_step=0.364]Epoch 0:  69%|██████▉   | 264/380 [00:08<00:03, 32.48it/s, loss=0.386, v_num=15, train_loss_step=0.413]Epoch 0:  70%|██████▉   | 265/380 [00:08<00:03, 32.48it/s, loss=0.382, v_num=15, train_loss_step=0.392]Epoch 0:  70%|███████   | 266/380 [00:08<00:03, 32.48it/s, loss=0.37, v_num=15, train_loss_step=0.313] Epoch 0:  70%|███████   | 267/380 [00:08<00:03, 32.48it/s, loss=0.37, v_num=15, train_loss_step=0.313]Epoch 0:  70%|███████   | 267/380 [00:08<00:03, 32.48it/s, loss=0.361, v_num=15, train_loss_step=0.534]Epoch 0:  71%|███████   | 268/380 [00:08<00:03, 32.48it/s, loss=0.361, v_num=15, train_loss_step=0.375]Epoch 0:  71%|███████   | 269/380 [00:08<00:03, 32.48it/s, loss=0.358, v_num=15, train_loss_step=0.428]Epoch 0:  71%|███████   | 270/380 [00:08<00:03, 32.48it/s, loss=0.363, v_num=15, train_loss_step=0.452]Epoch 0:  71%|███████▏  | 271/380 [00:08<00:03, 32.48it/s, loss=0.363, v_num=15, train_loss_step=0.452]Epoch 0:  71%|███████▏  | 271/380 [00:08<00:03, 32.48it/s, loss=0.362, v_num=15, train_loss_step=0.313]Epoch 0:  72%|███████▏  | 272/380 [00:08<00:03, 32.48it/s, loss=0.361, v_num=15, train_loss_step=0.412]Epoch 0:  72%|███████▏  | 273/380 [00:08<00:03, 32.48it/s, loss=0.361, v_num=15, train_loss_step=0.313]Epoch 0:  72%|███████▏  | 274/380 [00:08<00:03, 32.48it/s, loss=0.361, v_num=15, train_loss_step=0.313]Epoch 0:  72%|███████▏  | 275/380 [00:08<00:03, 32.48it/s, loss=0.361, v_num=15, train_loss_step=0.313]Epoch 0:  72%|███████▏  | 275/380 [00:08<00:03, 32.48it/s, loss=0.361, v_num=15, train_loss_step=0.313]Epoch 0:  73%|███████▎  | 276/380 [00:08<00:03, 32.48it/s, loss=0.363, v_num=15, train_loss_step=0.367]Epoch 0:  73%|███████▎  | 277/380 [00:08<00:03, 32.48it/s, loss=0.361, v_num=15, train_loss_step=0.335]Epoch 0:  73%|███████▎  | 278/380 [00:08<00:03, 32.48it/s, loss=0.368, v_num=15, train_loss_step=0.464]Epoch 0:  73%|███████▎  | 279/380 [00:08<00:03, 32.48it/s, loss=0.368, v_num=15, train_loss_step=0.464]Epoch 0:  73%|███████▎  | 279/380 [00:08<00:03, 32.48it/s, loss=0.386, v_num=15, train_loss_step=0.667]Epoch 0:  74%|███████▎  | 280/380 [00:08<00:03, 32.48it/s, loss=0.386, v_num=15, train_loss_step=0.324]Epoch 0:  74%|███████▍  | 281/380 [00:08<00:03, 32.47it/s, loss=0.391, v_num=15, train_loss_step=0.417]Epoch 0:  74%|███████▍  | 282/380 [00:08<00:03, 32.48it/s, loss=0.395, v_num=15, train_loss_step=0.390]Epoch 0:  74%|███████▍  | 283/380 [00:08<00:02, 32.48it/s, loss=0.395, v_num=15, train_loss_step=0.390]Epoch 0:  74%|███████▍  | 283/380 [00:08<00:02, 32.48it/s, loss=0.393, v_num=15, train_loss_step=0.314]Epoch 0:  75%|███████▍  | 284/380 [00:08<00:02, 32.47it/s, loss=0.4, v_num=15, train_loss_step=0.570]  Epoch 0:  75%|███████▌  | 285/380 [00:08<00:02, 32.48it/s, loss=0.402, v_num=15, train_loss_step=0.415]Epoch 0:  75%|███████▌  | 286/380 [00:08<00:02, 32.48it/s, loss=0.407, v_num=15, train_loss_step=0.424]Epoch 0:  76%|███████▌  | 287/380 [00:08<00:02, 32.48it/s, loss=0.407, v_num=15, train_loss_step=0.424]Epoch 0:  76%|███████▌  | 287/380 [00:08<00:02, 32.48it/s, loss=0.396, v_num=15, train_loss_step=0.313]Epoch 0:  76%|███████▌  | 288/380 [00:08<00:02, 32.48it/s, loss=0.393, v_num=15, train_loss_step=0.313]Epoch 0:  76%|███████▌  | 289/380 [00:08<00:02, 32.48it/s, loss=0.387, v_num=15, train_loss_step=0.313]Epoch 0:  76%|███████▋  | 290/380 [00:08<00:02, 32.48it/s, loss=0.38, v_num=15, train_loss_step=0.313] Epoch 0:  77%|███████▋  | 291/380 [00:08<00:02, 32.48it/s, loss=0.38, v_num=15, train_loss_step=0.313]Epoch 0:  77%|███████▋  | 291/380 [00:08<00:02, 32.48it/s, loss=0.382, v_num=15, train_loss_step=0.353]Epoch 0:  77%|███████▋  | 292/380 [00:09<00:02, 32.48it/s, loss=0.381, v_num=15, train_loss_step=0.377]Epoch 0:  77%|███████▋  | 293/380 [00:09<00:02, 32.48it/s, loss=0.399, v_num=15, train_loss_step=0.676]Epoch 0:  77%|███████▋  | 294/380 [00:09<00:02, 32.48it/s, loss=0.399, v_num=15, train_loss_step=0.327]Epoch 0:  78%|███████▊  | 295/380 [00:09<00:02, 32.48it/s, loss=0.399, v_num=15, train_loss_step=0.327]Epoch 0:  78%|███████▊  | 295/380 [00:09<00:02, 32.48it/s, loss=0.403, v_num=15, train_loss_step=0.385]Epoch 0:  78%|███████▊  | 296/380 [00:09<00:02, 32.48it/s, loss=0.401, v_num=15, train_loss_step=0.326]Epoch 0:  78%|███████▊  | 297/380 [00:09<00:02, 32.48it/s, loss=0.401, v_num=15, train_loss_step=0.333]Epoch 0:  78%|███████▊  | 298/380 [00:09<00:02, 32.48it/s, loss=0.393, v_num=15, train_loss_step=0.313]Epoch 0:  79%|███████▊  | 299/380 [00:09<00:02, 32.48it/s, loss=0.393, v_num=15, train_loss_step=0.313]Epoch 0:  79%|███████▊  | 299/380 [00:09<00:02, 32.48it/s, loss=0.375, v_num=15, train_loss_step=0.313]Epoch 0:  79%|███████▉  | 300/380 [00:09<00:02, 32.48it/s, loss=0.397, v_num=15, train_loss_step=0.763]Epoch 0:  79%|███████▉  | 301/380 [00:09<00:02, 32.48it/s, loss=0.412, v_num=15, train_loss_step=0.705]Epoch 0:  79%|███████▉  | 302/380 [00:09<00:02, 32.48it/s, loss=0.427, v_num=15, train_loss_step=0.693]Epoch 0:  80%|███████▉  | 303/380 [00:09<00:02, 32.48it/s, loss=0.427, v_num=15, train_loss_step=0.693]Epoch 0:  80%|███████▉  | 303/380 [00:09<00:02, 32.48it/s, loss=0.432, v_num=15, train_loss_step=0.417]Epoch 0:  80%|████████  | 304/380 [00:09<00:02, 32.47it/s, loss=0.437, v_num=15, train_loss_step=0.670]Epoch 0:  80%|████████  | 305/380 [00:09<00:02, 32.47it/s, loss=0.457, v_num=15, train_loss_step=0.806]Epoch 0:  81%|████████  | 306/380 [00:09<00:02, 32.47it/s, loss=0.456, v_num=15, train_loss_step=0.411]Epoch 0:  81%|████████  | 307/380 [00:09<00:02, 32.48it/s, loss=0.456, v_num=15, train_loss_step=0.411]Epoch 0:  81%|████████  | 307/380 [00:09<00:02, 32.47it/s, loss=0.457, v_num=15, train_loss_step=0.337]Epoch 0:  81%|████████  | 308/380 [00:09<00:02, 32.48it/s, loss=0.465, v_num=15, train_loss_step=0.475]Epoch 0:  81%|████████▏ | 309/380 [00:09<00:02, 32.48it/s, loss=0.465, v_num=15, train_loss_step=0.313]Epoch 0:  82%|████████▏ | 310/380 [00:09<00:02, 32.48it/s, loss=0.468, v_num=15, train_loss_step=0.358]Epoch 0:  82%|████████▏ | 311/380 [00:09<00:02, 32.48it/s, loss=0.468, v_num=15, train_loss_step=0.358]Epoch 0:  82%|████████▏ | 311/380 [00:09<00:02, 32.48it/s, loss=0.466, v_num=15, train_loss_step=0.332]Epoch 0:  82%|████████▏ | 312/380 [00:09<00:02, 32.48it/s, loss=0.463, v_num=15, train_loss_step=0.313]Epoch 0:  82%|████████▏ | 313/380 [00:09<00:02, 32.48it/s, loss=0.447, v_num=15, train_loss_step=0.347]Epoch 0:  83%|████████▎ | 314/380 [00:09<00:02, 32.47it/s, loss=0.456, v_num=15, train_loss_step=0.509]Epoch 0:  83%|████████▎ | 315/380 [00:09<00:02, 32.47it/s, loss=0.456, v_num=15, train_loss_step=0.509]Epoch 0:  83%|████████▎ | 315/380 [00:09<00:02, 32.47it/s, loss=0.468, v_num=15, train_loss_step=0.618]Epoch 0:  83%|████████▎ | 316/380 [00:09<00:01, 32.47it/s, loss=0.47, v_num=15, train_loss_step=0.371] Epoch 0:  83%|████████▎ | 317/380 [00:09<00:01, 32.47it/s, loss=0.471, v_num=15, train_loss_step=0.349]Epoch 0:  84%|████████▎ | 318/380 [00:09<00:01, 32.47it/s, loss=0.49, v_num=15, train_loss_step=0.702] Epoch 0:  84%|████████▍ | 319/380 [00:09<00:01, 32.47it/s, loss=0.49, v_num=15, train_loss_step=0.702]Epoch 0:  84%|████████▍ | 319/380 [00:09<00:01, 32.47it/s, loss=0.49, v_num=15, train_loss_step=0.313]Epoch 0:  84%|████████▍ | 320/380 [00:09<00:01, 32.47it/s, loss=0.468, v_num=15, train_loss_step=0.313]Epoch 0:  84%|████████▍ | 321/380 [00:09<00:01, 32.48it/s, loss=0.452, v_num=15, train_loss_step=0.388]Epoch 0:  85%|████████▍ | 322/380 [00:09<00:01, 32.48it/s, loss=0.448, v_num=15, train_loss_step=0.611]Epoch 0:  85%|████████▌ | 323/380 [00:09<00:01, 32.48it/s, loss=0.448, v_num=15, train_loss_step=0.611]Epoch 0:  85%|████████▌ | 323/380 [00:09<00:01, 32.48it/s, loss=0.442, v_num=15, train_loss_step=0.313]Epoch 0:  85%|████████▌ | 324/380 [00:10<00:01, 32.48it/s, loss=0.425, v_num=15, train_loss_step=0.313]Epoch 0:  86%|████████▌ | 325/380 [00:10<00:01, 32.48it/s, loss=0.406, v_num=15, train_loss_step=0.432]Epoch 0:  86%|████████▌ | 326/380 [00:10<00:01, 32.48it/s, loss=0.403, v_num=15, train_loss_step=0.360]Epoch 0:  86%|████████▌ | 327/380 [00:10<00:01, 32.48it/s, loss=0.403, v_num=15, train_loss_step=0.360]Epoch 0:  86%|████████▌ | 327/380 [00:10<00:01, 32.47it/s, loss=0.402, v_num=15, train_loss_step=0.313]Epoch 0:  86%|████████▋ | 328/380 [00:10<00:01, 32.47it/s, loss=0.423, v_num=15, train_loss_step=0.895]Epoch 0:  87%|████████▋ | 329/380 [00:10<00:01, 32.47it/s, loss=0.44, v_num=15, train_loss_step=0.644] Epoch 0:  87%|████████▋ | 330/380 [00:10<00:01, 32.47it/s, loss=0.437, v_num=15, train_loss_step=0.313]Epoch 0:  87%|████████▋ | 331/380 [00:10<00:01, 32.47it/s, loss=0.437, v_num=15, train_loss_step=0.313]Epoch 0:  87%|████████▋ | 331/380 [00:10<00:01, 32.47it/s, loss=0.47, v_num=15, train_loss_step=0.974] Epoch 0:  87%|████████▋ | 332/380 [00:10<00:01, 32.47it/s, loss=0.47, v_num=15, train_loss_step=0.313]Epoch 0:  88%|████████▊ | 333/380 [00:10<00:01, 32.47it/s, loss=0.473, v_num=15, train_loss_step=0.421]Epoch 0:  88%|████████▊ | 334/380 [00:10<00:01, 32.49it/s, loss=0.464, v_num=15, train_loss_step=0.323]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/46 [00:00<?, ?it/s][AEpoch 0:  88%|████████▊ | 336/380 [00:10<00:01, 32.43it/s, loss=0.464, v_num=15, train_loss_step=0.323]
Validating:   4%|▍         | 2/46 [00:00<00:03, 13.51it/s][A
Validating:   9%|▊         | 4/46 [00:00<00:03, 13.64it/s][A
Validating:  13%|█▎        | 6/46 [00:00<00:02, 13.56it/s][AEpoch 0:  90%|████████▉ | 341/380 [00:10<00:01, 31.79it/s, loss=0.464, v_num=15, train_loss_step=0.323]
Validating:  17%|█▋        | 8/46 [00:00<00:02, 13.64it/s][A
Validating:  22%|██▏       | 10/46 [00:00<00:02, 13.63it/s][AEpoch 0:  91%|█████████ | 346/380 [00:11<00:01, 31.20it/s, loss=0.464, v_num=15, train_loss_step=0.323]
Validating:  26%|██▌       | 12/46 [00:00<00:02, 13.65it/s][A
Validating:  30%|███       | 14/46 [00:01<00:02, 13.66it/s][A
Validating:  35%|███▍      | 16/46 [00:01<00:02, 13.65it/s][AEpoch 0:  92%|█████████▏| 351/380 [00:11<00:00, 30.64it/s, loss=0.464, v_num=15, train_loss_step=0.323]
Validating:  39%|███▉      | 18/46 [00:01<00:02, 13.66it/s][A
Validating:  43%|████▎     | 20/46 [00:01<00:01, 13.68it/s][AEpoch 0:  94%|█████████▎| 356/380 [00:11<00:00, 30.12it/s, loss=0.464, v_num=15, train_loss_step=0.323]
Validating:  48%|████▊     | 22/46 [00:01<00:01, 13.69it/s][A
Validating:  52%|█████▏    | 24/46 [00:01<00:01, 13.70it/s][A
Validating:  57%|█████▋    | 26/46 [00:01<00:01, 13.72it/s][AEpoch 0:  95%|█████████▌| 361/380 [00:12<00:00, 29.63it/s, loss=0.464, v_num=15, train_loss_step=0.323]
Validating:  61%|██████    | 28/46 [00:02<00:01, 13.72it/s][A
Validating:  65%|██████▌   | 30/46 [00:02<00:01, 13.71it/s][AEpoch 0:  96%|█████████▋| 366/380 [00:12<00:00, 29.16it/s, loss=0.464, v_num=15, train_loss_step=0.323]
Validating:  70%|██████▉   | 32/46 [00:02<00:01, 13.64it/s][A
Validating:  74%|███████▍  | 34/46 [00:02<00:00, 13.69it/s][A
Validating:  78%|███████▊  | 36/46 [00:02<00:00, 13.72it/s][AEpoch 0:  98%|█████████▊| 371/380 [00:12<00:00, 28.73it/s, loss=0.464, v_num=15, train_loss_step=0.323]
Validating:  83%|████████▎ | 38/46 [00:02<00:00, 13.76it/s][A
Validating:  87%|████████▋ | 40/46 [00:02<00:00, 13.69it/s][AEpoch 0:  99%|█████████▉| 376/380 [00:13<00:00, 28.32it/s, loss=0.464, v_num=15, train_loss_step=0.323]
Validating:  91%|█████████▏| 42/46 [00:03<00:00, 13.73it/s][A
Validating:  96%|█████████▌| 44/46 [00:03<00:00, 13.72it/s][A
Validating: 100%|██████████| 46/46 [00:03<00:00, 13.73it/s][AEpoch 0: 100%|██████████| 380/380 [00:13<00:00, 27.85it/s, loss=0.464, v_num=15, train_loss_step=0.323]
                                                           [AEpoch 0: 100%|██████████| 380/380 [00:13<00:00, 27.76it/s, loss=0.464, v_num=15, train_loss_step=0.323]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(

Testing: 0it [00:00, ?it/s]Testing:   2%|▏         | 3/169 [00:00<00:05, 28.09it/s]Testing:   4%|▎         | 6/169 [00:00<00:05, 28.63it/s]Testing:   5%|▌         | 9/169 [00:00<00:05, 29.10it/s]Testing:   7%|▋         | 12/169 [00:00<00:05, 29.28it/s]Testing:   9%|▉         | 15/169 [00:00<00:05, 29.30it/s]Testing:  11%|█         | 18/169 [00:00<00:05, 29.32it/s]Testing:  12%|█▏        | 21/169 [00:00<00:05, 29.25it/s]Testing:  14%|█▍        | 24/169 [00:00<00:04, 29.31it/s]Testing:  16%|█▌        | 27/169 [00:00<00:04, 29.19it/s]Testing:  18%|█▊        | 30/169 [00:01<00:04, 28.98it/s]Testing:  20%|█▉        | 33/169 [00:01<00:04, 29.08it/s]Testing:  21%|██▏       | 36/169 [00:01<00:04, 29.18it/s]Testing:  23%|██▎       | 39/169 [00:01<00:04, 28.95it/s]Testing:  25%|██▍       | 42/169 [00:01<00:04, 28.91it/s]Testing:  27%|██▋       | 45/169 [00:01<00:04, 29.06it/s]Testing:  28%|██▊       | 48/169 [00:01<00:04, 29.18it/s]Testing:  30%|███       | 51/169 [00:01<00:04, 29.30it/s]Testing:  32%|███▏      | 54/169 [00:01<00:03, 29.23it/s]Testing:  34%|███▎      | 57/169 [00:01<00:03, 29.08it/s]Testing:  36%|███▌      | 60/169 [00:02<00:03, 29.17it/s]Testing:  37%|███▋      | 63/169 [00:02<00:03, 29.21it/s]Testing:  39%|███▉      | 66/169 [00:02<00:03, 29.28it/s]Testing:  41%|████      | 69/169 [00:02<00:03, 29.35it/s]Testing:  43%|████▎     | 72/169 [00:02<00:03, 29.46it/s]Testing:  44%|████▍     | 75/169 [00:02<00:03, 29.44it/s]Testing:  46%|████▌     | 78/169 [00:02<00:03, 29.42it/s]Testing:  48%|████▊     | 81/169 [00:02<00:02, 29.34it/s]Testing:  50%|████▉     | 84/169 [00:02<00:02, 29.27it/s]Testing:  51%|█████▏    | 87/169 [00:02<00:02, 29.25it/s]Testing:  53%|█████▎    | 90/169 [00:03<00:02, 29.14it/s]Testing:  55%|█████▌    | 93/169 [00:03<00:02, 29.01it/s]Testing:  57%|█████▋    | 96/169 [00:03<00:02, 29.27it/s]Testing:  59%|█████▊    | 99/169 [00:03<00:02, 29.31it/s]Testing:  60%|██████    | 102/169 [00:03<00:02, 29.34it/s]Testing:  62%|██████▏   | 105/169 [00:03<00:02, 29.37it/s]Testing:  64%|██████▍   | 108/169 [00:03<00:02, 29.25it/s]Testing:  66%|██████▌   | 111/169 [00:03<00:01, 29.30it/s]Testing:  67%|██████▋   | 114/169 [00:03<00:01, 29.26it/s]Testing:  69%|██████▉   | 117/169 [00:04<00:01, 29.26it/s]Testing:  71%|███████   | 120/169 [00:04<00:01, 29.30it/s]Testing:  73%|███████▎  | 123/169 [00:04<00:01, 29.45it/s]Testing:  75%|███████▍  | 126/169 [00:04<00:01, 29.38it/s]Testing:  76%|███████▋  | 129/169 [00:04<00:01, 29.30it/s]Testing:  78%|███████▊  | 132/169 [00:04<00:01, 29.16it/s]Testing:  80%|███████▉  | 135/169 [00:04<00:01, 29.19it/s]Testing:  82%|████████▏ | 138/169 [00:04<00:01, 29.10it/s]Testing:  83%|████████▎ | 141/169 [00:04<00:00, 29.09it/s]Testing:  85%|████████▌ | 144/169 [00:04<00:00, 29.07it/s]Testing:  87%|████████▋ | 147/169 [00:05<00:00, 28.87it/s]Testing:  89%|████████▉ | 150/169 [00:05<00:00, 28.97it/s]Testing:  91%|█████████ | 153/169 [00:05<00:00, 28.99it/s]Testing:  92%|█████████▏| 156/169 [00:05<00:00, 29.02it/s]Testing:  94%|█████████▍| 159/169 [00:05<00:00, 29.01it/s]Testing:  96%|█████████▌| 162/169 [00:05<00:00, 28.88it/s]Testing:  98%|█████████▊| 165/169 [00:05<00:00, 28.94it/s]Testing:  99%|█████████▉| 168/169 [00:05<00:00, 28.88it/s]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'_mean_accuracy': 0.9837990403175354,
 '_standard_dev_accuracy': 0.03452220931649208,
 '_variance_accuracy': 0.0011917828815057874,
 'test_acc': 0.9837990403175354,
 'test_dice_c1': 0.0,
 'test_f2_c1': 0.0,
 'test_loss': 0.43117016553878784,
 'test_mean_c1': 0.0,
 'test_prec_c1': 0.0,
 'test_sens_c1': 0.0,
 'test_spec_c1': 1.0}
--------------------------------------------------------------------------------
Testing: 100%|██████████| 169/169 [00:05<00:00, 29.13it/s]
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

  | Name       | Type             | Params
------------------------------------------------
0 | encoder1   | EncoderBlock     | 37.6 K
1 | encoder2   | EncoderBlock     | 221 K 
2 | bottleneck | ConvolutionBlock | 885 K 
3 | dropout    | Dropout2d        | 0     
4 | decoder1   | DecoderBlock     | 573 K 
5 | decoder2   | DecoderBlock     | 143 K 
6 | conv       | Conv2d           | 130   
7 | softmax    | Softmax2d        | 0     
------------------------------------------------
1.9 M     Trainable params
0         Non-trainable params
1.9 M     Total params
7.447     Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  1.76it/s]Validation sanity check: 100%|██████████| 2/2 [00:00<00:00,  2.26it/s]                                                                      /home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Training: -1it [00:00, ?it/s]Training:   0%|          | 0/96 [00:00<00:00, 26214.40it/s]Epoch 0:   0%|          | 0/96 [00:00<00:00, 4364.52it/s]  Epoch 0:   1%|          | 1/96 [00:00<00:06, 14.70it/s]  Epoch 0:   1%|          | 1/96 [00:00<00:06, 14.66it/s, loss=0.669, v_num=16, train_loss_step=0.669]Epoch 0:   2%|▏         | 2/96 [00:00<00:07, 12.23it/s, loss=0.669, v_num=16, train_loss_step=0.669]Epoch 0:   2%|▏         | 2/96 [00:00<00:07, 12.22it/s, loss=0.664, v_num=16, train_loss_step=0.658]Epoch 0:   3%|▎         | 3/96 [00:00<00:08, 11.31it/s, loss=0.664, v_num=16, train_loss_step=0.658]Epoch 0:   3%|▎         | 3/96 [00:00<00:08, 11.30it/s, loss=0.659, v_num=16, train_loss_step=0.648]Epoch 0:   4%|▍         | 4/96 [00:00<00:08, 10.89it/s, loss=0.659, v_num=16, train_loss_step=0.648]Epoch 0:   4%|▍         | 4/96 [00:00<00:08, 10.88it/s, loss=0.649, v_num=16, train_loss_step=0.622]Epoch 0:   5%|▌         | 5/96 [00:00<00:08, 10.66it/s, loss=0.649, v_num=16, train_loss_step=0.622]Epoch 0:   5%|▌         | 5/96 [00:00<00:08, 10.65it/s, loss=0.639, v_num=16, train_loss_step=0.598]Epoch 0:   6%|▋         | 6/96 [00:00<00:08, 10.49it/s, loss=0.639, v_num=16, train_loss_step=0.598]Epoch 0:   6%|▋         | 6/96 [00:00<00:08, 10.49it/s, loss=0.593, v_num=16, train_loss_step=0.363]Epoch 0:   7%|▋         | 7/96 [00:00<00:08, 10.37it/s, loss=0.593, v_num=16, train_loss_step=0.363]Epoch 0:   7%|▋         | 7/96 [00:00<00:08, 10.37it/s, loss=0.56, v_num=16, train_loss_step=0.362] Epoch 0:   8%|▊         | 8/96 [00:00<00:08, 10.29it/s, loss=0.56, v_num=16, train_loss_step=0.362]Epoch 0:   8%|▊         | 8/96 [00:00<00:08, 10.28it/s, loss=0.572, v_num=16, train_loss_step=0.654]Epoch 0:   9%|▉         | 9/96 [00:00<00:08, 10.22it/s, loss=0.572, v_num=16, train_loss_step=0.654]Epoch 0:   9%|▉         | 9/96 [00:00<00:08, 10.22it/s, loss=0.546, v_num=16, train_loss_step=0.344]Epoch 0:  10%|█         | 10/96 [00:01<00:08, 10.17it/s, loss=0.546, v_num=16, train_loss_step=0.344]Epoch 0:  10%|█         | 10/96 [00:01<00:08, 10.16it/s, loss=0.53, v_num=16, train_loss_step=0.377] Epoch 0:  11%|█▏        | 11/96 [00:01<00:08, 10.12it/s, loss=0.53, v_num=16, train_loss_step=0.377]Epoch 0:  11%|█▏        | 11/96 [00:01<00:08, 10.11it/s, loss=0.515, v_num=16, train_loss_step=0.375]Epoch 0:  12%|█▎        | 12/96 [00:01<00:08, 10.07it/s, loss=0.515, v_num=16, train_loss_step=0.375]Epoch 0:  12%|█▎        | 12/96 [00:01<00:08, 10.07it/s, loss=0.51, v_num=16, train_loss_step=0.455] Epoch 0:  14%|█▎        | 13/96 [00:01<00:08, 10.04it/s, loss=0.51, v_num=16, train_loss_step=0.455]Epoch 0:  14%|█▎        | 13/96 [00:01<00:08, 10.03it/s, loss=0.525, v_num=16, train_loss_step=0.697]Epoch 0:  15%|█▍        | 14/96 [00:01<00:08, 10.01it/s, loss=0.525, v_num=16, train_loss_step=0.697]Epoch 0:  15%|█▍        | 14/96 [00:01<00:08, 10.01it/s, loss=0.523, v_num=16, train_loss_step=0.503]Epoch 0:  16%|█▌        | 15/96 [00:01<00:08,  9.98it/s, loss=0.523, v_num=16, train_loss_step=0.503]Epoch 0:  16%|█▌        | 15/96 [00:01<00:08,  9.98it/s, loss=0.524, v_num=16, train_loss_step=0.537]Epoch 0:  17%|█▋        | 16/96 [00:01<00:08,  9.96it/s, loss=0.524, v_num=16, train_loss_step=0.537]Epoch 0:  17%|█▋        | 16/96 [00:01<00:08,  9.96it/s, loss=0.518, v_num=16, train_loss_step=0.424]Epoch 0:  18%|█▊        | 17/96 [00:01<00:07,  9.93it/s, loss=0.518, v_num=16, train_loss_step=0.424]Epoch 0:  18%|█▊        | 17/96 [00:01<00:07,  9.93it/s, loss=0.523, v_num=16, train_loss_step=0.605]Epoch 0:  19%|█▉        | 18/96 [00:01<00:07,  9.92it/s, loss=0.523, v_num=16, train_loss_step=0.605]Epoch 0:  19%|█▉        | 18/96 [00:01<00:07,  9.92it/s, loss=0.521, v_num=16, train_loss_step=0.485]Epoch 0:  20%|█▉        | 19/96 [00:02<00:07,  9.90it/s, loss=0.521, v_num=16, train_loss_step=0.485]Epoch 0:  20%|█▉        | 19/96 [00:02<00:07,  9.90it/s, loss=0.511, v_num=16, train_loss_step=0.336]Epoch 0:  21%|██        | 20/96 [00:02<00:07,  9.89it/s, loss=0.511, v_num=16, train_loss_step=0.336]Epoch 0:  21%|██        | 20/96 [00:02<00:07,  9.89it/s, loss=0.509, v_num=16, train_loss_step=0.458]Epoch 0:  22%|██▏       | 21/96 [00:02<00:07,  9.87it/s, loss=0.509, v_num=16, train_loss_step=0.458]Epoch 0:  22%|██▏       | 21/96 [00:02<00:07,  9.87it/s, loss=0.494, v_num=16, train_loss_step=0.388]Epoch 0:  23%|██▎       | 22/96 [00:02<00:07,  9.86it/s, loss=0.494, v_num=16, train_loss_step=0.388]Epoch 0:  23%|██▎       | 22/96 [00:02<00:07,  9.86it/s, loss=0.489, v_num=16, train_loss_step=0.543]Epoch 0:  24%|██▍       | 23/96 [00:02<00:07,  9.85it/s, loss=0.489, v_num=16, train_loss_step=0.543]Epoch 0:  24%|██▍       | 23/96 [00:02<00:07,  9.85it/s, loss=0.476, v_num=16, train_loss_step=0.391]Epoch 0:  25%|██▌       | 24/96 [00:02<00:07,  9.84it/s, loss=0.476, v_num=16, train_loss_step=0.391]Epoch 0:  25%|██▌       | 24/96 [00:02<00:07,  9.84it/s, loss=0.463, v_num=16, train_loss_step=0.373]Epoch 0:  26%|██▌       | 25/96 [00:02<00:07,  9.83it/s, loss=0.463, v_num=16, train_loss_step=0.373]Epoch 0:  26%|██▌       | 25/96 [00:02<00:07,  9.82it/s, loss=0.453, v_num=16, train_loss_step=0.394]Epoch 0:  27%|██▋       | 26/96 [00:02<00:07,  9.81it/s, loss=0.453, v_num=16, train_loss_step=0.394]Epoch 0:  27%|██▋       | 26/96 [00:02<00:07,  9.81it/s, loss=0.468, v_num=16, train_loss_step=0.660]Epoch 0:  28%|██▊       | 27/96 [00:02<00:07,  9.80it/s, loss=0.468, v_num=16, train_loss_step=0.660]Epoch 0:  28%|██▊       | 27/96 [00:02<00:07,  9.80it/s, loss=0.481, v_num=16, train_loss_step=0.618]Epoch 0:  29%|██▉       | 28/96 [00:02<00:06,  9.80it/s, loss=0.481, v_num=16, train_loss_step=0.618]Epoch 0:  29%|██▉       | 28/96 [00:02<00:06,  9.79it/s, loss=0.47, v_num=16, train_loss_step=0.428] Epoch 0:  30%|███       | 29/96 [00:03<00:06,  9.79it/s, loss=0.47, v_num=16, train_loss_step=0.428]Epoch 0:  30%|███       | 29/96 [00:03<00:06,  9.79it/s, loss=0.476, v_num=16, train_loss_step=0.466]Epoch 0:  31%|███▏      | 30/96 [00:03<00:06,  9.78it/s, loss=0.476, v_num=16, train_loss_step=0.466]Epoch 0:  31%|███▏      | 30/96 [00:03<00:06,  9.78it/s, loss=0.479, v_num=16, train_loss_step=0.445]Epoch 0:  32%|███▏      | 31/96 [00:03<00:06,  9.77it/s, loss=0.479, v_num=16, train_loss_step=0.445]Epoch 0:  32%|███▏      | 31/96 [00:03<00:06,  9.77it/s, loss=0.485, v_num=16, train_loss_step=0.496]Epoch 0:  33%|███▎      | 32/96 [00:03<00:06,  9.76it/s, loss=0.485, v_num=16, train_loss_step=0.496]Epoch 0:  33%|███▎      | 32/96 [00:03<00:06,  9.76it/s, loss=0.484, v_num=16, train_loss_step=0.427]Epoch 0:  34%|███▍      | 33/96 [00:03<00:06,  9.76it/s, loss=0.484, v_num=16, train_loss_step=0.427]Epoch 0:  34%|███▍      | 33/96 [00:03<00:06,  9.76it/s, loss=0.473, v_num=16, train_loss_step=0.476]Epoch 0:  35%|███▌      | 34/96 [00:03<00:06,  9.75it/s, loss=0.473, v_num=16, train_loss_step=0.476]Epoch 0:  35%|███▌      | 34/96 [00:03<00:06,  9.75it/s, loss=0.473, v_num=16, train_loss_step=0.513]Epoch 0:  36%|███▋      | 35/96 [00:03<00:06,  9.75it/s, loss=0.473, v_num=16, train_loss_step=0.513]Epoch 0:  36%|███▋      | 35/96 [00:03<00:06,  9.75it/s, loss=0.469, v_num=16, train_loss_step=0.464]Epoch 0:  38%|███▊      | 36/96 [00:03<00:06,  9.75it/s, loss=0.469, v_num=16, train_loss_step=0.464]Epoch 0:  38%|███▊      | 36/96 [00:03<00:06,  9.75it/s, loss=0.469, v_num=16, train_loss_step=0.413]Epoch 0:  39%|███▊      | 37/96 [00:03<00:06,  9.74it/s, loss=0.469, v_num=16, train_loss_step=0.413]Epoch 0:  39%|███▊      | 37/96 [00:03<00:06,  9.74it/s, loss=0.454, v_num=16, train_loss_step=0.313]Epoch 0:  40%|███▉      | 38/96 [00:04<00:05,  9.74it/s, loss=0.454, v_num=16, train_loss_step=0.313]Epoch 0:  40%|███▉      | 38/96 [00:04<00:05,  9.74it/s, loss=0.451, v_num=16, train_loss_step=0.415]Epoch 0:  41%|████      | 39/96 [00:04<00:05,  9.73it/s, loss=0.451, v_num=16, train_loss_step=0.415]Epoch 0:  41%|████      | 39/96 [00:04<00:05,  9.73it/s, loss=0.462, v_num=16, train_loss_step=0.563]Epoch 0:  42%|████▏     | 40/96 [00:04<00:05,  9.73it/s, loss=0.462, v_num=16, train_loss_step=0.563]Epoch 0:  42%|████▏     | 40/96 [00:04<00:05,  9.72it/s, loss=0.461, v_num=16, train_loss_step=0.428]Epoch 0:  43%|████▎     | 41/96 [00:04<00:05,  9.72it/s, loss=0.461, v_num=16, train_loss_step=0.428]Epoch 0:  43%|████▎     | 41/96 [00:04<00:05,  9.72it/s, loss=0.467, v_num=16, train_loss_step=0.510]Epoch 0:  44%|████▍     | 42/96 [00:04<00:05,  9.72it/s, loss=0.467, v_num=16, train_loss_step=0.510]Epoch 0:  44%|████▍     | 42/96 [00:04<00:05,  9.72it/s, loss=0.46, v_num=16, train_loss_step=0.401] Epoch 0:  45%|████▍     | 43/96 [00:04<00:05,  9.72it/s, loss=0.46, v_num=16, train_loss_step=0.401]Epoch 0:  45%|████▍     | 43/96 [00:04<00:05,  9.72it/s, loss=0.462, v_num=16, train_loss_step=0.428]Epoch 0:  46%|████▌     | 44/96 [00:04<00:05,  9.72it/s, loss=0.462, v_num=16, train_loss_step=0.428]Epoch 0:  46%|████▌     | 44/96 [00:04<00:05,  9.72it/s, loss=0.459, v_num=16, train_loss_step=0.321]Epoch 0:  47%|████▋     | 45/96 [00:04<00:05,  9.72it/s, loss=0.459, v_num=16, train_loss_step=0.321]Epoch 0:  47%|████▋     | 45/96 [00:04<00:05,  9.72it/s, loss=0.456, v_num=16, train_loss_step=0.337]Epoch 0:  48%|████▊     | 46/96 [00:04<00:05,  9.72it/s, loss=0.456, v_num=16, train_loss_step=0.337]Epoch 0:  48%|████▊     | 46/96 [00:04<00:05,  9.72it/s, loss=0.443, v_num=16, train_loss_step=0.401]Epoch 0:  49%|████▉     | 47/96 [00:04<00:05,  9.72it/s, loss=0.443, v_num=16, train_loss_step=0.401]Epoch 0:  49%|████▉     | 47/96 [00:04<00:05,  9.71it/s, loss=0.444, v_num=16, train_loss_step=0.636]Epoch 0:  50%|█████     | 48/96 [00:05<00:04,  9.71it/s, loss=0.444, v_num=16, train_loss_step=0.636]Epoch 0:  50%|█████     | 48/96 [00:05<00:04,  9.71it/s, loss=0.439, v_num=16, train_loss_step=0.335]Epoch 0:  51%|█████     | 49/96 [00:05<00:04,  9.71it/s, loss=0.439, v_num=16, train_loss_step=0.335]Epoch 0:  51%|█████     | 49/96 [00:05<00:04,  9.71it/s, loss=0.443, v_num=16, train_loss_step=0.542]Epoch 0:  52%|█████▏    | 50/96 [00:05<00:04,  9.70it/s, loss=0.443, v_num=16, train_loss_step=0.542]Epoch 0:  52%|█████▏    | 50/96 [00:05<00:04,  9.70it/s, loss=0.447, v_num=16, train_loss_step=0.512]Epoch 0:  53%|█████▎    | 51/96 [00:05<00:04,  9.70it/s, loss=0.447, v_num=16, train_loss_step=0.512]Epoch 0:  53%|█████▎    | 51/96 [00:05<00:04,  9.70it/s, loss=0.449, v_num=16, train_loss_step=0.541]Epoch 0:  54%|█████▍    | 52/96 [00:05<00:04,  9.70it/s, loss=0.449, v_num=16, train_loss_step=0.541]Epoch 0:  54%|█████▍    | 52/96 [00:05<00:04,  9.70it/s, loss=0.455, v_num=16, train_loss_step=0.542]Epoch 0:  55%|█████▌    | 53/96 [00:05<00:04,  9.69it/s, loss=0.455, v_num=16, train_loss_step=0.542]Epoch 0:  55%|█████▌    | 53/96 [00:05<00:04,  9.69it/s, loss=0.464, v_num=16, train_loss_step=0.661]Epoch 0:  56%|█████▋    | 54/96 [00:05<00:04,  9.69it/s, loss=0.464, v_num=16, train_loss_step=0.661]Epoch 0:  56%|█████▋    | 54/96 [00:05<00:04,  9.69it/s, loss=0.459, v_num=16, train_loss_step=0.413]Epoch 0:  57%|█████▋    | 55/96 [00:05<00:04,  9.69it/s, loss=0.459, v_num=16, train_loss_step=0.413]Epoch 0:  57%|█████▋    | 55/96 [00:05<00:04,  9.69it/s, loss=0.457, v_num=16, train_loss_step=0.420]Epoch 0:  58%|█████▊    | 56/96 [00:05<00:04,  9.69it/s, loss=0.457, v_num=16, train_loss_step=0.420]Epoch 0:  58%|█████▊    | 56/96 [00:05<00:04,  9.69it/s, loss=0.469, v_num=16, train_loss_step=0.668]Epoch 0:  59%|█████▉    | 57/96 [00:05<00:04,  9.68it/s, loss=0.469, v_num=16, train_loss_step=0.668]Epoch 0:  59%|█████▉    | 57/96 [00:05<00:04,  9.68it/s, loss=0.477, v_num=16, train_loss_step=0.458]Epoch 0:  60%|██████    | 58/96 [00:06<00:03,  9.68it/s, loss=0.477, v_num=16, train_loss_step=0.458]Epoch 0:  60%|██████    | 58/96 [00:06<00:03,  9.68it/s, loss=0.482, v_num=16, train_loss_step=0.525]Epoch 0:  61%|██████▏   | 59/96 [00:06<00:03,  9.67it/s, loss=0.482, v_num=16, train_loss_step=0.525]Epoch 0:  61%|██████▏   | 59/96 [00:06<00:03,  9.67it/s, loss=0.482, v_num=16, train_loss_step=0.565]Epoch 0:  62%|██████▎   | 60/96 [00:06<00:03,  9.67it/s, loss=0.482, v_num=16, train_loss_step=0.565]Epoch 0:  62%|██████▎   | 60/96 [00:06<00:03,  9.67it/s, loss=0.5, v_num=16, train_loss_step=0.773]  Epoch 0:  64%|██████▎   | 61/96 [00:06<00:03,  9.67it/s, loss=0.5, v_num=16, train_loss_step=0.773]Epoch 0:  64%|██████▎   | 61/96 [00:06<00:03,  9.66it/s, loss=0.5, v_num=16, train_loss_step=0.513]Epoch 0:  65%|██████▍   | 62/96 [00:06<00:03,  9.66it/s, loss=0.5, v_num=16, train_loss_step=0.513]Epoch 0:  65%|██████▍   | 62/96 [00:06<00:03,  9.66it/s, loss=0.517, v_num=16, train_loss_step=0.738]Epoch 0:  66%|██████▌   | 63/96 [00:06<00:03,  9.66it/s, loss=0.517, v_num=16, train_loss_step=0.738]Epoch 0:  66%|██████▌   | 63/96 [00:06<00:03,  9.66it/s, loss=0.517, v_num=16, train_loss_step=0.438]Epoch 0:  67%|██████▋   | 64/96 [00:06<00:03,  9.66it/s, loss=0.517, v_num=16, train_loss_step=0.438]Epoch 0:  67%|██████▋   | 64/96 [00:06<00:03,  9.66it/s, loss=0.529, v_num=16, train_loss_step=0.567]Epoch 0:  68%|██████▊   | 65/96 [00:06<00:03,  9.66it/s, loss=0.529, v_num=16, train_loss_step=0.567]Epoch 0:  68%|██████▊   | 65/96 [00:06<00:03,  9.66it/s, loss=0.535, v_num=16, train_loss_step=0.450]Epoch 0:  69%|██████▉   | 66/96 [00:06<00:03,  9.66it/s, loss=0.535, v_num=16, train_loss_step=0.450]Epoch 0:  69%|██████▉   | 66/96 [00:06<00:03,  9.66it/s, loss=0.548, v_num=16, train_loss_step=0.659]Epoch 0:  70%|██████▉   | 67/96 [00:07<00:03,  9.66it/s, loss=0.548, v_num=16, train_loss_step=0.659]Epoch 0:  70%|██████▉   | 67/96 [00:07<00:03,  9.66it/s, loss=0.54, v_num=16, train_loss_step=0.473] Epoch 0:  71%|███████   | 68/96 [00:07<00:02,  9.66it/s, loss=0.54, v_num=16, train_loss_step=0.473]Epoch 0:  71%|███████   | 68/96 [00:07<00:02,  9.66it/s, loss=0.547, v_num=16, train_loss_step=0.476]Epoch 0:  72%|███████▏  | 69/96 [00:07<00:02,  9.65it/s, loss=0.547, v_num=16, train_loss_step=0.476]Epoch 0:  72%|███████▏  | 69/96 [00:07<00:02,  9.65it/s, loss=0.544, v_num=16, train_loss_step=0.490]Epoch 0:  73%|███████▎  | 70/96 [00:07<00:02,  9.65it/s, loss=0.544, v_num=16, train_loss_step=0.490]Epoch 0:  73%|███████▎  | 70/96 [00:07<00:02,  9.65it/s, loss=0.537, v_num=16, train_loss_step=0.371]Epoch 0:  74%|███████▍  | 71/96 [00:07<00:02,  9.65it/s, loss=0.537, v_num=16, train_loss_step=0.371]Epoch 0:  74%|███████▍  | 71/96 [00:07<00:02,  9.65it/s, loss=0.53, v_num=16, train_loss_step=0.389] Epoch 0:  75%|███████▌  | 72/96 [00:07<00:02,  9.65it/s, loss=0.53, v_num=16, train_loss_step=0.389]Epoch 0:  75%|███████▌  | 72/96 [00:07<00:02,  9.65it/s, loss=0.526, v_num=16, train_loss_step=0.467]Epoch 0:  76%|███████▌  | 73/96 [00:07<00:02,  9.65it/s, loss=0.526, v_num=16, train_loss_step=0.467]Epoch 0:  76%|███████▌  | 73/96 [00:07<00:02,  9.65it/s, loss=0.512, v_num=16, train_loss_step=0.381]Epoch 0:  77%|███████▋  | 74/96 [00:07<00:02,  9.65it/s, loss=0.512, v_num=16, train_loss_step=0.381]Epoch 0:  77%|███████▋  | 74/96 [00:07<00:02,  9.65it/s, loss=0.51, v_num=16, train_loss_step=0.373] Epoch 0:  78%|███████▊  | 75/96 [00:07<00:02,  9.65it/s, loss=0.51, v_num=16, train_loss_step=0.373]Epoch 0:  78%|███████▊  | 75/96 [00:07<00:02,  9.65it/s, loss=0.509, v_num=16, train_loss_step=0.412]Epoch 0:  79%|███████▉  | 76/96 [00:07<00:02,  9.65it/s, loss=0.509, v_num=16, train_loss_step=0.412]Epoch 0:  79%|███████▉  | 76/96 [00:07<00:02,  9.65it/s, loss=0.495, v_num=16, train_loss_step=0.385]Epoch 0:  80%|████████  | 77/96 [00:08<00:01,  9.65it/s, loss=0.495, v_num=16, train_loss_step=0.385]Epoch 0:  80%|████████  | 77/96 [00:08<00:01,  9.65it/s, loss=0.499, v_num=16, train_loss_step=0.539]Epoch 0:  81%|████████▏ | 78/96 [00:08<00:01,  9.65it/s, loss=0.499, v_num=16, train_loss_step=0.539]Epoch 0:  81%|████████▏ | 78/96 [00:08<00:01,  9.65it/s, loss=0.492, v_num=16, train_loss_step=0.390]Epoch 0:  82%|████████▏ | 79/96 [00:08<00:01,  9.65it/s, loss=0.492, v_num=16, train_loss_step=0.390]Epoch 0:  82%|████████▏ | 79/96 [00:08<00:01,  9.65it/s, loss=0.481, v_num=16, train_loss_step=0.335]Epoch 0:  83%|████████▎ | 80/96 [00:08<00:01,  9.65it/s, loss=0.481, v_num=16, train_loss_step=0.335]Epoch 0:  83%|████████▎ | 80/96 [00:08<00:01,  9.65it/s, loss=0.471, v_num=16, train_loss_step=0.572]Epoch 0:  84%|████████▍ | 81/96 [00:08<00:01,  9.65it/s, loss=0.471, v_num=16, train_loss_step=0.572]Epoch 0:  84%|████████▍ | 81/96 [00:08<00:01,  9.65it/s, loss=0.465, v_num=16, train_loss_step=0.390]Epoch 0:  85%|████████▌ | 82/96 [00:08<00:01,  9.65it/s, loss=0.465, v_num=16, train_loss_step=0.390]Epoch 0:  85%|████████▌ | 82/96 [00:08<00:01,  9.65it/s, loss=0.46, v_num=16, train_loss_step=0.639] Epoch 0:  86%|████████▋ | 83/96 [00:08<00:01,  9.66it/s, loss=0.457, v_num=16, train_loss_step=0.389]Epoch 0:  88%|████████▊ | 84/96 [00:08<00:01,  9.72it/s, loss=0.457, v_num=16, train_loss_step=0.389]Epoch 0:  88%|████████▊ | 84/96 [00:08<00:01,  9.72it/s, loss=0.458, v_num=16, train_loss_step=0.583]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/12 [00:00<?, ?it/s][A
Validating:   8%|▊         | 1/12 [00:00<00:03,  2.82it/s][AEpoch 0:  90%|████████▉ | 86/96 [00:09<00:01,  9.56it/s, loss=0.458, v_num=16, train_loss_step=0.583]
Validating:  17%|█▋        | 2/12 [00:00<00:03,  2.85it/s][A
Validating:  25%|██▌       | 3/12 [00:01<00:03,  2.85it/s][AEpoch 0:  92%|█████████▏| 88/96 [00:09<00:00,  9.08it/s, loss=0.458, v_num=16, train_loss_step=0.583]
Validating:  33%|███▎      | 4/12 [00:01<00:02,  2.85it/s][A
Validating:  42%|████▏     | 5/12 [00:01<00:02,  2.85it/s][AEpoch 0:  94%|█████████▍| 90/96 [00:10<00:00,  8.67it/s, loss=0.458, v_num=16, train_loss_step=0.583]
Validating:  50%|█████     | 6/12 [00:02<00:02,  2.86it/s][A
Validating:  58%|█████▊    | 7/12 [00:02<00:01,  2.85it/s][AEpoch 0:  96%|█████████▌| 92/96 [00:11<00:00,  8.30it/s, loss=0.458, v_num=16, train_loss_step=0.583]
Validating:  67%|██████▋   | 8/12 [00:02<00:01,  2.85it/s][A
Validating:  75%|███████▌  | 9/12 [00:03<00:01,  2.86it/s][AEpoch 0:  98%|█████████▊| 94/96 [00:11<00:00,  7.98it/s, loss=0.458, v_num=16, train_loss_step=0.583]
Validating:  83%|████████▎ | 10/12 [00:03<00:00,  2.85it/s][A
Validating:  92%|█████████▏| 11/12 [00:03<00:00,  2.86it/s][AEpoch 0: 100%|██████████| 96/96 [00:12<00:00,  7.70it/s, loss=0.458, v_num=16, train_loss_step=0.583]
Validating: 100%|██████████| 12/12 [00:04<00:00,  3.37it/s][AEpoch 0: 100%|██████████| 96/96 [00:12<00:00,  7.59it/s, loss=0.458, v_num=16, train_loss_step=0.583]
                                                           [AEpoch 0: 100%|██████████| 96/96 [00:12<00:00,  7.57it/s, loss=0.458, v_num=16, train_loss_step=0.583]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(

Testing: 0it [00:00, ?it/s]Testing:   2%|▏         | 3/169 [00:00<00:07, 21.91it/s]Testing:   4%|▎         | 6/169 [00:00<00:07, 23.07it/s]Testing:   5%|▌         | 9/169 [00:00<00:06, 23.38it/s]Testing:   7%|▋         | 12/169 [00:00<00:06, 23.55it/s]Testing:   9%|▉         | 15/169 [00:00<00:06, 23.44it/s]Testing:  11%|█         | 18/169 [00:00<00:06, 23.56it/s]Testing:  12%|█▏        | 21/169 [00:00<00:06, 23.64it/s]Testing:  14%|█▍        | 24/169 [00:01<00:06, 23.70it/s]Testing:  16%|█▌        | 27/169 [00:01<00:05, 23.76it/s]Testing:  18%|█▊        | 30/169 [00:01<00:05, 23.62it/s]Testing:  20%|█▉        | 33/169 [00:01<00:05, 23.62it/s]Testing:  21%|██▏       | 36/169 [00:01<00:05, 23.70it/s]Testing:  23%|██▎       | 39/169 [00:01<00:05, 23.71it/s]Testing:  25%|██▍       | 42/169 [00:01<00:05, 23.74it/s]Testing:  27%|██▋       | 45/169 [00:01<00:05, 23.63it/s]Testing:  28%|██▊       | 48/169 [00:02<00:05, 23.72it/s]Testing:  30%|███       | 51/169 [00:02<00:04, 23.71it/s]Testing:  32%|███▏      | 54/169 [00:02<00:04, 23.78it/s]Testing:  34%|███▎      | 57/169 [00:02<00:04, 23.79it/s]Testing:  36%|███▌      | 60/169 [00:02<00:04, 23.84it/s]Testing:  37%|███▋      | 63/169 [00:02<00:04, 23.82it/s]Testing:  39%|███▉      | 66/169 [00:02<00:04, 23.90it/s]Testing:  41%|████      | 69/169 [00:02<00:04, 23.85it/s]Testing:  43%|████▎     | 72/169 [00:03<00:04, 23.70it/s]Testing:  44%|████▍     | 75/169 [00:03<00:03, 23.69it/s]Testing:  46%|████▌     | 78/169 [00:03<00:03, 23.71it/s]Testing:  48%|████▊     | 81/169 [00:03<00:03, 23.66it/s]Testing:  50%|████▉     | 84/169 [00:03<00:03, 23.70it/s]Testing:  51%|█████▏    | 87/169 [00:03<00:03, 23.64it/s]Testing:  53%|█████▎    | 90/169 [00:03<00:03, 23.62it/s]Testing:  55%|█████▌    | 93/169 [00:03<00:03, 23.64it/s]Testing:  57%|█████▋    | 96/169 [00:04<00:03, 23.63it/s]Testing:  59%|█████▊    | 99/169 [00:04<00:02, 23.54it/s]Testing:  60%|██████    | 102/169 [00:04<00:02, 23.52it/s]Testing:  62%|██████▏   | 105/169 [00:04<00:02, 23.34it/s]Testing:  64%|██████▍   | 108/169 [00:04<00:02, 23.45it/s]Testing:  66%|██████▌   | 111/169 [00:04<00:02, 23.52it/s]Testing:  67%|██████▋   | 114/169 [00:04<00:02, 23.52it/s]Testing:  69%|██████▉   | 117/169 [00:04<00:02, 23.62it/s]Testing:  71%|███████   | 120/169 [00:05<00:02, 23.71it/s]Testing:  73%|███████▎  | 123/169 [00:05<00:01, 23.75it/s]Testing:  75%|███████▍  | 126/169 [00:05<00:01, 23.72it/s]Testing:  76%|███████▋  | 129/169 [00:05<00:01, 23.60it/s]Testing:  78%|███████▊  | 132/169 [00:05<00:01, 23.52it/s]Testing:  80%|███████▉  | 135/169 [00:05<00:01, 23.60it/s]Testing:  82%|████████▏ | 138/169 [00:05<00:01, 23.28it/s]Testing:  83%|████████▎ | 141/169 [00:05<00:01, 23.33it/s]Testing:  85%|████████▌ | 144/169 [00:06<00:01, 23.20it/s]Testing:  87%|████████▋ | 147/169 [00:06<00:00, 23.19it/s]Testing:  89%|████████▉ | 150/169 [00:06<00:00, 23.16it/s]Testing:  91%|█████████ | 153/169 [00:06<00:00, 23.11it/s]Testing:  92%|█████████▏| 156/169 [00:06<00:00, 23.10it/s]Testing:  94%|█████████▍| 159/169 [00:06<00:00, 23.24it/s]Testing:  96%|█████████▌| 162/169 [00:06<00:00, 23.30it/s]Testing:  98%|█████████▊| 165/169 [00:07<00:00, 23.41it/s]Testing:  99%|█████████▉| 168/169 [00:07<00:00, 23.52it/s]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'_mean_accuracy': 0.9869337677955627,
 '_standard_dev_accuracy': 0.024933693930506706,
 '_variance_accuracy': 0.0006216890760697424,
 'test_acc': 0.9869337677955627,
 'test_dice_c1': 0.0,
 'test_f2_c1': 0.0,
 'test_loss': 0.41963991522789,
 'test_mean_c1': 0.0,
 'test_prec_c1': 0.0,
 'test_sens_c1': 0.0,
 'test_spec_c1': 1.0}
--------------------------------------------------------------------------------
Testing: 100%|██████████| 169/169 [00:07<00:00, 23.53it/s]
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

  | Name       | Type             | Params
------------------------------------------------
0 | encoder1   | EncoderBlock     | 37.6 K
1 | encoder2   | EncoderBlock     | 221 K 
2 | bottleneck | ConvolutionBlock | 885 K 
3 | dropout    | Dropout2d        | 0     
4 | decoder1   | DecoderBlock     | 573 K 
5 | decoder2   | DecoderBlock     | 143 K 
6 | conv       | Conv2d           | 130   
7 | softmax    | Softmax2d        | 0     
------------------------------------------------
1.9 M     Trainable params
0         Non-trainable params
1.9 M     Total params
7.447     Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  1.53it/s]Validation sanity check: 100%|██████████| 2/2 [00:01<00:00,  1.91it/s]                                                                      /home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Training: -1it [00:00, ?it/s]Training:   0%|          | 0/64 [00:00<00:00, 27235.74it/s]Epoch 0:   0%|          | 0/64 [00:00<00:00, 4236.67it/s]  Epoch 0:   2%|▏         | 1/64 [00:00<00:06, 10.49it/s]  Epoch 0:   2%|▏         | 1/64 [00:00<00:06, 10.47it/s, loss=0.687, v_num=17, train_loss_step=0.687]Epoch 0:   3%|▎         | 2/64 [00:00<00:07,  8.61it/s, loss=0.687, v_num=17, train_loss_step=0.687]Epoch 0:   3%|▎         | 2/64 [00:00<00:07,  8.60it/s, loss=0.684, v_num=17, train_loss_step=0.682]Epoch 0:   5%|▍         | 3/64 [00:00<00:07,  7.90it/s, loss=0.684, v_num=17, train_loss_step=0.682]Epoch 0:   5%|▍         | 3/64 [00:00<00:07,  7.89it/s, loss=0.682, v_num=17, train_loss_step=0.676]Epoch 0:   6%|▋         | 4/64 [00:00<00:07,  7.53it/s, loss=0.682, v_num=17, train_loss_step=0.676]Epoch 0:   6%|▋         | 4/64 [00:00<00:07,  7.53it/s, loss=0.672, v_num=17, train_loss_step=0.643]Epoch 0:   8%|▊         | 5/64 [00:00<00:08,  7.31it/s, loss=0.672, v_num=17, train_loss_step=0.643]Epoch 0:   8%|▊         | 5/64 [00:00<00:08,  7.31it/s, loss=0.661, v_num=17, train_loss_step=0.619]Epoch 0:   9%|▉         | 6/64 [00:00<00:08,  7.16it/s, loss=0.661, v_num=17, train_loss_step=0.619]Epoch 0:   9%|▉         | 6/64 [00:00<00:08,  7.16it/s, loss=0.631, v_num=17, train_loss_step=0.482]Epoch 0:  11%|█         | 7/64 [00:01<00:08,  7.05it/s, loss=0.631, v_num=17, train_loss_step=0.482]Epoch 0:  11%|█         | 7/64 [00:01<00:08,  7.05it/s, loss=0.594, v_num=17, train_loss_step=0.369]Epoch 0:  12%|█▎        | 8/64 [00:01<00:08,  6.96it/s, loss=0.594, v_num=17, train_loss_step=0.369]Epoch 0:  12%|█▎        | 8/64 [00:01<00:08,  6.96it/s, loss=0.576, v_num=17, train_loss_step=0.449]Epoch 0:  14%|█▍        | 9/64 [00:01<00:07,  6.89it/s, loss=0.576, v_num=17, train_loss_step=0.449]Epoch 0:  14%|█▍        | 9/64 [00:01<00:07,  6.89it/s, loss=0.562, v_num=17, train_loss_step=0.448]Epoch 0:  16%|█▌        | 10/64 [00:01<00:07,  6.84it/s, loss=0.562, v_num=17, train_loss_step=0.448]Epoch 0:  16%|█▌        | 10/64 [00:01<00:07,  6.84it/s, loss=0.55, v_num=17, train_loss_step=0.442] Epoch 0:  17%|█▋        | 11/64 [00:01<00:07,  6.80it/s, loss=0.55, v_num=17, train_loss_step=0.442]Epoch 0:  17%|█▋        | 11/64 [00:01<00:07,  6.80it/s, loss=0.544, v_num=17, train_loss_step=0.483]Epoch 0:  19%|█▉        | 12/64 [00:01<00:07,  6.76it/s, loss=0.544, v_num=17, train_loss_step=0.483]Epoch 0:  19%|█▉        | 12/64 [00:01<00:07,  6.76it/s, loss=0.53, v_num=17, train_loss_step=0.375] Epoch 0:  20%|██        | 13/64 [00:02<00:07,  6.72it/s, loss=0.53, v_num=17, train_loss_step=0.375]Epoch 0:  20%|██        | 13/64 [00:02<00:07,  6.72it/s, loss=0.52, v_num=17, train_loss_step=0.402]Epoch 0:  22%|██▏       | 14/64 [00:02<00:07,  6.70it/s, loss=0.52, v_num=17, train_loss_step=0.402]Epoch 0:  22%|██▏       | 14/64 [00:02<00:07,  6.70it/s, loss=0.512, v_num=17, train_loss_step=0.414]Epoch 0:  23%|██▎       | 15/64 [00:02<00:07,  6.68it/s, loss=0.512, v_num=17, train_loss_step=0.414]Epoch 0:  23%|██▎       | 15/64 [00:02<00:07,  6.68it/s, loss=0.502, v_num=17, train_loss_step=0.367]Epoch 0:  25%|██▌       | 16/64 [00:02<00:07,  6.66it/s, loss=0.502, v_num=17, train_loss_step=0.367]Epoch 0:  25%|██▌       | 16/64 [00:02<00:07,  6.66it/s, loss=0.494, v_num=17, train_loss_step=0.370]Epoch 0:  27%|██▋       | 17/64 [00:02<00:07,  6.65it/s, loss=0.494, v_num=17, train_loss_step=0.370]Epoch 0:  27%|██▋       | 17/64 [00:02<00:07,  6.64it/s, loss=0.486, v_num=17, train_loss_step=0.363]Epoch 0:  28%|██▊       | 18/64 [00:02<00:06,  6.61it/s, loss=0.486, v_num=17, train_loss_step=0.363]Epoch 0:  28%|██▊       | 18/64 [00:02<00:06,  6.61it/s, loss=0.48, v_num=17, train_loss_step=0.367] Epoch 0:  30%|██▉       | 19/64 [00:03<00:06,  6.60it/s, loss=0.48, v_num=17, train_loss_step=0.367]Epoch 0:  30%|██▉       | 19/64 [00:03<00:06,  6.60it/s, loss=0.476, v_num=17, train_loss_step=0.402]Epoch 0:  31%|███▏      | 20/64 [00:03<00:06,  6.59it/s, loss=0.476, v_num=17, train_loss_step=0.402]Epoch 0:  31%|███▏      | 20/64 [00:03<00:06,  6.58it/s, loss=0.471, v_num=17, train_loss_step=0.377]Epoch 0:  33%|███▎      | 21/64 [00:03<00:06,  6.57it/s, loss=0.471, v_num=17, train_loss_step=0.377]Epoch 0:  33%|███▎      | 21/64 [00:03<00:06,  6.57it/s, loss=0.455, v_num=17, train_loss_step=0.377]Epoch 0:  34%|███▍      | 22/64 [00:03<00:06,  6.56it/s, loss=0.455, v_num=17, train_loss_step=0.377]Epoch 0:  34%|███▍      | 22/64 [00:03<00:06,  6.56it/s, loss=0.44, v_num=17, train_loss_step=0.378] Epoch 0:  36%|███▌      | 23/64 [00:03<00:06,  6.55it/s, loss=0.44, v_num=17, train_loss_step=0.378]Epoch 0:  36%|███▌      | 23/64 [00:03<00:06,  6.55it/s, loss=0.425, v_num=17, train_loss_step=0.374]Epoch 0:  38%|███▊      | 24/64 [00:03<00:06,  6.55it/s, loss=0.425, v_num=17, train_loss_step=0.374]Epoch 0:  38%|███▊      | 24/64 [00:03<00:06,  6.55it/s, loss=0.411, v_num=17, train_loss_step=0.356]Epoch 0:  39%|███▉      | 25/64 [00:03<00:05,  6.54it/s, loss=0.411, v_num=17, train_loss_step=0.356]Epoch 0:  39%|███▉      | 25/64 [00:03<00:05,  6.54it/s, loss=0.396, v_num=17, train_loss_step=0.330]Epoch 0:  41%|████      | 26/64 [00:04<00:05,  6.54it/s, loss=0.396, v_num=17, train_loss_step=0.330]Epoch 0:  41%|████      | 26/64 [00:04<00:05,  6.54it/s, loss=0.39, v_num=17, train_loss_step=0.363] Epoch 0:  42%|████▏     | 27/64 [00:04<00:05,  6.53it/s, loss=0.39, v_num=17, train_loss_step=0.363]Epoch 0:  42%|████▏     | 27/64 [00:04<00:05,  6.53it/s, loss=0.389, v_num=17, train_loss_step=0.350]Epoch 0:  44%|████▍     | 28/64 [00:04<00:05,  6.53it/s, loss=0.389, v_num=17, train_loss_step=0.350]Epoch 0:  44%|████▍     | 28/64 [00:04<00:05,  6.53it/s, loss=0.385, v_num=17, train_loss_step=0.365]Epoch 0:  45%|████▌     | 29/64 [00:04<00:05,  6.52it/s, loss=0.385, v_num=17, train_loss_step=0.365]Epoch 0:  45%|████▌     | 29/64 [00:04<00:05,  6.52it/s, loss=0.379, v_num=17, train_loss_step=0.324]Epoch 0:  47%|████▋     | 30/64 [00:04<00:05,  6.52it/s, loss=0.379, v_num=17, train_loss_step=0.324]Epoch 0:  47%|████▋     | 30/64 [00:04<00:05,  6.52it/s, loss=0.38, v_num=17, train_loss_step=0.456] Epoch 0:  48%|████▊     | 31/64 [00:04<00:05,  6.51it/s, loss=0.38, v_num=17, train_loss_step=0.456]Epoch 0:  48%|████▊     | 31/64 [00:04<00:05,  6.51it/s, loss=0.373, v_num=17, train_loss_step=0.357]Epoch 0:  50%|█████     | 32/64 [00:05<00:04,  6.51it/s, loss=0.373, v_num=17, train_loss_step=0.357]Epoch 0:  50%|█████     | 32/64 [00:05<00:04,  6.51it/s, loss=0.371, v_num=17, train_loss_step=0.339]Epoch 0:  52%|█████▏    | 33/64 [00:05<00:04,  6.50it/s, loss=0.371, v_num=17, train_loss_step=0.339]Epoch 0:  52%|█████▏    | 33/64 [00:05<00:04,  6.50it/s, loss=0.37, v_num=17, train_loss_step=0.378] Epoch 0:  53%|█████▎    | 34/64 [00:05<00:04,  6.50it/s, loss=0.37, v_num=17, train_loss_step=0.378]Epoch 0:  53%|█████▎    | 34/64 [00:05<00:04,  6.50it/s, loss=0.369, v_num=17, train_loss_step=0.379]Epoch 0:  55%|█████▍    | 35/64 [00:05<00:04,  6.50it/s, loss=0.369, v_num=17, train_loss_step=0.379]Epoch 0:  55%|█████▍    | 35/64 [00:05<00:04,  6.49it/s, loss=0.369, v_num=17, train_loss_step=0.372]Epoch 0:  56%|█████▋    | 36/64 [00:05<00:04,  6.49it/s, loss=0.369, v_num=17, train_loss_step=0.372]Epoch 0:  56%|█████▋    | 36/64 [00:05<00:04,  6.49it/s, loss=0.369, v_num=17, train_loss_step=0.366]Epoch 0:  58%|█████▊    | 37/64 [00:05<00:04,  6.48it/s, loss=0.369, v_num=17, train_loss_step=0.366]Epoch 0:  58%|█████▊    | 37/64 [00:05<00:04,  6.48it/s, loss=0.369, v_num=17, train_loss_step=0.369]Epoch 0:  59%|█████▉    | 38/64 [00:06<00:04,  6.47it/s, loss=0.369, v_num=17, train_loss_step=0.369]Epoch 0:  59%|█████▉    | 38/64 [00:06<00:04,  6.47it/s, loss=0.369, v_num=17, train_loss_step=0.364]Epoch 0:  61%|██████    | 39/64 [00:06<00:03,  6.47it/s, loss=0.369, v_num=17, train_loss_step=0.364]Epoch 0:  61%|██████    | 39/64 [00:06<00:03,  6.47it/s, loss=0.368, v_num=17, train_loss_step=0.386]Epoch 0:  62%|██████▎   | 40/64 [00:06<00:03,  6.47it/s, loss=0.368, v_num=17, train_loss_step=0.386]Epoch 0:  62%|██████▎   | 40/64 [00:06<00:03,  6.47it/s, loss=0.367, v_num=17, train_loss_step=0.354]Epoch 0:  64%|██████▍   | 41/64 [00:06<00:03,  6.47it/s, loss=0.367, v_num=17, train_loss_step=0.354]Epoch 0:  64%|██████▍   | 41/64 [00:06<00:03,  6.47it/s, loss=0.366, v_num=17, train_loss_step=0.364]Epoch 0:  66%|██████▌   | 42/64 [00:06<00:03,  6.46it/s, loss=0.366, v_num=17, train_loss_step=0.364]Epoch 0:  66%|██████▌   | 42/64 [00:06<00:03,  6.46it/s, loss=0.366, v_num=17, train_loss_step=0.369]Epoch 0:  67%|██████▋   | 43/64 [00:06<00:03,  6.46it/s, loss=0.366, v_num=17, train_loss_step=0.369]Epoch 0:  67%|██████▋   | 43/64 [00:06<00:03,  6.46it/s, loss=0.365, v_num=17, train_loss_step=0.354]Epoch 0:  69%|██████▉   | 44/64 [00:06<00:03,  6.46it/s, loss=0.365, v_num=17, train_loss_step=0.354]Epoch 0:  69%|██████▉   | 44/64 [00:06<00:03,  6.46it/s, loss=0.365, v_num=17, train_loss_step=0.357]Epoch 0:  70%|███████   | 45/64 [00:07<00:02,  6.46it/s, loss=0.365, v_num=17, train_loss_step=0.357]Epoch 0:  70%|███████   | 45/64 [00:07<00:02,  6.46it/s, loss=0.366, v_num=17, train_loss_step=0.352]Epoch 0:  72%|███████▏  | 46/64 [00:07<00:02,  6.46it/s, loss=0.366, v_num=17, train_loss_step=0.352]Epoch 0:  72%|███████▏  | 46/64 [00:07<00:02,  6.46it/s, loss=0.365, v_num=17, train_loss_step=0.341]Epoch 0:  73%|███████▎  | 47/64 [00:07<00:02,  6.45it/s, loss=0.365, v_num=17, train_loss_step=0.341]Epoch 0:  73%|███████▎  | 47/64 [00:07<00:02,  6.45it/s, loss=0.364, v_num=17, train_loss_step=0.335]Epoch 0:  75%|███████▌  | 48/64 [00:07<00:02,  6.45it/s, loss=0.364, v_num=17, train_loss_step=0.335]Epoch 0:  75%|███████▌  | 48/64 [00:07<00:02,  6.45it/s, loss=0.364, v_num=17, train_loss_step=0.366]Epoch 0:  77%|███████▋  | 49/64 [00:07<00:02,  6.45it/s, loss=0.364, v_num=17, train_loss_step=0.366]Epoch 0:  77%|███████▋  | 49/64 [00:07<00:02,  6.45it/s, loss=0.367, v_num=17, train_loss_step=0.387]Epoch 0:  78%|███████▊  | 50/64 [00:07<00:02,  6.45it/s, loss=0.367, v_num=17, train_loss_step=0.387]Epoch 0:  78%|███████▊  | 50/64 [00:07<00:02,  6.45it/s, loss=0.362, v_num=17, train_loss_step=0.355]Epoch 0:  80%|███████▉  | 51/64 [00:08<00:02,  6.45it/s, loss=0.362, v_num=17, train_loss_step=0.355]Epoch 0:  80%|███████▉  | 51/64 [00:08<00:02,  6.45it/s, loss=0.363, v_num=17, train_loss_step=0.364]Epoch 0:  81%|████████▏ | 52/64 [00:08<00:01,  6.44it/s, loss=0.363, v_num=17, train_loss_step=0.364]Epoch 0:  81%|████████▏ | 52/64 [00:08<00:01,  6.44it/s, loss=0.364, v_num=17, train_loss_step=0.373]Epoch 0:  83%|████████▎ | 53/64 [00:08<00:01,  6.44it/s, loss=0.364, v_num=17, train_loss_step=0.373]Epoch 0:  83%|████████▎ | 53/64 [00:08<00:01,  6.44it/s, loss=0.365, v_num=17, train_loss_step=0.388]Epoch 0:  84%|████████▍ | 54/64 [00:08<00:01,  6.44it/s, loss=0.365, v_num=17, train_loss_step=0.388]Epoch 0:  84%|████████▍ | 54/64 [00:08<00:01,  6.44it/s, loss=0.364, v_num=17, train_loss_step=0.361]Epoch 0:  86%|████████▌ | 55/64 [00:08<00:01,  6.44it/s, loss=0.364, v_num=17, train_loss_step=0.361]Epoch 0:  86%|████████▌ | 55/64 [00:08<00:01,  6.44it/s, loss=0.365, v_num=17, train_loss_step=0.389]Epoch 0:  88%|████████▊ | 56/64 [00:08<00:01,  6.50it/s, loss=0.364, v_num=17, train_loss_step=0.356]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/8 [00:00<?, ?it/s][A
Validating:  12%|█▎        | 1/8 [00:00<00:02,  2.35it/s][AEpoch 0:  91%|█████████ | 58/64 [00:09<00:00,  6.41it/s, loss=0.364, v_num=17, train_loss_step=0.356]
Validating:  25%|██▌       | 2/8 [00:00<00:02,  2.35it/s][A
Validating:  38%|███▊      | 3/8 [00:01<00:02,  2.36it/s][A
Validating:  50%|█████     | 4/8 [00:01<00:01,  2.37it/s][AEpoch 0:  95%|█████████▌| 61/64 [00:10<00:00,  5.92it/s, loss=0.364, v_num=17, train_loss_step=0.356]
Validating:  62%|██████▎   | 5/8 [00:02<00:01,  2.37it/s][A
Validating:  75%|███████▌  | 6/8 [00:02<00:00,  2.36it/s][A
Validating:  88%|████████▊ | 7/8 [00:02<00:00,  2.36it/s][AEpoch 0: 100%|██████████| 64/64 [00:11<00:00,  5.54it/s, loss=0.364, v_num=17, train_loss_step=0.356]
Validating: 100%|██████████| 8/8 [00:03<00:00,  2.64it/s][AEpoch 0: 100%|██████████| 64/64 [00:12<00:00,  5.40it/s, loss=0.364, v_num=17, train_loss_step=0.356]
                                                         [AEpoch 0: 100%|██████████| 64/64 [00:12<00:00,  5.38it/s, loss=0.364, v_num=17, train_loss_step=0.356]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(

Testing: 0it [00:00, ?it/s]Testing:   2%|▏         | 3/169 [00:00<00:06, 25.81it/s]Testing:   4%|▎         | 6/169 [00:00<00:05, 27.79it/s]Testing:   5%|▌         | 9/169 [00:00<00:05, 28.49it/s]Testing:   7%|▋         | 12/169 [00:00<00:05, 28.77it/s]Testing:   9%|▉         | 15/169 [00:00<00:05, 29.05it/s]Testing:  11%|█         | 18/169 [00:00<00:05, 28.71it/s]Testing:  12%|█▏        | 21/169 [00:00<00:05, 28.81it/s]Testing:  14%|█▍        | 24/169 [00:00<00:05, 28.81it/s]Testing:  16%|█▌        | 27/169 [00:00<00:04, 28.76it/s]Testing:  18%|█▊        | 30/169 [00:01<00:04, 28.81it/s]Testing:  20%|█▉        | 33/169 [00:01<00:04, 28.90it/s]Testing:  21%|██▏       | 36/169 [00:01<00:04, 29.01it/s]Testing:  23%|██▎       | 39/169 [00:01<00:04, 29.16it/s]Testing:  25%|██▍       | 42/169 [00:01<00:04, 29.21it/s]Testing:  27%|██▋       | 45/169 [00:01<00:04, 29.21it/s]Testing:  28%|██▊       | 48/169 [00:01<00:04, 29.24it/s]Testing:  30%|███       | 51/169 [00:01<00:04, 29.14it/s]Testing:  32%|███▏      | 54/169 [00:01<00:03, 29.15it/s]Testing:  34%|███▎      | 57/169 [00:01<00:03, 29.11it/s]Testing:  36%|███▌      | 60/169 [00:02<00:03, 29.24it/s]Testing:  37%|███▋      | 63/169 [00:02<00:03, 29.15it/s]Testing:  39%|███▉      | 66/169 [00:02<00:03, 29.19it/s]Testing:  41%|████      | 69/169 [00:02<00:03, 29.16it/s]Testing:  43%|████▎     | 72/169 [00:02<00:03, 29.24it/s]Testing:  44%|████▍     | 75/169 [00:02<00:03, 29.27it/s]Testing:  46%|████▌     | 78/169 [00:02<00:03, 29.14it/s]Testing:  48%|████▊     | 81/169 [00:02<00:03, 29.04it/s]Testing:  50%|████▉     | 84/169 [00:02<00:02, 29.13it/s]Testing:  51%|█████▏    | 87/169 [00:03<00:02, 29.09it/s]Testing:  53%|█████▎    | 90/169 [00:03<00:02, 29.10it/s]Testing:  55%|█████▌    | 93/169 [00:03<00:02, 29.07it/s]Testing:  57%|█████▋    | 96/169 [00:03<00:02, 28.97it/s]Testing:  59%|█████▊    | 99/169 [00:03<00:02, 28.66it/s]Testing:  60%|██████    | 102/169 [00:03<00:02, 28.69it/s]Testing:  62%|██████▏   | 105/169 [00:03<00:02, 28.76it/s]Testing:  64%|██████▍   | 108/169 [00:03<00:02, 28.76it/s]Testing:  66%|██████▌   | 111/169 [00:03<00:02, 28.81it/s]Testing:  67%|██████▋   | 114/169 [00:03<00:01, 28.80it/s]Testing:  69%|██████▉   | 117/169 [00:04<00:01, 28.85it/s]Testing:  71%|███████   | 120/169 [00:04<00:01, 28.77it/s]Testing:  73%|███████▎  | 123/169 [00:04<00:01, 28.77it/s]Testing:  75%|███████▍  | 126/169 [00:04<00:01, 28.82it/s]Testing:  76%|███████▋  | 129/169 [00:04<00:01, 28.82it/s]Testing:  78%|███████▊  | 132/169 [00:04<00:01, 28.80it/s]Testing:  80%|███████▉  | 135/169 [00:04<00:01, 28.65it/s]Testing:  82%|████████▏ | 138/169 [00:04<00:01, 28.79it/s]Testing:  83%|████████▎ | 141/169 [00:04<00:00, 28.84it/s]Testing:  85%|████████▌ | 144/169 [00:04<00:00, 28.76it/s]Testing:  87%|████████▋ | 147/169 [00:05<00:00, 28.78it/s]Testing:  89%|████████▉ | 150/169 [00:05<00:00, 28.79it/s]Testing:  91%|█████████ | 153/169 [00:05<00:00, 28.71it/s]Testing:  92%|█████████▏| 156/169 [00:05<00:00, 28.62it/s]Testing:  94%|█████████▍| 159/169 [00:05<00:00, 28.53it/s]Testing:  96%|█████████▌| 162/169 [00:05<00:00, 28.54it/s]Testing:  98%|█████████▊| 165/169 [00:05<00:00, 28.67it/s]Testing:  99%|█████████▉| 168/169 [00:05<00:00, 28.75it/s]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'_mean_accuracy': 0.9745603203773499,
 '_standard_dev_accuracy': 0.031432144343853,
 '_variance_accuracy': 0.000987979699857533,
 'test_acc': 0.9745603203773499,
 'test_dice_c1': 0.21243920922279358,
 'test_f2_c1': 0.26671266555786133,
 'test_loss': 0.3499024510383606,
 'test_mean_c1': 0.4124581217765808,
 'test_prec_c1': 0.18124331533908844,
 'test_sens_c1': 0.3897448182106018,
 'test_spec_c1': 0.9767829775810242}
--------------------------------------------------------------------------------
Testing: 100%|██████████| 169/169 [00:05<00:00, 28.84it/s]
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

  | Name       | Type             | Params
------------------------------------------------
0 | encoder1   | EncoderBlock     | 37.6 K
1 | encoder2   | EncoderBlock     | 221 K 
2 | bottleneck | ConvolutionBlock | 885 K 
3 | dropout    | Dropout2d        | 0     
4 | decoder1   | DecoderBlock     | 573 K 
5 | decoder2   | DecoderBlock     | 143 K 
6 | conv       | Conv2d           | 130   
7 | softmax    | Softmax2d        | 0     
------------------------------------------------
1.9 M     Trainable params
0         Non-trainable params
1.9 M     Total params
7.447     Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  1.72it/s]Validation sanity check: 100%|██████████| 2/2 [00:00<00:00,  2.32it/s]                                                                      /home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Training: -1it [00:00, ?it/s]Training:   0%|          | 0/380 [00:00<00:00, 25731.93it/s]Epoch 0:   0%|          | 0/380 [00:00<00:00, 4306.27it/s]  Epoch 0:   0%|          | 1/380 [00:00<00:44,  8.44it/s]  Epoch 0:   0%|          | 1/380 [00:00<00:44,  8.43it/s, loss=0.674, v_num=18, train_loss_step=0.674]Epoch 0:   1%|          | 2/380 [00:00<00:44,  8.51it/s, loss=0.674, v_num=18, train_loss_step=0.674]Epoch 0:   1%|          | 2/380 [00:00<00:44,  8.50it/s, loss=0.679, v_num=18, train_loss_step=0.684]Epoch 0:   1%|          | 3/380 [00:00<00:49,  7.69it/s, loss=0.679, v_num=18, train_loss_step=0.684]Epoch 0:   1%|          | 3/380 [00:00<00:49,  7.68it/s, loss=0.688, v_num=18, train_loss_step=0.706]Epoch 0:   1%|          | 4/380 [00:00<00:52,  7.14it/s, loss=0.688, v_num=18, train_loss_step=0.706]Epoch 0:   1%|          | 4/380 [00:00<00:52,  7.13it/s, loss=0.684, v_num=18, train_loss_step=0.670]Epoch 0:   1%|▏         | 5/380 [00:00<00:54,  6.94it/s, loss=0.684, v_num=18, train_loss_step=0.670]Epoch 0:   1%|▏         | 5/380 [00:00<00:54,  6.93it/s, loss=0.681, v_num=18, train_loss_step=0.670]Epoch 0:   2%|▏         | 6/380 [00:00<00:53,  7.04it/s, loss=0.681, v_num=18, train_loss_step=0.670]Epoch 0:   2%|▏         | 6/380 [00:00<00:53,  7.04it/s, loss=0.679, v_num=18, train_loss_step=0.669]Epoch 0:   2%|▏         | 7/380 [00:01<00:53,  6.94it/s, loss=0.679, v_num=18, train_loss_step=0.669]Epoch 0:   2%|▏         | 7/380 [00:01<00:53,  6.93it/s, loss=0.678, v_num=18, train_loss_step=0.670]Epoch 0:   2%|▏         | 8/380 [00:01<00:53,  6.95it/s, loss=0.678, v_num=18, train_loss_step=0.670]Epoch 0:   2%|▏         | 8/380 [00:01<00:53,  6.94it/s, loss=0.677, v_num=18, train_loss_step=0.673]Epoch 0:   2%|▏         | 9/380 [00:01<00:53,  6.88it/s, loss=0.677, v_num=18, train_loss_step=0.673]Epoch 0:   2%|▏         | 9/380 [00:01<00:53,  6.87it/s, loss=0.676, v_num=18, train_loss_step=0.668]Epoch 0:   3%|▎         | 10/380 [00:01<00:53,  6.86it/s, loss=0.676, v_num=18, train_loss_step=0.668]Epoch 0:   3%|▎         | 10/380 [00:01<00:53,  6.86it/s, loss=0.675, v_num=18, train_loss_step=0.666]Epoch 0:   3%|▎         | 11/380 [00:01<00:53,  6.87it/s, loss=0.675, v_num=18, train_loss_step=0.666]Epoch 0:   3%|▎         | 11/380 [00:01<00:53,  6.86it/s, loss=0.675, v_num=18, train_loss_step=0.673]Epoch 0:   3%|▎         | 12/380 [00:01<00:53,  6.92it/s, loss=0.675, v_num=18, train_loss_step=0.673]Epoch 0:   3%|▎         | 12/380 [00:01<00:53,  6.92it/s, loss=0.674, v_num=18, train_loss_step=0.666]Epoch 0:   3%|▎         | 13/380 [00:02<00:53,  6.85it/s, loss=0.674, v_num=18, train_loss_step=0.666]Epoch 0:   3%|▎         | 13/380 [00:02<00:53,  6.85it/s, loss=0.674, v_num=18, train_loss_step=0.674]Epoch 0:   4%|▎         | 14/380 [00:02<00:53,  6.88it/s, loss=0.674, v_num=18, train_loss_step=0.674]Epoch 0:   4%|▎         | 14/380 [00:02<00:53,  6.88it/s, loss=0.674, v_num=18, train_loss_step=0.668]Epoch 0:   4%|▍         | 15/380 [00:02<00:53,  6.84it/s, loss=0.674, v_num=18, train_loss_step=0.668]Epoch 0:   4%|▍         | 15/380 [00:02<00:53,  6.84it/s, loss=0.673, v_num=18, train_loss_step=0.661]Epoch 0:   4%|▍         | 16/380 [00:02<00:53,  6.86it/s, loss=0.673, v_num=18, train_loss_step=0.661]Epoch 0:   4%|▍         | 16/380 [00:02<00:53,  6.86it/s, loss=0.672, v_num=18, train_loss_step=0.660]Epoch 0:   4%|▍         | 17/380 [00:02<00:52,  6.87it/s, loss=0.672, v_num=18, train_loss_step=0.660]Epoch 0:   4%|▍         | 17/380 [00:02<00:52,  6.87it/s, loss=0.672, v_num=18, train_loss_step=0.680]Epoch 0:   5%|▍         | 18/380 [00:02<00:53,  6.82it/s, loss=0.672, v_num=18, train_loss_step=0.680]Epoch 0:   5%|▍         | 18/380 [00:02<00:53,  6.82it/s, loss=0.672, v_num=18, train_loss_step=0.656]Epoch 0:   5%|▌         | 19/380 [00:02<00:53,  6.80it/s, loss=0.672, v_num=18, train_loss_step=0.656]Epoch 0:   5%|▌         | 19/380 [00:02<00:53,  6.80it/s, loss=0.672, v_num=18, train_loss_step=0.683]Epoch 0:   5%|▌         | 20/380 [00:03<00:52,  6.84it/s, loss=0.672, v_num=18, train_loss_step=0.683]Epoch 0:   5%|▌         | 20/380 [00:03<00:52,  6.84it/s, loss=0.672, v_num=18, train_loss_step=0.669]Epoch 0:   6%|▌         | 21/380 [00:03<00:52,  6.88it/s, loss=0.672, v_num=18, train_loss_step=0.669]Epoch 0:   6%|▌         | 21/380 [00:03<00:52,  6.88it/s, loss=0.672, v_num=18, train_loss_step=0.669]Epoch 0:   6%|▌         | 22/380 [00:03<00:51,  6.89it/s, loss=0.672, v_num=18, train_loss_step=0.669]Epoch 0:   6%|▌         | 22/380 [00:03<00:51,  6.89it/s, loss=0.67, v_num=18, train_loss_step=0.650] Epoch 0:   6%|▌         | 23/380 [00:03<00:52,  6.84it/s, loss=0.67, v_num=18, train_loss_step=0.650]Epoch 0:   6%|▌         | 23/380 [00:03<00:52,  6.84it/s, loss=0.667, v_num=18, train_loss_step=0.651]Epoch 0:   6%|▋         | 24/380 [00:03<00:52,  6.84it/s, loss=0.667, v_num=18, train_loss_step=0.651]Epoch 0:   6%|▋         | 24/380 [00:03<00:52,  6.84it/s, loss=0.666, v_num=18, train_loss_step=0.643]Epoch 0:   7%|▋         | 25/380 [00:03<00:52,  6.82it/s, loss=0.666, v_num=18, train_loss_step=0.643]Epoch 0:   7%|▋         | 25/380 [00:03<00:52,  6.82it/s, loss=0.664, v_num=18, train_loss_step=0.639]Epoch 0:   7%|▋         | 26/380 [00:03<00:51,  6.83it/s, loss=0.664, v_num=18, train_loss_step=0.639]Epoch 0:   7%|▋         | 26/380 [00:03<00:51,  6.83it/s, loss=0.663, v_num=18, train_loss_step=0.640]Epoch 0:   7%|▋         | 27/380 [00:04<00:51,  6.83it/s, loss=0.663, v_num=18, train_loss_step=0.640]Epoch 0:   7%|▋         | 27/380 [00:04<00:51,  6.83it/s, loss=0.662, v_num=18, train_loss_step=0.644]Epoch 0:   7%|▋         | 28/380 [00:04<00:52,  6.65it/s, loss=0.662, v_num=18, train_loss_step=0.644]Epoch 0:   7%|▋         | 28/380 [00:04<00:52,  6.65it/s, loss=0.659, v_num=18, train_loss_step=0.624]Epoch 0:   8%|▊         | 29/380 [00:04<00:52,  6.68it/s, loss=0.659, v_num=18, train_loss_step=0.624]Epoch 0:   8%|▊         | 29/380 [00:04<00:52,  6.68it/s, loss=0.658, v_num=18, train_loss_step=0.644]Epoch 0:   8%|▊         | 30/380 [00:04<00:52,  6.67it/s, loss=0.658, v_num=18, train_loss_step=0.644]Epoch 0:   8%|▊         | 30/380 [00:04<00:52,  6.67it/s, loss=0.655, v_num=18, train_loss_step=0.614]Epoch 0:   8%|▊         | 31/380 [00:04<00:52,  6.70it/s, loss=0.655, v_num=18, train_loss_step=0.614]Epoch 0:   8%|▊         | 31/380 [00:04<00:52,  6.70it/s, loss=0.652, v_num=18, train_loss_step=0.601]Epoch 0:   8%|▊         | 32/380 [00:04<00:51,  6.70it/s, loss=0.652, v_num=18, train_loss_step=0.601]Epoch 0:   8%|▊         | 32/380 [00:04<00:51,  6.70it/s, loss=0.648, v_num=18, train_loss_step=0.587]Epoch 0:   9%|▊         | 33/380 [00:05<00:51,  6.68it/s, loss=0.648, v_num=18, train_loss_step=0.587]Epoch 0:   9%|▊         | 33/380 [00:05<00:51,  6.68it/s, loss=0.648, v_num=18, train_loss_step=0.673]Epoch 0:   9%|▉         | 34/380 [00:05<00:51,  6.67it/s, loss=0.648, v_num=18, train_loss_step=0.673]Epoch 0:   9%|▉         | 34/380 [00:05<00:51,  6.67it/s, loss=0.647, v_num=18, train_loss_step=0.646]Epoch 0:   9%|▉         | 35/380 [00:05<00:51,  6.64it/s, loss=0.647, v_num=18, train_loss_step=0.646]Epoch 0:   9%|▉         | 35/380 [00:05<00:51,  6.64it/s, loss=0.646, v_num=18, train_loss_step=0.655]Epoch 0:   9%|▉         | 36/380 [00:05<00:51,  6.66it/s, loss=0.646, v_num=18, train_loss_step=0.655]Epoch 0:   9%|▉         | 36/380 [00:05<00:51,  6.66it/s, loss=0.647, v_num=18, train_loss_step=0.668]Epoch 0:  10%|▉         | 37/380 [00:05<00:51,  6.68it/s, loss=0.647, v_num=18, train_loss_step=0.668]Epoch 0:  10%|▉         | 37/380 [00:05<00:51,  6.68it/s, loss=0.639, v_num=18, train_loss_step=0.529]Epoch 0:  10%|█         | 38/380 [00:05<00:51,  6.70it/s, loss=0.639, v_num=18, train_loss_step=0.529]Epoch 0:  10%|█         | 38/380 [00:05<00:51,  6.70it/s, loss=0.631, v_num=18, train_loss_step=0.483]Epoch 0:  10%|█         | 39/380 [00:05<00:50,  6.69it/s, loss=0.631, v_num=18, train_loss_step=0.483]Epoch 0:  10%|█         | 39/380 [00:05<00:50,  6.69it/s, loss=0.619, v_num=18, train_loss_step=0.449]Epoch 0:  11%|█         | 40/380 [00:06<00:50,  6.69it/s, loss=0.619, v_num=18, train_loss_step=0.449]Epoch 0:  11%|█         | 40/380 [00:06<00:50,  6.69it/s, loss=0.606, v_num=18, train_loss_step=0.415]Epoch 0:  11%|█         | 41/380 [00:06<00:50,  6.70it/s, loss=0.606, v_num=18, train_loss_step=0.415]Epoch 0:  11%|█         | 41/380 [00:06<00:50,  6.70it/s, loss=0.596, v_num=18, train_loss_step=0.470]Epoch 0:  11%|█         | 42/380 [00:06<00:50,  6.72it/s, loss=0.596, v_num=18, train_loss_step=0.470]Epoch 0:  11%|█         | 42/380 [00:06<00:50,  6.72it/s, loss=0.582, v_num=18, train_loss_step=0.368]Epoch 0:  11%|█▏        | 43/380 [00:06<00:50,  6.74it/s, loss=0.582, v_num=18, train_loss_step=0.368]Epoch 0:  11%|█▏        | 43/380 [00:06<00:50,  6.74it/s, loss=0.566, v_num=18, train_loss_step=0.335]Epoch 0:  12%|█▏        | 44/380 [00:06<00:49,  6.72it/s, loss=0.566, v_num=18, train_loss_step=0.335]Epoch 0:  12%|█▏        | 44/380 [00:06<00:49,  6.72it/s, loss=0.551, v_num=18, train_loss_step=0.335]Epoch 0:  12%|█▏        | 45/380 [00:06<00:49,  6.71it/s, loss=0.551, v_num=18, train_loss_step=0.335]Epoch 0:  12%|█▏        | 45/380 [00:06<00:49,  6.71it/s, loss=0.538, v_num=18, train_loss_step=0.376]Epoch 0:  12%|█▏        | 46/380 [00:07<00:49,  6.70it/s, loss=0.538, v_num=18, train_loss_step=0.376]Epoch 0:  12%|█▏        | 46/380 [00:07<00:49,  6.70it/s, loss=0.522, v_num=18, train_loss_step=0.314]Epoch 0:  12%|█▏        | 47/380 [00:07<00:49,  6.74it/s, loss=0.522, v_num=18, train_loss_step=0.314]Epoch 0:  12%|█▏        | 47/380 [00:07<00:49,  6.74it/s, loss=0.505, v_num=18, train_loss_step=0.314]Epoch 0:  13%|█▎        | 48/380 [00:07<00:49,  6.73it/s, loss=0.505, v_num=18, train_loss_step=0.314]Epoch 0:  13%|█▎        | 48/380 [00:07<00:49,  6.73it/s, loss=0.502, v_num=18, train_loss_step=0.563]Epoch 0:  13%|█▎        | 49/380 [00:07<00:49,  6.72it/s, loss=0.502, v_num=18, train_loss_step=0.563]Epoch 0:  13%|█▎        | 49/380 [00:07<00:49,  6.72it/s, loss=0.493, v_num=18, train_loss_step=0.463]Epoch 0:  13%|█▎        | 50/380 [00:07<00:49,  6.70it/s, loss=0.493, v_num=18, train_loss_step=0.463]Epoch 0:  13%|█▎        | 50/380 [00:07<00:49,  6.70it/s, loss=0.483, v_num=18, train_loss_step=0.423]Epoch 0:  13%|█▎        | 51/380 [00:07<00:49,  6.71it/s, loss=0.483, v_num=18, train_loss_step=0.423]Epoch 0:  13%|█▎        | 51/380 [00:07<00:49,  6.71it/s, loss=0.469, v_num=18, train_loss_step=0.313]Epoch 0:  14%|█▎        | 52/380 [00:07<00:48,  6.70it/s, loss=0.469, v_num=18, train_loss_step=0.313]Epoch 0:  14%|█▎        | 52/380 [00:07<00:48,  6.70it/s, loss=0.457, v_num=18, train_loss_step=0.345]Epoch 0:  14%|█▍        | 53/380 [00:08<00:48,  6.69it/s, loss=0.457, v_num=18, train_loss_step=0.345]Epoch 0:  14%|█▍        | 53/380 [00:08<00:48,  6.69it/s, loss=0.439, v_num=18, train_loss_step=0.313]Epoch 0:  14%|█▍        | 54/380 [00:08<00:48,  6.69it/s, loss=0.439, v_num=18, train_loss_step=0.313]Epoch 0:  14%|█▍        | 54/380 [00:08<00:48,  6.69it/s, loss=0.439, v_num=18, train_loss_step=0.659]Epoch 0:  14%|█▍        | 55/380 [00:08<00:48,  6.70it/s, loss=0.439, v_num=18, train_loss_step=0.659]Epoch 0:  14%|█▍        | 55/380 [00:08<00:48,  6.70it/s, loss=0.426, v_num=18, train_loss_step=0.388]Epoch 0:  15%|█▍        | 56/380 [00:08<00:48,  6.70it/s, loss=0.426, v_num=18, train_loss_step=0.388]Epoch 0:  15%|█▍        | 56/380 [00:08<00:48,  6.70it/s, loss=0.408, v_num=18, train_loss_step=0.313]Epoch 0:  15%|█▌        | 57/380 [00:08<00:48,  6.72it/s, loss=0.408, v_num=18, train_loss_step=0.313]Epoch 0:  15%|█▌        | 57/380 [00:08<00:48,  6.72it/s, loss=0.401, v_num=18, train_loss_step=0.390]Epoch 0:  15%|█▌        | 58/380 [00:08<00:48,  6.70it/s, loss=0.401, v_num=18, train_loss_step=0.390]Epoch 0:  15%|█▌        | 58/380 [00:08<00:48,  6.70it/s, loss=0.393, v_num=18, train_loss_step=0.313]Epoch 0:  16%|█▌        | 59/380 [00:08<00:47,  6.70it/s, loss=0.393, v_num=18, train_loss_step=0.313]Epoch 0:  16%|█▌        | 59/380 [00:08<00:47,  6.70it/s, loss=0.39, v_num=18, train_loss_step=0.388] Epoch 0:  16%|█▌        | 60/380 [00:09<00:47,  6.69it/s, loss=0.39, v_num=18, train_loss_step=0.388]Epoch 0:  16%|█▌        | 60/380 [00:09<00:47,  6.69it/s, loss=0.39, v_num=18, train_loss_step=0.421]Epoch 0:  16%|█▌        | 61/380 [00:09<00:47,  6.70it/s, loss=0.39, v_num=18, train_loss_step=0.421]Epoch 0:  16%|█▌        | 61/380 [00:09<00:47,  6.70it/s, loss=0.387, v_num=18, train_loss_step=0.399]Epoch 0:  16%|█▋        | 62/380 [00:09<00:47,  6.70it/s, loss=0.387, v_num=18, train_loss_step=0.399]Epoch 0:  16%|█▋        | 62/380 [00:09<00:47,  6.70it/s, loss=0.396, v_num=18, train_loss_step=0.554]Epoch 0:  17%|█▋        | 63/380 [00:09<00:47,  6.70it/s, loss=0.396, v_num=18, train_loss_step=0.554]Epoch 0:  17%|█▋        | 63/380 [00:09<00:47,  6.70it/s, loss=0.399, v_num=18, train_loss_step=0.406]Epoch 0:  17%|█▋        | 64/380 [00:09<00:47,  6.71it/s, loss=0.399, v_num=18, train_loss_step=0.406]Epoch 0:  17%|█▋        | 64/380 [00:09<00:47,  6.71it/s, loss=0.401, v_num=18, train_loss_step=0.358]Epoch 0:  17%|█▋        | 65/380 [00:09<00:46,  6.73it/s, loss=0.401, v_num=18, train_loss_step=0.358]Epoch 0:  17%|█▋        | 65/380 [00:09<00:46,  6.73it/s, loss=0.401, v_num=18, train_loss_step=0.376]Epoch 0:  17%|█▋        | 66/380 [00:09<00:46,  6.72it/s, loss=0.401, v_num=18, train_loss_step=0.376]Epoch 0:  17%|█▋        | 66/380 [00:09<00:46,  6.72it/s, loss=0.402, v_num=18, train_loss_step=0.332]Epoch 0:  18%|█▊        | 67/380 [00:10<00:46,  6.73it/s, loss=0.402, v_num=18, train_loss_step=0.332]Epoch 0:  18%|█▊        | 67/380 [00:10<00:46,  6.73it/s, loss=0.401, v_num=18, train_loss_step=0.313]Epoch 0:  18%|█▊        | 68/380 [00:10<00:46,  6.76it/s, loss=0.401, v_num=18, train_loss_step=0.313]Epoch 0:  18%|█▊        | 68/380 [00:10<00:46,  6.76it/s, loss=0.396, v_num=18, train_loss_step=0.456]Epoch 0:  18%|█▊        | 69/380 [00:10<00:46,  6.76it/s, loss=0.396, v_num=18, train_loss_step=0.456]Epoch 0:  18%|█▊        | 69/380 [00:10<00:46,  6.76it/s, loss=0.401, v_num=18, train_loss_step=0.566]Epoch 0:  18%|█▊        | 70/380 [00:10<00:45,  6.75it/s, loss=0.401, v_num=18, train_loss_step=0.566]Epoch 0:  18%|█▊        | 70/380 [00:10<00:45,  6.75it/s, loss=0.396, v_num=18, train_loss_step=0.313]Epoch 0:  19%|█▊        | 71/380 [00:10<00:45,  6.74it/s, loss=0.396, v_num=18, train_loss_step=0.313]Epoch 0:  19%|█▊        | 71/380 [00:10<00:45,  6.74it/s, loss=0.407, v_num=18, train_loss_step=0.534]Epoch 0:  19%|█▉        | 72/380 [00:10<00:45,  6.74it/s, loss=0.407, v_num=18, train_loss_step=0.534]Epoch 0:  19%|█▉        | 72/380 [00:10<00:45,  6.74it/s, loss=0.407, v_num=18, train_loss_step=0.347]Epoch 0:  19%|█▉        | 73/380 [00:10<00:45,  6.74it/s, loss=0.407, v_num=18, train_loss_step=0.347]Epoch 0:  19%|█▉        | 73/380 [00:10<00:45,  6.74it/s, loss=0.408, v_num=18, train_loss_step=0.337]Epoch 0:  19%|█▉        | 74/380 [00:11<00:45,  6.75it/s, loss=0.408, v_num=18, train_loss_step=0.337]Epoch 0:  19%|█▉        | 74/380 [00:11<00:45,  6.75it/s, loss=0.408, v_num=18, train_loss_step=0.660]Epoch 0:  20%|█▉        | 75/380 [00:11<00:45,  6.75it/s, loss=0.408, v_num=18, train_loss_step=0.660]Epoch 0:  20%|█▉        | 75/380 [00:11<00:45,  6.75it/s, loss=0.408, v_num=18, train_loss_step=0.388]Epoch 0:  20%|██        | 76/380 [00:11<00:44,  6.76it/s, loss=0.408, v_num=18, train_loss_step=0.388]Epoch 0:  20%|██        | 76/380 [00:11<00:44,  6.76it/s, loss=0.435, v_num=18, train_loss_step=0.843]Epoch 0:  20%|██        | 77/380 [00:11<00:44,  6.75it/s, loss=0.435, v_num=18, train_loss_step=0.843]Epoch 0:  20%|██        | 77/380 [00:11<00:44,  6.75it/s, loss=0.46, v_num=18, train_loss_step=0.887] Epoch 0:  21%|██        | 78/380 [00:11<00:44,  6.75it/s, loss=0.46, v_num=18, train_loss_step=0.887]Epoch 0:  21%|██        | 78/380 [00:11<00:44,  6.75it/s, loss=0.461, v_num=18, train_loss_step=0.332]Epoch 0:  21%|██        | 79/380 [00:11<00:44,  6.74it/s, loss=0.461, v_num=18, train_loss_step=0.332]Epoch 0:  21%|██        | 79/380 [00:11<00:44,  6.74it/s, loss=0.469, v_num=18, train_loss_step=0.553]Epoch 0:  21%|██        | 80/380 [00:12<00:44,  6.74it/s, loss=0.469, v_num=18, train_loss_step=0.553]Epoch 0:  21%|██        | 80/380 [00:12<00:44,  6.74it/s, loss=0.465, v_num=18, train_loss_step=0.343]Epoch 0:  21%|██▏       | 81/380 [00:12<00:44,  6.74it/s, loss=0.465, v_num=18, train_loss_step=0.343]Epoch 0:  21%|██▏       | 81/380 [00:12<00:44,  6.74it/s, loss=0.476, v_num=18, train_loss_step=0.613]Epoch 0:  22%|██▏       | 82/380 [00:12<00:44,  6.75it/s, loss=0.476, v_num=18, train_loss_step=0.613]Epoch 0:  22%|██▏       | 82/380 [00:12<00:44,  6.75it/s, loss=0.464, v_num=18, train_loss_step=0.313]Epoch 0:  22%|██▏       | 83/380 [00:12<00:44,  6.75it/s, loss=0.464, v_num=18, train_loss_step=0.313]Epoch 0:  22%|██▏       | 83/380 [00:12<00:44,  6.75it/s, loss=0.467, v_num=18, train_loss_step=0.483]Epoch 0:  22%|██▏       | 84/380 [00:12<00:43,  6.74it/s, loss=0.467, v_num=18, train_loss_step=0.483]Epoch 0:  22%|██▏       | 84/380 [00:12<00:43,  6.74it/s, loss=0.466, v_num=18, train_loss_step=0.337]Epoch 0:  22%|██▏       | 85/380 [00:12<00:43,  6.75it/s, loss=0.466, v_num=18, train_loss_step=0.337]Epoch 0:  22%|██▏       | 85/380 [00:12<00:43,  6.75it/s, loss=0.464, v_num=18, train_loss_step=0.332]Epoch 0:  23%|██▎       | 86/380 [00:12<00:43,  6.74it/s, loss=0.464, v_num=18, train_loss_step=0.332]Epoch 0:  23%|██▎       | 86/380 [00:12<00:43,  6.74it/s, loss=0.472, v_num=18, train_loss_step=0.479]Epoch 0:  23%|██▎       | 87/380 [00:13<00:43,  6.75it/s, loss=0.472, v_num=18, train_loss_step=0.479]Epoch 0:  23%|██▎       | 87/380 [00:13<00:43,  6.75it/s, loss=0.472, v_num=18, train_loss_step=0.313]Epoch 0:  23%|██▎       | 88/380 [00:13<00:43,  6.76it/s, loss=0.472, v_num=18, train_loss_step=0.313]Epoch 0:  23%|██▎       | 88/380 [00:13<00:43,  6.75it/s, loss=0.467, v_num=18, train_loss_step=0.355]Epoch 0:  23%|██▎       | 89/380 [00:13<00:43,  6.75it/s, loss=0.467, v_num=18, train_loss_step=0.355]Epoch 0:  23%|██▎       | 89/380 [00:13<00:43,  6.75it/s, loss=0.457, v_num=18, train_loss_step=0.383]Epoch 0:  24%|██▎       | 90/380 [00:13<00:42,  6.77it/s, loss=0.457, v_num=18, train_loss_step=0.383]Epoch 0:  24%|██▎       | 90/380 [00:13<00:42,  6.77it/s, loss=0.457, v_num=18, train_loss_step=0.313]Epoch 0:  24%|██▍       | 91/380 [00:13<00:42,  6.76it/s, loss=0.457, v_num=18, train_loss_step=0.313]Epoch 0:  24%|██▍       | 91/380 [00:13<00:42,  6.76it/s, loss=0.447, v_num=18, train_loss_step=0.334]Epoch 0:  24%|██▍       | 92/380 [00:13<00:42,  6.77it/s, loss=0.447, v_num=18, train_loss_step=0.334]Epoch 0:  24%|██▍       | 92/380 [00:13<00:42,  6.77it/s, loss=0.446, v_num=18, train_loss_step=0.313]Epoch 0:  24%|██▍       | 93/380 [00:13<00:42,  6.77it/s, loss=0.446, v_num=18, train_loss_step=0.313]Epoch 0:  24%|██▍       | 93/380 [00:13<00:42,  6.77it/s, loss=0.445, v_num=18, train_loss_step=0.329]Epoch 0:  25%|██▍       | 94/380 [00:14<00:42,  6.77it/s, loss=0.445, v_num=18, train_loss_step=0.329]Epoch 0:  25%|██▍       | 94/380 [00:14<00:42,  6.77it/s, loss=0.43, v_num=18, train_loss_step=0.350] Epoch 0:  25%|██▌       | 95/380 [00:14<00:42,  6.76it/s, loss=0.43, v_num=18, train_loss_step=0.350]Epoch 0:  25%|██▌       | 95/380 [00:14<00:42,  6.76it/s, loss=0.427, v_num=18, train_loss_step=0.324]Epoch 0:  25%|██▌       | 96/380 [00:14<00:42,  6.75it/s, loss=0.427, v_num=18, train_loss_step=0.324]Epoch 0:  25%|██▌       | 96/380 [00:14<00:42,  6.75it/s, loss=0.4, v_num=18, train_loss_step=0.321]  Epoch 0:  26%|██▌       | 97/380 [00:14<00:41,  6.75it/s, loss=0.4, v_num=18, train_loss_step=0.321]Epoch 0:  26%|██▌       | 97/380 [00:14<00:41,  6.75it/s, loss=0.372, v_num=18, train_loss_step=0.322]Epoch 0:  26%|██▌       | 98/380 [00:14<00:41,  6.75it/s, loss=0.372, v_num=18, train_loss_step=0.322]Epoch 0:  26%|██▌       | 98/380 [00:14<00:41,  6.75it/s, loss=0.391, v_num=18, train_loss_step=0.714]Epoch 0:  26%|██▌       | 99/380 [00:14<00:41,  6.75it/s, loss=0.391, v_num=18, train_loss_step=0.714]Epoch 0:  26%|██▌       | 99/380 [00:14<00:41,  6.75it/s, loss=0.403, v_num=18, train_loss_step=0.783]Epoch 0:  26%|██▋       | 100/380 [00:14<00:41,  6.76it/s, loss=0.403, v_num=18, train_loss_step=0.783]Epoch 0:  26%|██▋       | 100/380 [00:14<00:41,  6.76it/s, loss=0.402, v_num=18, train_loss_step=0.325]Epoch 0:  27%|██▋       | 101/380 [00:15<00:41,  6.75it/s, loss=0.402, v_num=18, train_loss_step=0.325]Epoch 0:  27%|██▋       | 101/380 [00:15<00:41,  6.75it/s, loss=0.402, v_num=18, train_loss_step=0.613]Epoch 0:  27%|██▋       | 102/380 [00:15<00:41,  6.75it/s, loss=0.402, v_num=18, train_loss_step=0.613]Epoch 0:  27%|██▋       | 102/380 [00:15<00:41,  6.75it/s, loss=0.402, v_num=18, train_loss_step=0.313]Epoch 0:  27%|██▋       | 103/380 [00:15<00:41,  6.74it/s, loss=0.402, v_num=18, train_loss_step=0.313]Epoch 0:  27%|██▋       | 103/380 [00:15<00:41,  6.74it/s, loss=0.394, v_num=18, train_loss_step=0.323]Epoch 0:  27%|██▋       | 104/380 [00:15<00:40,  6.76it/s, loss=0.394, v_num=18, train_loss_step=0.323]Epoch 0:  27%|██▋       | 104/380 [00:15<00:40,  6.76it/s, loss=0.398, v_num=18, train_loss_step=0.427]Epoch 0:  28%|██▊       | 105/380 [00:15<00:40,  6.76it/s, loss=0.398, v_num=18, train_loss_step=0.427]Epoch 0:  28%|██▊       | 105/380 [00:15<00:40,  6.76it/s, loss=0.404, v_num=18, train_loss_step=0.452]Epoch 0:  28%|██▊       | 106/380 [00:15<00:40,  6.78it/s, loss=0.404, v_num=18, train_loss_step=0.452]Epoch 0:  28%|██▊       | 106/380 [00:15<00:40,  6.78it/s, loss=0.399, v_num=18, train_loss_step=0.381]Epoch 0:  28%|██▊       | 107/380 [00:15<00:40,  6.77it/s, loss=0.399, v_num=18, train_loss_step=0.381]Epoch 0:  28%|██▊       | 107/380 [00:15<00:40,  6.77it/s, loss=0.402, v_num=18, train_loss_step=0.368]Epoch 0:  28%|██▊       | 108/380 [00:16<00:40,  6.77it/s, loss=0.402, v_num=18, train_loss_step=0.368]Epoch 0:  28%|██▊       | 108/380 [00:16<00:40,  6.77it/s, loss=0.4, v_num=18, train_loss_step=0.322]  Epoch 0:  29%|██▊       | 109/380 [00:16<00:40,  6.76it/s, loss=0.4, v_num=18, train_loss_step=0.322]Epoch 0:  29%|██▊       | 109/380 [00:16<00:40,  6.76it/s, loss=0.397, v_num=18, train_loss_step=0.313]Epoch 0:  29%|██▉       | 110/380 [00:16<00:39,  6.77it/s, loss=0.397, v_num=18, train_loss_step=0.313]Epoch 0:  29%|██▉       | 110/380 [00:16<00:39,  6.77it/s, loss=0.397, v_num=18, train_loss_step=0.314]Epoch 0:  29%|██▉       | 111/380 [00:16<00:39,  6.76it/s, loss=0.397, v_num=18, train_loss_step=0.314]Epoch 0:  29%|██▉       | 111/380 [00:16<00:39,  6.76it/s, loss=0.398, v_num=18, train_loss_step=0.353]Epoch 0:  29%|██▉       | 112/380 [00:16<00:39,  6.76it/s, loss=0.398, v_num=18, train_loss_step=0.353]Epoch 0:  29%|██▉       | 112/380 [00:16<00:39,  6.76it/s, loss=0.399, v_num=18, train_loss_step=0.324]Epoch 0:  30%|██▉       | 113/380 [00:16<00:39,  6.75it/s, loss=0.399, v_num=18, train_loss_step=0.324]Epoch 0:  30%|██▉       | 113/380 [00:16<00:39,  6.75it/s, loss=0.398, v_num=18, train_loss_step=0.319]Epoch 0:  30%|███       | 114/380 [00:17<00:39,  6.76it/s, loss=0.398, v_num=18, train_loss_step=0.319]Epoch 0:  30%|███       | 114/380 [00:17<00:39,  6.76it/s, loss=0.396, v_num=18, train_loss_step=0.313]Epoch 0:  30%|███       | 115/380 [00:17<00:39,  6.77it/s, loss=0.396, v_num=18, train_loss_step=0.313]Epoch 0:  30%|███       | 115/380 [00:17<00:39,  6.77it/s, loss=0.414, v_num=18, train_loss_step=0.689]Epoch 0:  31%|███       | 116/380 [00:17<00:38,  6.77it/s, loss=0.414, v_num=18, train_loss_step=0.689]Epoch 0:  31%|███       | 116/380 [00:17<00:38,  6.77it/s, loss=0.423, v_num=18, train_loss_step=0.482]Epoch 0:  31%|███       | 117/380 [00:17<00:38,  6.77it/s, loss=0.423, v_num=18, train_loss_step=0.482]Epoch 0:  31%|███       | 117/380 [00:17<00:38,  6.77it/s, loss=0.437, v_num=18, train_loss_step=0.602]Epoch 0:  31%|███       | 118/380 [00:17<00:38,  6.78it/s, loss=0.437, v_num=18, train_loss_step=0.602]Epoch 0:  31%|███       | 118/380 [00:17<00:38,  6.78it/s, loss=0.42, v_num=18, train_loss_step=0.388] Epoch 0:  31%|███▏      | 119/380 [00:17<00:38,  6.79it/s, loss=0.42, v_num=18, train_loss_step=0.388]Epoch 0:  31%|███▏      | 119/380 [00:17<00:38,  6.79it/s, loss=0.416, v_num=18, train_loss_step=0.698]Epoch 0:  32%|███▏      | 120/380 [00:17<00:38,  6.79it/s, loss=0.416, v_num=18, train_loss_step=0.698]Epoch 0:  32%|███▏      | 120/380 [00:17<00:38,  6.79it/s, loss=0.42, v_num=18, train_loss_step=0.415] Epoch 0:  32%|███▏      | 121/380 [00:17<00:38,  6.80it/s, loss=0.42, v_num=18, train_loss_step=0.415]Epoch 0:  32%|███▏      | 121/380 [00:17<00:38,  6.80it/s, loss=0.413, v_num=18, train_loss_step=0.472]Epoch 0:  32%|███▏      | 122/380 [00:18<00:37,  6.80it/s, loss=0.413, v_num=18, train_loss_step=0.472]Epoch 0:  32%|███▏      | 122/380 [00:18<00:37,  6.80it/s, loss=0.427, v_num=18, train_loss_step=0.590]Epoch 0:  32%|███▏      | 123/380 [00:18<00:37,  6.80it/s, loss=0.427, v_num=18, train_loss_step=0.590]Epoch 0:  32%|███▏      | 123/380 [00:18<00:37,  6.80it/s, loss=0.427, v_num=18, train_loss_step=0.313]Epoch 0:  33%|███▎      | 124/380 [00:18<00:37,  6.80it/s, loss=0.427, v_num=18, train_loss_step=0.313]Epoch 0:  33%|███▎      | 124/380 [00:18<00:37,  6.80it/s, loss=0.421, v_num=18, train_loss_step=0.313]Epoch 0:  33%|███▎      | 125/380 [00:18<00:37,  6.81it/s, loss=0.421, v_num=18, train_loss_step=0.313]Epoch 0:  33%|███▎      | 125/380 [00:18<00:37,  6.81it/s, loss=0.414, v_num=18, train_loss_step=0.313]Epoch 0:  33%|███▎      | 126/380 [00:18<00:37,  6.81it/s, loss=0.414, v_num=18, train_loss_step=0.313]Epoch 0:  33%|███▎      | 126/380 [00:18<00:37,  6.81it/s, loss=0.413, v_num=18, train_loss_step=0.358]Epoch 0:  33%|███▎      | 127/380 [00:18<00:37,  6.82it/s, loss=0.413, v_num=18, train_loss_step=0.358]Epoch 0:  33%|███▎      | 127/380 [00:18<00:37,  6.82it/s, loss=0.41, v_num=18, train_loss_step=0.313] Epoch 0:  34%|███▎      | 128/380 [00:18<00:36,  6.82it/s, loss=0.41, v_num=18, train_loss_step=0.313]Epoch 0:  34%|███▎      | 128/380 [00:18<00:36,  6.82it/s, loss=0.41, v_num=18, train_loss_step=0.313]Epoch 0:  34%|███▍      | 129/380 [00:19<00:36,  6.82it/s, loss=0.41, v_num=18, train_loss_step=0.313]Epoch 0:  34%|███▍      | 129/380 [00:19<00:36,  6.82it/s, loss=0.41, v_num=18, train_loss_step=0.313]Epoch 0:  34%|███▍      | 130/380 [00:19<00:36,  6.82it/s, loss=0.41, v_num=18, train_loss_step=0.313]Epoch 0:  34%|███▍      | 130/380 [00:19<00:36,  6.82it/s, loss=0.41, v_num=18, train_loss_step=0.326]Epoch 0:  34%|███▍      | 131/380 [00:19<00:36,  6.83it/s, loss=0.41, v_num=18, train_loss_step=0.326]Epoch 0:  34%|███▍      | 131/380 [00:19<00:36,  6.83it/s, loss=0.433, v_num=18, train_loss_step=0.797]Epoch 0:  35%|███▍      | 132/380 [00:19<00:36,  6.83it/s, loss=0.433, v_num=18, train_loss_step=0.797]Epoch 0:  35%|███▍      | 132/380 [00:19<00:36,  6.83it/s, loss=0.461, v_num=18, train_loss_step=0.895]Epoch 0:  35%|███▌      | 133/380 [00:19<00:36,  6.84it/s, loss=0.461, v_num=18, train_loss_step=0.895]Epoch 0:  35%|███▌      | 133/380 [00:19<00:36,  6.84it/s, loss=0.465, v_num=18, train_loss_step=0.390]Epoch 0:  35%|███▌      | 134/380 [00:19<00:36,  6.83it/s, loss=0.465, v_num=18, train_loss_step=0.390]Epoch 0:  35%|███▌      | 134/380 [00:19<00:36,  6.83it/s, loss=0.466, v_num=18, train_loss_step=0.346]Epoch 0:  36%|███▌      | 135/380 [00:19<00:35,  6.83it/s, loss=0.466, v_num=18, train_loss_step=0.346]Epoch 0:  36%|███▌      | 135/380 [00:19<00:35,  6.83it/s, loss=0.452, v_num=18, train_loss_step=0.395]Epoch 0:  36%|███▌      | 136/380 [00:20<00:35,  6.84it/s, loss=0.452, v_num=18, train_loss_step=0.395]Epoch 0:  36%|███▌      | 136/380 [00:20<00:35,  6.84it/s, loss=0.443, v_num=18, train_loss_step=0.313]Epoch 0:  36%|███▌      | 137/380 [00:20<00:35,  6.84it/s, loss=0.443, v_num=18, train_loss_step=0.313]Epoch 0:  36%|███▌      | 137/380 [00:20<00:35,  6.84it/s, loss=0.429, v_num=18, train_loss_step=0.313]Epoch 0:  36%|███▋      | 138/380 [00:20<00:35,  6.85it/s, loss=0.429, v_num=18, train_loss_step=0.313]Epoch 0:  36%|███▋      | 138/380 [00:20<00:35,  6.85it/s, loss=0.428, v_num=18, train_loss_step=0.383]Epoch 0:  37%|███▋      | 139/380 [00:20<00:35,  6.85it/s, loss=0.428, v_num=18, train_loss_step=0.383]Epoch 0:  37%|███▋      | 139/380 [00:20<00:35,  6.85it/s, loss=0.414, v_num=18, train_loss_step=0.416]Epoch 0:  37%|███▋      | 140/380 [00:20<00:35,  6.85it/s, loss=0.414, v_num=18, train_loss_step=0.416]Epoch 0:  37%|███▋      | 140/380 [00:20<00:35,  6.85it/s, loss=0.41, v_num=18, train_loss_step=0.324] Epoch 0:  37%|███▋      | 141/380 [00:20<00:34,  6.85it/s, loss=0.41, v_num=18, train_loss_step=0.324]Epoch 0:  37%|███▋      | 141/380 [00:20<00:34,  6.85it/s, loss=0.402, v_num=18, train_loss_step=0.319]Epoch 0:  37%|███▋      | 142/380 [00:20<00:34,  6.85it/s, loss=0.402, v_num=18, train_loss_step=0.319]Epoch 0:  37%|███▋      | 142/380 [00:20<00:34,  6.85it/s, loss=0.393, v_num=18, train_loss_step=0.412]Epoch 0:  38%|███▊      | 143/380 [00:21<00:34,  6.82it/s, loss=0.393, v_num=18, train_loss_step=0.412]Epoch 0:  38%|███▊      | 143/380 [00:21<00:34,  6.82it/s, loss=0.395, v_num=18, train_loss_step=0.349]Epoch 0:  38%|███▊      | 144/380 [00:21<00:34,  6.81it/s, loss=0.395, v_num=18, train_loss_step=0.349]Epoch 0:  38%|███▊      | 144/380 [00:21<00:34,  6.81it/s, loss=0.407, v_num=18, train_loss_step=0.556]Epoch 0:  38%|███▊      | 145/380 [00:21<00:34,  6.82it/s, loss=0.407, v_num=18, train_loss_step=0.556]Epoch 0:  38%|███▊      | 145/380 [00:21<00:34,  6.82it/s, loss=0.414, v_num=18, train_loss_step=0.438]Epoch 0:  38%|███▊      | 146/380 [00:21<00:34,  6.82it/s, loss=0.414, v_num=18, train_loss_step=0.438]Epoch 0:  38%|███▊      | 146/380 [00:21<00:34,  6.82it/s, loss=0.417, v_num=18, train_loss_step=0.418]Epoch 0:  39%|███▊      | 147/380 [00:21<00:34,  6.82it/s, loss=0.417, v_num=18, train_loss_step=0.418]Epoch 0:  39%|███▊      | 147/380 [00:21<00:34,  6.82it/s, loss=0.42, v_num=18, train_loss_step=0.388] Epoch 0:  39%|███▉      | 148/380 [00:21<00:33,  6.83it/s, loss=0.42, v_num=18, train_loss_step=0.388]Epoch 0:  39%|███▉      | 148/380 [00:21<00:33,  6.83it/s, loss=0.429, v_num=18, train_loss_step=0.489]Epoch 0:  39%|███▉      | 149/380 [00:22<00:33,  6.81it/s, loss=0.429, v_num=18, train_loss_step=0.489]Epoch 0:  39%|███▉      | 149/380 [00:22<00:33,  6.81it/s, loss=0.429, v_num=18, train_loss_step=0.313]Epoch 0:  39%|███▉      | 150/380 [00:22<00:33,  6.81it/s, loss=0.429, v_num=18, train_loss_step=0.313]Epoch 0:  39%|███▉      | 150/380 [00:22<00:33,  6.81it/s, loss=0.434, v_num=18, train_loss_step=0.433]Epoch 0:  40%|███▉      | 151/380 [00:22<00:33,  6.82it/s, loss=0.434, v_num=18, train_loss_step=0.433]Epoch 0:  40%|███▉      | 151/380 [00:22<00:33,  6.82it/s, loss=0.413, v_num=18, train_loss_step=0.377]Epoch 0:  40%|████      | 152/380 [00:22<00:33,  6.82it/s, loss=0.413, v_num=18, train_loss_step=0.377]Epoch 0:  40%|████      | 152/380 [00:22<00:33,  6.82it/s, loss=0.388, v_num=18, train_loss_step=0.381]Epoch 0:  40%|████      | 153/380 [00:22<00:33,  6.82it/s, loss=0.388, v_num=18, train_loss_step=0.381]Epoch 0:  40%|████      | 153/380 [00:22<00:33,  6.82it/s, loss=0.385, v_num=18, train_loss_step=0.325]Epoch 0:  41%|████      | 154/380 [00:22<00:33,  6.82it/s, loss=0.385, v_num=18, train_loss_step=0.325]Epoch 0:  41%|████      | 154/380 [00:22<00:33,  6.82it/s, loss=0.383, v_num=18, train_loss_step=0.313]Epoch 0:  41%|████      | 155/380 [00:22<00:33,  6.82it/s, loss=0.383, v_num=18, train_loss_step=0.313]Epoch 0:  41%|████      | 155/380 [00:22<00:33,  6.81it/s, loss=0.382, v_num=18, train_loss_step=0.381]Epoch 0:  41%|████      | 156/380 [00:23<00:32,  6.81it/s, loss=0.382, v_num=18, train_loss_step=0.381]Epoch 0:  41%|████      | 156/380 [00:23<00:32,  6.81it/s, loss=0.398, v_num=18, train_loss_step=0.631]Epoch 0:  41%|████▏     | 157/380 [00:23<00:32,  6.82it/s, loss=0.398, v_num=18, train_loss_step=0.631]Epoch 0:  41%|████▏     | 157/380 [00:23<00:32,  6.82it/s, loss=0.406, v_num=18, train_loss_step=0.464]Epoch 0:  42%|████▏     | 158/380 [00:23<00:32,  6.82it/s, loss=0.406, v_num=18, train_loss_step=0.464]Epoch 0:  42%|████▏     | 158/380 [00:23<00:32,  6.82it/s, loss=0.403, v_num=18, train_loss_step=0.324]Epoch 0:  42%|████▏     | 159/380 [00:23<00:32,  6.82it/s, loss=0.403, v_num=18, train_loss_step=0.324]Epoch 0:  42%|████▏     | 159/380 [00:23<00:32,  6.82it/s, loss=0.412, v_num=18, train_loss_step=0.613]Epoch 0:  42%|████▏     | 160/380 [00:23<00:32,  6.82it/s, loss=0.412, v_num=18, train_loss_step=0.613]Epoch 0:  42%|████▏     | 160/380 [00:23<00:32,  6.82it/s, loss=0.419, v_num=18, train_loss_step=0.463]Epoch 0:  42%|████▏     | 161/380 [00:23<00:32,  6.83it/s, loss=0.419, v_num=18, train_loss_step=0.463]Epoch 0:  42%|████▏     | 161/380 [00:23<00:32,  6.83it/s, loss=0.42, v_num=18, train_loss_step=0.327] Epoch 0:  43%|████▎     | 162/380 [00:23<00:31,  6.83it/s, loss=0.42, v_num=18, train_loss_step=0.327]Epoch 0:  43%|████▎     | 162/380 [00:23<00:31,  6.83it/s, loss=0.429, v_num=18, train_loss_step=0.592]Epoch 0:  43%|████▎     | 163/380 [00:23<00:31,  6.84it/s, loss=0.429, v_num=18, train_loss_step=0.592]Epoch 0:  43%|████▎     | 163/380 [00:23<00:31,  6.84it/s, loss=0.434, v_num=18, train_loss_step=0.452]Epoch 0:  43%|████▎     | 164/380 [00:24<00:31,  6.84it/s, loss=0.434, v_num=18, train_loss_step=0.452]Epoch 0:  43%|████▎     | 164/380 [00:24<00:31,  6.84it/s, loss=0.429, v_num=18, train_loss_step=0.452]Epoch 0:  43%|████▎     | 165/380 [00:24<00:31,  6.85it/s, loss=0.429, v_num=18, train_loss_step=0.452]Epoch 0:  43%|████▎     | 165/380 [00:24<00:31,  6.85it/s, loss=0.435, v_num=18, train_loss_step=0.560]Epoch 0:  44%|████▎     | 166/380 [00:24<00:31,  6.84it/s, loss=0.435, v_num=18, train_loss_step=0.560]Epoch 0:  44%|████▎     | 166/380 [00:24<00:31,  6.84it/s, loss=0.44, v_num=18, train_loss_step=0.522] Epoch 0:  44%|████▍     | 167/380 [00:24<00:31,  6.84it/s, loss=0.44, v_num=18, train_loss_step=0.522]Epoch 0:  44%|████▍     | 167/380 [00:24<00:31,  6.84it/s, loss=0.436, v_num=18, train_loss_step=0.313]Epoch 0:  44%|████▍     | 168/380 [00:24<00:31,  6.84it/s, loss=0.436, v_num=18, train_loss_step=0.313]Epoch 0:  44%|████▍     | 168/380 [00:24<00:31,  6.84it/s, loss=0.429, v_num=18, train_loss_step=0.349]Epoch 0:  44%|████▍     | 169/380 [00:24<00:30,  6.84it/s, loss=0.429, v_num=18, train_loss_step=0.349]Epoch 0:  44%|████▍     | 169/380 [00:24<00:30,  6.84it/s, loss=0.432, v_num=18, train_loss_step=0.360]Epoch 0:  45%|████▍     | 170/380 [00:25<00:30,  6.84it/s, loss=0.432, v_num=18, train_loss_step=0.360]Epoch 0:  45%|████▍     | 170/380 [00:25<00:30,  6.84it/s, loss=0.433, v_num=18, train_loss_step=0.470]Epoch 0:  45%|████▌     | 171/380 [00:25<00:30,  6.84it/s, loss=0.433, v_num=18, train_loss_step=0.470]Epoch 0:  45%|████▌     | 171/380 [00:25<00:30,  6.84it/s, loss=0.435, v_num=18, train_loss_step=0.408]Epoch 0:  45%|████▌     | 172/380 [00:25<00:30,  6.85it/s, loss=0.435, v_num=18, train_loss_step=0.408]Epoch 0:  45%|████▌     | 172/380 [00:25<00:30,  6.85it/s, loss=0.432, v_num=18, train_loss_step=0.313]Epoch 0:  46%|████▌     | 173/380 [00:25<00:30,  6.85it/s, loss=0.432, v_num=18, train_loss_step=0.313]Epoch 0:  46%|████▌     | 173/380 [00:25<00:30,  6.85it/s, loss=0.452, v_num=18, train_loss_step=0.731]Epoch 0:  46%|████▌     | 174/380 [00:25<00:30,  6.85it/s, loss=0.452, v_num=18, train_loss_step=0.731]Epoch 0:  46%|████▌     | 174/380 [00:25<00:30,  6.85it/s, loss=0.453, v_num=18, train_loss_step=0.337]Epoch 0:  46%|████▌     | 175/380 [00:25<00:29,  6.86it/s, loss=0.453, v_num=18, train_loss_step=0.337]Epoch 0:  46%|████▌     | 175/380 [00:25<00:29,  6.86it/s, loss=0.452, v_num=18, train_loss_step=0.360]Epoch 0:  46%|████▋     | 176/380 [00:25<00:29,  6.86it/s, loss=0.452, v_num=18, train_loss_step=0.360]Epoch 0:  46%|████▋     | 176/380 [00:25<00:29,  6.86it/s, loss=0.44, v_num=18, train_loss_step=0.389] Epoch 0:  47%|████▋     | 177/380 [00:25<00:29,  6.86it/s, loss=0.44, v_num=18, train_loss_step=0.389]Epoch 0:  47%|████▋     | 177/380 [00:25<00:29,  6.86it/s, loss=0.432, v_num=18, train_loss_step=0.313]Epoch 0:  47%|████▋     | 178/380 [00:26<00:29,  6.86it/s, loss=0.432, v_num=18, train_loss_step=0.313]Epoch 0:  47%|████▋     | 178/380 [00:26<00:29,  6.86it/s, loss=0.447, v_num=18, train_loss_step=0.625]Epoch 0:  47%|████▋     | 179/380 [00:26<00:29,  6.86it/s, loss=0.447, v_num=18, train_loss_step=0.625]Epoch 0:  47%|████▋     | 179/380 [00:26<00:29,  6.86it/s, loss=0.433, v_num=18, train_loss_step=0.324]Epoch 0:  47%|████▋     | 180/380 [00:26<00:29,  6.86it/s, loss=0.433, v_num=18, train_loss_step=0.324]Epoch 0:  47%|████▋     | 180/380 [00:26<00:29,  6.86it/s, loss=0.433, v_num=18, train_loss_step=0.472]Epoch 0:  48%|████▊     | 181/380 [00:26<00:29,  6.86it/s, loss=0.433, v_num=18, train_loss_step=0.472]Epoch 0:  48%|████▊     | 181/380 [00:26<00:29,  6.86it/s, loss=0.434, v_num=18, train_loss_step=0.335]Epoch 0:  48%|████▊     | 182/380 [00:26<00:28,  6.86it/s, loss=0.434, v_num=18, train_loss_step=0.335]Epoch 0:  48%|████▊     | 182/380 [00:26<00:28,  6.86it/s, loss=0.42, v_num=18, train_loss_step=0.313] Epoch 0:  48%|████▊     | 183/380 [00:26<00:28,  6.86it/s, loss=0.42, v_num=18, train_loss_step=0.313]Epoch 0:  48%|████▊     | 183/380 [00:26<00:28,  6.86it/s, loss=0.419, v_num=18, train_loss_step=0.441]Epoch 0:  48%|████▊     | 184/380 [00:26<00:28,  6.86it/s, loss=0.419, v_num=18, train_loss_step=0.441]Epoch 0:  48%|████▊     | 184/380 [00:26<00:28,  6.86it/s, loss=0.414, v_num=18, train_loss_step=0.352]Epoch 0:  49%|████▊     | 185/380 [00:27<00:28,  6.86it/s, loss=0.414, v_num=18, train_loss_step=0.352]Epoch 0:  49%|████▊     | 185/380 [00:27<00:28,  6.86it/s, loss=0.418, v_num=18, train_loss_step=0.624]Epoch 0:  49%|████▉     | 186/380 [00:27<00:28,  6.86it/s, loss=0.418, v_num=18, train_loss_step=0.624]Epoch 0:  49%|████▉     | 186/380 [00:27<00:28,  6.86it/s, loss=0.433, v_num=18, train_loss_step=0.823]Epoch 0:  49%|████▉     | 187/380 [00:27<00:28,  6.86it/s, loss=0.433, v_num=18, train_loss_step=0.823]Epoch 0:  49%|████▉     | 187/380 [00:27<00:28,  6.86it/s, loss=0.439, v_num=18, train_loss_step=0.440]Epoch 0:  49%|████▉     | 188/380 [00:27<00:27,  6.86it/s, loss=0.439, v_num=18, train_loss_step=0.440]Epoch 0:  49%|████▉     | 188/380 [00:27<00:27,  6.86it/s, loss=0.437, v_num=18, train_loss_step=0.314]Epoch 0:  50%|████▉     | 189/380 [00:27<00:27,  6.86it/s, loss=0.437, v_num=18, train_loss_step=0.314]Epoch 0:  50%|████▉     | 189/380 [00:27<00:27,  6.86it/s, loss=0.462, v_num=18, train_loss_step=0.848]Epoch 0:  50%|█████     | 190/380 [00:27<00:27,  6.87it/s, loss=0.462, v_num=18, train_loss_step=0.848]Epoch 0:  50%|█████     | 190/380 [00:27<00:27,  6.87it/s, loss=0.454, v_num=18, train_loss_step=0.313]Epoch 0:  50%|█████     | 191/380 [00:27<00:27,  6.87it/s, loss=0.454, v_num=18, train_loss_step=0.313]Epoch 0:  50%|█████     | 191/380 [00:27<00:27,  6.87it/s, loss=0.456, v_num=18, train_loss_step=0.456]Epoch 0:  51%|█████     | 192/380 [00:28<00:27,  6.83it/s, loss=0.456, v_num=18, train_loss_step=0.456]Epoch 0:  51%|█████     | 192/380 [00:28<00:27,  6.83it/s, loss=0.468, v_num=18, train_loss_step=0.559]Epoch 0:  51%|█████     | 193/380 [00:28<00:27,  6.83it/s, loss=0.468, v_num=18, train_loss_step=0.559]Epoch 0:  51%|█████     | 193/380 [00:28<00:27,  6.83it/s, loss=0.448, v_num=18, train_loss_step=0.322]Epoch 0:  51%|█████     | 194/380 [00:28<00:27,  6.83it/s, loss=0.448, v_num=18, train_loss_step=0.322]Epoch 0:  51%|█████     | 194/380 [00:28<00:27,  6.83it/s, loss=0.473, v_num=18, train_loss_step=0.833]Epoch 0:  51%|█████▏    | 195/380 [00:28<00:27,  6.84it/s, loss=0.473, v_num=18, train_loss_step=0.833]Epoch 0:  51%|█████▏    | 195/380 [00:28<00:27,  6.84it/s, loss=0.476, v_num=18, train_loss_step=0.418]Epoch 0:  52%|█████▏    | 196/380 [00:28<00:26,  6.84it/s, loss=0.476, v_num=18, train_loss_step=0.418]Epoch 0:  52%|█████▏    | 196/380 [00:28<00:26,  6.84it/s, loss=0.477, v_num=18, train_loss_step=0.417]Epoch 0:  52%|█████▏    | 197/380 [00:28<00:26,  6.84it/s, loss=0.477, v_num=18, train_loss_step=0.417]Epoch 0:  52%|█████▏    | 197/380 [00:28<00:26,  6.84it/s, loss=0.477, v_num=18, train_loss_step=0.313]Epoch 0:  52%|█████▏    | 198/380 [00:29<00:26,  6.84it/s, loss=0.477, v_num=18, train_loss_step=0.313]Epoch 0:  52%|█████▏    | 198/380 [00:29<00:26,  6.84it/s, loss=0.465, v_num=18, train_loss_step=0.378]Epoch 0:  52%|█████▏    | 199/380 [00:29<00:26,  6.84it/s, loss=0.465, v_num=18, train_loss_step=0.378]Epoch 0:  52%|█████▏    | 199/380 [00:29<00:26,  6.84it/s, loss=0.469, v_num=18, train_loss_step=0.416]Epoch 0:  53%|█████▎    | 200/380 [00:29<00:26,  6.84it/s, loss=0.469, v_num=18, train_loss_step=0.416]Epoch 0:  53%|█████▎    | 200/380 [00:29<00:26,  6.84it/s, loss=0.464, v_num=18, train_loss_step=0.370]Epoch 0:  53%|█████▎    | 201/380 [00:29<00:26,  6.84it/s, loss=0.464, v_num=18, train_loss_step=0.370]Epoch 0:  53%|█████▎    | 201/380 [00:29<00:26,  6.84it/s, loss=0.464, v_num=18, train_loss_step=0.329]Epoch 0:  53%|█████▎    | 202/380 [00:29<00:26,  6.83it/s, loss=0.464, v_num=18, train_loss_step=0.329]Epoch 0:  53%|█████▎    | 202/380 [00:29<00:26,  6.83it/s, loss=0.464, v_num=18, train_loss_step=0.313]Epoch 0:  53%|█████▎    | 203/380 [00:29<00:25,  6.84it/s, loss=0.464, v_num=18, train_loss_step=0.313]Epoch 0:  53%|█████▎    | 203/380 [00:29<00:25,  6.84it/s, loss=0.461, v_num=18, train_loss_step=0.387]Epoch 0:  54%|█████▎    | 204/380 [00:29<00:25,  6.84it/s, loss=0.461, v_num=18, train_loss_step=0.387]Epoch 0:  54%|█████▎    | 204/380 [00:29<00:25,  6.84it/s, loss=0.459, v_num=18, train_loss_step=0.313]Epoch 0:  54%|█████▍    | 205/380 [00:30<00:25,  6.84it/s, loss=0.459, v_num=18, train_loss_step=0.313]Epoch 0:  54%|█████▍    | 205/380 [00:30<00:25,  6.84it/s, loss=0.444, v_num=18, train_loss_step=0.313]Epoch 0:  54%|█████▍    | 206/380 [00:30<00:25,  6.83it/s, loss=0.444, v_num=18, train_loss_step=0.313]Epoch 0:  54%|█████▍    | 206/380 [00:30<00:25,  6.83it/s, loss=0.423, v_num=18, train_loss_step=0.402]Epoch 0:  54%|█████▍    | 207/380 [00:30<00:25,  6.83it/s, loss=0.423, v_num=18, train_loss_step=0.402]Epoch 0:  54%|█████▍    | 207/380 [00:30<00:25,  6.83it/s, loss=0.421, v_num=18, train_loss_step=0.413]Epoch 0:  55%|█████▍    | 208/380 [00:30<00:25,  6.83it/s, loss=0.421, v_num=18, train_loss_step=0.413]Epoch 0:  55%|█████▍    | 208/380 [00:30<00:25,  6.83it/s, loss=0.425, v_num=18, train_loss_step=0.378]Epoch 0:  55%|█████▌    | 209/380 [00:30<00:25,  6.83it/s, loss=0.425, v_num=18, train_loss_step=0.378]Epoch 0:  55%|█████▌    | 209/380 [00:30<00:25,  6.83it/s, loss=0.401, v_num=18, train_loss_step=0.374]Epoch 0:  55%|█████▌    | 210/380 [00:30<00:24,  6.83it/s, loss=0.401, v_num=18, train_loss_step=0.374]Epoch 0:  55%|█████▌    | 210/380 [00:30<00:24,  6.83it/s, loss=0.404, v_num=18, train_loss_step=0.376]Epoch 0:  56%|█████▌    | 211/380 [00:31<00:24,  6.83it/s, loss=0.404, v_num=18, train_loss_step=0.376]Epoch 0:  56%|█████▌    | 211/380 [00:31<00:24,  6.83it/s, loss=0.415, v_num=18, train_loss_step=0.678]Epoch 0:  56%|█████▌    | 212/380 [00:31<00:24,  6.83it/s, loss=0.415, v_num=18, train_loss_step=0.678]Epoch 0:  56%|█████▌    | 212/380 [00:31<00:24,  6.83it/s, loss=0.413, v_num=18, train_loss_step=0.518]Epoch 0:  56%|█████▌    | 213/380 [00:31<00:24,  6.83it/s, loss=0.413, v_num=18, train_loss_step=0.518]Epoch 0:  56%|█████▌    | 213/380 [00:31<00:24,  6.83it/s, loss=0.42, v_num=18, train_loss_step=0.457] Epoch 0:  56%|█████▋    | 214/380 [00:31<00:24,  6.84it/s, loss=0.42, v_num=18, train_loss_step=0.457]Epoch 0:  56%|█████▋    | 214/380 [00:31<00:24,  6.84it/s, loss=0.394, v_num=18, train_loss_step=0.313]Epoch 0:  57%|█████▋    | 215/380 [00:31<00:24,  6.85it/s, loss=0.394, v_num=18, train_loss_step=0.313]Epoch 0:  57%|█████▋    | 215/380 [00:31<00:24,  6.85it/s, loss=0.409, v_num=18, train_loss_step=0.711]Epoch 0:  57%|█████▋    | 216/380 [00:31<00:23,  6.84it/s, loss=0.409, v_num=18, train_loss_step=0.711]Epoch 0:  57%|█████▋    | 216/380 [00:31<00:23,  6.84it/s, loss=0.406, v_num=18, train_loss_step=0.366]Epoch 0:  57%|█████▋    | 217/380 [00:31<00:23,  6.85it/s, loss=0.406, v_num=18, train_loss_step=0.366]Epoch 0:  57%|█████▋    | 217/380 [00:31<00:23,  6.85it/s, loss=0.406, v_num=18, train_loss_step=0.313]Epoch 0:  57%|█████▋    | 218/380 [00:31<00:23,  6.86it/s, loss=0.406, v_num=18, train_loss_step=0.313]Epoch 0:  57%|█████▋    | 218/380 [00:31<00:23,  6.86it/s, loss=0.403, v_num=18, train_loss_step=0.313]Epoch 0:  58%|█████▊    | 219/380 [00:32<00:23,  6.86it/s, loss=0.403, v_num=18, train_loss_step=0.313]Epoch 0:  58%|█████▊    | 219/380 [00:32<00:23,  6.86it/s, loss=0.398, v_num=18, train_loss_step=0.313]Epoch 0:  58%|█████▊    | 220/380 [00:32<00:23,  6.85it/s, loss=0.398, v_num=18, train_loss_step=0.313]Epoch 0:  58%|█████▊    | 220/380 [00:32<00:23,  6.85it/s, loss=0.395, v_num=18, train_loss_step=0.313]Epoch 0:  58%|█████▊    | 221/380 [00:32<00:23,  6.85it/s, loss=0.395, v_num=18, train_loss_step=0.313]Epoch 0:  58%|█████▊    | 221/380 [00:32<00:23,  6.85it/s, loss=0.394, v_num=18, train_loss_step=0.320]Epoch 0:  58%|█████▊    | 222/380 [00:32<00:23,  6.86it/s, loss=0.394, v_num=18, train_loss_step=0.320]Epoch 0:  58%|█████▊    | 222/380 [00:32<00:23,  6.86it/s, loss=0.409, v_num=18, train_loss_step=0.609]Epoch 0:  59%|█████▊    | 223/380 [00:32<00:22,  6.86it/s, loss=0.409, v_num=18, train_loss_step=0.609]Epoch 0:  59%|█████▊    | 223/380 [00:32<00:22,  6.86it/s, loss=0.413, v_num=18, train_loss_step=0.457]Epoch 0:  59%|█████▉    | 224/380 [00:32<00:22,  6.87it/s, loss=0.413, v_num=18, train_loss_step=0.457]Epoch 0:  59%|█████▉    | 224/380 [00:32<00:22,  6.87it/s, loss=0.423, v_num=18, train_loss_step=0.511]Epoch 0:  59%|█████▉    | 225/380 [00:32<00:22,  6.86it/s, loss=0.423, v_num=18, train_loss_step=0.511]Epoch 0:  59%|█████▉    | 225/380 [00:32<00:22,  6.86it/s, loss=0.423, v_num=18, train_loss_step=0.313]Epoch 0:  59%|█████▉    | 226/380 [00:33<00:22,  6.86it/s, loss=0.423, v_num=18, train_loss_step=0.313]Epoch 0:  59%|█████▉    | 226/380 [00:33<00:22,  6.86it/s, loss=0.418, v_num=18, train_loss_step=0.313]Epoch 0:  60%|█████▉    | 227/380 [00:33<00:22,  6.86it/s, loss=0.418, v_num=18, train_loss_step=0.313]Epoch 0:  60%|█████▉    | 227/380 [00:33<00:22,  6.86it/s, loss=0.413, v_num=18, train_loss_step=0.313]Epoch 0:  60%|██████    | 228/380 [00:33<00:22,  6.86it/s, loss=0.413, v_num=18, train_loss_step=0.313]Epoch 0:  60%|██████    | 228/380 [00:33<00:22,  6.86it/s, loss=0.428, v_num=18, train_loss_step=0.670]Epoch 0:  60%|██████    | 229/380 [00:33<00:22,  6.86it/s, loss=0.428, v_num=18, train_loss_step=0.670]Epoch 0:  60%|██████    | 229/380 [00:33<00:22,  6.86it/s, loss=0.425, v_num=18, train_loss_step=0.313]Epoch 0:  61%|██████    | 230/380 [00:33<00:21,  6.87it/s, loss=0.425, v_num=18, train_loss_step=0.313]Epoch 0:  61%|██████    | 230/380 [00:33<00:21,  6.87it/s, loss=0.454, v_num=18, train_loss_step=0.957]Epoch 0:  61%|██████    | 231/380 [00:33<00:21,  6.87it/s, loss=0.454, v_num=18, train_loss_step=0.957]Epoch 0:  61%|██████    | 231/380 [00:33<00:21,  6.87it/s, loss=0.464, v_num=18, train_loss_step=0.882]Epoch 0:  61%|██████    | 232/380 [00:33<00:21,  6.88it/s, loss=0.464, v_num=18, train_loss_step=0.882]Epoch 0:  61%|██████    | 232/380 [00:33<00:21,  6.88it/s, loss=0.456, v_num=18, train_loss_step=0.367]Epoch 0:  61%|██████▏   | 233/380 [00:34<00:21,  6.88it/s, loss=0.456, v_num=18, train_loss_step=0.367]Epoch 0:  61%|██████▏   | 233/380 [00:34<00:21,  6.88it/s, loss=0.459, v_num=18, train_loss_step=0.506]Epoch 0:  62%|██████▏   | 234/380 [00:34<00:21,  6.88it/s, loss=0.459, v_num=18, train_loss_step=0.506]Epoch 0:  62%|██████▏   | 234/380 [00:34<00:21,  6.88it/s, loss=0.477, v_num=18, train_loss_step=0.672]Epoch 0:  62%|██████▏   | 235/380 [00:34<00:21,  6.88it/s, loss=0.477, v_num=18, train_loss_step=0.672]Epoch 0:  62%|██████▏   | 235/380 [00:34<00:21,  6.88it/s, loss=0.457, v_num=18, train_loss_step=0.313]Epoch 0:  62%|██████▏   | 236/380 [00:34<00:20,  6.89it/s, loss=0.457, v_num=18, train_loss_step=0.313]Epoch 0:  62%|██████▏   | 236/380 [00:34<00:20,  6.89it/s, loss=0.461, v_num=18, train_loss_step=0.442]Epoch 0:  62%|██████▏   | 237/380 [00:34<00:20,  6.89it/s, loss=0.461, v_num=18, train_loss_step=0.442]Epoch 0:  62%|██████▏   | 237/380 [00:34<00:20,  6.89it/s, loss=0.477, v_num=18, train_loss_step=0.636]Epoch 0:  63%|██████▎   | 238/380 [00:34<00:20,  6.89it/s, loss=0.477, v_num=18, train_loss_step=0.636]Epoch 0:  63%|██████▎   | 238/380 [00:34<00:20,  6.89it/s, loss=0.481, v_num=18, train_loss_step=0.395]Epoch 0:  63%|██████▎   | 239/380 [00:34<00:20,  6.89it/s, loss=0.481, v_num=18, train_loss_step=0.395]Epoch 0:  63%|██████▎   | 239/380 [00:34<00:20,  6.89it/s, loss=0.482, v_num=18, train_loss_step=0.347]Epoch 0:  63%|██████▎   | 240/380 [00:34<00:20,  6.90it/s, loss=0.482, v_num=18, train_loss_step=0.347]Epoch 0:  63%|██████▎   | 240/380 [00:34<00:20,  6.90it/s, loss=0.482, v_num=18, train_loss_step=0.313]Epoch 0:  63%|██████▎   | 241/380 [00:35<00:20,  6.90it/s, loss=0.482, v_num=18, train_loss_step=0.313]Epoch 0:  63%|██████▎   | 241/380 [00:35<00:20,  6.90it/s, loss=0.49, v_num=18, train_loss_step=0.474] Epoch 0:  64%|██████▎   | 242/380 [00:35<00:19,  6.90it/s, loss=0.49, v_num=18, train_loss_step=0.474]Epoch 0:  64%|██████▎   | 242/380 [00:35<00:19,  6.90it/s, loss=0.495, v_num=18, train_loss_step=0.708]Epoch 0:  64%|██████▍   | 243/380 [00:35<00:19,  6.90it/s, loss=0.495, v_num=18, train_loss_step=0.708]Epoch 0:  64%|██████▍   | 243/380 [00:35<00:19,  6.90it/s, loss=0.495, v_num=18, train_loss_step=0.448]Epoch 0:  64%|██████▍   | 244/380 [00:35<00:19,  6.90it/s, loss=0.495, v_num=18, train_loss_step=0.448]Epoch 0:  64%|██████▍   | 244/380 [00:35<00:19,  6.90it/s, loss=0.485, v_num=18, train_loss_step=0.313]Epoch 0:  64%|██████▍   | 245/380 [00:35<00:19,  6.91it/s, loss=0.485, v_num=18, train_loss_step=0.313]Epoch 0:  64%|██████▍   | 245/380 [00:35<00:19,  6.91it/s, loss=0.485, v_num=18, train_loss_step=0.313]Epoch 0:  65%|██████▍   | 246/380 [00:35<00:19,  6.91it/s, loss=0.485, v_num=18, train_loss_step=0.313]Epoch 0:  65%|██████▍   | 246/380 [00:35<00:19,  6.91it/s, loss=0.485, v_num=18, train_loss_step=0.313]Epoch 0:  65%|██████▌   | 247/380 [00:35<00:19,  6.90it/s, loss=0.485, v_num=18, train_loss_step=0.313]Epoch 0:  65%|██████▌   | 247/380 [00:35<00:19,  6.90it/s, loss=0.49, v_num=18, train_loss_step=0.411] Epoch 0:  65%|██████▌   | 248/380 [00:36<00:19,  6.90it/s, loss=0.49, v_num=18, train_loss_step=0.411]Epoch 0:  65%|██████▌   | 248/380 [00:36<00:19,  6.90it/s, loss=0.472, v_num=18, train_loss_step=0.313]Epoch 0:  66%|██████▌   | 249/380 [00:36<00:18,  6.90it/s, loss=0.472, v_num=18, train_loss_step=0.313]Epoch 0:  66%|██████▌   | 249/380 [00:36<00:18,  6.90it/s, loss=0.477, v_num=18, train_loss_step=0.413]Epoch 0:  66%|██████▌   | 250/380 [00:36<00:18,  6.91it/s, loss=0.477, v_num=18, train_loss_step=0.413]Epoch 0:  66%|██████▌   | 250/380 [00:36<00:18,  6.91it/s, loss=0.463, v_num=18, train_loss_step=0.676]Epoch 0:  66%|██████▌   | 251/380 [00:36<00:18,  6.91it/s, loss=0.463, v_num=18, train_loss_step=0.676]Epoch 0:  66%|██████▌   | 251/380 [00:36<00:18,  6.91it/s, loss=0.435, v_num=18, train_loss_step=0.333]Epoch 0:  66%|██████▋   | 252/380 [00:36<00:18,  6.91it/s, loss=0.435, v_num=18, train_loss_step=0.333]Epoch 0:  66%|██████▋   | 252/380 [00:36<00:18,  6.91it/s, loss=0.433, v_num=18, train_loss_step=0.313]Epoch 0:  67%|██████▋   | 253/380 [00:36<00:18,  6.91it/s, loss=0.433, v_num=18, train_loss_step=0.313]Epoch 0:  67%|██████▋   | 253/380 [00:36<00:18,  6.91it/s, loss=0.426, v_num=18, train_loss_step=0.372]Epoch 0:  67%|██████▋   | 254/380 [00:36<00:18,  6.91it/s, loss=0.426, v_num=18, train_loss_step=0.372]Epoch 0:  67%|██████▋   | 254/380 [00:36<00:18,  6.91it/s, loss=0.409, v_num=18, train_loss_step=0.340]Epoch 0:  67%|██████▋   | 255/380 [00:37<00:18,  6.91it/s, loss=0.409, v_num=18, train_loss_step=0.340]Epoch 0:  67%|██████▋   | 255/380 [00:37<00:18,  6.91it/s, loss=0.428, v_num=18, train_loss_step=0.686]Epoch 0:  67%|██████▋   | 256/380 [00:37<00:17,  6.91it/s, loss=0.428, v_num=18, train_loss_step=0.686]Epoch 0:  67%|██████▋   | 256/380 [00:37<00:17,  6.91it/s, loss=0.422, v_num=18, train_loss_step=0.333]Epoch 0:  68%|██████▊   | 257/380 [00:37<00:17,  6.91it/s, loss=0.422, v_num=18, train_loss_step=0.333]Epoch 0:  68%|██████▊   | 257/380 [00:37<00:17,  6.91it/s, loss=0.412, v_num=18, train_loss_step=0.418]Epoch 0:  68%|██████▊   | 258/380 [00:37<00:17,  6.91it/s, loss=0.412, v_num=18, train_loss_step=0.418]Epoch 0:  68%|██████▊   | 258/380 [00:37<00:17,  6.91it/s, loss=0.41, v_num=18, train_loss_step=0.355] Epoch 0:  68%|██████▊   | 259/380 [00:37<00:17,  6.91it/s, loss=0.41, v_num=18, train_loss_step=0.355]Epoch 0:  68%|██████▊   | 259/380 [00:37<00:17,  6.91it/s, loss=0.41, v_num=18, train_loss_step=0.361]Epoch 0:  68%|██████▊   | 260/380 [00:37<00:17,  6.91it/s, loss=0.41, v_num=18, train_loss_step=0.361]Epoch 0:  68%|██████▊   | 260/380 [00:37<00:17,  6.91it/s, loss=0.427, v_num=18, train_loss_step=0.637]Epoch 0:  69%|██████▊   | 261/380 [00:37<00:17,  6.91it/s, loss=0.427, v_num=18, train_loss_step=0.637]Epoch 0:  69%|██████▊   | 261/380 [00:37<00:17,  6.91it/s, loss=0.443, v_num=18, train_loss_step=0.809]Epoch 0:  69%|██████▉   | 262/380 [00:38<00:17,  6.91it/s, loss=0.443, v_num=18, train_loss_step=0.809]Epoch 0:  69%|██████▉   | 262/380 [00:38<00:17,  6.91it/s, loss=0.434, v_num=18, train_loss_step=0.529]Epoch 0:  69%|██████▉   | 263/380 [00:38<00:16,  6.91it/s, loss=0.434, v_num=18, train_loss_step=0.529]Epoch 0:  69%|██████▉   | 263/380 [00:38<00:16,  6.91it/s, loss=0.445, v_num=18, train_loss_step=0.659]Epoch 0:  69%|██████▉   | 264/380 [00:38<00:16,  6.91it/s, loss=0.445, v_num=18, train_loss_step=0.659]Epoch 0:  69%|██████▉   | 264/380 [00:38<00:16,  6.91it/s, loss=0.445, v_num=18, train_loss_step=0.313]Epoch 0:  70%|██████▉   | 265/380 [00:38<00:16,  6.92it/s, loss=0.445, v_num=18, train_loss_step=0.313]Epoch 0:  70%|██████▉   | 265/380 [00:38<00:16,  6.92it/s, loss=0.453, v_num=18, train_loss_step=0.470]Epoch 0:  70%|███████   | 266/380 [00:38<00:16,  6.92it/s, loss=0.453, v_num=18, train_loss_step=0.470]Epoch 0:  70%|███████   | 266/380 [00:38<00:16,  6.92it/s, loss=0.472, v_num=18, train_loss_step=0.691]Epoch 0:  70%|███████   | 267/380 [00:38<00:16,  6.92it/s, loss=0.472, v_num=18, train_loss_step=0.691]Epoch 0:  70%|███████   | 267/380 [00:38<00:16,  6.92it/s, loss=0.467, v_num=18, train_loss_step=0.313]Epoch 0:  71%|███████   | 268/380 [00:38<00:16,  6.93it/s, loss=0.467, v_num=18, train_loss_step=0.313]Epoch 0:  71%|███████   | 268/380 [00:38<00:16,  6.93it/s, loss=0.467, v_num=18, train_loss_step=0.320]Epoch 0:  71%|███████   | 269/380 [00:38<00:16,  6.93it/s, loss=0.467, v_num=18, train_loss_step=0.320]Epoch 0:  71%|███████   | 269/380 [00:38<00:16,  6.93it/s, loss=0.466, v_num=18, train_loss_step=0.400]Epoch 0:  71%|███████   | 270/380 [00:39<00:15,  6.93it/s, loss=0.466, v_num=18, train_loss_step=0.400]Epoch 0:  71%|███████   | 270/380 [00:39<00:15,  6.93it/s, loss=0.462, v_num=18, train_loss_step=0.586]Epoch 0:  71%|███████▏  | 271/380 [00:39<00:15,  6.94it/s, loss=0.462, v_num=18, train_loss_step=0.586]Epoch 0:  71%|███████▏  | 271/380 [00:39<00:15,  6.94it/s, loss=0.461, v_num=18, train_loss_step=0.313]Epoch 0:  72%|███████▏  | 272/380 [00:39<00:15,  6.94it/s, loss=0.461, v_num=18, train_loss_step=0.313]Epoch 0:  72%|███████▏  | 272/380 [00:39<00:15,  6.94it/s, loss=0.464, v_num=18, train_loss_step=0.371]Epoch 0:  72%|███████▏  | 273/380 [00:39<00:15,  6.94it/s, loss=0.464, v_num=18, train_loss_step=0.371]Epoch 0:  72%|███████▏  | 273/380 [00:39<00:15,  6.94it/s, loss=0.461, v_num=18, train_loss_step=0.318]Epoch 0:  72%|███████▏  | 274/380 [00:39<00:15,  6.95it/s, loss=0.461, v_num=18, train_loss_step=0.318]Epoch 0:  72%|███████▏  | 274/380 [00:39<00:15,  6.95it/s, loss=0.464, v_num=18, train_loss_step=0.402]Epoch 0:  72%|███████▏  | 275/380 [00:39<00:15,  6.95it/s, loss=0.464, v_num=18, train_loss_step=0.402]Epoch 0:  72%|███████▏  | 275/380 [00:39<00:15,  6.95it/s, loss=0.446, v_num=18, train_loss_step=0.313]Epoch 0:  73%|███████▎  | 276/380 [00:39<00:14,  6.95it/s, loss=0.446, v_num=18, train_loss_step=0.313]Epoch 0:  73%|███████▎  | 276/380 [00:39<00:14,  6.95it/s, loss=0.478, v_num=18, train_loss_step=0.984]Epoch 0:  73%|███████▎  | 277/380 [00:39<00:14,  6.95it/s, loss=0.478, v_num=18, train_loss_step=0.984]Epoch 0:  73%|███████▎  | 277/380 [00:39<00:14,  6.95it/s, loss=0.473, v_num=18, train_loss_step=0.313]Epoch 0:  73%|███████▎  | 278/380 [00:40<00:14,  6.96it/s, loss=0.473, v_num=18, train_loss_step=0.313]Epoch 0:  73%|███████▎  | 278/380 [00:40<00:14,  6.96it/s, loss=0.472, v_num=18, train_loss_step=0.341]Epoch 0:  73%|███████▎  | 279/380 [00:40<00:14,  6.96it/s, loss=0.472, v_num=18, train_loss_step=0.341]Epoch 0:  73%|███████▎  | 279/380 [00:40<00:14,  6.96it/s, loss=0.476, v_num=18, train_loss_step=0.431]Epoch 0:  74%|███████▎  | 280/380 [00:40<00:14,  6.96it/s, loss=0.476, v_num=18, train_loss_step=0.431]Epoch 0:  74%|███████▎  | 280/380 [00:40<00:14,  6.96it/s, loss=0.46, v_num=18, train_loss_step=0.331] Epoch 0:  74%|███████▍  | 281/380 [00:40<00:14,  6.96it/s, loss=0.46, v_num=18, train_loss_step=0.331]Epoch 0:  74%|███████▍  | 281/380 [00:40<00:14,  6.96it/s, loss=0.436, v_num=18, train_loss_step=0.313]Epoch 0:  74%|███████▍  | 282/380 [00:40<00:14,  6.96it/s, loss=0.436, v_num=18, train_loss_step=0.313]Epoch 0:  74%|███████▍  | 282/380 [00:40<00:14,  6.96it/s, loss=0.437, v_num=18, train_loss_step=0.563]Epoch 0:  74%|███████▍  | 283/380 [00:40<00:13,  6.96it/s, loss=0.437, v_num=18, train_loss_step=0.563]Epoch 0:  74%|███████▍  | 283/380 [00:40<00:13,  6.96it/s, loss=0.424, v_num=18, train_loss_step=0.402]Epoch 0:  75%|███████▍  | 284/380 [00:40<00:13,  6.97it/s, loss=0.424, v_num=18, train_loss_step=0.402]Epoch 0:  75%|███████▍  | 284/380 [00:40<00:13,  6.97it/s, loss=0.435, v_num=18, train_loss_step=0.531]Epoch 0:  75%|███████▌  | 285/380 [00:41<00:13,  6.97it/s, loss=0.435, v_num=18, train_loss_step=0.531]Epoch 0:  75%|███████▌  | 285/380 [00:41<00:13,  6.97it/s, loss=0.451, v_num=18, train_loss_step=0.787]Epoch 0:  75%|███████▌  | 286/380 [00:41<00:13,  6.96it/s, loss=0.451, v_num=18, train_loss_step=0.787]Epoch 0:  75%|███████▌  | 286/380 [00:41<00:13,  6.96it/s, loss=0.44, v_num=18, train_loss_step=0.475] Epoch 0:  76%|███████▌  | 287/380 [00:41<00:13,  6.97it/s, loss=0.44, v_num=18, train_loss_step=0.475]Epoch 0:  76%|███████▌  | 287/380 [00:41<00:13,  6.97it/s, loss=0.443, v_num=18, train_loss_step=0.367]Epoch 0:  76%|███████▌  | 288/380 [00:41<00:13,  6.97it/s, loss=0.443, v_num=18, train_loss_step=0.367]Epoch 0:  76%|███████▌  | 288/380 [00:41<00:13,  6.97it/s, loss=0.443, v_num=18, train_loss_step=0.313]Epoch 0:  76%|███████▌  | 289/380 [00:41<00:13,  6.98it/s, loss=0.443, v_num=18, train_loss_step=0.313]Epoch 0:  76%|███████▌  | 289/380 [00:41<00:13,  6.98it/s, loss=0.462, v_num=18, train_loss_step=0.791]Epoch 0:  76%|███████▋  | 290/380 [00:41<00:12,  6.98it/s, loss=0.462, v_num=18, train_loss_step=0.791]Epoch 0:  76%|███████▋  | 290/380 [00:41<00:12,  6.98it/s, loss=0.464, v_num=18, train_loss_step=0.616]Epoch 0:  77%|███████▋  | 291/380 [00:41<00:12,  6.98it/s, loss=0.464, v_num=18, train_loss_step=0.616]Epoch 0:  77%|███████▋  | 291/380 [00:41<00:12,  6.98it/s, loss=0.464, v_num=18, train_loss_step=0.313]Epoch 0:  77%|███████▋  | 292/380 [00:42<00:12,  6.97it/s, loss=0.464, v_num=18, train_loss_step=0.313]Epoch 0:  77%|███████▋  | 292/380 [00:42<00:12,  6.97it/s, loss=0.474, v_num=18, train_loss_step=0.568]Epoch 0:  77%|███████▋  | 293/380 [00:42<00:12,  6.97it/s, loss=0.474, v_num=18, train_loss_step=0.568]Epoch 0:  77%|███████▋  | 293/380 [00:42<00:12,  6.97it/s, loss=0.475, v_num=18, train_loss_step=0.352]Epoch 0:  77%|███████▋  | 294/380 [00:42<00:12,  6.97it/s, loss=0.475, v_num=18, train_loss_step=0.352]Epoch 0:  77%|███████▋  | 294/380 [00:42<00:12,  6.97it/s, loss=0.477, v_num=18, train_loss_step=0.442]Epoch 0:  78%|███████▊  | 295/380 [00:42<00:12,  6.97it/s, loss=0.477, v_num=18, train_loss_step=0.442]Epoch 0:  78%|███████▊  | 295/380 [00:42<00:12,  6.97it/s, loss=0.478, v_num=18, train_loss_step=0.327]Epoch 0:  78%|███████▊  | 296/380 [00:42<00:12,  6.97it/s, loss=0.478, v_num=18, train_loss_step=0.327]Epoch 0:  78%|███████▊  | 296/380 [00:42<00:12,  6.97it/s, loss=0.445, v_num=18, train_loss_step=0.330]Epoch 0:  78%|███████▊  | 297/380 [00:42<00:11,  6.97it/s, loss=0.445, v_num=18, train_loss_step=0.330]Epoch 0:  78%|███████▊  | 297/380 [00:42<00:11,  6.97it/s, loss=0.455, v_num=18, train_loss_step=0.515]Epoch 0:  78%|███████▊  | 298/380 [00:42<00:11,  6.98it/s, loss=0.455, v_num=18, train_loss_step=0.515]Epoch 0:  78%|███████▊  | 298/380 [00:42<00:11,  6.98it/s, loss=0.468, v_num=18, train_loss_step=0.588]Epoch 0:  79%|███████▊  | 299/380 [00:42<00:11,  6.98it/s, loss=0.468, v_num=18, train_loss_step=0.588]Epoch 0:  79%|███████▊  | 299/380 [00:42<00:11,  6.98it/s, loss=0.464, v_num=18, train_loss_step=0.345]Epoch 0:  79%|███████▉  | 300/380 [00:43<00:11,  6.98it/s, loss=0.464, v_num=18, train_loss_step=0.345]Epoch 0:  79%|███████▉  | 300/380 [00:43<00:11,  6.98it/s, loss=0.483, v_num=18, train_loss_step=0.720]Epoch 0:  79%|███████▉  | 301/380 [00:43<00:11,  6.98it/s, loss=0.483, v_num=18, train_loss_step=0.720]Epoch 0:  79%|███████▉  | 301/380 [00:43<00:11,  6.98it/s, loss=0.483, v_num=18, train_loss_step=0.313]Epoch 0:  79%|███████▉  | 302/380 [00:43<00:11,  6.98it/s, loss=0.483, v_num=18, train_loss_step=0.313]Epoch 0:  79%|███████▉  | 302/380 [00:43<00:11,  6.98it/s, loss=0.471, v_num=18, train_loss_step=0.333]Epoch 0:  80%|███████▉  | 303/380 [00:43<00:11,  6.98it/s, loss=0.471, v_num=18, train_loss_step=0.333]Epoch 0:  80%|███████▉  | 303/380 [00:43<00:11,  6.98it/s, loss=0.474, v_num=18, train_loss_step=0.450]Epoch 0:  80%|████████  | 304/380 [00:43<00:10,  6.98it/s, loss=0.474, v_num=18, train_loss_step=0.450]Epoch 0:  80%|████████  | 304/380 [00:43<00:10,  6.98it/s, loss=0.475, v_num=18, train_loss_step=0.562]Epoch 0:  80%|████████  | 305/380 [00:43<00:10,  6.98it/s, loss=0.475, v_num=18, train_loss_step=0.562]Epoch 0:  80%|████████  | 305/380 [00:43<00:10,  6.98it/s, loss=0.452, v_num=18, train_loss_step=0.313]Epoch 0:  81%|████████  | 306/380 [00:43<00:10,  6.99it/s, loss=0.452, v_num=18, train_loss_step=0.313]Epoch 0:  81%|████████  | 306/380 [00:43<00:10,  6.99it/s, loss=0.46, v_num=18, train_loss_step=0.632] Epoch 0:  81%|████████  | 307/380 [00:44<00:10,  6.99it/s, loss=0.46, v_num=18, train_loss_step=0.632]Epoch 0:  81%|████████  | 307/380 [00:44<00:10,  6.99it/s, loss=0.471, v_num=18, train_loss_step=0.602]Epoch 0:  81%|████████  | 308/380 [00:44<00:10,  6.99it/s, loss=0.471, v_num=18, train_loss_step=0.602]Epoch 0:  81%|████████  | 308/380 [00:44<00:10,  6.99it/s, loss=0.471, v_num=18, train_loss_step=0.313]Epoch 0:  81%|████████▏ | 309/380 [00:44<00:10,  6.99it/s, loss=0.471, v_num=18, train_loss_step=0.313]Epoch 0:  81%|████████▏ | 309/380 [00:44<00:10,  6.99it/s, loss=0.45, v_num=18, train_loss_step=0.364] Epoch 0:  82%|████████▏ | 310/380 [00:44<00:10,  6.99it/s, loss=0.45, v_num=18, train_loss_step=0.364]Epoch 0:  82%|████████▏ | 310/380 [00:44<00:10,  6.99it/s, loss=0.435, v_num=18, train_loss_step=0.313]Epoch 0:  82%|████████▏ | 311/380 [00:44<00:09,  6.99it/s, loss=0.435, v_num=18, train_loss_step=0.313]Epoch 0:  82%|████████▏ | 311/380 [00:44<00:09,  6.99it/s, loss=0.443, v_num=18, train_loss_step=0.484]Epoch 0:  82%|████████▏ | 312/380 [00:44<00:09,  6.99it/s, loss=0.443, v_num=18, train_loss_step=0.484]Epoch 0:  82%|████████▏ | 312/380 [00:44<00:09,  6.99it/s, loss=0.433, v_num=18, train_loss_step=0.368]Epoch 0:  82%|████████▏ | 313/380 [00:44<00:09,  6.99it/s, loss=0.433, v_num=18, train_loss_step=0.368]Epoch 0:  82%|████████▏ | 313/380 [00:44<00:09,  6.99it/s, loss=0.432, v_num=18, train_loss_step=0.335]Epoch 0:  83%|████████▎ | 314/380 [00:45<00:09,  7.00it/s, loss=0.432, v_num=18, train_loss_step=0.335]Epoch 0:  83%|████████▎ | 314/380 [00:45<00:09,  7.00it/s, loss=0.426, v_num=18, train_loss_step=0.322]Epoch 0:  83%|████████▎ | 315/380 [00:45<00:09,  7.00it/s, loss=0.426, v_num=18, train_loss_step=0.322]Epoch 0:  83%|████████▎ | 315/380 [00:45<00:09,  7.00it/s, loss=0.433, v_num=18, train_loss_step=0.449]Epoch 0:  83%|████████▎ | 316/380 [00:45<00:09,  7.00it/s, loss=0.433, v_num=18, train_loss_step=0.449]Epoch 0:  83%|████████▎ | 316/380 [00:45<00:09,  7.00it/s, loss=0.432, v_num=18, train_loss_step=0.313]Epoch 0:  83%|████████▎ | 317/380 [00:45<00:09,  7.00it/s, loss=0.432, v_num=18, train_loss_step=0.313]Epoch 0:  83%|████████▎ | 317/380 [00:45<00:09,  7.00it/s, loss=0.422, v_num=18, train_loss_step=0.313]Epoch 0:  84%|████████▎ | 318/380 [00:45<00:08,  7.00it/s, loss=0.422, v_num=18, train_loss_step=0.313]Epoch 0:  84%|████████▎ | 318/380 [00:45<00:08,  7.00it/s, loss=0.408, v_num=18, train_loss_step=0.313]Epoch 0:  84%|████████▍ | 319/380 [00:45<00:08,  7.00it/s, loss=0.408, v_num=18, train_loss_step=0.313]Epoch 0:  84%|████████▍ | 319/380 [00:45<00:08,  7.00it/s, loss=0.41, v_num=18, train_loss_step=0.386] Epoch 0:  84%|████████▍ | 320/380 [00:45<00:08,  7.00it/s, loss=0.41, v_num=18, train_loss_step=0.386]Epoch 0:  84%|████████▍ | 320/380 [00:45<00:08,  7.00it/s, loss=0.393, v_num=18, train_loss_step=0.380]Epoch 0:  84%|████████▍ | 321/380 [00:45<00:08,  7.01it/s, loss=0.393, v_num=18, train_loss_step=0.380]Epoch 0:  84%|████████▍ | 321/380 [00:45<00:08,  7.01it/s, loss=0.418, v_num=18, train_loss_step=0.819]Epoch 0:  85%|████████▍ | 322/380 [00:46<00:08,  7.01it/s, loss=0.418, v_num=18, train_loss_step=0.819]Epoch 0:  85%|████████▍ | 322/380 [00:46<00:08,  7.01it/s, loss=0.42, v_num=18, train_loss_step=0.370] Epoch 0:  85%|████████▌ | 323/380 [00:46<00:08,  7.01it/s, loss=0.42, v_num=18, train_loss_step=0.370]Epoch 0:  85%|████████▌ | 323/380 [00:46<00:08,  7.01it/s, loss=0.417, v_num=18, train_loss_step=0.384]Epoch 0:  85%|████████▌ | 324/380 [00:46<00:07,  7.01it/s, loss=0.417, v_num=18, train_loss_step=0.384]Epoch 0:  85%|████████▌ | 324/380 [00:46<00:07,  7.01it/s, loss=0.423, v_num=18, train_loss_step=0.688]Epoch 0:  86%|████████▌ | 325/380 [00:46<00:07,  7.01it/s, loss=0.423, v_num=18, train_loss_step=0.688]Epoch 0:  86%|████████▌ | 325/380 [00:46<00:07,  7.01it/s, loss=0.437, v_num=18, train_loss_step=0.599]Epoch 0:  86%|████████▌ | 326/380 [00:46<00:07,  7.01it/s, loss=0.437, v_num=18, train_loss_step=0.599]Epoch 0:  86%|████████▌ | 326/380 [00:46<00:07,  7.01it/s, loss=0.44, v_num=18, train_loss_step=0.675] Epoch 0:  86%|████████▌ | 327/380 [00:46<00:07,  7.01it/s, loss=0.44, v_num=18, train_loss_step=0.675]Epoch 0:  86%|████████▌ | 327/380 [00:46<00:07,  7.01it/s, loss=0.425, v_num=18, train_loss_step=0.313]Epoch 0:  86%|████████▋ | 328/380 [00:46<00:07,  7.02it/s, loss=0.425, v_num=18, train_loss_step=0.313]Epoch 0:  86%|████████▋ | 328/380 [00:46<00:07,  7.02it/s, loss=0.431, v_num=18, train_loss_step=0.440]Epoch 0:  87%|████████▋ | 329/380 [00:47<00:07,  7.01it/s, loss=0.431, v_num=18, train_loss_step=0.440]Epoch 0:  87%|████████▋ | 329/380 [00:47<00:07,  7.01it/s, loss=0.447, v_num=18, train_loss_step=0.679]Epoch 0:  87%|████████▋ | 330/380 [00:47<00:07,  7.01it/s, loss=0.447, v_num=18, train_loss_step=0.679]Epoch 0:  87%|████████▋ | 330/380 [00:47<00:07,  7.01it/s, loss=0.456, v_num=18, train_loss_step=0.495]Epoch 0:  87%|████████▋ | 331/380 [00:47<00:06,  7.01it/s, loss=0.456, v_num=18, train_loss_step=0.495]Epoch 0:  87%|████████▋ | 331/380 [00:47<00:06,  7.01it/s, loss=0.451, v_num=18, train_loss_step=0.386]Epoch 0:  87%|████████▋ | 332/380 [00:47<00:06,  7.02it/s, loss=0.451, v_num=18, train_loss_step=0.386]Epoch 0:  87%|████████▋ | 332/380 [00:47<00:06,  7.02it/s, loss=0.454, v_num=18, train_loss_step=0.416]Epoch 0:  88%|████████▊ | 333/380 [00:47<00:06,  7.02it/s, loss=0.454, v_num=18, train_loss_step=0.416]Epoch 0:  88%|████████▊ | 333/380 [00:47<00:06,  7.02it/s, loss=0.453, v_num=18, train_loss_step=0.313]Epoch 0:  88%|████████▊ | 334/380 [00:47<00:06,  7.03it/s, loss=0.452, v_num=18, train_loss_step=0.317]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/46 [00:00<?, ?it/s][A
Validating:   2%|▏         | 1/46 [00:00<00:12,  3.51it/s][AEpoch 0:  88%|████████▊ | 336/380 [00:47<00:06,  7.03it/s, loss=0.452, v_num=18, train_loss_step=0.317]
Validating:   4%|▍         | 2/46 [00:00<00:12,  3.57it/s][A
Validating:   7%|▋         | 3/46 [00:00<00:12,  3.46it/s][A
Validating:   9%|▊         | 4/46 [00:01<00:12,  3.32it/s][AEpoch 0:  89%|████████▉ | 339/380 [00:48<00:05,  6.96it/s, loss=0.452, v_num=18, train_loss_step=0.317]
Validating:  11%|█         | 5/46 [00:01<00:12,  3.37it/s][A
Validating:  13%|█▎        | 6/46 [00:01<00:11,  3.37it/s][A
Validating:  15%|█▌        | 7/46 [00:02<00:11,  3.35it/s][AEpoch 0:  90%|█████████ | 342/380 [00:49<00:05,  6.90it/s, loss=0.452, v_num=18, train_loss_step=0.317]
Validating:  17%|█▋        | 8/46 [00:02<00:11,  3.28it/s][A
Validating:  20%|█▉        | 9/46 [00:02<00:11,  3.34it/s][A
Validating:  22%|██▏       | 10/46 [00:02<00:10,  3.35it/s][AEpoch 0:  91%|█████████ | 345/380 [00:50<00:05,  6.83it/s, loss=0.452, v_num=18, train_loss_step=0.317]
Validating:  24%|██▍       | 11/46 [00:03<00:10,  3.30it/s][A
Validating:  26%|██▌       | 12/46 [00:03<00:10,  3.23it/s][A
Validating:  28%|██▊       | 13/46 [00:03<00:10,  3.29it/s][AEpoch 0:  92%|█████████▏| 348/380 [00:51<00:04,  6.77it/s, loss=0.452, v_num=18, train_loss_step=0.317]
Validating:  30%|███       | 14/46 [00:04<00:09,  3.26it/s][A
Validating:  33%|███▎      | 15/46 [00:04<00:09,  3.30it/s][A
Validating:  35%|███▍      | 16/46 [00:04<00:09,  3.22it/s][AEpoch 0:  92%|█████████▏| 351/380 [00:52<00:04,  6.71it/s, loss=0.452, v_num=18, train_loss_step=0.317]
Validating:  37%|███▋      | 17/46 [00:05<00:09,  3.06it/s][A
Validating:  39%|███▉      | 18/46 [00:05<00:09,  3.10it/s][A
Validating:  41%|████▏     | 19/46 [00:05<00:08,  3.17it/s][AEpoch 0:  93%|█████████▎| 354/380 [00:53<00:03,  6.64it/s, loss=0.452, v_num=18, train_loss_step=0.317]
Validating:  43%|████▎     | 20/46 [00:06<00:08,  3.17it/s][A
Validating:  46%|████▌     | 21/46 [00:06<00:07,  3.19it/s][A
Validating:  48%|████▊     | 22/46 [00:06<00:07,  3.26it/s][AEpoch 0:  94%|█████████▍| 357/380 [00:54<00:03,  6.58it/s, loss=0.452, v_num=18, train_loss_step=0.317]
Validating:  50%|█████     | 23/46 [00:07<00:07,  3.25it/s][A
Validating:  52%|█████▏    | 24/46 [00:07<00:06,  3.31it/s][A
Validating:  54%|█████▍    | 25/46 [00:07<00:06,  3.34it/s][AEpoch 0:  95%|█████████▍| 360/380 [00:55<00:03,  6.53it/s, loss=0.452, v_num=18, train_loss_step=0.317]
Validating:  57%|█████▋    | 26/46 [00:07<00:06,  3.22it/s][A
Validating:  59%|█████▊    | 27/46 [00:08<00:06,  3.10it/s][A
Validating:  61%|██████    | 28/46 [00:08<00:05,  3.17it/s][AEpoch 0:  96%|█████████▌| 363/380 [00:56<00:02,  6.47it/s, loss=0.452, v_num=18, train_loss_step=0.317]
Validating:  63%|██████▎   | 29/46 [00:08<00:05,  3.18it/s][A
Validating:  65%|██████▌   | 30/46 [00:09<00:04,  3.22it/s][A
Validating:  67%|██████▋   | 31/46 [00:09<00:04,  3.24it/s][AEpoch 0:  96%|█████████▋| 366/380 [00:57<00:02,  6.42it/s, loss=0.452, v_num=18, train_loss_step=0.317]
Validating:  70%|██████▉   | 32/46 [00:09<00:04,  3.26it/s][A
Validating:  72%|███████▏  | 33/46 [00:10<00:04,  3.21it/s][A
Validating:  74%|███████▍  | 34/46 [00:10<00:03,  3.27it/s][AEpoch 0:  97%|█████████▋| 369/380 [00:58<00:01,  6.37it/s, loss=0.452, v_num=18, train_loss_step=0.317]
Validating:  76%|███████▌  | 35/46 [00:10<00:03,  3.35it/s][A
Validating:  78%|███████▊  | 36/46 [00:11<00:02,  3.36it/s][A
Validating:  80%|████████  | 37/46 [00:11<00:02,  3.27it/s][AEpoch 0:  98%|█████████▊| 372/380 [00:58<00:01,  6.32it/s, loss=0.452, v_num=18, train_loss_step=0.317]
Validating:  83%|████████▎ | 38/46 [00:11<00:02,  3.23it/s][A
Validating:  85%|████████▍ | 39/46 [00:11<00:02,  3.30it/s][A
Validating:  87%|████████▋ | 40/46 [00:12<00:01,  3.30it/s][AEpoch 0:  99%|█████████▊| 375/380 [00:59<00:00,  6.28it/s, loss=0.452, v_num=18, train_loss_step=0.317]
Validating:  89%|████████▉ | 41/46 [00:12<00:01,  3.27it/s][A
Validating:  91%|█████████▏| 42/46 [00:12<00:01,  3.28it/s][A
Validating:  93%|█████████▎| 43/46 [00:13<00:00,  3.24it/s][AEpoch 0:  99%|█████████▉| 378/380 [01:00<00:00,  6.23it/s, loss=0.452, v_num=18, train_loss_step=0.317]
Validating:  96%|█████████▌| 44/46 [00:13<00:00,  3.22it/s][A
Validating:  98%|█████████▊| 45/46 [00:13<00:00,  3.25it/s][A
Validating: 100%|██████████| 46/46 [00:14<00:00,  3.26it/s][AEpoch 0: 100%|██████████| 380/380 [01:01<00:00,  6.17it/s, loss=0.452, v_num=18, train_loss_step=0.317]
                                                           [AEpoch 0: 100%|██████████| 380/380 [01:01<00:00,  6.16it/s, loss=0.452, v_num=18, train_loss_step=0.317]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(

Testing: 0it [00:00, ?it/s]Testing:   1%|          | 1/169 [00:00<00:27,  6.05it/s]Testing:   1%|          | 2/169 [00:00<00:23,  7.03it/s]Testing:   2%|▏         | 3/169 [00:00<00:23,  7.03it/s]Testing:   2%|▏         | 4/169 [00:00<00:23,  6.97it/s]Testing:   3%|▎         | 5/169 [00:00<00:24,  6.82it/s]Testing:   4%|▎         | 6/169 [00:00<00:22,  7.19it/s]Testing:   4%|▍         | 7/169 [00:00<00:22,  7.28it/s]Testing:   5%|▍         | 8/169 [00:01<00:22,  7.17it/s]Testing:   5%|▌         | 9/169 [00:01<00:21,  7.39it/s]Testing:   6%|▌         | 10/169 [00:01<00:21,  7.24it/s]Testing:   7%|▋         | 11/169 [00:01<00:21,  7.21it/s]Testing:   7%|▋         | 12/169 [00:01<00:22,  7.11it/s]Testing:   8%|▊         | 13/169 [00:01<00:21,  7.17it/s]Testing:   8%|▊         | 14/169 [00:01<00:21,  7.13it/s]Testing:   9%|▉         | 15/169 [00:02<00:21,  7.02it/s]Testing:   9%|▉         | 16/169 [00:02<00:22,  6.83it/s]Testing:  10%|█         | 17/169 [00:02<00:22,  6.82it/s]Testing:  11%|█         | 18/169 [00:02<00:21,  6.99it/s]Testing:  11%|█         | 19/169 [00:02<00:20,  7.26it/s]Testing:  12%|█▏        | 20/169 [00:02<00:21,  7.08it/s]Testing:  12%|█▏        | 21/169 [00:02<00:21,  6.86it/s]Testing:  13%|█▎        | 22/169 [00:03<00:21,  6.81it/s]Testing:  14%|█▎        | 23/169 [00:03<00:21,  6.85it/s]Testing:  14%|█▍        | 24/169 [00:03<00:21,  6.90it/s]Testing:  15%|█▍        | 25/169 [00:03<00:20,  7.17it/s]Testing:  15%|█▌        | 26/169 [00:03<00:19,  7.22it/s]Testing:  16%|█▌        | 27/169 [00:03<00:19,  7.41it/s]Testing:  17%|█▋        | 28/169 [00:03<00:19,  7.25it/s]Testing:  17%|█▋        | 29/169 [00:04<00:19,  7.05it/s]Testing:  18%|█▊        | 30/169 [00:04<00:19,  6.98it/s]Testing:  18%|█▊        | 31/169 [00:04<00:19,  7.22it/s]Testing:  19%|█▉        | 32/169 [00:04<00:18,  7.30it/s]Testing:  20%|█▉        | 33/169 [00:04<00:18,  7.19it/s]Testing:  20%|██        | 34/169 [00:04<00:19,  6.91it/s]Testing:  21%|██        | 35/169 [00:04<00:19,  6.82it/s]Testing:  21%|██▏       | 36/169 [00:05<00:19,  6.91it/s]Testing:  22%|██▏       | 37/169 [00:05<00:18,  7.19it/s]Testing:  22%|██▏       | 38/169 [00:05<00:18,  7.23it/s]Testing:  23%|██▎       | 39/169 [00:05<00:18,  7.20it/s]Testing:  24%|██▎       | 40/169 [00:05<00:17,  7.42it/s]Testing:  24%|██▍       | 41/169 [00:05<00:16,  7.54it/s]Testing:  25%|██▍       | 42/169 [00:05<00:17,  7.31it/s]Testing:  25%|██▌       | 43/169 [00:06<00:17,  7.14it/s]Testing:  26%|██▌       | 44/169 [00:06<00:17,  7.21it/s]Testing:  27%|██▋       | 45/169 [00:06<00:17,  7.24it/s]Testing:  27%|██▋       | 46/169 [00:06<00:17,  6.84it/s]Testing:  28%|██▊       | 47/169 [00:06<00:17,  7.16it/s]Testing:  28%|██▊       | 48/169 [00:06<00:17,  7.07it/s]Testing:  29%|██▉       | 49/169 [00:06<00:16,  7.19it/s]Testing:  30%|██▉       | 50/169 [00:07<00:16,  7.42it/s]Testing:  30%|███       | 51/169 [00:07<00:16,  7.32it/s]Testing:  31%|███       | 52/169 [00:07<00:15,  7.37it/s]Testing:  31%|███▏      | 53/169 [00:07<00:16,  7.09it/s]Testing:  32%|███▏      | 54/169 [00:07<00:16,  6.94it/s]Testing:  33%|███▎      | 55/169 [00:07<00:15,  7.21it/s]Testing:  33%|███▎      | 56/169 [00:07<00:15,  7.41it/s]Testing:  34%|███▎      | 57/169 [00:07<00:15,  7.37it/s]Testing:  34%|███▍      | 58/169 [00:08<00:15,  7.21it/s]Testing:  35%|███▍      | 59/169 [00:08<00:15,  7.15it/s]Testing:  36%|███▌      | 60/169 [00:08<00:15,  7.18it/s]Testing:  36%|███▌      | 61/169 [00:08<00:14,  7.23it/s]Testing:  37%|███▋      | 62/169 [00:08<00:14,  7.29it/s]Testing:  37%|███▋      | 63/169 [00:08<00:14,  7.37it/s]Testing:  38%|███▊      | 64/169 [00:08<00:14,  7.26it/s]Testing:  38%|███▊      | 65/169 [00:09<00:14,  7.36it/s]Testing:  39%|███▉      | 66/169 [00:09<00:14,  7.20it/s]Testing:  40%|███▉      | 67/169 [00:09<00:14,  7.13it/s]Testing:  40%|████      | 68/169 [00:09<00:14,  7.17it/s]Testing:  41%|████      | 69/169 [00:09<00:14,  7.05it/s]Testing:  41%|████▏     | 70/169 [00:09<00:14,  7.03it/s]Testing:  42%|████▏     | 71/169 [00:09<00:13,  7.27it/s]Testing:  43%|████▎     | 72/169 [00:10<00:13,  6.97it/s]Testing:  43%|████▎     | 73/169 [00:10<00:13,  6.94it/s]Testing:  44%|████▍     | 74/169 [00:10<00:13,  7.24it/s]Testing:  44%|████▍     | 75/169 [00:10<00:12,  7.33it/s]Testing:  45%|████▍     | 76/169 [00:10<00:13,  7.13it/s]Testing:  46%|████▌     | 77/169 [00:10<00:13,  6.87it/s]Testing:  46%|████▌     | 78/169 [00:10<00:13,  6.90it/s]Testing:  47%|████▋     | 79/169 [00:11<00:12,  7.04it/s]Testing:  47%|████▋     | 80/169 [00:11<00:12,  7.25it/s]Testing:  48%|████▊     | 81/169 [00:11<00:11,  7.43it/s]Testing:  49%|████▊     | 82/169 [00:11<00:11,  7.52it/s]Testing:  49%|████▉     | 83/169 [00:11<00:12,  7.10it/s]Testing:  50%|████▉     | 84/169 [00:11<00:12,  7.05it/s]Testing:  50%|█████     | 85/169 [00:11<00:11,  7.32it/s]Testing:  51%|█████     | 86/169 [00:12<00:11,  7.31it/s]Testing:  51%|█████▏    | 87/169 [00:12<00:11,  7.23it/s]Testing:  52%|█████▏    | 88/169 [00:12<00:11,  7.35it/s]Testing:  53%|█████▎    | 89/169 [00:12<00:10,  7.45it/s]Testing:  53%|█████▎    | 90/169 [00:12<00:10,  7.34it/s]Testing:  54%|█████▍    | 91/169 [00:12<00:10,  7.24it/s]Testing:  54%|█████▍    | 92/169 [00:12<00:10,  7.44it/s]Testing:  55%|█████▌    | 93/169 [00:12<00:10,  7.25it/s]Testing:  56%|█████▌    | 94/169 [00:13<00:10,  7.45it/s]Testing:  56%|█████▌    | 95/169 [00:13<00:09,  7.61it/s]Testing:  57%|█████▋    | 96/169 [00:13<00:09,  7.50it/s]Testing:  57%|█████▋    | 97/169 [00:13<00:09,  7.40it/s]Testing:  58%|█████▊    | 98/169 [00:13<00:09,  7.28it/s]Testing:  59%|█████▊    | 99/169 [00:13<00:09,  7.20it/s]Testing:  59%|█████▉    | 100/169 [00:13<00:10,  6.87it/s]Testing:  60%|█████▉    | 101/169 [00:14<00:09,  7.16it/s]Testing:  60%|██████    | 102/169 [00:14<00:09,  7.14it/s]Testing:  61%|██████    | 103/169 [00:14<00:08,  7.37it/s]Testing:  62%|██████▏   | 104/169 [00:14<00:09,  7.15it/s]Testing:  62%|██████▏   | 105/169 [00:14<00:08,  7.24it/s]Testing:  63%|██████▎   | 106/169 [00:14<00:08,  7.44it/s]Testing:  63%|██████▎   | 107/169 [00:14<00:08,  7.47it/s]Testing:  64%|██████▍   | 108/169 [00:15<00:08,  7.38it/s]Testing:  64%|██████▍   | 109/169 [00:15<00:07,  7.53it/s]Testing:  65%|██████▌   | 110/169 [00:15<00:07,  7.62it/s]Testing:  66%|██████▌   | 111/169 [00:15<00:08,  7.23it/s]Testing:  66%|██████▋   | 112/169 [00:15<00:08,  7.03it/s]Testing:  67%|██████▋   | 113/169 [00:15<00:07,  7.03it/s]Testing:  67%|██████▋   | 114/169 [00:15<00:07,  7.27it/s]Testing:  68%|██████▊   | 115/169 [00:16<00:07,  7.15it/s]Testing:  69%|██████▊   | 116/169 [00:16<00:07,  6.83it/s]Testing:  69%|██████▉   | 117/169 [00:16<00:07,  6.65it/s]Testing:  70%|██████▉   | 118/169 [00:16<00:07,  6.48it/s]Testing:  70%|███████   | 119/169 [00:16<00:07,  6.78it/s]Testing:  71%|███████   | 120/169 [00:16<00:06,  7.09it/s]Testing:  72%|███████▏  | 121/169 [00:16<00:06,  7.34it/s]Testing:  72%|███████▏  | 122/169 [00:17<00:06,  7.04it/s]Testing:  73%|███████▎  | 123/169 [00:17<00:06,  7.09it/s]Testing:  73%|███████▎  | 124/169 [00:17<00:06,  7.11it/s]Testing:  74%|███████▍  | 125/169 [00:17<00:05,  7.35it/s]Testing:  75%|███████▍  | 126/169 [00:17<00:05,  7.31it/s]Testing:  75%|███████▌  | 127/169 [00:17<00:05,  7.09it/s]Testing:  76%|███████▌  | 128/169 [00:17<00:05,  7.23it/s]Testing:  76%|███████▋  | 129/169 [00:17<00:05,  7.41it/s]Testing:  77%|███████▋  | 130/169 [00:18<00:05,  7.04it/s]Testing:  78%|███████▊  | 131/169 [00:18<00:05,  6.98it/s]Testing:  78%|███████▊  | 132/169 [00:18<00:05,  7.10it/s]Testing:  79%|███████▊  | 133/169 [00:18<00:05,  6.91it/s]Testing:  79%|███████▉  | 134/169 [00:18<00:05,  6.86it/s]Testing:  80%|███████▉  | 135/169 [00:18<00:04,  6.92it/s]Testing:  80%|████████  | 136/169 [00:19<00:04,  7.08it/s]Testing:  81%|████████  | 137/169 [00:19<00:04,  7.33it/s]Testing:  82%|████████▏ | 138/169 [00:19<00:04,  7.49it/s]Testing:  82%|████████▏ | 139/169 [00:19<00:04,  7.43it/s]Testing:  83%|████████▎ | 140/169 [00:19<00:03,  7.39it/s]Testing:  83%|████████▎ | 141/169 [00:19<00:03,  7.35it/s]Testing:  84%|████████▍ | 142/169 [00:19<00:03,  7.22it/s]Testing:  85%|████████▍ | 143/169 [00:19<00:03,  7.16it/s]Testing:  85%|████████▌ | 144/169 [00:20<00:03,  7.34it/s]Testing:  86%|████████▌ | 145/169 [00:20<00:03,  7.47it/s]Testing:  86%|████████▋ | 146/169 [00:20<00:03,  7.62it/s]Testing:  87%|████████▋ | 147/169 [00:20<00:02,  7.54it/s]Testing:  88%|████████▊ | 148/169 [00:20<00:02,  7.49it/s]Testing:  88%|████████▊ | 149/169 [00:20<00:02,  7.40it/s]Testing:  89%|████████▉ | 150/169 [00:20<00:02,  7.09it/s]Testing:  89%|████████▉ | 151/169 [00:21<00:02,  7.11it/s]Testing:  90%|████████▉ | 152/169 [00:21<00:02,  7.22it/s]Testing:  91%|█████████ | 153/169 [00:21<00:02,  7.16it/s]Testing:  91%|█████████ | 154/169 [00:21<00:02,  7.22it/s]Testing:  92%|█████████▏| 155/169 [00:21<00:01,  7.24it/s]Testing:  92%|█████████▏| 156/169 [00:21<00:01,  7.44it/s]Testing:  93%|█████████▎| 157/169 [00:21<00:01,  7.59it/s]Testing:  93%|█████████▎| 158/169 [00:21<00:01,  7.37it/s]Testing:  94%|█████████▍| 159/169 [00:22<00:01,  7.24it/s]Testing:  95%|█████████▍| 160/169 [00:22<00:01,  7.01it/s]Testing:  95%|█████████▌| 161/169 [00:22<00:01,  6.84it/s]Testing:  96%|█████████▌| 162/169 [00:22<00:00,  7.13it/s]Testing:  96%|█████████▋| 163/169 [00:22<00:00,  6.89it/s]Testing:  97%|█████████▋| 164/169 [00:22<00:00,  7.10it/s]Testing:  98%|█████████▊| 165/169 [00:22<00:00,  7.31it/s]Testing:  98%|█████████▊| 166/169 [00:23<00:00,  7.23it/s]Testing:  99%|█████████▉| 167/169 [00:23<00:00,  7.44it/s]Testing:  99%|█████████▉| 168/169 [00:23<00:00,  7.58it/s]Testing: 100%|██████████| 169/169 [00:23<00:00,  7.52it/s]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'_mean_accuracy': 0.9799597263336182,
 '_standard_dev_accuracy': 0.04008766636252403,
 '_variance_accuracy': 0.0016070210840553045,
 'test_acc': 0.9799600839614868,
 'test_dice_c1': 0.0,
 'test_f2_c1': 0.0,
 'test_loss': 0.4506128430366516,
 'test_mean_c1': 0.0,
 'test_prec_c1': 0.0,
 'test_sens_c1': 0.0,
 'test_spec_c1': 1.0}
--------------------------------------------------------------------------------
Testing: 100%|██████████| 169/169 [00:23<00:00,  7.19it/s]
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

  | Name       | Type             | Params
------------------------------------------------
0 | encoder1   | EncoderBlock     | 37.6 K
1 | encoder2   | EncoderBlock     | 221 K 
2 | bottleneck | ConvolutionBlock | 885 K 
3 | dropout    | Dropout2d        | 0     
4 | decoder1   | DecoderBlock     | 573 K 
5 | decoder2   | DecoderBlock     | 143 K 
6 | conv       | Conv2d           | 130   
7 | softmax    | Softmax2d        | 0     
------------------------------------------------
1.9 M     Trainable params
0         Non-trainable params
1.9 M     Total params
7.447     Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Validation sanity check:  50%|█████     | 1/2 [00:01<00:01,  1.50s/it]Validation sanity check: 100%|██████████| 2/2 [00:02<00:00,  1.34s/it]                                                                      /home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Training: -1it [00:00, ?it/s]Training:   0%|          | 0/96 [00:00<00:00, 28728.11it/s]Epoch 0:   0%|          | 0/96 [00:00<00:00, 4510.00it/s]  Epoch 0:   1%|          | 1/96 [00:00<00:22,  4.24it/s]  Epoch 0:   1%|          | 1/96 [00:00<00:22,  4.24it/s, loss=0.667, v_num=19, train_loss_step=0.667]Epoch 0:   2%|▏         | 2/96 [00:00<00:27,  3.40it/s, loss=0.667, v_num=19, train_loss_step=0.667]Epoch 0:   2%|▏         | 2/96 [00:00<00:27,  3.39it/s, loss=0.671, v_num=19, train_loss_step=0.675]Epoch 0:   3%|▎         | 3/96 [00:01<00:30,  3.09it/s, loss=0.671, v_num=19, train_loss_step=0.675]Epoch 0:   3%|▎         | 3/96 [00:01<00:30,  3.09it/s, loss=0.672, v_num=19, train_loss_step=0.673]Epoch 0:   4%|▍         | 4/96 [00:01<00:31,  2.93it/s, loss=0.672, v_num=19, train_loss_step=0.673]Epoch 0:   4%|▍         | 4/96 [00:01<00:31,  2.93it/s, loss=0.67, v_num=19, train_loss_step=0.663] Epoch 0:   5%|▌         | 5/96 [00:02<00:32,  2.83it/s, loss=0.67, v_num=19, train_loss_step=0.663]Epoch 0:   5%|▌         | 5/96 [00:02<00:32,  2.83it/s, loss=0.67, v_num=19, train_loss_step=0.673]Epoch 0:   6%|▋         | 6/96 [00:02<00:32,  2.76it/s, loss=0.67, v_num=19, train_loss_step=0.673]Epoch 0:   6%|▋         | 6/96 [00:02<00:32,  2.76it/s, loss=0.67, v_num=19, train_loss_step=0.666]Epoch 0:   7%|▋         | 7/96 [00:02<00:32,  2.71it/s, loss=0.67, v_num=19, train_loss_step=0.666]Epoch 0:   7%|▋         | 7/96 [00:02<00:32,  2.71it/s, loss=0.669, v_num=19, train_loss_step=0.669]Epoch 0:   8%|▊         | 8/96 [00:03<00:32,  2.67it/s, loss=0.669, v_num=19, train_loss_step=0.669]Epoch 0:   8%|▊         | 8/96 [00:03<00:32,  2.67it/s, loss=0.668, v_num=19, train_loss_step=0.660]Epoch 0:   9%|▉         | 9/96 [00:03<00:32,  2.64it/s, loss=0.668, v_num=19, train_loss_step=0.660]Epoch 0:   9%|▉         | 9/96 [00:03<00:32,  2.64it/s, loss=0.67, v_num=19, train_loss_step=0.685] Epoch 0:  10%|█         | 10/96 [00:04<00:32,  2.62it/s, loss=0.67, v_num=19, train_loss_step=0.685]Epoch 0:  10%|█         | 10/96 [00:04<00:32,  2.62it/s, loss=0.668, v_num=19, train_loss_step=0.654]Epoch 0:  11%|█▏        | 11/96 [00:04<00:32,  2.60it/s, loss=0.668, v_num=19, train_loss_step=0.654]Epoch 0:  11%|█▏        | 11/96 [00:04<00:32,  2.60it/s, loss=0.667, v_num=19, train_loss_step=0.655]Epoch 0:  12%|█▎        | 12/96 [00:05<00:32,  2.58it/s, loss=0.667, v_num=19, train_loss_step=0.655]Epoch 0:  12%|█▎        | 12/96 [00:05<00:32,  2.58it/s, loss=0.665, v_num=19, train_loss_step=0.641]Epoch 0:  14%|█▎        | 13/96 [00:05<00:32,  2.57it/s, loss=0.665, v_num=19, train_loss_step=0.641]Epoch 0:  14%|█▎        | 13/96 [00:05<00:32,  2.57it/s, loss=0.664, v_num=19, train_loss_step=0.649]Epoch 0:  15%|█▍        | 14/96 [00:05<00:32,  2.56it/s, loss=0.664, v_num=19, train_loss_step=0.649]Epoch 0:  15%|█▍        | 14/96 [00:05<00:32,  2.56it/s, loss=0.663, v_num=19, train_loss_step=0.654]Epoch 0:  16%|█▌        | 15/96 [00:06<00:31,  2.54it/s, loss=0.663, v_num=19, train_loss_step=0.654]Epoch 0:  16%|█▌        | 15/96 [00:06<00:31,  2.54it/s, loss=0.661, v_num=19, train_loss_step=0.636]Epoch 0:  17%|█▋        | 16/96 [00:06<00:31,  2.54it/s, loss=0.661, v_num=19, train_loss_step=0.636]Epoch 0:  17%|█▋        | 16/96 [00:06<00:31,  2.54it/s, loss=0.663, v_num=19, train_loss_step=0.682]Epoch 0:  18%|█▊        | 17/96 [00:07<00:31,  2.53it/s, loss=0.663, v_num=19, train_loss_step=0.682]Epoch 0:  18%|█▊        | 17/96 [00:07<00:31,  2.53it/s, loss=0.661, v_num=19, train_loss_step=0.636]Epoch 0:  19%|█▉        | 18/96 [00:07<00:30,  2.52it/s, loss=0.661, v_num=19, train_loss_step=0.636]Epoch 0:  19%|█▉        | 18/96 [00:07<00:30,  2.52it/s, loss=0.661, v_num=19, train_loss_step=0.652]Epoch 0:  20%|█▉        | 19/96 [00:07<00:30,  2.52it/s, loss=0.661, v_num=19, train_loss_step=0.652]Epoch 0:  20%|█▉        | 19/96 [00:07<00:30,  2.52it/s, loss=0.66, v_num=19, train_loss_step=0.650] Epoch 0:  21%|██        | 20/96 [00:08<00:30,  2.51it/s, loss=0.66, v_num=19, train_loss_step=0.650]Epoch 0:  21%|██        | 20/96 [00:08<00:30,  2.51it/s, loss=0.658, v_num=19, train_loss_step=0.621]Epoch 0:  22%|██▏       | 21/96 [00:08<00:29,  2.51it/s, loss=0.658, v_num=19, train_loss_step=0.621]Epoch 0:  22%|██▏       | 21/96 [00:08<00:29,  2.51it/s, loss=0.656, v_num=19, train_loss_step=0.618]Epoch 0:  23%|██▎       | 22/96 [00:09<00:29,  2.50it/s, loss=0.656, v_num=19, train_loss_step=0.618]Epoch 0:  23%|██▎       | 22/96 [00:09<00:29,  2.50it/s, loss=0.653, v_num=19, train_loss_step=0.623]Epoch 0:  24%|██▍       | 23/96 [00:09<00:29,  2.50it/s, loss=0.653, v_num=19, train_loss_step=0.623]Epoch 0:  24%|██▍       | 23/96 [00:09<00:29,  2.50it/s, loss=0.651, v_num=19, train_loss_step=0.630]Epoch 0:  25%|██▌       | 24/96 [00:10<00:28,  2.50it/s, loss=0.651, v_num=19, train_loss_step=0.630]Epoch 0:  25%|██▌       | 24/96 [00:10<00:28,  2.50it/s, loss=0.647, v_num=19, train_loss_step=0.591]Epoch 0:  26%|██▌       | 25/96 [00:10<00:28,  2.49it/s, loss=0.647, v_num=19, train_loss_step=0.591]Epoch 0:  26%|██▌       | 25/96 [00:10<00:28,  2.49it/s, loss=0.646, v_num=19, train_loss_step=0.650]Epoch 0:  27%|██▋       | 26/96 [00:10<00:28,  2.49it/s, loss=0.646, v_num=19, train_loss_step=0.650]Epoch 0:  27%|██▋       | 26/96 [00:10<00:28,  2.49it/s, loss=0.642, v_num=19, train_loss_step=0.582]Epoch 0:  28%|██▊       | 27/96 [00:11<00:27,  2.49it/s, loss=0.642, v_num=19, train_loss_step=0.582]Epoch 0:  28%|██▊       | 27/96 [00:11<00:27,  2.49it/s, loss=0.638, v_num=19, train_loss_step=0.596]Epoch 0:  29%|██▉       | 28/96 [00:11<00:27,  2.48it/s, loss=0.638, v_num=19, train_loss_step=0.596]Epoch 0:  29%|██▉       | 28/96 [00:11<00:27,  2.48it/s, loss=0.635, v_num=19, train_loss_step=0.591]Epoch 0:  30%|███       | 29/96 [00:12<00:26,  2.48it/s, loss=0.635, v_num=19, train_loss_step=0.591]Epoch 0:  30%|███       | 29/96 [00:12<00:26,  2.48it/s, loss=0.627, v_num=19, train_loss_step=0.536]Epoch 0:  31%|███▏      | 30/96 [00:12<00:26,  2.48it/s, loss=0.627, v_num=19, train_loss_step=0.536]Epoch 0:  31%|███▏      | 30/96 [00:12<00:26,  2.48it/s, loss=0.62, v_num=19, train_loss_step=0.506] Epoch 0:  32%|███▏      | 31/96 [00:12<00:26,  2.48it/s, loss=0.62, v_num=19, train_loss_step=0.506]Epoch 0:  32%|███▏      | 31/96 [00:12<00:26,  2.48it/s, loss=0.612, v_num=19, train_loss_step=0.507]Epoch 0:  33%|███▎      | 32/96 [00:13<00:25,  2.48it/s, loss=0.612, v_num=19, train_loss_step=0.507]Epoch 0:  33%|███▎      | 32/96 [00:13<00:25,  2.48it/s, loss=0.606, v_num=19, train_loss_step=0.520]Epoch 0:  34%|███▍      | 33/96 [00:13<00:25,  2.47it/s, loss=0.606, v_num=19, train_loss_step=0.520]Epoch 0:  34%|███▍      | 33/96 [00:13<00:25,  2.47it/s, loss=0.598, v_num=19, train_loss_step=0.488]Epoch 0:  35%|███▌      | 34/96 [00:14<00:25,  2.47it/s, loss=0.598, v_num=19, train_loss_step=0.488]Epoch 0:  35%|███▌      | 34/96 [00:14<00:25,  2.47it/s, loss=0.594, v_num=19, train_loss_step=0.557]Epoch 0:  36%|███▋      | 35/96 [00:14<00:24,  2.47it/s, loss=0.594, v_num=19, train_loss_step=0.557]Epoch 0:  36%|███▋      | 35/96 [00:14<00:24,  2.47it/s, loss=0.584, v_num=19, train_loss_step=0.448]Epoch 0:  38%|███▊      | 36/96 [00:14<00:24,  2.47it/s, loss=0.584, v_num=19, train_loss_step=0.448]Epoch 0:  38%|███▊      | 36/96 [00:14<00:24,  2.47it/s, loss=0.572, v_num=19, train_loss_step=0.447]Epoch 0:  39%|███▊      | 37/96 [00:15<00:23,  2.47it/s, loss=0.572, v_num=19, train_loss_step=0.447]Epoch 0:  39%|███▊      | 37/96 [00:15<00:23,  2.47it/s, loss=0.56, v_num=19, train_loss_step=0.392] Epoch 0:  40%|███▉      | 38/96 [00:15<00:23,  2.47it/s, loss=0.56, v_num=19, train_loss_step=0.392]Epoch 0:  40%|███▉      | 38/96 [00:15<00:23,  2.47it/s, loss=0.546, v_num=19, train_loss_step=0.378]Epoch 0:  41%|████      | 39/96 [00:16<00:23,  2.47it/s, loss=0.546, v_num=19, train_loss_step=0.378]Epoch 0:  41%|████      | 39/96 [00:16<00:23,  2.47it/s, loss=0.532, v_num=19, train_loss_step=0.353]Epoch 0:  42%|████▏     | 40/96 [00:16<00:22,  2.46it/s, loss=0.532, v_num=19, train_loss_step=0.353]Epoch 0:  42%|████▏     | 40/96 [00:16<00:22,  2.46it/s, loss=0.521, v_num=19, train_loss_step=0.402]Epoch 0:  43%|████▎     | 41/96 [00:17<00:22,  2.46it/s, loss=0.521, v_num=19, train_loss_step=0.402]Epoch 0:  43%|████▎     | 41/96 [00:17<00:22,  2.46it/s, loss=0.514, v_num=19, train_loss_step=0.482]Epoch 0:  44%|████▍     | 42/96 [00:17<00:21,  2.46it/s, loss=0.514, v_num=19, train_loss_step=0.482]Epoch 0:  44%|████▍     | 42/96 [00:17<00:21,  2.46it/s, loss=0.504, v_num=19, train_loss_step=0.420]Epoch 0:  45%|████▍     | 43/96 [00:17<00:21,  2.46it/s, loss=0.504, v_num=19, train_loss_step=0.420]Epoch 0:  45%|████▍     | 43/96 [00:17<00:21,  2.46it/s, loss=0.497, v_num=19, train_loss_step=0.498]Epoch 0:  46%|████▌     | 44/96 [00:18<00:21,  2.46it/s, loss=0.497, v_num=19, train_loss_step=0.498]Epoch 0:  46%|████▌     | 44/96 [00:18<00:21,  2.46it/s, loss=0.488, v_num=19, train_loss_step=0.398]Epoch 0:  47%|████▋     | 45/96 [00:18<00:20,  2.45it/s, loss=0.488, v_num=19, train_loss_step=0.398]Epoch 0:  47%|████▋     | 45/96 [00:18<00:20,  2.45it/s, loss=0.472, v_num=19, train_loss_step=0.342]Epoch 0:  48%|████▊     | 46/96 [00:19<00:20,  2.45it/s, loss=0.472, v_num=19, train_loss_step=0.342]Epoch 0:  48%|████▊     | 46/96 [00:19<00:20,  2.45it/s, loss=0.466, v_num=19, train_loss_step=0.462]Epoch 0:  49%|████▉     | 47/96 [00:19<00:19,  2.45it/s, loss=0.466, v_num=19, train_loss_step=0.462]Epoch 0:  49%|████▉     | 47/96 [00:19<00:19,  2.45it/s, loss=0.454, v_num=19, train_loss_step=0.351]Epoch 0:  50%|█████     | 48/96 [00:20<00:19,  2.45it/s, loss=0.454, v_num=19, train_loss_step=0.351]Epoch 0:  50%|█████     | 48/96 [00:20<00:19,  2.45it/s, loss=0.446, v_num=19, train_loss_step=0.442]Epoch 0:  51%|█████     | 49/96 [00:20<00:19,  2.45it/s, loss=0.446, v_num=19, train_loss_step=0.442]Epoch 0:  51%|█████     | 49/96 [00:20<00:19,  2.45it/s, loss=0.441, v_num=19, train_loss_step=0.436]Epoch 0:  52%|█████▏    | 50/96 [00:20<00:18,  2.45it/s, loss=0.441, v_num=19, train_loss_step=0.436]Epoch 0:  52%|█████▏    | 50/96 [00:20<00:18,  2.45it/s, loss=0.44, v_num=19, train_loss_step=0.477] Epoch 0:  53%|█████▎    | 51/96 [00:21<00:18,  2.45it/s, loss=0.44, v_num=19, train_loss_step=0.477]Epoch 0:  53%|█████▎    | 51/96 [00:21<00:18,  2.45it/s, loss=0.435, v_num=19, train_loss_step=0.398]Epoch 0:  54%|█████▍    | 52/96 [00:21<00:17,  2.45it/s, loss=0.435, v_num=19, train_loss_step=0.398]Epoch 0:  54%|█████▍    | 52/96 [00:21<00:17,  2.45it/s, loss=0.426, v_num=19, train_loss_step=0.358]Epoch 0:  55%|█████▌    | 53/96 [00:22<00:17,  2.45it/s, loss=0.426, v_num=19, train_loss_step=0.358]Epoch 0:  55%|█████▌    | 53/96 [00:22<00:17,  2.45it/s, loss=0.422, v_num=19, train_loss_step=0.390]Epoch 0:  56%|█████▋    | 54/96 [00:22<00:17,  2.45it/s, loss=0.422, v_num=19, train_loss_step=0.390]Epoch 0:  56%|█████▋    | 54/96 [00:22<00:17,  2.45it/s, loss=0.411, v_num=19, train_loss_step=0.346]Epoch 0:  57%|█████▋    | 55/96 [00:22<00:16,  2.45it/s, loss=0.411, v_num=19, train_loss_step=0.346]Epoch 0:  57%|█████▋    | 55/96 [00:22<00:16,  2.45it/s, loss=0.406, v_num=19, train_loss_step=0.356]Epoch 0:  58%|█████▊    | 56/96 [00:23<00:16,  2.45it/s, loss=0.406, v_num=19, train_loss_step=0.356]Epoch 0:  58%|█████▊    | 56/96 [00:23<00:16,  2.45it/s, loss=0.402, v_num=19, train_loss_step=0.368]Epoch 0:  59%|█████▉    | 57/96 [00:23<00:15,  2.44it/s, loss=0.402, v_num=19, train_loss_step=0.368]Epoch 0:  59%|█████▉    | 57/96 [00:23<00:15,  2.44it/s, loss=0.403, v_num=19, train_loss_step=0.402]Epoch 0:  60%|██████    | 58/96 [00:24<00:15,  2.44it/s, loss=0.403, v_num=19, train_loss_step=0.402]Epoch 0:  60%|██████    | 58/96 [00:24<00:15,  2.44it/s, loss=0.407, v_num=19, train_loss_step=0.467]Epoch 0:  61%|██████▏   | 59/96 [00:24<00:15,  2.44it/s, loss=0.407, v_num=19, train_loss_step=0.467]Epoch 0:  61%|██████▏   | 59/96 [00:24<00:15,  2.44it/s, loss=0.407, v_num=19, train_loss_step=0.338]Epoch 0:  62%|██████▎   | 60/96 [00:24<00:14,  2.44it/s, loss=0.407, v_num=19, train_loss_step=0.338]Epoch 0:  62%|██████▎   | 60/96 [00:24<00:14,  2.44it/s, loss=0.406, v_num=19, train_loss_step=0.399]Epoch 0:  64%|██████▎   | 61/96 [00:25<00:14,  2.44it/s, loss=0.406, v_num=19, train_loss_step=0.399]Epoch 0:  64%|██████▎   | 61/96 [00:25<00:14,  2.44it/s, loss=0.404, v_num=19, train_loss_step=0.427]Epoch 0:  65%|██████▍   | 62/96 [00:25<00:13,  2.44it/s, loss=0.404, v_num=19, train_loss_step=0.427]Epoch 0:  65%|██████▍   | 62/96 [00:25<00:13,  2.44it/s, loss=0.401, v_num=19, train_loss_step=0.358]Epoch 0:  66%|██████▌   | 63/96 [00:26<00:13,  2.44it/s, loss=0.401, v_num=19, train_loss_step=0.358]Epoch 0:  66%|██████▌   | 63/96 [00:26<00:13,  2.44it/s, loss=0.395, v_num=19, train_loss_step=0.385]Epoch 0:  67%|██████▋   | 64/96 [00:26<00:13,  2.44it/s, loss=0.395, v_num=19, train_loss_step=0.385]Epoch 0:  67%|██████▋   | 64/96 [00:26<00:13,  2.44it/s, loss=0.396, v_num=19, train_loss_step=0.424]Epoch 0:  68%|██████▊   | 65/96 [00:27<00:12,  2.44it/s, loss=0.396, v_num=19, train_loss_step=0.424]Epoch 0:  68%|██████▊   | 65/96 [00:27<00:12,  2.44it/s, loss=0.397, v_num=19, train_loss_step=0.346]Epoch 0:  69%|██████▉   | 66/96 [00:27<00:12,  2.44it/s, loss=0.397, v_num=19, train_loss_step=0.346]Epoch 0:  69%|██████▉   | 66/96 [00:27<00:12,  2.44it/s, loss=0.392, v_num=19, train_loss_step=0.367]Epoch 0:  70%|██████▉   | 67/96 [00:27<00:11,  2.44it/s, loss=0.392, v_num=19, train_loss_step=0.367]Epoch 0:  70%|██████▉   | 67/96 [00:27<00:11,  2.44it/s, loss=0.392, v_num=19, train_loss_step=0.355]Epoch 0:  71%|███████   | 68/96 [00:28<00:11,  2.44it/s, loss=0.392, v_num=19, train_loss_step=0.355]Epoch 0:  71%|███████   | 68/96 [00:28<00:11,  2.44it/s, loss=0.39, v_num=19, train_loss_step=0.406] Epoch 0:  72%|███████▏  | 69/96 [00:28<00:11,  2.44it/s, loss=0.39, v_num=19, train_loss_step=0.406]Epoch 0:  72%|███████▏  | 69/96 [00:28<00:11,  2.44it/s, loss=0.387, v_num=19, train_loss_step=0.368]Epoch 0:  73%|███████▎  | 70/96 [00:29<00:10,  2.44it/s, loss=0.387, v_num=19, train_loss_step=0.368]Epoch 0:  73%|███████▎  | 70/96 [00:29<00:10,  2.44it/s, loss=0.38, v_num=19, train_loss_step=0.345] Epoch 0:  74%|███████▍  | 71/96 [00:29<00:10,  2.44it/s, loss=0.38, v_num=19, train_loss_step=0.345]Epoch 0:  74%|███████▍  | 71/96 [00:29<00:10,  2.44it/s, loss=0.382, v_num=19, train_loss_step=0.440]Epoch 0:  75%|███████▌  | 72/96 [00:29<00:09,  2.44it/s, loss=0.382, v_num=19, train_loss_step=0.440]Epoch 0:  75%|███████▌  | 72/96 [00:29<00:09,  2.44it/s, loss=0.386, v_num=19, train_loss_step=0.439]Epoch 0:  76%|███████▌  | 73/96 [00:30<00:09,  2.44it/s, loss=0.386, v_num=19, train_loss_step=0.439]Epoch 0:  76%|███████▌  | 73/96 [00:30<00:09,  2.44it/s, loss=0.387, v_num=19, train_loss_step=0.395]Epoch 0:  77%|███████▋  | 74/96 [00:30<00:09,  2.44it/s, loss=0.387, v_num=19, train_loss_step=0.395]Epoch 0:  77%|███████▋  | 74/96 [00:30<00:09,  2.44it/s, loss=0.39, v_num=19, train_loss_step=0.417] Epoch 0:  78%|███████▊  | 75/96 [00:31<00:08,  2.44it/s, loss=0.39, v_num=19, train_loss_step=0.417]Epoch 0:  78%|███████▊  | 75/96 [00:31<00:08,  2.44it/s, loss=0.394, v_num=19, train_loss_step=0.442]Epoch 0:  79%|███████▉  | 76/96 [00:31<00:08,  2.44it/s, loss=0.394, v_num=19, train_loss_step=0.442]Epoch 0:  79%|███████▉  | 76/96 [00:31<00:08,  2.44it/s, loss=0.396, v_num=19, train_loss_step=0.390]Epoch 0:  80%|████████  | 77/96 [00:32<00:07,  2.43it/s, loss=0.396, v_num=19, train_loss_step=0.390]Epoch 0:  80%|████████  | 77/96 [00:32<00:07,  2.43it/s, loss=0.395, v_num=19, train_loss_step=0.387]Epoch 0:  81%|████████▏ | 78/96 [00:32<00:07,  2.43it/s, loss=0.395, v_num=19, train_loss_step=0.387]Epoch 0:  81%|████████▏ | 78/96 [00:32<00:07,  2.43it/s, loss=0.391, v_num=19, train_loss_step=0.390]Epoch 0:  82%|████████▏ | 79/96 [00:32<00:06,  2.43it/s, loss=0.391, v_num=19, train_loss_step=0.390]Epoch 0:  82%|████████▏ | 79/96 [00:32<00:06,  2.43it/s, loss=0.395, v_num=19, train_loss_step=0.412]Epoch 0:  83%|████████▎ | 80/96 [00:33<00:06,  2.43it/s, loss=0.395, v_num=19, train_loss_step=0.412]Epoch 0:  83%|████████▎ | 80/96 [00:33<00:06,  2.43it/s, loss=0.392, v_num=19, train_loss_step=0.345]Epoch 0:  84%|████████▍ | 81/96 [00:33<00:06,  2.43it/s, loss=0.392, v_num=19, train_loss_step=0.345]Epoch 0:  84%|████████▍ | 81/96 [00:33<00:06,  2.43it/s, loss=0.393, v_num=19, train_loss_step=0.444]Epoch 0:  85%|████████▌ | 82/96 [00:34<00:05,  2.43it/s, loss=0.393, v_num=19, train_loss_step=0.444]Epoch 0:  85%|████████▌ | 82/96 [00:34<00:05,  2.43it/s, loss=0.396, v_num=19, train_loss_step=0.421]Epoch 0:  86%|████████▋ | 83/96 [00:34<00:05,  2.43it/s, loss=0.396, v_num=19, train_loss_step=0.421]Epoch 0:  86%|████████▋ | 83/96 [00:34<00:05,  2.43it/s, loss=0.395, v_num=19, train_loss_step=0.373]Epoch 0:  88%|████████▊ | 84/96 [00:34<00:04,  2.45it/s, loss=0.395, v_num=19, train_loss_step=0.373]Epoch 0:  88%|████████▊ | 84/96 [00:34<00:04,  2.45it/s, loss=0.394, v_num=19, train_loss_step=0.393]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/12 [00:00<?, ?it/s][A
Validating:   8%|▊         | 1/12 [00:01<00:13,  1.23s/it][AEpoch 0:  90%|████████▉ | 86/96 [00:35<00:04,  2.42it/s, loss=0.394, v_num=19, train_loss_step=0.393]
Validating:  17%|█▋        | 2/12 [00:02<00:12,  1.23s/it][A
Validating:  25%|██▌       | 3/12 [00:03<00:11,  1.23s/it][AEpoch 0:  92%|█████████▏| 88/96 [00:38<00:03,  2.32it/s, loss=0.394, v_num=19, train_loss_step=0.393]
Validating:  33%|███▎      | 4/12 [00:04<00:09,  1.22s/it][A
Validating:  42%|████▏     | 5/12 [00:06<00:08,  1.22s/it][AEpoch 0:  94%|█████████▍| 90/96 [00:40<00:02,  2.23it/s, loss=0.394, v_num=19, train_loss_step=0.393]
Validating:  50%|█████     | 6/12 [00:07<00:07,  1.22s/it][A
Validating:  58%|█████▊    | 7/12 [00:08<00:06,  1.22s/it][AEpoch 0:  96%|█████████▌| 92/96 [00:43<00:01,  2.15it/s, loss=0.394, v_num=19, train_loss_step=0.393]
Validating:  67%|██████▋   | 8/12 [00:09<00:04,  1.23s/it][A
Validating:  75%|███████▌  | 9/12 [00:11<00:03,  1.22s/it][AEpoch 0:  98%|█████████▊| 94/96 [00:45<00:00,  2.08it/s, loss=0.394, v_num=19, train_loss_step=0.393]
Validating:  83%|████████▎ | 10/12 [00:12<00:02,  1.22s/it][A
Validating:  92%|█████████▏| 11/12 [00:13<00:01,  1.21s/it][AEpoch 0: 100%|██████████| 96/96 [00:48<00:00,  2.02it/s, loss=0.394, v_num=19, train_loss_step=0.393]
Validating: 100%|██████████| 12/12 [00:13<00:00,  1.01s/it][AEpoch 0: 100%|██████████| 96/96 [00:48<00:00,  1.99it/s, loss=0.394, v_num=19, train_loss_step=0.393]
                                                           [AEpoch 0: 100%|██████████| 96/96 [00:48<00:00,  1.99it/s, loss=0.394, v_num=19, train_loss_step=0.393]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(

Testing: 0it [00:00, ?it/s]Testing:   1%|          | 1/169 [00:00<00:23,  7.25it/s]Testing:   1%|          | 2/169 [00:00<00:22,  7.58it/s]Testing:   2%|▏         | 3/169 [00:00<00:21,  7.75it/s]Testing:   2%|▏         | 4/169 [00:00<00:20,  7.93it/s]Testing:   3%|▎         | 5/169 [00:00<00:20,  7.97it/s]Testing:   4%|▎         | 6/169 [00:00<00:20,  8.03it/s]Testing:   4%|▍         | 7/169 [00:00<00:20,  8.09it/s]Testing:   5%|▍         | 8/169 [00:01<00:19,  8.11it/s]Testing:   5%|▌         | 9/169 [00:01<00:19,  8.10it/s]Testing:   6%|▌         | 10/169 [00:01<00:19,  8.13it/s]Testing:   7%|▋         | 11/169 [00:01<00:19,  8.10it/s]Testing:   7%|▋         | 12/169 [00:01<00:19,  8.13it/s]Testing:   8%|▊         | 13/169 [00:01<00:19,  8.09it/s]Testing:   8%|▊         | 14/169 [00:01<00:19,  8.12it/s]Testing:   9%|▉         | 15/169 [00:01<00:19,  8.10it/s]Testing:   9%|▉         | 16/169 [00:01<00:18,  8.13it/s]Testing:  10%|█         | 17/169 [00:02<00:18,  8.10it/s]Testing:  11%|█         | 18/169 [00:02<00:18,  8.14it/s]Testing:  11%|█         | 19/169 [00:02<00:18,  8.10it/s]Testing:  12%|█▏        | 20/169 [00:02<00:18,  8.09it/s]Testing:  12%|█▏        | 21/169 [00:02<00:18,  8.09it/s]Testing:  13%|█▎        | 22/169 [00:02<00:18,  8.11it/s]Testing:  14%|█▎        | 23/169 [00:02<00:17,  8.13it/s]Testing:  14%|█▍        | 24/169 [00:02<00:17,  8.13it/s]Testing:  15%|█▍        | 25/169 [00:03<00:17,  8.12it/s]Testing:  15%|█▌        | 26/169 [00:03<00:17,  8.13it/s]Testing:  16%|█▌        | 27/169 [00:03<00:17,  8.08it/s]Testing:  17%|█▋        | 28/169 [00:03<00:17,  8.05it/s]Testing:  17%|█▋        | 29/169 [00:03<00:17,  7.97it/s]Testing:  18%|█▊        | 30/169 [00:03<00:17,  7.97it/s]Testing:  18%|█▊        | 31/169 [00:03<00:17,  7.94it/s]Testing:  19%|█▉        | 32/169 [00:03<00:17,  7.95it/s]Testing:  20%|█▉        | 33/169 [00:04<00:17,  7.93it/s]Testing:  20%|██        | 34/169 [00:04<00:17,  7.94it/s]Testing:  21%|██        | 35/169 [00:04<00:16,  7.98it/s]Testing:  21%|██▏       | 36/169 [00:04<00:16,  7.96it/s]Testing:  22%|██▏       | 37/169 [00:04<00:16,  8.00it/s]Testing:  22%|██▏       | 38/169 [00:04<00:16,  7.99it/s]Testing:  23%|██▎       | 39/169 [00:04<00:16,  7.97it/s]Testing:  24%|██▎       | 40/169 [00:04<00:16,  7.99it/s]Testing:  24%|██▍       | 41/169 [00:05<00:16,  7.91it/s]Testing:  25%|██▍       | 42/169 [00:05<00:16,  7.88it/s]Testing:  25%|██▌       | 43/169 [00:05<00:15,  7.91it/s]Testing:  26%|██▌       | 44/169 [00:05<00:15,  7.85it/s]Testing:  27%|██▋       | 45/169 [00:05<00:15,  7.91it/s]Testing:  27%|██▋       | 46/169 [00:05<00:15,  7.89it/s]Testing:  28%|██▊       | 47/169 [00:05<00:15,  7.91it/s]Testing:  28%|██▊       | 48/169 [00:05<00:15,  7.98it/s]Testing:  29%|██▉       | 49/169 [00:06<00:15,  7.97it/s]Testing:  30%|██▉       | 50/169 [00:06<00:14,  7.97it/s]Testing:  30%|███       | 51/169 [00:06<00:14,  8.00it/s]Testing:  31%|███       | 52/169 [00:06<00:14,  8.00it/s]Testing:  31%|███▏      | 53/169 [00:06<00:14,  7.99it/s]Testing:  32%|███▏      | 54/169 [00:06<00:14,  8.02it/s]Testing:  33%|███▎      | 55/169 [00:06<00:14,  8.02it/s]Testing:  33%|███▎      | 56/169 [00:06<00:14,  8.04it/s]Testing:  34%|███▎      | 57/169 [00:07<00:13,  8.06it/s]Testing:  34%|███▍      | 58/169 [00:07<00:13,  8.03it/s]Testing:  35%|███▍      | 59/169 [00:07<00:13,  8.01it/s]Testing:  36%|███▌      | 60/169 [00:07<00:13,  8.03it/s]Testing:  36%|███▌      | 61/169 [00:07<00:13,  8.09it/s]Testing:  37%|███▋      | 62/169 [00:07<00:13,  8.05it/s]Testing:  37%|███▋      | 63/169 [00:07<00:13,  8.02it/s]Testing:  38%|███▊      | 64/169 [00:07<00:13,  8.02it/s]Testing:  38%|███▊      | 65/169 [00:08<00:12,  8.01it/s]Testing:  39%|███▉      | 66/169 [00:08<00:12,  8.06it/s]Testing:  40%|███▉      | 67/169 [00:08<00:12,  8.06it/s]Testing:  40%|████      | 68/169 [00:08<00:12,  8.00it/s]Testing:  41%|████      | 69/169 [00:08<00:12,  8.00it/s]Testing:  41%|████▏     | 70/169 [00:08<00:12,  7.96it/s]Testing:  42%|████▏     | 71/169 [00:08<00:12,  7.96it/s]Testing:  43%|████▎     | 72/169 [00:08<00:12,  7.96it/s]Testing:  43%|████▎     | 73/169 [00:09<00:12,  7.99it/s]Testing:  44%|████▍     | 74/169 [00:09<00:11,  8.01it/s]Testing:  44%|████▍     | 75/169 [00:09<00:11,  8.00it/s]Testing:  45%|████▍     | 76/169 [00:09<00:11,  8.01it/s]Testing:  46%|████▌     | 77/169 [00:09<00:11,  8.01it/s]Testing:  46%|████▌     | 78/169 [00:09<00:11,  8.02it/s]Testing:  47%|████▋     | 79/169 [00:09<00:11,  8.02it/s]Testing:  47%|████▋     | 80/169 [00:09<00:11,  8.00it/s]Testing:  48%|████▊     | 81/169 [00:10<00:10,  8.01it/s]Testing:  49%|████▊     | 82/169 [00:10<00:10,  8.02it/s]Testing:  49%|████▉     | 83/169 [00:10<00:10,  8.04it/s]Testing:  50%|████▉     | 84/169 [00:10<00:10,  8.04it/s]Testing:  50%|█████     | 85/169 [00:10<00:10,  8.02it/s]Testing:  51%|█████     | 86/169 [00:10<00:10,  8.03it/s]Testing:  51%|█████▏    | 87/169 [00:10<00:10,  7.97it/s]Testing:  52%|█████▏    | 88/169 [00:10<00:10,  7.94it/s]Testing:  53%|█████▎    | 89/169 [00:11<00:10,  7.97it/s]Testing:  53%|█████▎    | 90/169 [00:11<00:09,  7.99it/s]Testing:  54%|█████▍    | 91/169 [00:11<00:09,  7.94it/s]Testing:  54%|█████▍    | 92/169 [00:11<00:09,  7.97it/s]Testing:  55%|█████▌    | 93/169 [00:11<00:09,  7.98it/s]Testing:  56%|█████▌    | 94/169 [00:11<00:09,  8.00it/s]Testing:  56%|█████▌    | 95/169 [00:11<00:09,  8.03it/s]Testing:  57%|█████▋    | 96/169 [00:11<00:09,  8.01it/s]Testing:  57%|█████▋    | 97/169 [00:12<00:09,  7.98it/s]Testing:  58%|█████▊    | 98/169 [00:12<00:08,  8.02it/s]Testing:  59%|█████▊    | 99/169 [00:12<00:08,  7.99it/s]Testing:  59%|█████▉    | 100/169 [00:12<00:08,  8.01it/s]Testing:  60%|█████▉    | 101/169 [00:12<00:08,  8.02it/s]Testing:  60%|██████    | 102/169 [00:12<00:08,  8.01it/s]Testing:  61%|██████    | 103/169 [00:12<00:08,  8.05it/s]Testing:  62%|██████▏   | 104/169 [00:12<00:08,  8.02it/s]Testing:  62%|██████▏   | 105/169 [00:13<00:08,  7.98it/s]Testing:  63%|██████▎   | 106/169 [00:13<00:07,  7.98it/s]Testing:  63%|██████▎   | 107/169 [00:13<00:07,  7.97it/s]Testing:  64%|██████▍   | 108/169 [00:13<00:07,  7.98it/s]Testing:  64%|██████▍   | 109/169 [00:13<00:07,  7.99it/s]Testing:  65%|██████▌   | 110/169 [00:13<00:07,  8.02it/s]Testing:  66%|██████▌   | 111/169 [00:13<00:07,  8.02it/s]Testing:  66%|██████▋   | 112/169 [00:13<00:07,  8.00it/s]Testing:  67%|██████▋   | 113/169 [00:14<00:06,  8.00it/s]Testing:  67%|██████▋   | 114/169 [00:14<00:06,  7.98it/s]Testing:  68%|██████▊   | 115/169 [00:14<00:06,  7.98it/s]Testing:  69%|██████▊   | 116/169 [00:14<00:06,  7.97it/s]Testing:  69%|██████▉   | 117/169 [00:14<00:06,  7.94it/s]Testing:  70%|██████▉   | 118/169 [00:14<00:06,  7.94it/s]Testing:  70%|███████   | 119/169 [00:14<00:06,  7.96it/s]Testing:  71%|███████   | 120/169 [00:14<00:06,  7.96it/s]Testing:  72%|███████▏  | 121/169 [00:15<00:05,  8.00it/s]Testing:  72%|███████▏  | 122/169 [00:15<00:05,  8.00it/s]Testing:  73%|███████▎  | 123/169 [00:15<00:05,  8.00it/s]Testing:  73%|███████▎  | 124/169 [00:15<00:05,  7.99it/s]Testing:  74%|███████▍  | 125/169 [00:15<00:05,  7.98it/s]Testing:  75%|███████▍  | 126/169 [00:15<00:05,  7.97it/s]Testing:  75%|███████▌  | 127/169 [00:15<00:05,  7.97it/s]Testing:  76%|███████▌  | 128/169 [00:15<00:05,  8.02it/s]Testing:  76%|███████▋  | 129/169 [00:16<00:04,  8.02it/s]Testing:  77%|███████▋  | 130/169 [00:16<00:04,  8.00it/s]Testing:  78%|███████▊  | 131/169 [00:16<00:04,  7.98it/s]Testing:  78%|███████▊  | 132/169 [00:16<00:04,  8.01it/s]Testing:  79%|███████▊  | 133/169 [00:16<00:04,  7.99it/s]Testing:  79%|███████▉  | 134/169 [00:16<00:04,  8.03it/s]Testing:  80%|███████▉  | 135/169 [00:16<00:04,  8.03it/s]Testing:  80%|████████  | 136/169 [00:16<00:04,  8.03it/s]Testing:  81%|████████  | 137/169 [00:17<00:04,  7.99it/s]Testing:  82%|████████▏ | 138/169 [00:17<00:03,  7.95it/s]Testing:  82%|████████▏ | 139/169 [00:17<00:03,  7.96it/s]Testing:  83%|████████▎ | 140/169 [00:17<00:03,  7.98it/s]Testing:  83%|████████▎ | 141/169 [00:17<00:03,  8.01it/s]Testing:  84%|████████▍ | 142/169 [00:17<00:03,  8.01it/s]Testing:  85%|████████▍ | 143/169 [00:17<00:03,  8.04it/s]Testing:  85%|████████▌ | 144/169 [00:17<00:03,  8.02it/s]Testing:  86%|████████▌ | 145/169 [00:18<00:02,  8.01it/s]Testing:  86%|████████▋ | 146/169 [00:18<00:02,  8.00it/s]Testing:  87%|████████▋ | 147/169 [00:18<00:02,  8.03it/s]Testing:  88%|████████▊ | 148/169 [00:18<00:02,  7.94it/s]Testing:  88%|████████▊ | 149/169 [00:18<00:02,  7.98it/s]Testing:  89%|████████▉ | 150/169 [00:18<00:02,  8.01it/s]Testing:  89%|████████▉ | 151/169 [00:18<00:02,  8.01it/s]Testing:  90%|████████▉ | 152/169 [00:18<00:02,  7.98it/s]Testing:  91%|█████████ | 153/169 [00:19<00:02,  7.97it/s]Testing:  91%|█████████ | 154/169 [00:19<00:01,  7.97it/s]Testing:  92%|█████████▏| 155/169 [00:19<00:01,  7.98it/s]Testing:  92%|█████████▏| 156/169 [00:19<00:01,  7.98it/s]Testing:  93%|█████████▎| 157/169 [00:19<00:01,  7.97it/s]Testing:  93%|█████████▎| 158/169 [00:19<00:01,  7.90it/s]Testing:  94%|█████████▍| 159/169 [00:19<00:01,  7.89it/s]Testing:  95%|█████████▍| 160/169 [00:20<00:01,  7.92it/s]Testing:  95%|█████████▌| 161/169 [00:20<00:01,  7.94it/s]Testing:  96%|█████████▌| 162/169 [00:20<00:00,  7.91it/s]Testing:  96%|█████████▋| 163/169 [00:20<00:00,  7.96it/s]Testing:  97%|█████████▋| 164/169 [00:20<00:00,  7.96it/s]Testing:  98%|█████████▊| 165/169 [00:20<00:00,  7.91it/s]Testing:  98%|█████████▊| 166/169 [00:20<00:00,  7.90it/s]Testing:  99%|█████████▉| 167/169 [00:20<00:00,  7.93it/s]Testing:  99%|█████████▉| 168/169 [00:21<00:00,  7.93it/s]Testing: 100%|██████████| 169/169 [00:21<00:00,  7.97it/s]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'_mean_accuracy': 0.9227982759475708,
 '_standard_dev_accuracy': 0.06861376017332077,
 '_variance_accuracy': 0.004707847721874714,
 'test_acc': 0.9227980971336365,
 'test_dice_c1': 0.20341861248016357,
 'test_f2_c1': 0.259023517370224,
 'test_loss': 0.37877488136291504,
 'test_mean_c1': 0.45569542050361633,
 'test_prec_c1': 0.16430401802062988,
 'test_sens_c1': 0.4579542279243469,
 'test_spec_c1': 0.922990083694458}
--------------------------------------------------------------------------------
Testing: 100%|██████████| 169/169 [00:21<00:00,  7.99it/s]
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

  | Name       | Type             | Params
------------------------------------------------
0 | encoder1   | EncoderBlock     | 37.6 K
1 | encoder2   | EncoderBlock     | 221 K 
2 | bottleneck | ConvolutionBlock | 885 K 
3 | dropout    | Dropout2d        | 0     
4 | decoder1   | DecoderBlock     | 573 K 
5 | decoder2   | DecoderBlock     | 143 K 
6 | conv       | Conv2d           | 130   
7 | softmax    | Softmax2d        | 0     
------------------------------------------------
1.9 M     Trainable params
0         Non-trainable params
1.9 M     Total params
7.447     Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Validation sanity check:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Validation sanity check: 100%|██████████| 2/2 [00:04<00:00,  1.98s/it]                                                                      /home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Training: -1it [00:00, ?it/s]Training:   0%|          | 0/64 [00:00<00:00, 30174.85it/s]Epoch 0:   0%|          | 0/64 [00:00<00:00, 5533.38it/s]  Epoch 0:   2%|▏         | 1/64 [00:00<00:23,  2.74it/s]  Epoch 0:   2%|▏         | 1/64 [00:00<00:23,  2.74it/s, loss=0.725, v_num=20, train_loss_step=0.725]Epoch 0:   3%|▎         | 2/64 [00:01<00:28,  2.19it/s, loss=0.725, v_num=20, train_loss_step=0.725]Epoch 0:   3%|▎         | 2/64 [00:01<00:28,  2.19it/s, loss=0.721, v_num=20, train_loss_step=0.718]Epoch 0:   5%|▍         | 3/64 [00:02<00:30,  1.99it/s, loss=0.721, v_num=20, train_loss_step=0.718]Epoch 0:   5%|▍         | 3/64 [00:02<00:30,  1.98it/s, loss=0.722, v_num=20, train_loss_step=0.723]Epoch 0:   6%|▋         | 4/64 [00:02<00:31,  1.88it/s, loss=0.722, v_num=20, train_loss_step=0.723]Epoch 0:   6%|▋         | 4/64 [00:02<00:31,  1.88it/s, loss=0.721, v_num=20, train_loss_step=0.717]Epoch 0:   8%|▊         | 5/64 [00:03<00:32,  1.82it/s, loss=0.721, v_num=20, train_loss_step=0.717]Epoch 0:   8%|▊         | 5/64 [00:03<00:32,  1.82it/s, loss=0.721, v_num=20, train_loss_step=0.720]Epoch 0:   9%|▉         | 6/64 [00:03<00:32,  1.78it/s, loss=0.721, v_num=20, train_loss_step=0.720]Epoch 0:   9%|▉         | 6/64 [00:03<00:32,  1.78it/s, loss=0.721, v_num=20, train_loss_step=0.721]Epoch 0:  11%|█         | 7/64 [00:04<00:32,  1.74it/s, loss=0.721, v_num=20, train_loss_step=0.721]Epoch 0:  11%|█         | 7/64 [00:04<00:32,  1.74it/s, loss=0.721, v_num=20, train_loss_step=0.725]Epoch 0:  12%|█▎        | 8/64 [00:05<00:32,  1.72it/s, loss=0.721, v_num=20, train_loss_step=0.725]Epoch 0:  12%|█▎        | 8/64 [00:05<00:32,  1.72it/s, loss=0.721, v_num=20, train_loss_step=0.719]Epoch 0:  14%|█▍        | 9/64 [00:05<00:32,  1.70it/s, loss=0.721, v_num=20, train_loss_step=0.719]Epoch 0:  14%|█▍        | 9/64 [00:05<00:32,  1.70it/s, loss=0.721, v_num=20, train_loss_step=0.718]Epoch 0:  16%|█▌        | 10/64 [00:06<00:32,  1.69it/s, loss=0.721, v_num=20, train_loss_step=0.718]Epoch 0:  16%|█▌        | 10/64 [00:06<00:32,  1.69it/s, loss=0.721, v_num=20, train_loss_step=0.722]Epoch 0:  17%|█▋        | 11/64 [00:07<00:31,  1.68it/s, loss=0.721, v_num=20, train_loss_step=0.722]Epoch 0:  17%|█▋        | 11/64 [00:07<00:31,  1.68it/s, loss=0.721, v_num=20, train_loss_step=0.719]Epoch 0:  19%|█▉        | 12/64 [00:07<00:31,  1.67it/s, loss=0.721, v_num=20, train_loss_step=0.719]Epoch 0:  19%|█▉        | 12/64 [00:07<00:31,  1.67it/s, loss=0.72, v_num=20, train_loss_step=0.709] Epoch 0:  20%|██        | 13/64 [00:08<00:30,  1.66it/s, loss=0.72, v_num=20, train_loss_step=0.709]Epoch 0:  20%|██        | 13/64 [00:08<00:30,  1.66it/s, loss=0.719, v_num=20, train_loss_step=0.707]Epoch 0:  22%|██▏       | 14/64 [00:09<00:30,  1.65it/s, loss=0.719, v_num=20, train_loss_step=0.707]Epoch 0:  22%|██▏       | 14/64 [00:09<00:30,  1.65it/s, loss=0.718, v_num=20, train_loss_step=0.709]Epoch 0:  23%|██▎       | 15/64 [00:09<00:29,  1.64it/s, loss=0.718, v_num=20, train_loss_step=0.709]Epoch 0:  23%|██▎       | 15/64 [00:09<00:29,  1.64it/s, loss=0.717, v_num=20, train_loss_step=0.707]Epoch 0:  25%|██▌       | 16/64 [00:10<00:29,  1.64it/s, loss=0.717, v_num=20, train_loss_step=0.707]Epoch 0:  25%|██▌       | 16/64 [00:10<00:29,  1.64it/s, loss=0.717, v_num=20, train_loss_step=0.709]Epoch 0:  27%|██▋       | 17/64 [00:11<00:28,  1.63it/s, loss=0.717, v_num=20, train_loss_step=0.709]Epoch 0:  27%|██▋       | 17/64 [00:11<00:28,  1.63it/s, loss=0.716, v_num=20, train_loss_step=0.706]Epoch 0:  28%|██▊       | 18/64 [00:11<00:28,  1.63it/s, loss=0.716, v_num=20, train_loss_step=0.706]Epoch 0:  28%|██▊       | 18/64 [00:11<00:28,  1.63it/s, loss=0.716, v_num=20, train_loss_step=0.707]Epoch 0:  30%|██▉       | 19/64 [00:12<00:27,  1.63it/s, loss=0.716, v_num=20, train_loss_step=0.707]Epoch 0:  30%|██▉       | 19/64 [00:12<00:27,  1.63it/s, loss=0.715, v_num=20, train_loss_step=0.704]Epoch 0:  31%|███▏      | 20/64 [00:12<00:27,  1.62it/s, loss=0.715, v_num=20, train_loss_step=0.704]Epoch 0:  31%|███▏      | 20/64 [00:12<00:27,  1.62it/s, loss=0.714, v_num=20, train_loss_step=0.704]Epoch 0:  33%|███▎      | 21/64 [00:13<00:26,  1.62it/s, loss=0.714, v_num=20, train_loss_step=0.704]Epoch 0:  33%|███▎      | 21/64 [00:13<00:26,  1.62it/s, loss=0.713, v_num=20, train_loss_step=0.698]Epoch 0:  34%|███▍      | 22/64 [00:14<00:25,  1.62it/s, loss=0.713, v_num=20, train_loss_step=0.698]Epoch 0:  34%|███▍      | 22/64 [00:14<00:25,  1.62it/s, loss=0.712, v_num=20, train_loss_step=0.695]Epoch 0:  36%|███▌      | 23/64 [00:14<00:25,  1.62it/s, loss=0.712, v_num=20, train_loss_step=0.695]Epoch 0:  36%|███▌      | 23/64 [00:14<00:25,  1.62it/s, loss=0.71, v_num=20, train_loss_step=0.693] Epoch 0:  38%|███▊      | 24/64 [00:15<00:24,  1.61it/s, loss=0.71, v_num=20, train_loss_step=0.693]Epoch 0:  38%|███▊      | 24/64 [00:15<00:24,  1.61it/s, loss=0.709, v_num=20, train_loss_step=0.689]Epoch 0:  39%|███▉      | 25/64 [00:16<00:24,  1.61it/s, loss=0.709, v_num=20, train_loss_step=0.689]Epoch 0:  39%|███▉      | 25/64 [00:16<00:24,  1.61it/s, loss=0.707, v_num=20, train_loss_step=0.684]Epoch 0:  41%|████      | 26/64 [00:16<00:23,  1.61it/s, loss=0.707, v_num=20, train_loss_step=0.684]Epoch 0:  41%|████      | 26/64 [00:16<00:23,  1.61it/s, loss=0.705, v_num=20, train_loss_step=0.677]Epoch 0:  42%|████▏     | 27/64 [00:17<00:23,  1.60it/s, loss=0.705, v_num=20, train_loss_step=0.677]Epoch 0:  42%|████▏     | 27/64 [00:17<00:23,  1.60it/s, loss=0.702, v_num=20, train_loss_step=0.664]Epoch 0:  44%|████▍     | 28/64 [00:18<00:22,  1.60it/s, loss=0.702, v_num=20, train_loss_step=0.664]Epoch 0:  44%|████▍     | 28/64 [00:18<00:22,  1.60it/s, loss=0.699, v_num=20, train_loss_step=0.655]Epoch 0:  45%|████▌     | 29/64 [00:18<00:21,  1.60it/s, loss=0.699, v_num=20, train_loss_step=0.655]Epoch 0:  45%|████▌     | 29/64 [00:18<00:21,  1.60it/s, loss=0.695, v_num=20, train_loss_step=0.647]Epoch 0:  47%|████▋     | 30/64 [00:19<00:21,  1.60it/s, loss=0.695, v_num=20, train_loss_step=0.647]Epoch 0:  47%|████▋     | 30/64 [00:19<00:21,  1.60it/s, loss=0.69, v_num=20, train_loss_step=0.617] Epoch 0:  48%|████▊     | 31/64 [00:20<00:20,  1.60it/s, loss=0.69, v_num=20, train_loss_step=0.617]Epoch 0:  48%|████▊     | 31/64 [00:20<00:20,  1.60it/s, loss=0.685, v_num=20, train_loss_step=0.624]Epoch 0:  50%|█████     | 32/64 [00:20<00:20,  1.60it/s, loss=0.685, v_num=20, train_loss_step=0.624]Epoch 0:  50%|█████     | 32/64 [00:20<00:20,  1.60it/s, loss=0.679, v_num=20, train_loss_step=0.588]Epoch 0:  52%|█████▏    | 33/64 [00:21<00:19,  1.60it/s, loss=0.679, v_num=20, train_loss_step=0.588]Epoch 0:  52%|█████▏    | 33/64 [00:21<00:19,  1.60it/s, loss=0.672, v_num=20, train_loss_step=0.555]Epoch 0:  53%|█████▎    | 34/64 [00:21<00:18,  1.59it/s, loss=0.672, v_num=20, train_loss_step=0.555]Epoch 0:  53%|█████▎    | 34/64 [00:21<00:18,  1.59it/s, loss=0.659, v_num=20, train_loss_step=0.449]Epoch 0:  55%|█████▍    | 35/64 [00:22<00:18,  1.59it/s, loss=0.659, v_num=20, train_loss_step=0.449]Epoch 0:  55%|█████▍    | 35/64 [00:22<00:18,  1.59it/s, loss=0.649, v_num=20, train_loss_step=0.521]Epoch 0:  56%|█████▋    | 36/64 [00:23<00:17,  1.59it/s, loss=0.649, v_num=20, train_loss_step=0.521]Epoch 0:  56%|█████▋    | 36/64 [00:23<00:17,  1.59it/s, loss=0.645, v_num=20, train_loss_step=0.616]Epoch 0:  58%|█████▊    | 37/64 [00:23<00:16,  1.59it/s, loss=0.645, v_num=20, train_loss_step=0.616]Epoch 0:  58%|█████▊    | 37/64 [00:23<00:16,  1.59it/s, loss=0.64, v_num=20, train_loss_step=0.611] Epoch 0:  59%|█████▉    | 38/64 [00:24<00:16,  1.59it/s, loss=0.64, v_num=20, train_loss_step=0.611]Epoch 0:  59%|█████▉    | 38/64 [00:24<00:16,  1.59it/s, loss=0.636, v_num=20, train_loss_step=0.623]Epoch 0:  61%|██████    | 39/64 [00:25<00:15,  1.59it/s, loss=0.636, v_num=20, train_loss_step=0.623]Epoch 0:  61%|██████    | 39/64 [00:25<00:15,  1.59it/s, loss=0.621, v_num=20, train_loss_step=0.408]Epoch 0:  62%|██████▎   | 40/64 [00:25<00:15,  1.59it/s, loss=0.621, v_num=20, train_loss_step=0.408]Epoch 0:  62%|██████▎   | 40/64 [00:25<00:15,  1.59it/s, loss=0.609, v_num=20, train_loss_step=0.467]Epoch 0:  64%|██████▍   | 41/64 [00:26<00:14,  1.59it/s, loss=0.609, v_num=20, train_loss_step=0.467]Epoch 0:  64%|██████▍   | 41/64 [00:26<00:14,  1.59it/s, loss=0.595, v_num=20, train_loss_step=0.426]Epoch 0:  66%|██████▌   | 42/64 [00:27<00:13,  1.59it/s, loss=0.595, v_num=20, train_loss_step=0.426]Epoch 0:  66%|██████▌   | 42/64 [00:27<00:13,  1.59it/s, loss=0.579, v_num=20, train_loss_step=0.362]Epoch 0:  67%|██████▋   | 43/64 [00:27<00:13,  1.59it/s, loss=0.579, v_num=20, train_loss_step=0.362]Epoch 0:  67%|██████▋   | 43/64 [00:27<00:13,  1.59it/s, loss=0.568, v_num=20, train_loss_step=0.476]Epoch 0:  69%|██████▉   | 44/64 [00:28<00:12,  1.58it/s, loss=0.568, v_num=20, train_loss_step=0.476]Epoch 0:  69%|██████▉   | 44/64 [00:28<00:12,  1.58it/s, loss=0.566, v_num=20, train_loss_step=0.657]Epoch 0:  70%|███████   | 45/64 [00:29<00:11,  1.58it/s, loss=0.566, v_num=20, train_loss_step=0.657]Epoch 0:  70%|███████   | 45/64 [00:29<00:11,  1.58it/s, loss=0.561, v_num=20, train_loss_step=0.585]Epoch 0:  72%|███████▏  | 46/64 [00:29<00:11,  1.58it/s, loss=0.561, v_num=20, train_loss_step=0.585]Epoch 0:  72%|███████▏  | 46/64 [00:29<00:11,  1.58it/s, loss=0.551, v_num=20, train_loss_step=0.469]Epoch 0:  73%|███████▎  | 47/64 [00:30<00:10,  1.58it/s, loss=0.551, v_num=20, train_loss_step=0.469]Epoch 0:  73%|███████▎  | 47/64 [00:30<00:10,  1.58it/s, loss=0.547, v_num=20, train_loss_step=0.583]Epoch 0:  75%|███████▌  | 48/64 [00:30<00:10,  1.58it/s, loss=0.547, v_num=20, train_loss_step=0.583]Epoch 0:  75%|███████▌  | 48/64 [00:30<00:10,  1.58it/s, loss=0.539, v_num=20, train_loss_step=0.499]Epoch 0:  77%|███████▋  | 49/64 [00:31<00:09,  1.58it/s, loss=0.539, v_num=20, train_loss_step=0.499]Epoch 0:  77%|███████▋  | 49/64 [00:31<00:09,  1.58it/s, loss=0.532, v_num=20, train_loss_step=0.509]Epoch 0:  78%|███████▊  | 50/64 [00:32<00:08,  1.58it/s, loss=0.532, v_num=20, train_loss_step=0.509]Epoch 0:  78%|███████▊  | 50/64 [00:32<00:08,  1.58it/s, loss=0.523, v_num=20, train_loss_step=0.433]Epoch 0:  80%|███████▉  | 51/64 [00:32<00:08,  1.58it/s, loss=0.523, v_num=20, train_loss_step=0.433]Epoch 0:  80%|███████▉  | 51/64 [00:32<00:08,  1.58it/s, loss=0.527, v_num=20, train_loss_step=0.702]Epoch 0:  81%|████████▏ | 52/64 [00:33<00:07,  1.58it/s, loss=0.527, v_num=20, train_loss_step=0.702]Epoch 0:  81%|████████▏ | 52/64 [00:33<00:07,  1.58it/s, loss=0.516, v_num=20, train_loss_step=0.368]Epoch 0:  83%|████████▎ | 53/64 [00:34<00:06,  1.58it/s, loss=0.516, v_num=20, train_loss_step=0.368]Epoch 0:  83%|████████▎ | 53/64 [00:34<00:06,  1.58it/s, loss=0.51, v_num=20, train_loss_step=0.443] Epoch 0:  84%|████████▍ | 54/64 [00:34<00:06,  1.58it/s, loss=0.51, v_num=20, train_loss_step=0.443]Epoch 0:  84%|████████▍ | 54/64 [00:34<00:06,  1.58it/s, loss=0.509, v_num=20, train_loss_step=0.421]Epoch 0:  86%|████████▌ | 55/64 [00:35<00:05,  1.58it/s, loss=0.509, v_num=20, train_loss_step=0.421]Epoch 0:  86%|████████▌ | 55/64 [00:35<00:05,  1.58it/s, loss=0.509, v_num=20, train_loss_step=0.518]Epoch 0:  88%|████████▊ | 56/64 [00:35<00:05,  1.59it/s, loss=0.509, v_num=20, train_loss_step=0.518]Epoch 0:  88%|████████▊ | 56/64 [00:35<00:05,  1.59it/s, loss=0.509, v_num=20, train_loss_step=0.628]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/8 [00:00<?, ?it/s][A
Validating:  12%|█▎        | 1/8 [00:01<00:13,  1.86s/it][AEpoch 0:  91%|█████████ | 58/64 [00:37<00:03,  1.56it/s, loss=0.509, v_num=20, train_loss_step=0.628]
Validating:  25%|██▌       | 2/8 [00:03<00:11,  1.86s/it][A
Validating:  38%|███▊      | 3/8 [00:05<00:09,  1.87s/it][AEpoch 0:  94%|█████████▍| 60/64 [00:41<00:02,  1.47it/s, loss=0.509, v_num=20, train_loss_step=0.628]
Validating:  50%|█████     | 4/8 [00:07<00:07,  1.86s/it][A
Validating:  62%|██████▎   | 5/8 [00:09<00:05,  1.85s/it][AEpoch 0:  97%|█████████▋| 62/64 [00:45<00:01,  1.40it/s, loss=0.509, v_num=20, train_loss_step=0.628]
Validating:  75%|███████▌  | 6/8 [00:11<00:03,  1.85s/it][A
Validating:  88%|████████▊ | 7/8 [00:12<00:01,  1.84s/it][AEpoch 0: 100%|██████████| 64/64 [00:48<00:00,  1.33it/s, loss=0.509, v_num=20, train_loss_step=0.628]
Validating: 100%|██████████| 8/8 [00:14<00:00,  1.61s/it][AEpoch 0: 100%|██████████| 64/64 [00:49<00:00,  1.30it/s, loss=0.509, v_num=20, train_loss_step=0.628]
                                                         [AEpoch 0: 100%|██████████| 64/64 [00:50<00:00,  1.30it/s, loss=0.509, v_num=20, train_loss_step=0.628]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(

Testing: 0it [00:00, ?it/s]Testing:   1%|          | 1/169 [00:00<00:22,  7.38it/s]Testing:   1%|          | 2/169 [00:00<00:21,  7.73it/s]Testing:   2%|▏         | 3/169 [00:00<00:21,  7.84it/s]Testing:   2%|▏         | 4/169 [00:00<00:20,  7.88it/s]Testing:   3%|▎         | 5/169 [00:00<00:20,  7.97it/s]Testing:   4%|▎         | 6/169 [00:00<00:20,  7.98it/s]Testing:   4%|▍         | 7/169 [00:00<00:20,  8.02it/s]Testing:   5%|▍         | 8/169 [00:01<00:19,  8.05it/s]Testing:   5%|▌         | 9/169 [00:01<00:19,  8.04it/s]Testing:   6%|▌         | 10/169 [00:01<00:19,  8.08it/s]Testing:   7%|▋         | 11/169 [00:01<00:19,  8.05it/s]Testing:   7%|▋         | 12/169 [00:01<00:19,  8.08it/s]Testing:   8%|▊         | 13/169 [00:01<00:19,  8.08it/s]Testing:   8%|▊         | 14/169 [00:01<00:19,  8.10it/s]Testing:   9%|▉         | 15/169 [00:01<00:19,  8.07it/s]Testing:   9%|▉         | 16/169 [00:01<00:18,  8.11it/s]Testing:  10%|█         | 17/169 [00:02<00:18,  8.14it/s]Testing:  11%|█         | 18/169 [00:02<00:18,  8.12it/s]Testing:  11%|█         | 19/169 [00:02<00:18,  8.10it/s]Testing:  12%|█▏        | 20/169 [00:02<00:18,  8.12it/s]Testing:  12%|█▏        | 21/169 [00:02<00:18,  8.12it/s]Testing:  13%|█▎        | 22/169 [00:02<00:18,  8.06it/s]Testing:  14%|█▎        | 23/169 [00:02<00:18,  8.05it/s]Testing:  14%|█▍        | 24/169 [00:02<00:18,  8.03it/s]Testing:  15%|█▍        | 25/169 [00:03<00:17,  8.05it/s]Testing:  15%|█▌        | 26/169 [00:03<00:17,  8.04it/s]Testing:  16%|█▌        | 27/169 [00:03<00:17,  8.03it/s]Testing:  17%|█▋        | 28/169 [00:03<00:17,  8.04it/s]Testing:  17%|█▋        | 29/169 [00:03<00:17,  8.01it/s]Testing:  18%|█▊        | 30/169 [00:03<00:17,  8.02it/s]Testing:  18%|█▊        | 31/169 [00:03<00:17,  8.01it/s]Testing:  19%|█▉        | 32/169 [00:03<00:17,  8.02it/s]Testing:  20%|█▉        | 33/169 [00:04<00:16,  8.03it/s]Testing:  20%|██        | 34/169 [00:04<00:16,  8.03it/s]Testing:  21%|██        | 35/169 [00:04<00:16,  8.03it/s]Testing:  21%|██▏       | 36/169 [00:04<00:16,  8.05it/s]Testing:  22%|██▏       | 37/169 [00:04<00:16,  8.01it/s]Testing:  22%|██▏       | 38/169 [00:04<00:16,  8.01it/s]Testing:  23%|██▎       | 39/169 [00:04<00:16,  8.01it/s]Testing:  24%|██▎       | 40/169 [00:04<00:16,  7.99it/s]Testing:  24%|██▍       | 41/169 [00:05<00:16,  7.96it/s]Testing:  25%|██▍       | 42/169 [00:05<00:15,  7.99it/s]Testing:  25%|██▌       | 43/169 [00:05<00:15,  7.99it/s]Testing:  26%|██▌       | 44/169 [00:05<00:15,  7.99it/s]Testing:  27%|██▋       | 45/169 [00:05<00:15,  7.99it/s]Testing:  27%|██▋       | 46/169 [00:05<00:15,  8.01it/s]Testing:  28%|██▊       | 47/169 [00:05<00:15,  7.98it/s]Testing:  28%|██▊       | 48/169 [00:05<00:15,  8.01it/s]Testing:  29%|██▉       | 49/169 [00:06<00:14,  8.02it/s]Testing:  30%|██▉       | 50/169 [00:06<00:14,  8.02it/s]Testing:  30%|███       | 51/169 [00:06<00:14,  8.04it/s]Testing:  31%|███       | 52/169 [00:06<00:14,  8.04it/s]Testing:  31%|███▏      | 53/169 [00:06<00:14,  8.03it/s]Testing:  32%|███▏      | 54/169 [00:06<00:14,  8.03it/s]Testing:  33%|███▎      | 55/169 [00:06<00:14,  7.98it/s]Testing:  33%|███▎      | 56/169 [00:06<00:14,  8.01it/s]Testing:  34%|███▎      | 57/169 [00:07<00:14,  8.00it/s]Testing:  34%|███▍      | 58/169 [00:07<00:13,  7.99it/s]Testing:  35%|███▍      | 59/169 [00:07<00:13,  7.99it/s]Testing:  36%|███▌      | 60/169 [00:07<00:13,  8.01it/s]Testing:  36%|███▌      | 61/169 [00:07<00:13,  8.01it/s]Testing:  37%|███▋      | 62/169 [00:07<00:13,  7.96it/s]Testing:  37%|███▋      | 63/169 [00:07<00:13,  7.94it/s]Testing:  38%|███▊      | 64/169 [00:07<00:13,  7.99it/s]Testing:  38%|███▊      | 65/169 [00:08<00:13,  7.99it/s]Testing:  39%|███▉      | 66/169 [00:08<00:12,  8.03it/s]Testing:  40%|███▉      | 67/169 [00:08<00:12,  8.02it/s]Testing:  40%|████      | 68/169 [00:08<00:12,  8.02it/s]Testing:  41%|████      | 69/169 [00:08<00:12,  8.02it/s]Testing:  41%|████▏     | 70/169 [00:08<00:12,  8.04it/s]Testing:  42%|████▏     | 71/169 [00:08<00:12,  8.02it/s]Testing:  43%|████▎     | 72/169 [00:08<00:12,  8.04it/s]Testing:  43%|████▎     | 73/169 [00:09<00:11,  8.08it/s]Testing:  44%|████▍     | 74/169 [00:09<00:11,  8.02it/s]Testing:  44%|████▍     | 75/169 [00:09<00:11,  7.98it/s]Testing:  45%|████▍     | 76/169 [00:09<00:11,  8.00it/s]Testing:  46%|████▌     | 77/169 [00:09<00:11,  7.97it/s]Testing:  46%|████▌     | 78/169 [00:09<00:11,  7.95it/s]Testing:  47%|████▋     | 79/169 [00:09<00:11,  7.94it/s]Testing:  47%|████▋     | 80/169 [00:09<00:11,  7.97it/s]Testing:  48%|████▊     | 81/169 [00:10<00:11,  7.97it/s]Testing:  49%|████▊     | 82/169 [00:10<00:10,  7.96it/s]Testing:  49%|████▉     | 83/169 [00:10<00:10,  7.96it/s]Testing:  50%|████▉     | 84/169 [00:10<00:10,  8.00it/s]Testing:  50%|█████     | 85/169 [00:10<00:10,  7.99it/s]Testing:  51%|█████     | 86/169 [00:10<00:10,  8.00it/s]Testing:  51%|█████▏    | 87/169 [00:10<00:10,  7.99it/s]Testing:  52%|█████▏    | 88/169 [00:10<00:10,  7.98it/s]Testing:  53%|█████▎    | 89/169 [00:11<00:09,  8.00it/s]Testing:  53%|█████▎    | 90/169 [00:11<00:09,  7.98it/s]Testing:  54%|█████▍    | 91/169 [00:11<00:09,  7.98it/s]Testing:  54%|█████▍    | 92/169 [00:11<00:09,  7.95it/s]Testing:  55%|█████▌    | 93/169 [00:11<00:09,  7.97it/s]Testing:  56%|█████▌    | 94/169 [00:11<00:09,  8.02it/s]Testing:  56%|█████▌    | 95/169 [00:11<00:09,  8.00it/s]Testing:  57%|█████▋    | 96/169 [00:11<00:09,  8.01it/s]Testing:  57%|█████▋    | 97/169 [00:12<00:08,  8.03it/s]Testing:  58%|█████▊    | 98/169 [00:12<00:08,  7.98it/s]Testing:  59%|█████▊    | 99/169 [00:12<00:08,  7.98it/s]Testing:  59%|█████▉    | 100/169 [00:12<00:08,  7.98it/s]Testing:  60%|█████▉    | 101/169 [00:12<00:08,  7.99it/s]Testing:  60%|██████    | 102/169 [00:12<00:08,  8.01it/s]Testing:  61%|██████    | 103/169 [00:12<00:08,  8.00it/s]Testing:  62%|██████▏   | 104/169 [00:12<00:08,  8.02it/s]Testing:  62%|██████▏   | 105/169 [00:13<00:07,  8.02it/s]Testing:  63%|██████▎   | 106/169 [00:13<00:07,  8.04it/s]Testing:  63%|██████▎   | 107/169 [00:13<00:07,  8.03it/s]Testing:  64%|██████▍   | 108/169 [00:13<00:07,  8.04it/s]Testing:  64%|██████▍   | 109/169 [00:13<00:07,  8.01it/s]Testing:  65%|██████▌   | 110/169 [00:13<00:07,  7.99it/s]Testing:  66%|██████▌   | 111/169 [00:13<00:07,  7.97it/s]Testing:  66%|██████▋   | 112/169 [00:13<00:07,  7.99it/s]Testing:  67%|██████▋   | 113/169 [00:14<00:06,  8.00it/s]Testing:  67%|██████▋   | 114/169 [00:14<00:06,  7.96it/s]Testing:  68%|██████▊   | 115/169 [00:14<00:06,  7.92it/s]Testing:  69%|██████▊   | 116/169 [00:14<00:06,  7.94it/s]Testing:  69%|██████▉   | 117/169 [00:14<00:06,  7.89it/s]Testing:  70%|██████▉   | 118/169 [00:14<00:06,  7.97it/s]Testing:  70%|███████   | 119/169 [00:14<00:06,  7.99it/s]Testing:  71%|███████   | 120/169 [00:14<00:06,  7.99it/s]Testing:  72%|███████▏  | 121/169 [00:15<00:05,  8.01it/s]Testing:  72%|███████▏  | 122/169 [00:15<00:05,  8.02it/s]Testing:  73%|███████▎  | 123/169 [00:15<00:05,  8.02it/s]Testing:  73%|███████▎  | 124/169 [00:15<00:05,  8.03it/s]Testing:  74%|███████▍  | 125/169 [00:15<00:05,  7.98it/s]Testing:  75%|███████▍  | 126/169 [00:15<00:05,  7.96it/s]Testing:  75%|███████▌  | 127/169 [00:15<00:05,  7.97it/s]Testing:  76%|███████▌  | 128/169 [00:15<00:05,  7.99it/s]Testing:  76%|███████▋  | 129/169 [00:16<00:04,  8.01it/s]Testing:  77%|███████▋  | 130/169 [00:16<00:04,  8.00it/s]Testing:  78%|███████▊  | 131/169 [00:16<00:04,  8.00it/s]Testing:  78%|███████▊  | 132/169 [00:16<00:04,  8.00it/s]Testing:  79%|███████▊  | 133/169 [00:16<00:04,  8.02it/s]Testing:  79%|███████▉  | 134/169 [00:16<00:04,  8.02it/s]Testing:  80%|███████▉  | 135/169 [00:16<00:04,  8.02it/s]Testing:  80%|████████  | 136/169 [00:16<00:04,  8.00it/s]Testing:  81%|████████  | 137/169 [00:17<00:03,  8.02it/s]Testing:  82%|████████▏ | 138/169 [00:17<00:03,  8.05it/s]Testing:  82%|████████▏ | 139/169 [00:17<00:03,  8.03it/s]Testing:  83%|████████▎ | 140/169 [00:17<00:03,  8.01it/s]Testing:  83%|████████▎ | 141/169 [00:17<00:03,  7.98it/s]Testing:  84%|████████▍ | 142/169 [00:17<00:03,  7.97it/s]Testing:  85%|████████▍ | 143/169 [00:17<00:03,  7.97it/s]Testing:  85%|████████▌ | 144/169 [00:17<00:03,  8.02it/s]Testing:  86%|████████▌ | 145/169 [00:18<00:02,  8.02it/s]Testing:  86%|████████▋ | 146/169 [00:18<00:02,  8.04it/s]Testing:  87%|████████▋ | 147/169 [00:18<00:02,  7.99it/s]Testing:  88%|████████▊ | 148/169 [00:18<00:02,  7.99it/s]Testing:  88%|████████▊ | 149/169 [00:18<00:02,  8.03it/s]Testing:  89%|████████▉ | 150/169 [00:18<00:02,  8.05it/s]Testing:  89%|████████▉ | 151/169 [00:18<00:02,  8.02it/s]Testing:  90%|████████▉ | 152/169 [00:18<00:02,  8.03it/s]Testing:  91%|█████████ | 153/169 [00:19<00:01,  8.01it/s]Testing:  91%|█████████ | 154/169 [00:19<00:01,  8.04it/s]Testing:  92%|█████████▏| 155/169 [00:19<00:01,  8.01it/s]Testing:  92%|█████████▏| 156/169 [00:19<00:01,  7.99it/s]Testing:  93%|█████████▎| 157/169 [00:19<00:01,  8.03it/s]Testing:  93%|█████████▎| 158/169 [00:19<00:01,  7.99it/s]Testing:  94%|█████████▍| 159/169 [00:19<00:01,  7.97it/s]Testing:  95%|█████████▍| 160/169 [00:19<00:01,  8.00it/s]Testing:  95%|█████████▌| 161/169 [00:20<00:00,  8.02it/s]Testing:  96%|█████████▌| 162/169 [00:20<00:00,  7.97it/s]Testing:  96%|█████████▋| 163/169 [00:20<00:00,  7.98it/s]Testing:  97%|█████████▋| 164/169 [00:20<00:00,  7.96it/s]Testing:  98%|█████████▊| 165/169 [00:20<00:00,  7.97it/s]Testing:  98%|█████████▊| 166/169 [00:20<00:00,  7.97it/s]Testing:  99%|█████████▉| 167/169 [00:20<00:00,  7.97it/s]Testing:  99%|█████████▉| 168/169 [00:20<00:00,  7.96it/s]Testing: 100%|██████████| 169/169 [00:21<00:00,  7.99it/s]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'_mean_accuracy': 0.9876740574836731,
 '_standard_dev_accuracy': 0.030018869787454605,
 '_variance_accuracy': 0.0009011325309984386,
 'test_acc': 0.987674355506897,
 'test_dice_c1': 0.0,
 'test_f2_c1': 0.0,
 'test_loss': 0.4067150354385376,
 'test_mean_c1': 0.0,
 'test_prec_c1': 0.0,
 'test_sens_c1': 0.0,
 'test_spec_c1': 1.0}
--------------------------------------------------------------------------------
Testing: 100%|██████████| 169/169 [00:21<00:00,  8.00it/s]
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

  | Name       | Type             | Params
------------------------------------------------
0 | encoder1   | EncoderBlock     | 37.6 K
1 | encoder2   | EncoderBlock     | 221 K 
2 | bottleneck | ConvolutionBlock | 885 K 
3 | dropout    | Dropout2d        | 0     
4 | decoder1   | DecoderBlock     | 573 K 
5 | decoder2   | DecoderBlock     | 143 K 
6 | conv       | Conv2d           | 130   
7 | softmax    | Softmax2d        | 0     
------------------------------------------------
1.9 M     Trainable params
0         Non-trainable params
1.9 M     Total params
7.447     Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  2.03it/s]Validation sanity check: 100%|██████████| 2/2 [00:00<00:00,  2.71it/s]                                                                      /home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Training: -1it [00:00, ?it/s]Training:   0%|          | 0/380 [00:00<00:00, 28532.68it/s]Epoch 0:   0%|          | 0/380 [00:00<00:00, 4116.10it/s]  Epoch 0:   0%|          | 1/380 [00:00<00:25, 14.90it/s]  Epoch 0:   0%|          | 1/380 [00:00<00:25, 14.87it/s, loss=0.734, v_num=21, train_loss_step=0.734]Epoch 0:   1%|          | 2/380 [00:00<00:31, 12.10it/s, loss=0.734, v_num=21, train_loss_step=0.734]Epoch 0:   1%|          | 2/380 [00:00<00:31, 12.09it/s, loss=0.719, v_num=21, train_loss_step=0.704]Epoch 0:   1%|          | 3/380 [00:00<00:33, 11.19it/s, loss=0.719, v_num=21, train_loss_step=0.704]Epoch 0:   1%|          | 3/380 [00:00<00:33, 11.18it/s, loss=0.722, v_num=21, train_loss_step=0.729]Epoch 0:   1%|          | 4/380 [00:00<00:34, 10.85it/s, loss=0.722, v_num=21, train_loss_step=0.729]Epoch 0:   1%|          | 4/380 [00:00<00:34, 10.84it/s, loss=0.722, v_num=21, train_loss_step=0.723]Epoch 0:   1%|▏         | 5/380 [00:00<00:35, 10.58it/s, loss=0.722, v_num=21, train_loss_step=0.723]Epoch 0:   1%|▏         | 5/380 [00:00<00:35, 10.58it/s, loss=0.721, v_num=21, train_loss_step=0.715]Epoch 0:   2%|▏         | 6/380 [00:00<00:36, 10.38it/s, loss=0.721, v_num=21, train_loss_step=0.715]Epoch 0:   2%|▏         | 6/380 [00:00<00:36, 10.37it/s, loss=0.718, v_num=21, train_loss_step=0.701]Epoch 0:   2%|▏         | 7/380 [00:00<00:36, 10.27it/s, loss=0.718, v_num=21, train_loss_step=0.701]Epoch 0:   2%|▏         | 7/380 [00:00<00:36, 10.26it/s, loss=0.714, v_num=21, train_loss_step=0.693]Epoch 0:   2%|▏         | 8/380 [00:00<00:36, 10.18it/s, loss=0.714, v_num=21, train_loss_step=0.693]Epoch 0:   2%|▏         | 8/380 [00:00<00:36, 10.18it/s, loss=0.706, v_num=21, train_loss_step=0.651]Epoch 0:   2%|▏         | 9/380 [00:00<00:36, 10.09it/s, loss=0.706, v_num=21, train_loss_step=0.651]Epoch 0:   2%|▏         | 9/380 [00:00<00:36, 10.09it/s, loss=0.69, v_num=21, train_loss_step=0.557] Epoch 0:   3%|▎         | 10/380 [00:01<00:36, 10.03it/s, loss=0.69, v_num=21, train_loss_step=0.557]Epoch 0:   3%|▎         | 10/380 [00:01<00:36, 10.03it/s, loss=0.676, v_num=21, train_loss_step=0.549]Epoch 0:   3%|▎         | 11/380 [00:01<00:36,  9.98it/s, loss=0.676, v_num=21, train_loss_step=0.549]Epoch 0:   3%|▎         | 11/380 [00:01<00:36,  9.98it/s, loss=0.645, v_num=21, train_loss_step=0.338]Epoch 0:   3%|▎         | 12/380 [00:01<00:36,  9.95it/s, loss=0.645, v_num=21, train_loss_step=0.338]Epoch 0:   3%|▎         | 12/380 [00:01<00:36,  9.95it/s, loss=0.617, v_num=21, train_loss_step=0.314]Epoch 0:   3%|▎         | 13/380 [00:01<00:36,  9.92it/s, loss=0.617, v_num=21, train_loss_step=0.314]Epoch 0:   3%|▎         | 13/380 [00:01<00:36,  9.92it/s, loss=0.596, v_num=21, train_loss_step=0.341]Epoch 0:   4%|▎         | 14/380 [00:01<00:36,  9.90it/s, loss=0.596, v_num=21, train_loss_step=0.341]Epoch 0:   4%|▎         | 14/380 [00:01<00:36,  9.90it/s, loss=0.58, v_num=21, train_loss_step=0.377] Epoch 0:   4%|▍         | 15/380 [00:01<00:36,  9.88it/s, loss=0.58, v_num=21, train_loss_step=0.377]Epoch 0:   4%|▍         | 15/380 [00:01<00:36,  9.88it/s, loss=0.567, v_num=21, train_loss_step=0.372]Epoch 0:   4%|▍         | 16/380 [00:01<00:36,  9.85it/s, loss=0.567, v_num=21, train_loss_step=0.372]Epoch 0:   4%|▍         | 16/380 [00:01<00:36,  9.85it/s, loss=0.551, v_num=21, train_loss_step=0.323]Epoch 0:   4%|▍         | 17/380 [00:01<00:36,  9.83it/s, loss=0.551, v_num=21, train_loss_step=0.323]Epoch 0:   4%|▍         | 17/380 [00:01<00:36,  9.83it/s, loss=0.539, v_num=21, train_loss_step=0.345]Epoch 0:   5%|▍         | 18/380 [00:01<00:36,  9.82it/s, loss=0.539, v_num=21, train_loss_step=0.345]Epoch 0:   5%|▍         | 18/380 [00:01<00:36,  9.82it/s, loss=0.529, v_num=21, train_loss_step=0.354]Epoch 0:   5%|▌         | 19/380 [00:02<00:36,  9.81it/s, loss=0.529, v_num=21, train_loss_step=0.354]Epoch 0:   5%|▌         | 19/380 [00:02<00:36,  9.80it/s, loss=0.518, v_num=21, train_loss_step=0.313]Epoch 0:   5%|▌         | 20/380 [00:02<00:36,  9.79it/s, loss=0.518, v_num=21, train_loss_step=0.313]Epoch 0:   5%|▌         | 20/380 [00:02<00:36,  9.79it/s, loss=0.51, v_num=21, train_loss_step=0.369] Epoch 0:   6%|▌         | 21/380 [00:02<00:36,  9.77it/s, loss=0.51, v_num=21, train_loss_step=0.369]Epoch 0:   6%|▌         | 21/380 [00:02<00:36,  9.77it/s, loss=0.508, v_num=21, train_loss_step=0.683]Epoch 0:   6%|▌         | 22/380 [00:02<00:36,  9.76it/s, loss=0.508, v_num=21, train_loss_step=0.683]Epoch 0:   6%|▌         | 22/380 [00:02<00:36,  9.76it/s, loss=0.493, v_num=21, train_loss_step=0.413]Epoch 0:   6%|▌         | 23/380 [00:02<00:36,  9.74it/s, loss=0.493, v_num=21, train_loss_step=0.413]Epoch 0:   6%|▌         | 23/380 [00:02<00:36,  9.74it/s, loss=0.491, v_num=21, train_loss_step=0.688]Epoch 0:   6%|▋         | 24/380 [00:02<00:36,  9.73it/s, loss=0.491, v_num=21, train_loss_step=0.688]Epoch 0:   6%|▋         | 24/380 [00:02<00:36,  9.73it/s, loss=0.476, v_num=21, train_loss_step=0.433]Epoch 0:   7%|▋         | 25/380 [00:02<00:36,  9.72it/s, loss=0.476, v_num=21, train_loss_step=0.433]Epoch 0:   7%|▋         | 25/380 [00:02<00:36,  9.72it/s, loss=0.46, v_num=21, train_loss_step=0.379] Epoch 0:   7%|▋         | 26/380 [00:02<00:36,  9.72it/s, loss=0.46, v_num=21, train_loss_step=0.379]Epoch 0:   7%|▋         | 26/380 [00:02<00:36,  9.72it/s, loss=0.44, v_num=21, train_loss_step=0.313]Epoch 0:   7%|▋         | 27/380 [00:02<00:36,  9.72it/s, loss=0.44, v_num=21, train_loss_step=0.313]Epoch 0:   7%|▋         | 27/380 [00:02<00:36,  9.71it/s, loss=0.421, v_num=21, train_loss_step=0.313]Epoch 0:   7%|▋         | 28/380 [00:02<00:36,  9.72it/s, loss=0.421, v_num=21, train_loss_step=0.313]Epoch 0:   7%|▋         | 28/380 [00:02<00:36,  9.71it/s, loss=0.404, v_num=21, train_loss_step=0.313]Epoch 0:   8%|▊         | 29/380 [00:03<00:36,  9.70it/s, loss=0.404, v_num=21, train_loss_step=0.313]Epoch 0:   8%|▊         | 29/380 [00:03<00:36,  9.70it/s, loss=0.392, v_num=21, train_loss_step=0.313]Epoch 0:   8%|▊         | 30/380 [00:03<00:36,  9.69it/s, loss=0.392, v_num=21, train_loss_step=0.313]Epoch 0:   8%|▊         | 30/380 [00:03<00:36,  9.69it/s, loss=0.413, v_num=21, train_loss_step=0.959]Epoch 0:   8%|▊         | 31/380 [00:03<00:36,  9.68it/s, loss=0.413, v_num=21, train_loss_step=0.959]Epoch 0:   8%|▊         | 31/380 [00:03<00:36,  9.68it/s, loss=0.42, v_num=21, train_loss_step=0.490] Epoch 0:   8%|▊         | 32/380 [00:03<00:35,  9.68it/s, loss=0.42, v_num=21, train_loss_step=0.490]Epoch 0:   8%|▊         | 32/380 [00:03<00:35,  9.68it/s, loss=0.423, v_num=21, train_loss_step=0.362]Epoch 0:   9%|▊         | 33/380 [00:03<00:35,  9.67it/s, loss=0.423, v_num=21, train_loss_step=0.362]Epoch 0:   9%|▊         | 33/380 [00:03<00:35,  9.67it/s, loss=0.421, v_num=21, train_loss_step=0.313]Epoch 0:   9%|▉         | 34/380 [00:03<00:35,  9.67it/s, loss=0.421, v_num=21, train_loss_step=0.313]Epoch 0:   9%|▉         | 34/380 [00:03<00:35,  9.67it/s, loss=0.425, v_num=21, train_loss_step=0.448]Epoch 0:   9%|▉         | 35/380 [00:03<00:35,  9.67it/s, loss=0.425, v_num=21, train_loss_step=0.448]Epoch 0:   9%|▉         | 35/380 [00:03<00:35,  9.67it/s, loss=0.423, v_num=21, train_loss_step=0.342]Epoch 0:   9%|▉         | 36/380 [00:03<00:35,  9.67it/s, loss=0.423, v_num=21, train_loss_step=0.342]Epoch 0:   9%|▉         | 36/380 [00:03<00:35,  9.67it/s, loss=0.423, v_num=21, train_loss_step=0.313]Epoch 0:  10%|▉         | 37/380 [00:03<00:35,  9.65it/s, loss=0.423, v_num=21, train_loss_step=0.313]Epoch 0:  10%|▉         | 37/380 [00:03<00:35,  9.65it/s, loss=0.433, v_num=21, train_loss_step=0.553]Epoch 0:  10%|█         | 38/380 [00:04<00:35,  9.65it/s, loss=0.433, v_num=21, train_loss_step=0.553]Epoch 0:  10%|█         | 38/380 [00:04<00:35,  9.65it/s, loss=0.458, v_num=21, train_loss_step=0.850]Epoch 0:  10%|█         | 39/380 [00:04<00:35,  9.65it/s, loss=0.458, v_num=21, train_loss_step=0.850]Epoch 0:  10%|█         | 39/380 [00:04<00:35,  9.65it/s, loss=0.46, v_num=21, train_loss_step=0.355] Epoch 0:  11%|█         | 40/380 [00:04<00:35,  9.65it/s, loss=0.46, v_num=21, train_loss_step=0.355]Epoch 0:  11%|█         | 40/380 [00:04<00:35,  9.64it/s, loss=0.46, v_num=21, train_loss_step=0.372]Epoch 0:  11%|█         | 41/380 [00:04<00:35,  9.64it/s, loss=0.46, v_num=21, train_loss_step=0.372]Epoch 0:  11%|█         | 41/380 [00:04<00:35,  9.64it/s, loss=0.447, v_num=21, train_loss_step=0.416]Epoch 0:  11%|█         | 42/380 [00:04<00:35,  9.64it/s, loss=0.447, v_num=21, train_loss_step=0.416]Epoch 0:  11%|█         | 42/380 [00:04<00:35,  9.64it/s, loss=0.454, v_num=21, train_loss_step=0.549]Epoch 0:  11%|█▏        | 43/380 [00:04<00:34,  9.64it/s, loss=0.454, v_num=21, train_loss_step=0.549]Epoch 0:  11%|█▏        | 43/380 [00:04<00:34,  9.64it/s, loss=0.435, v_num=21, train_loss_step=0.313]Epoch 0:  12%|█▏        | 44/380 [00:04<00:34,  9.64it/s, loss=0.435, v_num=21, train_loss_step=0.313]Epoch 0:  12%|█▏        | 44/380 [00:04<00:34,  9.64it/s, loss=0.429, v_num=21, train_loss_step=0.313]Epoch 0:  12%|█▏        | 45/380 [00:04<00:34,  9.64it/s, loss=0.429, v_num=21, train_loss_step=0.313]Epoch 0:  12%|█▏        | 45/380 [00:04<00:34,  9.64it/s, loss=0.44, v_num=21, train_loss_step=0.592] Epoch 0:  12%|█▏        | 46/380 [00:04<00:34,  9.64it/s, loss=0.44, v_num=21, train_loss_step=0.592]Epoch 0:  12%|█▏        | 46/380 [00:04<00:34,  9.63it/s, loss=0.44, v_num=21, train_loss_step=0.313]Epoch 0:  12%|█▏        | 47/380 [00:04<00:34,  9.63it/s, loss=0.44, v_num=21, train_loss_step=0.313]Epoch 0:  12%|█▏        | 47/380 [00:04<00:34,  9.63it/s, loss=0.443, v_num=21, train_loss_step=0.387]Epoch 0:  13%|█▎        | 48/380 [00:05<00:34,  9.63it/s, loss=0.443, v_num=21, train_loss_step=0.387]Epoch 0:  13%|█▎        | 48/380 [00:05<00:34,  9.63it/s, loss=0.457, v_num=21, train_loss_step=0.587]Epoch 0:  13%|█▎        | 49/380 [00:05<00:34,  9.62it/s, loss=0.457, v_num=21, train_loss_step=0.587]Epoch 0:  13%|█▎        | 49/380 [00:05<00:34,  9.62it/s, loss=0.465, v_num=21, train_loss_step=0.479]Epoch 0:  13%|█▎        | 50/380 [00:05<00:34,  9.62it/s, loss=0.465, v_num=21, train_loss_step=0.479]Epoch 0:  13%|█▎        | 50/380 [00:05<00:34,  9.62it/s, loss=0.458, v_num=21, train_loss_step=0.814]Epoch 0:  13%|█▎        | 51/380 [00:05<00:34,  9.62it/s, loss=0.458, v_num=21, train_loss_step=0.814]Epoch 0:  13%|█▎        | 51/380 [00:05<00:34,  9.62it/s, loss=0.449, v_num=21, train_loss_step=0.314]Epoch 0:  14%|█▎        | 52/380 [00:05<00:34,  9.62it/s, loss=0.449, v_num=21, train_loss_step=0.314]Epoch 0:  14%|█▎        | 52/380 [00:05<00:34,  9.62it/s, loss=0.447, v_num=21, train_loss_step=0.313]Epoch 0:  14%|█▍        | 53/380 [00:05<00:34,  9.61it/s, loss=0.447, v_num=21, train_loss_step=0.313]Epoch 0:  14%|█▍        | 53/380 [00:05<00:34,  9.61it/s, loss=0.447, v_num=21, train_loss_step=0.313]Epoch 0:  14%|█▍        | 54/380 [00:05<00:33,  9.61it/s, loss=0.447, v_num=21, train_loss_step=0.313]Epoch 0:  14%|█▍        | 54/380 [00:05<00:33,  9.61it/s, loss=0.456, v_num=21, train_loss_step=0.640]Epoch 0:  14%|█▍        | 55/380 [00:05<00:33,  9.61it/s, loss=0.456, v_num=21, train_loss_step=0.640]Epoch 0:  14%|█▍        | 55/380 [00:05<00:33,  9.61it/s, loss=0.457, v_num=21, train_loss_step=0.349]Epoch 0:  15%|█▍        | 56/380 [00:05<00:33,  9.61it/s, loss=0.457, v_num=21, train_loss_step=0.349]Epoch 0:  15%|█▍        | 56/380 [00:05<00:33,  9.61it/s, loss=0.48, v_num=21, train_loss_step=0.769] Epoch 0:  15%|█▌        | 57/380 [00:06<00:33,  9.61it/s, loss=0.48, v_num=21, train_loss_step=0.769]Epoch 0:  15%|█▌        | 57/380 [00:06<00:33,  9.60it/s, loss=0.485, v_num=21, train_loss_step=0.658]Epoch 0:  15%|█▌        | 58/380 [00:06<00:33,  9.60it/s, loss=0.485, v_num=21, train_loss_step=0.658]Epoch 0:  15%|█▌        | 58/380 [00:06<00:33,  9.60it/s, loss=0.458, v_num=21, train_loss_step=0.313]Epoch 0:  16%|█▌        | 59/380 [00:06<00:33,  9.59it/s, loss=0.458, v_num=21, train_loss_step=0.313]Epoch 0:  16%|█▌        | 59/380 [00:06<00:33,  9.59it/s, loss=0.456, v_num=21, train_loss_step=0.321]Epoch 0:  16%|█▌        | 60/380 [00:06<00:33,  9.58it/s, loss=0.456, v_num=21, train_loss_step=0.321]Epoch 0:  16%|█▌        | 60/380 [00:06<00:33,  9.58it/s, loss=0.459, v_num=21, train_loss_step=0.425]Epoch 0:  16%|█▌        | 61/380 [00:06<00:33,  9.58it/s, loss=0.459, v_num=21, train_loss_step=0.425]Epoch 0:  16%|█▌        | 61/380 [00:06<00:33,  9.58it/s, loss=0.466, v_num=21, train_loss_step=0.564]Epoch 0:  16%|█▋        | 62/380 [00:06<00:33,  9.58it/s, loss=0.466, v_num=21, train_loss_step=0.564]Epoch 0:  16%|█▋        | 62/380 [00:06<00:33,  9.58it/s, loss=0.488, v_num=21, train_loss_step=0.974]Epoch 0:  17%|█▋        | 63/380 [00:06<00:33,  9.58it/s, loss=0.488, v_num=21, train_loss_step=0.974]Epoch 0:  17%|█▋        | 63/380 [00:06<00:33,  9.58it/s, loss=0.488, v_num=21, train_loss_step=0.313]Epoch 0:  17%|█▋        | 64/380 [00:06<00:33,  9.58it/s, loss=0.488, v_num=21, train_loss_step=0.313]Epoch 0:  17%|█▋        | 64/380 [00:06<00:33,  9.57it/s, loss=0.488, v_num=21, train_loss_step=0.313]Epoch 0:  17%|█▋        | 65/380 [00:06<00:32,  9.57it/s, loss=0.488, v_num=21, train_loss_step=0.313]Epoch 0:  17%|█▋        | 65/380 [00:06<00:32,  9.57it/s, loss=0.477, v_num=21, train_loss_step=0.381]Epoch 0:  17%|█▋        | 66/380 [00:06<00:32,  9.58it/s, loss=0.477, v_num=21, train_loss_step=0.381]Epoch 0:  17%|█▋        | 66/380 [00:06<00:32,  9.57it/s, loss=0.477, v_num=21, train_loss_step=0.313]Epoch 0:  18%|█▊        | 67/380 [00:07<00:32,  9.57it/s, loss=0.477, v_num=21, train_loss_step=0.313]Epoch 0:  18%|█▊        | 67/380 [00:07<00:32,  9.57it/s, loss=0.473, v_num=21, train_loss_step=0.313]Epoch 0:  18%|█▊        | 68/380 [00:07<00:32,  9.57it/s, loss=0.473, v_num=21, train_loss_step=0.313]Epoch 0:  18%|█▊        | 68/380 [00:07<00:32,  9.57it/s, loss=0.464, v_num=21, train_loss_step=0.394]Epoch 0:  18%|█▊        | 69/380 [00:07<00:32,  9.57it/s, loss=0.464, v_num=21, train_loss_step=0.394]Epoch 0:  18%|█▊        | 69/380 [00:07<00:32,  9.57it/s, loss=0.487, v_num=21, train_loss_step=0.951]Epoch 0:  18%|█▊        | 70/380 [00:07<00:32,  9.56it/s, loss=0.487, v_num=21, train_loss_step=0.951]Epoch 0:  18%|█▊        | 70/380 [00:07<00:32,  9.56it/s, loss=0.463, v_num=21, train_loss_step=0.334]Epoch 0:  19%|█▊        | 71/380 [00:07<00:32,  9.57it/s, loss=0.463, v_num=21, train_loss_step=0.334]Epoch 0:  19%|█▊        | 71/380 [00:07<00:32,  9.57it/s, loss=0.463, v_num=21, train_loss_step=0.313]Epoch 0:  19%|█▉        | 72/380 [00:07<00:32,  9.56it/s, loss=0.463, v_num=21, train_loss_step=0.313]Epoch 0:  19%|█▉        | 72/380 [00:07<00:32,  9.56it/s, loss=0.463, v_num=21, train_loss_step=0.313]Epoch 0:  19%|█▉        | 73/380 [00:07<00:32,  9.56it/s, loss=0.463, v_num=21, train_loss_step=0.313]Epoch 0:  19%|█▉        | 73/380 [00:07<00:32,  9.56it/s, loss=0.466, v_num=21, train_loss_step=0.371]Epoch 0:  19%|█▉        | 74/380 [00:07<00:32,  9.56it/s, loss=0.466, v_num=21, train_loss_step=0.371]Epoch 0:  19%|█▉        | 74/380 [00:07<00:32,  9.56it/s, loss=0.453, v_num=21, train_loss_step=0.380]Epoch 0:  20%|█▉        | 75/380 [00:07<00:31,  9.56it/s, loss=0.453, v_num=21, train_loss_step=0.380]Epoch 0:  20%|█▉        | 75/380 [00:07<00:31,  9.56it/s, loss=0.464, v_num=21, train_loss_step=0.569]Epoch 0:  20%|██        | 76/380 [00:08<00:31,  9.56it/s, loss=0.464, v_num=21, train_loss_step=0.569]Epoch 0:  20%|██        | 76/380 [00:08<00:31,  9.56it/s, loss=0.443, v_num=21, train_loss_step=0.353]Epoch 0:  20%|██        | 77/380 [00:08<00:31,  9.56it/s, loss=0.443, v_num=21, train_loss_step=0.353]Epoch 0:  20%|██        | 77/380 [00:08<00:31,  9.56it/s, loss=0.426, v_num=21, train_loss_step=0.313]Epoch 0:  21%|██        | 78/380 [00:08<00:31,  9.56it/s, loss=0.426, v_num=21, train_loss_step=0.313]Epoch 0:  21%|██        | 78/380 [00:08<00:31,  9.56it/s, loss=0.427, v_num=21, train_loss_step=0.332]Epoch 0:  21%|██        | 79/380 [00:08<00:31,  9.56it/s, loss=0.427, v_num=21, train_loss_step=0.332]Epoch 0:  21%|██        | 79/380 [00:08<00:31,  9.56it/s, loss=0.428, v_num=21, train_loss_step=0.339]Epoch 0:  21%|██        | 80/380 [00:08<00:31,  9.56it/s, loss=0.428, v_num=21, train_loss_step=0.339]Epoch 0:  21%|██        | 80/380 [00:08<00:31,  9.56it/s, loss=0.423, v_num=21, train_loss_step=0.321]Epoch 0:  21%|██▏       | 81/380 [00:08<00:31,  9.56it/s, loss=0.423, v_num=21, train_loss_step=0.321]Epoch 0:  21%|██▏       | 81/380 [00:08<00:31,  9.56it/s, loss=0.425, v_num=21, train_loss_step=0.600]Epoch 0:  22%|██▏       | 82/380 [00:08<00:31,  9.56it/s, loss=0.425, v_num=21, train_loss_step=0.600]Epoch 0:  22%|██▏       | 82/380 [00:08<00:31,  9.56it/s, loss=0.394, v_num=21, train_loss_step=0.361]Epoch 0:  22%|██▏       | 83/380 [00:08<00:31,  9.56it/s, loss=0.394, v_num=21, train_loss_step=0.361]Epoch 0:  22%|██▏       | 83/380 [00:08<00:31,  9.55it/s, loss=0.395, v_num=21, train_loss_step=0.329]Epoch 0:  22%|██▏       | 84/380 [00:08<00:30,  9.55it/s, loss=0.395, v_num=21, train_loss_step=0.329]Epoch 0:  22%|██▏       | 84/380 [00:08<00:30,  9.55it/s, loss=0.404, v_num=21, train_loss_step=0.503]Epoch 0:  22%|██▏       | 85/380 [00:09<00:30,  9.56it/s, loss=0.404, v_num=21, train_loss_step=0.503]Epoch 0:  22%|██▏       | 85/380 [00:09<00:30,  9.56it/s, loss=0.406, v_num=21, train_loss_step=0.417]Epoch 0:  23%|██▎       | 86/380 [00:09<00:30,  9.56it/s, loss=0.406, v_num=21, train_loss_step=0.417]Epoch 0:  23%|██▎       | 86/380 [00:09<00:30,  9.56it/s, loss=0.407, v_num=21, train_loss_step=0.342]Epoch 0:  23%|██▎       | 87/380 [00:09<00:30,  9.56it/s, loss=0.407, v_num=21, train_loss_step=0.342]Epoch 0:  23%|██▎       | 87/380 [00:09<00:30,  9.56it/s, loss=0.407, v_num=21, train_loss_step=0.313]Epoch 0:  23%|██▎       | 88/380 [00:09<00:30,  9.56it/s, loss=0.407, v_num=21, train_loss_step=0.313]Epoch 0:  23%|██▎       | 88/380 [00:09<00:30,  9.56it/s, loss=0.403, v_num=21, train_loss_step=0.313]Epoch 0:  23%|██▎       | 89/380 [00:09<00:30,  9.56it/s, loss=0.403, v_num=21, train_loss_step=0.313]Epoch 0:  23%|██▎       | 89/380 [00:09<00:30,  9.56it/s, loss=0.372, v_num=21, train_loss_step=0.313]Epoch 0:  24%|██▎       | 90/380 [00:09<00:30,  9.56it/s, loss=0.372, v_num=21, train_loss_step=0.313]Epoch 0:  24%|██▎       | 90/380 [00:09<00:30,  9.56it/s, loss=0.374, v_num=21, train_loss_step=0.383]Epoch 0:  24%|██▍       | 91/380 [00:09<00:30,  9.55it/s, loss=0.374, v_num=21, train_loss_step=0.383]Epoch 0:  24%|██▍       | 91/380 [00:09<00:30,  9.55it/s, loss=0.375, v_num=21, train_loss_step=0.333]Epoch 0:  24%|██▍       | 92/380 [00:09<00:30,  9.55it/s, loss=0.375, v_num=21, train_loss_step=0.333]Epoch 0:  24%|██▍       | 92/380 [00:09<00:30,  9.55it/s, loss=0.383, v_num=21, train_loss_step=0.464]Epoch 0:  24%|██▍       | 93/380 [00:09<00:30,  9.55it/s, loss=0.383, v_num=21, train_loss_step=0.464]Epoch 0:  24%|██▍       | 93/380 [00:09<00:30,  9.55it/s, loss=0.388, v_num=21, train_loss_step=0.482]Epoch 0:  25%|██▍       | 94/380 [00:09<00:29,  9.55it/s, loss=0.388, v_num=21, train_loss_step=0.482]Epoch 0:  25%|██▍       | 94/380 [00:09<00:29,  9.55it/s, loss=0.389, v_num=21, train_loss_step=0.396]Epoch 0:  25%|██▌       | 95/380 [00:10<00:29,  9.55it/s, loss=0.389, v_num=21, train_loss_step=0.396]Epoch 0:  25%|██▌       | 95/380 [00:10<00:29,  9.55it/s, loss=0.397, v_num=21, train_loss_step=0.740]Epoch 0:  25%|██▌       | 96/380 [00:10<00:29,  9.54it/s, loss=0.397, v_num=21, train_loss_step=0.740]Epoch 0:  25%|██▌       | 96/380 [00:10<00:29,  9.54it/s, loss=0.395, v_num=21, train_loss_step=0.313]Epoch 0:  26%|██▌       | 97/380 [00:10<00:29,  9.55it/s, loss=0.395, v_num=21, train_loss_step=0.313]Epoch 0:  26%|██▌       | 97/380 [00:10<00:29,  9.55it/s, loss=0.399, v_num=21, train_loss_step=0.389]Epoch 0:  26%|██▌       | 98/380 [00:10<00:29,  9.55it/s, loss=0.399, v_num=21, train_loss_step=0.389]Epoch 0:  26%|██▌       | 98/380 [00:10<00:29,  9.55it/s, loss=0.398, v_num=21, train_loss_step=0.313]Epoch 0:  26%|██▌       | 99/380 [00:10<00:29,  9.55it/s, loss=0.398, v_num=21, train_loss_step=0.313]Epoch 0:  26%|██▌       | 99/380 [00:10<00:29,  9.55it/s, loss=0.397, v_num=21, train_loss_step=0.313]Epoch 0:  26%|██▋       | 100/380 [00:10<00:29,  9.55it/s, loss=0.397, v_num=21, train_loss_step=0.313]Epoch 0:  26%|██▋       | 100/380 [00:10<00:29,  9.55it/s, loss=0.4, v_num=21, train_loss_step=0.376]  Epoch 0:  27%|██▋       | 101/380 [00:10<00:29,  9.55it/s, loss=0.4, v_num=21, train_loss_step=0.376]Epoch 0:  27%|██▋       | 101/380 [00:10<00:29,  9.55it/s, loss=0.385, v_num=21, train_loss_step=0.313]Epoch 0:  27%|██▋       | 102/380 [00:10<00:29,  9.55it/s, loss=0.385, v_num=21, train_loss_step=0.313]Epoch 0:  27%|██▋       | 102/380 [00:10<00:29,  9.55it/s, loss=0.383, v_num=21, train_loss_step=0.313]Epoch 0:  27%|██▋       | 103/380 [00:10<00:29,  9.55it/s, loss=0.383, v_num=21, train_loss_step=0.313]Epoch 0:  27%|██▋       | 103/380 [00:10<00:29,  9.55it/s, loss=0.397, v_num=21, train_loss_step=0.617]Epoch 0:  27%|██▋       | 104/380 [00:10<00:28,  9.55it/s, loss=0.397, v_num=21, train_loss_step=0.617]Epoch 0:  27%|██▋       | 104/380 [00:10<00:28,  9.55it/s, loss=0.402, v_num=21, train_loss_step=0.602]Epoch 0:  28%|██▊       | 105/380 [00:11<00:28,  9.55it/s, loss=0.402, v_num=21, train_loss_step=0.602]Epoch 0:  28%|██▊       | 105/380 [00:11<00:28,  9.55it/s, loss=0.425, v_num=21, train_loss_step=0.875]Epoch 0:  28%|██▊       | 106/380 [00:11<00:28,  9.55it/s, loss=0.425, v_num=21, train_loss_step=0.875]Epoch 0:  28%|██▊       | 106/380 [00:11<00:28,  9.55it/s, loss=0.424, v_num=21, train_loss_step=0.313]Epoch 0:  28%|██▊       | 107/380 [00:11<00:28,  9.54it/s, loss=0.424, v_num=21, train_loss_step=0.313]Epoch 0:  28%|██▊       | 107/380 [00:11<00:28,  9.54it/s, loss=0.427, v_num=21, train_loss_step=0.370]Epoch 0:  28%|██▊       | 108/380 [00:11<00:28,  9.54it/s, loss=0.427, v_num=21, train_loss_step=0.370]Epoch 0:  28%|██▊       | 108/380 [00:11<00:28,  9.54it/s, loss=0.454, v_num=21, train_loss_step=0.869]Epoch 0:  29%|██▊       | 109/380 [00:11<00:28,  9.54it/s, loss=0.454, v_num=21, train_loss_step=0.869]Epoch 0:  29%|██▊       | 109/380 [00:11<00:28,  9.54it/s, loss=0.466, v_num=21, train_loss_step=0.546]Epoch 0:  29%|██▉       | 110/380 [00:11<00:28,  9.55it/s, loss=0.466, v_num=21, train_loss_step=0.546]Epoch 0:  29%|██▉       | 110/380 [00:11<00:28,  9.55it/s, loss=0.464, v_num=21, train_loss_step=0.346]Epoch 0:  29%|██▉       | 111/380 [00:11<00:28,  9.55it/s, loss=0.464, v_num=21, train_loss_step=0.346]Epoch 0:  29%|██▉       | 111/380 [00:11<00:28,  9.55it/s, loss=0.463, v_num=21, train_loss_step=0.313]Epoch 0:  29%|██▉       | 112/380 [00:11<00:28,  9.55it/s, loss=0.463, v_num=21, train_loss_step=0.313]Epoch 0:  29%|██▉       | 112/380 [00:11<00:28,  9.55it/s, loss=0.457, v_num=21, train_loss_step=0.333]Epoch 0:  30%|██▉       | 113/380 [00:11<00:27,  9.55it/s, loss=0.457, v_num=21, train_loss_step=0.333]Epoch 0:  30%|██▉       | 113/380 [00:11<00:27,  9.55it/s, loss=0.45, v_num=21, train_loss_step=0.352] Epoch 0:  30%|███       | 114/380 [00:12<00:27,  9.55it/s, loss=0.45, v_num=21, train_loss_step=0.352]Epoch 0:  30%|███       | 114/380 [00:12<00:27,  9.55it/s, loss=0.447, v_num=21, train_loss_step=0.332]Epoch 0:  30%|███       | 115/380 [00:12<00:27,  9.54it/s, loss=0.447, v_num=21, train_loss_step=0.332]Epoch 0:  30%|███       | 115/380 [00:12<00:27,  9.54it/s, loss=0.426, v_num=21, train_loss_step=0.330]Epoch 0:  31%|███       | 116/380 [00:12<00:27,  9.54it/s, loss=0.426, v_num=21, train_loss_step=0.330]Epoch 0:  31%|███       | 116/380 [00:12<00:27,  9.54it/s, loss=0.439, v_num=21, train_loss_step=0.556]Epoch 0:  31%|███       | 117/380 [00:12<00:27,  9.54it/s, loss=0.439, v_num=21, train_loss_step=0.556]Epoch 0:  31%|███       | 117/380 [00:12<00:27,  9.54it/s, loss=0.435, v_num=21, train_loss_step=0.313]Epoch 0:  31%|███       | 118/380 [00:12<00:27,  9.54it/s, loss=0.435, v_num=21, train_loss_step=0.313]Epoch 0:  31%|███       | 118/380 [00:12<00:27,  9.54it/s, loss=0.439, v_num=21, train_loss_step=0.388]Epoch 0:  31%|███▏      | 119/380 [00:12<00:27,  9.54it/s, loss=0.439, v_num=21, train_loss_step=0.388]Epoch 0:  31%|███▏      | 119/380 [00:12<00:27,  9.54it/s, loss=0.439, v_num=21, train_loss_step=0.313]Epoch 0:  32%|███▏      | 120/380 [00:12<00:27,  9.54it/s, loss=0.439, v_num=21, train_loss_step=0.313]Epoch 0:  32%|███▏      | 120/380 [00:12<00:27,  9.54it/s, loss=0.441, v_num=21, train_loss_step=0.419]Epoch 0:  32%|███▏      | 121/380 [00:12<00:27,  9.54it/s, loss=0.441, v_num=21, train_loss_step=0.419]Epoch 0:  32%|███▏      | 121/380 [00:12<00:27,  9.54it/s, loss=0.45, v_num=21, train_loss_step=0.495] Epoch 0:  32%|███▏      | 122/380 [00:12<00:27,  9.54it/s, loss=0.45, v_num=21, train_loss_step=0.495]Epoch 0:  32%|███▏      | 122/380 [00:12<00:27,  9.54it/s, loss=0.45, v_num=21, train_loss_step=0.313]Epoch 0:  32%|███▏      | 123/380 [00:13<00:26,  9.54it/s, loss=0.45, v_num=21, train_loss_step=0.313]Epoch 0:  32%|███▏      | 123/380 [00:13<00:26,  9.54it/s, loss=0.435, v_num=21, train_loss_step=0.313]Epoch 0:  33%|███▎      | 124/380 [00:13<00:26,  9.54it/s, loss=0.435, v_num=21, train_loss_step=0.313]Epoch 0:  33%|███▎      | 124/380 [00:13<00:26,  9.54it/s, loss=0.423, v_num=21, train_loss_step=0.364]Epoch 0:  33%|███▎      | 125/380 [00:13<00:26,  9.54it/s, loss=0.423, v_num=21, train_loss_step=0.364]Epoch 0:  33%|███▎      | 125/380 [00:13<00:26,  9.54it/s, loss=0.397, v_num=21, train_loss_step=0.360]Epoch 0:  33%|███▎      | 126/380 [00:13<00:26,  9.54it/s, loss=0.397, v_num=21, train_loss_step=0.360]Epoch 0:  33%|███▎      | 126/380 [00:13<00:26,  9.54it/s, loss=0.397, v_num=21, train_loss_step=0.317]Epoch 0:  33%|███▎      | 127/380 [00:13<00:26,  9.54it/s, loss=0.397, v_num=21, train_loss_step=0.317]Epoch 0:  33%|███▎      | 127/380 [00:13<00:26,  9.53it/s, loss=0.415, v_num=21, train_loss_step=0.725]Epoch 0:  34%|███▎      | 128/380 [00:13<00:26,  9.53it/s, loss=0.415, v_num=21, train_loss_step=0.725]Epoch 0:  34%|███▎      | 128/380 [00:13<00:26,  9.53it/s, loss=0.401, v_num=21, train_loss_step=0.598]Epoch 0:  34%|███▍      | 129/380 [00:13<00:26,  9.53it/s, loss=0.401, v_num=21, train_loss_step=0.598]Epoch 0:  34%|███▍      | 129/380 [00:13<00:26,  9.53it/s, loss=0.418, v_num=21, train_loss_step=0.878]Epoch 0:  34%|███▍      | 130/380 [00:13<00:26,  9.53it/s, loss=0.418, v_num=21, train_loss_step=0.878]Epoch 0:  34%|███▍      | 130/380 [00:13<00:26,  9.53it/s, loss=0.419, v_num=21, train_loss_step=0.372]Epoch 0:  34%|███▍      | 131/380 [00:13<00:26,  9.53it/s, loss=0.419, v_num=21, train_loss_step=0.372]Epoch 0:  34%|███▍      | 131/380 [00:13<00:26,  9.53it/s, loss=0.424, v_num=21, train_loss_step=0.406]Epoch 0:  35%|███▍      | 132/380 [00:13<00:26,  9.53it/s, loss=0.424, v_num=21, train_loss_step=0.406]Epoch 0:  35%|███▍      | 132/380 [00:13<00:26,  9.53it/s, loss=0.426, v_num=21, train_loss_step=0.381]Epoch 0:  35%|███▌      | 133/380 [00:14<00:25,  9.53it/s, loss=0.426, v_num=21, train_loss_step=0.381]Epoch 0:  35%|███▌      | 133/380 [00:14<00:25,  9.53it/s, loss=0.439, v_num=21, train_loss_step=0.610]Epoch 0:  35%|███▌      | 134/380 [00:14<00:25,  9.53it/s, loss=0.439, v_num=21, train_loss_step=0.610]Epoch 0:  35%|███▌      | 134/380 [00:14<00:25,  9.53it/s, loss=0.459, v_num=21, train_loss_step=0.723]Epoch 0:  36%|███▌      | 135/380 [00:14<00:25,  9.53it/s, loss=0.459, v_num=21, train_loss_step=0.723]Epoch 0:  36%|███▌      | 135/380 [00:14<00:25,  9.53it/s, loss=0.476, v_num=21, train_loss_step=0.672]Epoch 0:  36%|███▌      | 136/380 [00:14<00:25,  9.53it/s, loss=0.476, v_num=21, train_loss_step=0.672]Epoch 0:  36%|███▌      | 136/380 [00:14<00:25,  9.53it/s, loss=0.469, v_num=21, train_loss_step=0.420]Epoch 0:  36%|███▌      | 137/380 [00:14<00:25,  9.53it/s, loss=0.469, v_num=21, train_loss_step=0.420]Epoch 0:  36%|███▌      | 137/380 [00:14<00:25,  9.53it/s, loss=0.47, v_num=21, train_loss_step=0.329] Epoch 0:  36%|███▋      | 138/380 [00:14<00:25,  9.53it/s, loss=0.47, v_num=21, train_loss_step=0.329]Epoch 0:  36%|███▋      | 138/380 [00:14<00:25,  9.53it/s, loss=0.466, v_num=21, train_loss_step=0.313]Epoch 0:  37%|███▋      | 139/380 [00:14<00:25,  9.53it/s, loss=0.466, v_num=21, train_loss_step=0.313]Epoch 0:  37%|███▋      | 139/380 [00:14<00:25,  9.53it/s, loss=0.468, v_num=21, train_loss_step=0.356]Epoch 0:  37%|███▋      | 140/380 [00:14<00:25,  9.53it/s, loss=0.468, v_num=21, train_loss_step=0.356]Epoch 0:  37%|███▋      | 140/380 [00:14<00:25,  9.53it/s, loss=0.463, v_num=21, train_loss_step=0.313]Epoch 0:  37%|███▋      | 141/380 [00:14<00:25,  9.53it/s, loss=0.463, v_num=21, train_loss_step=0.313]Epoch 0:  37%|███▋      | 141/380 [00:14<00:25,  9.53it/s, loss=0.457, v_num=21, train_loss_step=0.384]Epoch 0:  37%|███▋      | 142/380 [00:15<00:24,  9.53it/s, loss=0.457, v_num=21, train_loss_step=0.384]Epoch 0:  37%|███▋      | 142/380 [00:15<00:24,  9.53it/s, loss=0.465, v_num=21, train_loss_step=0.458]Epoch 0:  38%|███▊      | 143/380 [00:15<00:24,  9.53it/s, loss=0.465, v_num=21, train_loss_step=0.458]Epoch 0:  38%|███▊      | 143/380 [00:15<00:24,  9.53it/s, loss=0.489, v_num=21, train_loss_step=0.809]Epoch 0:  38%|███▊      | 144/380 [00:15<00:24,  9.53it/s, loss=0.489, v_num=21, train_loss_step=0.809]Epoch 0:  38%|███▊      | 144/380 [00:15<00:24,  9.53it/s, loss=0.487, v_num=21, train_loss_step=0.317]Epoch 0:  38%|███▊      | 145/380 [00:15<00:24,  9.53it/s, loss=0.487, v_num=21, train_loss_step=0.317]Epoch 0:  38%|███▊      | 145/380 [00:15<00:24,  9.53it/s, loss=0.485, v_num=21, train_loss_step=0.313]Epoch 0:  38%|███▊      | 146/380 [00:15<00:24,  9.53it/s, loss=0.485, v_num=21, train_loss_step=0.313]Epoch 0:  38%|███▊      | 146/380 [00:15<00:24,  9.53it/s, loss=0.494, v_num=21, train_loss_step=0.497]Epoch 0:  39%|███▊      | 147/380 [00:15<00:24,  9.53it/s, loss=0.494, v_num=21, train_loss_step=0.497]Epoch 0:  39%|███▊      | 147/380 [00:15<00:24,  9.53it/s, loss=0.473, v_num=21, train_loss_step=0.313]Epoch 0:  39%|███▉      | 148/380 [00:15<00:24,  9.53it/s, loss=0.473, v_num=21, train_loss_step=0.313]Epoch 0:  39%|███▉      | 148/380 [00:15<00:24,  9.53it/s, loss=0.462, v_num=21, train_loss_step=0.368]Epoch 0:  39%|███▉      | 149/380 [00:15<00:24,  9.53it/s, loss=0.462, v_num=21, train_loss_step=0.368]Epoch 0:  39%|███▉      | 149/380 [00:15<00:24,  9.53it/s, loss=0.433, v_num=21, train_loss_step=0.313]Epoch 0:  39%|███▉      | 150/380 [00:15<00:24,  9.53it/s, loss=0.433, v_num=21, train_loss_step=0.313]Epoch 0:  39%|███▉      | 150/380 [00:15<00:24,  9.53it/s, loss=0.43, v_num=21, train_loss_step=0.313] Epoch 0:  40%|███▉      | 151/380 [00:15<00:24,  9.53it/s, loss=0.43, v_num=21, train_loss_step=0.313]Epoch 0:  40%|███▉      | 151/380 [00:15<00:24,  9.53it/s, loss=0.434, v_num=21, train_loss_step=0.486]Epoch 0:  40%|████      | 152/380 [00:16<00:23,  9.53it/s, loss=0.434, v_num=21, train_loss_step=0.486]Epoch 0:  40%|████      | 152/380 [00:16<00:23,  9.53it/s, loss=0.434, v_num=21, train_loss_step=0.379]Epoch 0:  40%|████      | 153/380 [00:16<00:23,  9.53it/s, loss=0.434, v_num=21, train_loss_step=0.379]Epoch 0:  40%|████      | 153/380 [00:16<00:23,  9.53it/s, loss=0.423, v_num=21, train_loss_step=0.380]Epoch 0:  41%|████      | 154/380 [00:16<00:23,  9.53it/s, loss=0.423, v_num=21, train_loss_step=0.380]Epoch 0:  41%|████      | 154/380 [00:16<00:23,  9.53it/s, loss=0.402, v_num=21, train_loss_step=0.313]Epoch 0:  41%|████      | 155/380 [00:16<00:23,  9.53it/s, loss=0.402, v_num=21, train_loss_step=0.313]Epoch 0:  41%|████      | 155/380 [00:16<00:23,  9.53it/s, loss=0.403, v_num=21, train_loss_step=0.691]Epoch 0:  41%|████      | 156/380 [00:16<00:23,  9.53it/s, loss=0.403, v_num=21, train_loss_step=0.691]Epoch 0:  41%|████      | 156/380 [00:16<00:23,  9.53it/s, loss=0.409, v_num=21, train_loss_step=0.541]Epoch 0:  41%|████▏     | 157/380 [00:16<00:23,  9.53it/s, loss=0.409, v_num=21, train_loss_step=0.541]Epoch 0:  41%|████▏     | 157/380 [00:16<00:23,  9.53it/s, loss=0.409, v_num=21, train_loss_step=0.313]Epoch 0:  42%|████▏     | 158/380 [00:16<00:23,  9.53it/s, loss=0.409, v_num=21, train_loss_step=0.313]Epoch 0:  42%|████▏     | 158/380 [00:16<00:23,  9.53it/s, loss=0.411, v_num=21, train_loss_step=0.367]Epoch 0:  42%|████▏     | 159/380 [00:16<00:23,  9.53it/s, loss=0.411, v_num=21, train_loss_step=0.367]Epoch 0:  42%|████▏     | 159/380 [00:16<00:23,  9.53it/s, loss=0.422, v_num=21, train_loss_step=0.568]Epoch 0:  42%|████▏     | 160/380 [00:16<00:23,  9.53it/s, loss=0.422, v_num=21, train_loss_step=0.568]Epoch 0:  42%|████▏     | 160/380 [00:16<00:23,  9.53it/s, loss=0.437, v_num=21, train_loss_step=0.611]Epoch 0:  42%|████▏     | 161/380 [00:17<00:22,  9.53it/s, loss=0.437, v_num=21, train_loss_step=0.611]Epoch 0:  42%|████▏     | 161/380 [00:17<00:22,  9.53it/s, loss=0.448, v_num=21, train_loss_step=0.600]Epoch 0:  43%|████▎     | 162/380 [00:17<00:22,  9.53it/s, loss=0.448, v_num=21, train_loss_step=0.600]Epoch 0:  43%|████▎     | 162/380 [00:17<00:22,  9.53it/s, loss=0.456, v_num=21, train_loss_step=0.631]Epoch 0:  43%|████▎     | 163/380 [00:17<00:22,  9.53it/s, loss=0.456, v_num=21, train_loss_step=0.631]Epoch 0:  43%|████▎     | 163/380 [00:17<00:22,  9.53it/s, loss=0.45, v_num=21, train_loss_step=0.690] Epoch 0:  43%|████▎     | 164/380 [00:17<00:22,  9.53it/s, loss=0.45, v_num=21, train_loss_step=0.690]Epoch 0:  43%|████▎     | 164/380 [00:17<00:22,  9.53it/s, loss=0.454, v_num=21, train_loss_step=0.387]Epoch 0:  43%|████▎     | 165/380 [00:17<00:22,  9.53it/s, loss=0.454, v_num=21, train_loss_step=0.387]Epoch 0:  43%|████▎     | 165/380 [00:17<00:22,  9.53it/s, loss=0.458, v_num=21, train_loss_step=0.396]Epoch 0:  44%|████▎     | 166/380 [00:17<00:22,  9.52it/s, loss=0.458, v_num=21, train_loss_step=0.396]Epoch 0:  44%|████▎     | 166/380 [00:17<00:22,  9.52it/s, loss=0.453, v_num=21, train_loss_step=0.389]Epoch 0:  44%|████▍     | 167/380 [00:17<00:22,  9.52it/s, loss=0.453, v_num=21, train_loss_step=0.389]Epoch 0:  44%|████▍     | 167/380 [00:17<00:22,  9.52it/s, loss=0.482, v_num=21, train_loss_step=0.903]Epoch 0:  44%|████▍     | 168/380 [00:17<00:22,  9.52it/s, loss=0.482, v_num=21, train_loss_step=0.903]Epoch 0:  44%|████▍     | 168/380 [00:17<00:22,  9.52it/s, loss=0.484, v_num=21, train_loss_step=0.409]Epoch 0:  44%|████▍     | 169/380 [00:17<00:22,  9.52it/s, loss=0.484, v_num=21, train_loss_step=0.409]Epoch 0:  44%|████▍     | 169/380 [00:17<00:22,  9.52it/s, loss=0.486, v_num=21, train_loss_step=0.355]Epoch 0:  45%|████▍     | 170/380 [00:17<00:22,  9.52it/s, loss=0.486, v_num=21, train_loss_step=0.355]Epoch 0:  45%|████▍     | 170/380 [00:17<00:22,  9.52it/s, loss=0.487, v_num=21, train_loss_step=0.324]Epoch 0:  45%|████▌     | 171/380 [00:18<00:21,  9.52it/s, loss=0.487, v_num=21, train_loss_step=0.324]Epoch 0:  45%|████▌     | 171/380 [00:18<00:21,  9.52it/s, loss=0.481, v_num=21, train_loss_step=0.370]Epoch 0:  45%|████▌     | 172/380 [00:18<00:21,  9.52it/s, loss=0.481, v_num=21, train_loss_step=0.370]Epoch 0:  45%|████▌     | 172/380 [00:18<00:21,  9.52it/s, loss=0.478, v_num=21, train_loss_step=0.322]Epoch 0:  46%|████▌     | 173/380 [00:18<00:21,  9.52it/s, loss=0.478, v_num=21, train_loss_step=0.322]Epoch 0:  46%|████▌     | 173/380 [00:18<00:21,  9.52it/s, loss=0.481, v_num=21, train_loss_step=0.435]Epoch 0:  46%|████▌     | 174/380 [00:18<00:21,  9.52it/s, loss=0.481, v_num=21, train_loss_step=0.435]Epoch 0:  46%|████▌     | 174/380 [00:18<00:21,  9.52it/s, loss=0.482, v_num=21, train_loss_step=0.338]Epoch 0:  46%|████▌     | 175/380 [00:18<00:21,  9.52it/s, loss=0.482, v_num=21, train_loss_step=0.338]Epoch 0:  46%|████▌     | 175/380 [00:18<00:21,  9.52it/s, loss=0.465, v_num=21, train_loss_step=0.355]Epoch 0:  46%|████▋     | 176/380 [00:18<00:21,  9.52it/s, loss=0.465, v_num=21, train_loss_step=0.355]Epoch 0:  46%|████▋     | 176/380 [00:18<00:21,  9.52it/s, loss=0.454, v_num=21, train_loss_step=0.318]Epoch 0:  47%|████▋     | 177/380 [00:18<00:21,  9.52it/s, loss=0.454, v_num=21, train_loss_step=0.318]Epoch 0:  47%|████▋     | 177/380 [00:18<00:21,  9.52it/s, loss=0.483, v_num=21, train_loss_step=0.895]Epoch 0:  47%|████▋     | 178/380 [00:18<00:21,  9.52it/s, loss=0.483, v_num=21, train_loss_step=0.895]Epoch 0:  47%|████▋     | 178/380 [00:18<00:21,  9.52it/s, loss=0.483, v_num=21, train_loss_step=0.366]Epoch 0:  47%|████▋     | 179/380 [00:18<00:21,  9.52it/s, loss=0.483, v_num=21, train_loss_step=0.366]Epoch 0:  47%|████▋     | 179/380 [00:18<00:21,  9.52it/s, loss=0.473, v_num=21, train_loss_step=0.376]Epoch 0:  47%|████▋     | 180/380 [00:19<00:21,  9.52it/s, loss=0.473, v_num=21, train_loss_step=0.376]Epoch 0:  47%|████▋     | 180/380 [00:19<00:21,  9.52it/s, loss=0.46, v_num=21, train_loss_step=0.345] Epoch 0:  48%|████▊     | 181/380 [00:19<00:20,  9.52it/s, loss=0.46, v_num=21, train_loss_step=0.345]Epoch 0:  48%|████▊     | 181/380 [00:19<00:20,  9.52it/s, loss=0.446, v_num=21, train_loss_step=0.313]Epoch 0:  48%|████▊     | 182/380 [00:19<00:20,  9.52it/s, loss=0.446, v_num=21, train_loss_step=0.313]Epoch 0:  48%|████▊     | 182/380 [00:19<00:20,  9.52it/s, loss=0.435, v_num=21, train_loss_step=0.415]Epoch 0:  48%|████▊     | 183/380 [00:19<00:20,  9.52it/s, loss=0.435, v_num=21, train_loss_step=0.415]Epoch 0:  48%|████▊     | 183/380 [00:19<00:20,  9.52it/s, loss=0.427, v_num=21, train_loss_step=0.535]Epoch 0:  48%|████▊     | 184/380 [00:19<00:20,  9.52it/s, loss=0.427, v_num=21, train_loss_step=0.535]Epoch 0:  48%|████▊     | 184/380 [00:19<00:20,  9.52it/s, loss=0.438, v_num=21, train_loss_step=0.599]Epoch 0:  49%|████▊     | 185/380 [00:19<00:20,  9.52it/s, loss=0.438, v_num=21, train_loss_step=0.599]Epoch 0:  49%|████▊     | 185/380 [00:19<00:20,  9.52it/s, loss=0.437, v_num=21, train_loss_step=0.380]Epoch 0:  49%|████▉     | 186/380 [00:19<00:20,  9.52it/s, loss=0.437, v_num=21, train_loss_step=0.380]Epoch 0:  49%|████▉     | 186/380 [00:19<00:20,  9.52it/s, loss=0.435, v_num=21, train_loss_step=0.339]Epoch 0:  49%|████▉     | 187/380 [00:19<00:20,  9.52it/s, loss=0.435, v_num=21, train_loss_step=0.339]Epoch 0:  49%|████▉     | 187/380 [00:19<00:20,  9.52it/s, loss=0.407, v_num=21, train_loss_step=0.342]Epoch 0:  49%|████▉     | 188/380 [00:19<00:20,  9.52it/s, loss=0.407, v_num=21, train_loss_step=0.342]Epoch 0:  49%|████▉     | 188/380 [00:19<00:20,  9.52it/s, loss=0.402, v_num=21, train_loss_step=0.325]Epoch 0:  50%|████▉     | 189/380 [00:19<00:20,  9.52it/s, loss=0.402, v_num=21, train_loss_step=0.325]Epoch 0:  50%|████▉     | 189/380 [00:19<00:20,  9.52it/s, loss=0.408, v_num=21, train_loss_step=0.465]Epoch 0:  50%|█████     | 190/380 [00:20<00:19,  9.52it/s, loss=0.408, v_num=21, train_loss_step=0.465]Epoch 0:  50%|█████     | 190/380 [00:20<00:19,  9.52it/s, loss=0.412, v_num=21, train_loss_step=0.408]Epoch 0:  50%|█████     | 191/380 [00:20<00:19,  9.51it/s, loss=0.412, v_num=21, train_loss_step=0.408]Epoch 0:  50%|█████     | 191/380 [00:20<00:19,  9.51it/s, loss=0.409, v_num=21, train_loss_step=0.313]Epoch 0:  51%|█████     | 192/380 [00:20<00:19,  9.52it/s, loss=0.409, v_num=21, train_loss_step=0.313]Epoch 0:  51%|█████     | 192/380 [00:20<00:19,  9.52it/s, loss=0.442, v_num=21, train_loss_step=0.977]Epoch 0:  51%|█████     | 193/380 [00:20<00:19,  9.52it/s, loss=0.442, v_num=21, train_loss_step=0.977]Epoch 0:  51%|█████     | 193/380 [00:20<00:19,  9.52it/s, loss=0.436, v_num=21, train_loss_step=0.313]Epoch 0:  51%|█████     | 194/380 [00:20<00:19,  9.52it/s, loss=0.436, v_num=21, train_loss_step=0.313]Epoch 0:  51%|█████     | 194/380 [00:20<00:19,  9.52it/s, loss=0.452, v_num=21, train_loss_step=0.670]Epoch 0:  51%|█████▏    | 195/380 [00:20<00:19,  9.52it/s, loss=0.452, v_num=21, train_loss_step=0.670]Epoch 0:  51%|█████▏    | 195/380 [00:20<00:19,  9.52it/s, loss=0.454, v_num=21, train_loss_step=0.382]Epoch 0:  52%|█████▏    | 196/380 [00:20<00:19,  9.52it/s, loss=0.454, v_num=21, train_loss_step=0.382]Epoch 0:  52%|█████▏    | 196/380 [00:20<00:19,  9.52it/s, loss=0.463, v_num=21, train_loss_step=0.497]Epoch 0:  52%|█████▏    | 197/380 [00:20<00:19,  9.52it/s, loss=0.463, v_num=21, train_loss_step=0.497]Epoch 0:  52%|█████▏    | 197/380 [00:20<00:19,  9.52it/s, loss=0.442, v_num=21, train_loss_step=0.485]Epoch 0:  52%|█████▏    | 198/380 [00:20<00:19,  9.52it/s, loss=0.442, v_num=21, train_loss_step=0.485]Epoch 0:  52%|█████▏    | 198/380 [00:20<00:19,  9.52it/s, loss=0.44, v_num=21, train_loss_step=0.313] Epoch 0:  52%|█████▏    | 199/380 [00:21<00:19,  9.52it/s, loss=0.44, v_num=21, train_loss_step=0.313]Epoch 0:  52%|█████▏    | 199/380 [00:21<00:19,  9.51it/s, loss=0.444, v_num=21, train_loss_step=0.457]Epoch 0:  53%|█████▎    | 200/380 [00:21<00:18,  9.51it/s, loss=0.444, v_num=21, train_loss_step=0.457]Epoch 0:  53%|█████▎    | 200/380 [00:21<00:18,  9.51it/s, loss=0.469, v_num=21, train_loss_step=0.857]Epoch 0:  53%|█████▎    | 201/380 [00:21<00:18,  9.52it/s, loss=0.469, v_num=21, train_loss_step=0.857]Epoch 0:  53%|█████▎    | 201/380 [00:21<00:18,  9.52it/s, loss=0.477, v_num=21, train_loss_step=0.470]Epoch 0:  53%|█████▎    | 202/380 [00:21<00:18,  9.51it/s, loss=0.477, v_num=21, train_loss_step=0.470]Epoch 0:  53%|█████▎    | 202/380 [00:21<00:18,  9.51it/s, loss=0.472, v_num=21, train_loss_step=0.313]Epoch 0:  53%|█████▎    | 203/380 [00:21<00:18,  9.52it/s, loss=0.472, v_num=21, train_loss_step=0.313]Epoch 0:  53%|█████▎    | 203/380 [00:21<00:18,  9.51it/s, loss=0.479, v_num=21, train_loss_step=0.669]Epoch 0:  54%|█████▎    | 204/380 [00:21<00:18,  9.51it/s, loss=0.479, v_num=21, train_loss_step=0.669]Epoch 0:  54%|█████▎    | 204/380 [00:21<00:18,  9.51it/s, loss=0.482, v_num=21, train_loss_step=0.658]Epoch 0:  54%|█████▍    | 205/380 [00:21<00:18,  9.51it/s, loss=0.482, v_num=21, train_loss_step=0.658]Epoch 0:  54%|█████▍    | 205/380 [00:21<00:18,  9.51it/s, loss=0.496, v_num=21, train_loss_step=0.665]Epoch 0:  54%|█████▍    | 206/380 [00:21<00:18,  9.51it/s, loss=0.496, v_num=21, train_loss_step=0.665]Epoch 0:  54%|█████▍    | 206/380 [00:21<00:18,  9.51it/s, loss=0.505, v_num=21, train_loss_step=0.527]Epoch 0:  54%|█████▍    | 207/380 [00:21<00:18,  9.52it/s, loss=0.505, v_num=21, train_loss_step=0.527]Epoch 0:  54%|█████▍    | 207/380 [00:21<00:18,  9.52it/s, loss=0.504, v_num=21, train_loss_step=0.313]Epoch 0:  55%|█████▍    | 208/380 [00:21<00:18,  9.52it/s, loss=0.504, v_num=21, train_loss_step=0.313]Epoch 0:  55%|█████▍    | 208/380 [00:21<00:18,  9.52it/s, loss=0.504, v_num=21, train_loss_step=0.318]Epoch 0:  55%|█████▌    | 209/380 [00:22<00:17,  9.51it/s, loss=0.504, v_num=21, train_loss_step=0.318]Epoch 0:  55%|█████▌    | 209/380 [00:22<00:17,  9.51it/s, loss=0.503, v_num=21, train_loss_step=0.454]Epoch 0:  55%|█████▌    | 210/380 [00:22<00:17,  9.51it/s, loss=0.503, v_num=21, train_loss_step=0.454]Epoch 0:  55%|█████▌    | 210/380 [00:22<00:17,  9.51it/s, loss=0.517, v_num=21, train_loss_step=0.694]Epoch 0:  56%|█████▌    | 211/380 [00:22<00:17,  9.51it/s, loss=0.517, v_num=21, train_loss_step=0.694]Epoch 0:  56%|█████▌    | 211/380 [00:22<00:17,  9.51it/s, loss=0.526, v_num=21, train_loss_step=0.494]Epoch 0:  56%|█████▌    | 212/380 [00:22<00:17,  9.51it/s, loss=0.526, v_num=21, train_loss_step=0.494]Epoch 0:  56%|█████▌    | 212/380 [00:22<00:17,  9.51it/s, loss=0.493, v_num=21, train_loss_step=0.313]Epoch 0:  56%|█████▌    | 213/380 [00:22<00:17,  9.51it/s, loss=0.493, v_num=21, train_loss_step=0.313]Epoch 0:  56%|█████▌    | 213/380 [00:22<00:17,  9.51it/s, loss=0.498, v_num=21, train_loss_step=0.402]Epoch 0:  56%|█████▋    | 214/380 [00:22<00:17,  9.51it/s, loss=0.498, v_num=21, train_loss_step=0.402]Epoch 0:  56%|█████▋    | 214/380 [00:22<00:17,  9.51it/s, loss=0.481, v_num=21, train_loss_step=0.340]Epoch 0:  57%|█████▋    | 215/380 [00:22<00:17,  9.51it/s, loss=0.481, v_num=21, train_loss_step=0.340]Epoch 0:  57%|█████▋    | 215/380 [00:22<00:17,  9.51it/s, loss=0.485, v_num=21, train_loss_step=0.452]Epoch 0:  57%|█████▋    | 216/380 [00:22<00:17,  9.52it/s, loss=0.485, v_num=21, train_loss_step=0.452]Epoch 0:  57%|█████▋    | 216/380 [00:22<00:17,  9.52it/s, loss=0.475, v_num=21, train_loss_step=0.313]Epoch 0:  57%|█████▋    | 217/380 [00:22<00:17,  9.51it/s, loss=0.475, v_num=21, train_loss_step=0.313]Epoch 0:  57%|█████▋    | 217/380 [00:22<00:17,  9.51it/s, loss=0.467, v_num=21, train_loss_step=0.313]Epoch 0:  57%|█████▋    | 218/380 [00:23<00:17,  9.51it/s, loss=0.467, v_num=21, train_loss_step=0.313]Epoch 0:  57%|█████▋    | 218/380 [00:23<00:17,  9.51it/s, loss=0.482, v_num=21, train_loss_step=0.615]Epoch 0:  58%|█████▊    | 219/380 [00:23<00:16,  9.51it/s, loss=0.482, v_num=21, train_loss_step=0.615]Epoch 0:  58%|█████▊    | 219/380 [00:23<00:16,  9.51it/s, loss=0.482, v_num=21, train_loss_step=0.466]Epoch 0:  58%|█████▊    | 220/380 [00:23<00:16,  9.52it/s, loss=0.482, v_num=21, train_loss_step=0.466]Epoch 0:  58%|█████▊    | 220/380 [00:23<00:16,  9.51it/s, loss=0.456, v_num=21, train_loss_step=0.332]Epoch 0:  58%|█████▊    | 221/380 [00:23<00:16,  9.51it/s, loss=0.456, v_num=21, train_loss_step=0.332]Epoch 0:  58%|█████▊    | 221/380 [00:23<00:16,  9.51it/s, loss=0.448, v_num=21, train_loss_step=0.313]Epoch 0:  58%|█████▊    | 222/380 [00:23<00:16,  9.51it/s, loss=0.448, v_num=21, train_loss_step=0.313]Epoch 0:  58%|█████▊    | 222/380 [00:23<00:16,  9.51it/s, loss=0.462, v_num=21, train_loss_step=0.581]Epoch 0:  59%|█████▊    | 223/380 [00:23<00:16,  9.52it/s, loss=0.462, v_num=21, train_loss_step=0.581]Epoch 0:  59%|█████▊    | 223/380 [00:23<00:16,  9.52it/s, loss=0.444, v_num=21, train_loss_step=0.313]Epoch 0:  59%|█████▉    | 224/380 [00:23<00:16,  9.52it/s, loss=0.444, v_num=21, train_loss_step=0.313]Epoch 0:  59%|█████▉    | 224/380 [00:23<00:16,  9.52it/s, loss=0.427, v_num=21, train_loss_step=0.313]Epoch 0:  59%|█████▉    | 225/380 [00:23<00:16,  9.52it/s, loss=0.427, v_num=21, train_loss_step=0.313]Epoch 0:  59%|█████▉    | 225/380 [00:23<00:16,  9.52it/s, loss=0.409, v_num=21, train_loss_step=0.313]Epoch 0:  59%|█████▉    | 226/380 [00:23<00:16,  9.52it/s, loss=0.409, v_num=21, train_loss_step=0.313]Epoch 0:  59%|█████▉    | 226/380 [00:23<00:16,  9.52it/s, loss=0.399, v_num=21, train_loss_step=0.324]Epoch 0:  60%|█████▉    | 227/380 [00:23<00:16,  9.52it/s, loss=0.399, v_num=21, train_loss_step=0.324]Epoch 0:  60%|█████▉    | 227/380 [00:23<00:16,  9.52it/s, loss=0.399, v_num=21, train_loss_step=0.313]Epoch 0:  60%|██████    | 228/380 [00:24<00:15,  9.52it/s, loss=0.399, v_num=21, train_loss_step=0.313]Epoch 0:  60%|██████    | 228/380 [00:24<00:15,  9.52it/s, loss=0.411, v_num=21, train_loss_step=0.560]Epoch 0:  60%|██████    | 229/380 [00:24<00:15,  9.52it/s, loss=0.411, v_num=21, train_loss_step=0.560]Epoch 0:  60%|██████    | 229/380 [00:24<00:15,  9.52it/s, loss=0.405, v_num=21, train_loss_step=0.335]Epoch 0:  61%|██████    | 230/380 [00:24<00:15,  9.52it/s, loss=0.405, v_num=21, train_loss_step=0.335]Epoch 0:  61%|██████    | 230/380 [00:24<00:15,  9.52it/s, loss=0.389, v_num=21, train_loss_step=0.370]Epoch 0:  61%|██████    | 231/380 [00:24<00:15,  9.52it/s, loss=0.389, v_num=21, train_loss_step=0.370]Epoch 0:  61%|██████    | 231/380 [00:24<00:15,  9.52it/s, loss=0.38, v_num=21, train_loss_step=0.313] Epoch 0:  61%|██████    | 232/380 [00:24<00:15,  9.52it/s, loss=0.38, v_num=21, train_loss_step=0.313]Epoch 0:  61%|██████    | 232/380 [00:24<00:15,  9.52it/s, loss=0.38, v_num=21, train_loss_step=0.313]Epoch 0:  61%|██████▏   | 233/380 [00:24<00:15,  9.52it/s, loss=0.38, v_num=21, train_loss_step=0.313]Epoch 0:  61%|██████▏   | 233/380 [00:24<00:15,  9.52it/s, loss=0.378, v_num=21, train_loss_step=0.359]Epoch 0:  62%|██████▏   | 234/380 [00:24<00:15,  9.52it/s, loss=0.378, v_num=21, train_loss_step=0.359]Epoch 0:  62%|██████▏   | 234/380 [00:24<00:15,  9.52it/s, loss=0.378, v_num=21, train_loss_step=0.337]Epoch 0:  62%|██████▏   | 235/380 [00:24<00:15,  9.52it/s, loss=0.378, v_num=21, train_loss_step=0.337]Epoch 0:  62%|██████▏   | 235/380 [00:24<00:15,  9.52it/s, loss=0.401, v_num=21, train_loss_step=0.913]Epoch 0:  62%|██████▏   | 236/380 [00:24<00:15,  9.52it/s, loss=0.401, v_num=21, train_loss_step=0.913]Epoch 0:  62%|██████▏   | 236/380 [00:24<00:15,  9.52it/s, loss=0.404, v_num=21, train_loss_step=0.377]Epoch 0:  62%|██████▏   | 237/380 [00:25<00:15,  9.52it/s, loss=0.404, v_num=21, train_loss_step=0.377]Epoch 0:  62%|██████▏   | 237/380 [00:25<00:15,  9.52it/s, loss=0.429, v_num=21, train_loss_step=0.822]Epoch 0:  63%|██████▎   | 238/380 [00:25<00:14,  9.52it/s, loss=0.429, v_num=21, train_loss_step=0.822]Epoch 0:  63%|██████▎   | 238/380 [00:25<00:14,  9.52it/s, loss=0.419, v_num=21, train_loss_step=0.406]Epoch 0:  63%|██████▎   | 239/380 [00:25<00:14,  9.51it/s, loss=0.419, v_num=21, train_loss_step=0.406]Epoch 0:  63%|██████▎   | 239/380 [00:25<00:14,  9.51it/s, loss=0.437, v_num=21, train_loss_step=0.840]Epoch 0:  63%|██████▎   | 240/380 [00:25<00:14,  9.51it/s, loss=0.437, v_num=21, train_loss_step=0.840]Epoch 0:  63%|██████▎   | 240/380 [00:25<00:14,  9.51it/s, loss=0.44, v_num=21, train_loss_step=0.382] Epoch 0:  63%|██████▎   | 241/380 [00:25<00:14,  9.51it/s, loss=0.44, v_num=21, train_loss_step=0.382]Epoch 0:  63%|██████▎   | 241/380 [00:25<00:14,  9.51it/s, loss=0.453, v_num=21, train_loss_step=0.584]Epoch 0:  64%|██████▎   | 242/380 [00:25<00:14,  9.51it/s, loss=0.453, v_num=21, train_loss_step=0.584]Epoch 0:  64%|██████▎   | 242/380 [00:25<00:14,  9.51it/s, loss=0.442, v_num=21, train_loss_step=0.350]Epoch 0:  64%|██████▍   | 243/380 [00:25<00:14,  9.51it/s, loss=0.442, v_num=21, train_loss_step=0.350]Epoch 0:  64%|██████▍   | 243/380 [00:25<00:14,  9.51it/s, loss=0.448, v_num=21, train_loss_step=0.431]Epoch 0:  64%|██████▍   | 244/380 [00:25<00:14,  9.51it/s, loss=0.448, v_num=21, train_loss_step=0.431]Epoch 0:  64%|██████▍   | 244/380 [00:25<00:14,  9.51it/s, loss=0.462, v_num=21, train_loss_step=0.592]Epoch 0:  64%|██████▍   | 245/380 [00:25<00:14,  9.51it/s, loss=0.462, v_num=21, train_loss_step=0.592]Epoch 0:  64%|██████▍   | 245/380 [00:25<00:14,  9.51it/s, loss=0.467, v_num=21, train_loss_step=0.426]Epoch 0:  65%|██████▍   | 246/380 [00:25<00:14,  9.51it/s, loss=0.467, v_num=21, train_loss_step=0.426]Epoch 0:  65%|██████▍   | 246/380 [00:25<00:14,  9.51it/s, loss=0.467, v_num=21, train_loss_step=0.313]Epoch 0:  65%|██████▌   | 247/380 [00:26<00:13,  9.51it/s, loss=0.467, v_num=21, train_loss_step=0.313]Epoch 0:  65%|██████▌   | 247/380 [00:26<00:13,  9.51it/s, loss=0.496, v_num=21, train_loss_step=0.895]Epoch 0:  65%|██████▌   | 248/380 [00:26<00:13,  9.51it/s, loss=0.496, v_num=21, train_loss_step=0.895]Epoch 0:  65%|██████▌   | 248/380 [00:26<00:13,  9.51it/s, loss=0.5, v_num=21, train_loss_step=0.647]  Epoch 0:  66%|██████▌   | 249/380 [00:26<00:13,  9.51it/s, loss=0.5, v_num=21, train_loss_step=0.647]Epoch 0:  66%|██████▌   | 249/380 [00:26<00:13,  9.51it/s, loss=0.5, v_num=21, train_loss_step=0.338]Epoch 0:  66%|██████▌   | 250/380 [00:26<00:13,  9.51it/s, loss=0.5, v_num=21, train_loss_step=0.338]Epoch 0:  66%|██████▌   | 250/380 [00:26<00:13,  9.51it/s, loss=0.51, v_num=21, train_loss_step=0.559]Epoch 0:  66%|██████▌   | 251/380 [00:26<00:13,  9.51it/s, loss=0.51, v_num=21, train_loss_step=0.559]Epoch 0:  66%|██████▌   | 251/380 [00:26<00:13,  9.51it/s, loss=0.51, v_num=21, train_loss_step=0.320]Epoch 0:  66%|██████▋   | 252/380 [00:26<00:13,  9.51it/s, loss=0.51, v_num=21, train_loss_step=0.320]Epoch 0:  66%|██████▋   | 252/380 [00:26<00:13,  9.51it/s, loss=0.513, v_num=21, train_loss_step=0.374]Epoch 0:  67%|██████▋   | 253/380 [00:26<00:13,  9.51it/s, loss=0.513, v_num=21, train_loss_step=0.374]Epoch 0:  67%|██████▋   | 253/380 [00:26<00:13,  9.51it/s, loss=0.514, v_num=21, train_loss_step=0.376]Epoch 0:  67%|██████▋   | 254/380 [00:26<00:13,  9.51it/s, loss=0.514, v_num=21, train_loss_step=0.376]Epoch 0:  67%|██████▋   | 254/380 [00:26<00:13,  9.51it/s, loss=0.513, v_num=21, train_loss_step=0.313]Epoch 0:  67%|██████▋   | 255/380 [00:26<00:13,  9.51it/s, loss=0.513, v_num=21, train_loss_step=0.313]Epoch 0:  67%|██████▋   | 255/380 [00:26<00:13,  9.51it/s, loss=0.502, v_num=21, train_loss_step=0.692]Epoch 0:  67%|██████▋   | 256/380 [00:27<00:13,  9.51it/s, loss=0.502, v_num=21, train_loss_step=0.692]Epoch 0:  67%|██████▋   | 256/380 [00:27<00:13,  9.51it/s, loss=0.503, v_num=21, train_loss_step=0.392]Epoch 0:  68%|██████▊   | 257/380 [00:27<00:12,  9.51it/s, loss=0.503, v_num=21, train_loss_step=0.392]Epoch 0:  68%|██████▊   | 257/380 [00:27<00:12,  9.51it/s, loss=0.477, v_num=21, train_loss_step=0.313]Epoch 0:  68%|██████▊   | 258/380 [00:27<00:12,  9.51it/s, loss=0.477, v_num=21, train_loss_step=0.313]Epoch 0:  68%|██████▊   | 258/380 [00:27<00:12,  9.51it/s, loss=0.494, v_num=21, train_loss_step=0.744]Epoch 0:  68%|██████▊   | 259/380 [00:27<00:12,  9.51it/s, loss=0.494, v_num=21, train_loss_step=0.744]Epoch 0:  68%|██████▊   | 259/380 [00:27<00:12,  9.51it/s, loss=0.479, v_num=21, train_loss_step=0.543]Epoch 0:  68%|██████▊   | 260/380 [00:27<00:12,  9.51it/s, loss=0.479, v_num=21, train_loss_step=0.543]Epoch 0:  68%|██████▊   | 260/380 [00:27<00:12,  9.51it/s, loss=0.487, v_num=21, train_loss_step=0.540]Epoch 0:  69%|██████▊   | 261/380 [00:27<00:12,  9.51it/s, loss=0.487, v_num=21, train_loss_step=0.540]Epoch 0:  69%|██████▊   | 261/380 [00:27<00:12,  9.51it/s, loss=0.493, v_num=21, train_loss_step=0.701]Epoch 0:  69%|██████▉   | 262/380 [00:27<00:12,  9.51it/s, loss=0.493, v_num=21, train_loss_step=0.701]Epoch 0:  69%|██████▉   | 262/380 [00:27<00:12,  9.51it/s, loss=0.495, v_num=21, train_loss_step=0.380]Epoch 0:  69%|██████▉   | 263/380 [00:27<00:12,  9.51it/s, loss=0.495, v_num=21, train_loss_step=0.380]Epoch 0:  69%|██████▉   | 263/380 [00:27<00:12,  9.51it/s, loss=0.499, v_num=21, train_loss_step=0.512]Epoch 0:  69%|██████▉   | 264/380 [00:27<00:12,  9.51it/s, loss=0.499, v_num=21, train_loss_step=0.512]Epoch 0:  69%|██████▉   | 264/380 [00:27<00:12,  9.51it/s, loss=0.487, v_num=21, train_loss_step=0.368]Epoch 0:  70%|██████▉   | 265/380 [00:27<00:12,  9.51it/s, loss=0.487, v_num=21, train_loss_step=0.368]Epoch 0:  70%|██████▉   | 265/380 [00:27<00:12,  9.51it/s, loss=0.483, v_num=21, train_loss_step=0.343]Epoch 0:  70%|███████   | 266/380 [00:28<00:11,  9.51it/s, loss=0.483, v_num=21, train_loss_step=0.343]Epoch 0:  70%|███████   | 266/380 [00:28<00:11,  9.51it/s, loss=0.485, v_num=21, train_loss_step=0.340]Epoch 0:  70%|███████   | 267/380 [00:28<00:11,  9.51it/s, loss=0.485, v_num=21, train_loss_step=0.340]Epoch 0:  70%|███████   | 267/380 [00:28<00:11,  9.51it/s, loss=0.455, v_num=21, train_loss_step=0.313]Epoch 0:  71%|███████   | 268/380 [00:28<00:11,  9.51it/s, loss=0.455, v_num=21, train_loss_step=0.313]Epoch 0:  71%|███████   | 268/380 [00:28<00:11,  9.51it/s, loss=0.452, v_num=21, train_loss_step=0.570]Epoch 0:  71%|███████   | 269/380 [00:28<00:11,  9.51it/s, loss=0.452, v_num=21, train_loss_step=0.570]Epoch 0:  71%|███████   | 269/380 [00:28<00:11,  9.51it/s, loss=0.45, v_num=21, train_loss_step=0.313] Epoch 0:  71%|███████   | 270/380 [00:28<00:11,  9.51it/s, loss=0.45, v_num=21, train_loss_step=0.313]Epoch 0:  71%|███████   | 270/380 [00:28<00:11,  9.51it/s, loss=0.462, v_num=21, train_loss_step=0.782]Epoch 0:  71%|███████▏  | 271/380 [00:28<00:11,  9.51it/s, loss=0.462, v_num=21, train_loss_step=0.782]Epoch 0:  71%|███████▏  | 271/380 [00:28<00:11,  9.51it/s, loss=0.461, v_num=21, train_loss_step=0.313]Epoch 0:  72%|███████▏  | 272/380 [00:28<00:11,  9.51it/s, loss=0.461, v_num=21, train_loss_step=0.313]Epoch 0:  72%|███████▏  | 272/380 [00:28<00:11,  9.51it/s, loss=0.465, v_num=21, train_loss_step=0.450]Epoch 0:  72%|███████▏  | 273/380 [00:28<00:11,  9.51it/s, loss=0.465, v_num=21, train_loss_step=0.450]Epoch 0:  72%|███████▏  | 273/380 [00:28<00:11,  9.51it/s, loss=0.48, v_num=21, train_loss_step=0.683] Epoch 0:  72%|███████▏  | 274/380 [00:28<00:11,  9.51it/s, loss=0.48, v_num=21, train_loss_step=0.683]Epoch 0:  72%|███████▏  | 274/380 [00:28<00:11,  9.51it/s, loss=0.48, v_num=21, train_loss_step=0.313]Epoch 0:  72%|███████▏  | 275/380 [00:29<00:11,  9.51it/s, loss=0.48, v_num=21, train_loss_step=0.313]Epoch 0:  72%|███████▏  | 275/380 [00:29<00:11,  9.51it/s, loss=0.465, v_num=21, train_loss_step=0.381]Epoch 0:  73%|███████▎  | 276/380 [00:29<00:10,  9.51it/s, loss=0.465, v_num=21, train_loss_step=0.381]Epoch 0:  73%|███████▎  | 276/380 [00:29<00:10,  9.51it/s, loss=0.461, v_num=21, train_loss_step=0.313]Epoch 0:  73%|███████▎  | 277/380 [00:29<00:10,  9.51it/s, loss=0.461, v_num=21, train_loss_step=0.313]Epoch 0:  73%|███████▎  | 277/380 [00:29<00:10,  9.51it/s, loss=0.473, v_num=21, train_loss_step=0.558]Epoch 0:  73%|███████▎  | 278/380 [00:29<00:10,  9.51it/s, loss=0.473, v_num=21, train_loss_step=0.558]Epoch 0:  73%|███████▎  | 278/380 [00:29<00:10,  9.51it/s, loss=0.453, v_num=21, train_loss_step=0.349]Epoch 0:  73%|███████▎  | 279/380 [00:29<00:10,  9.51it/s, loss=0.453, v_num=21, train_loss_step=0.349]Epoch 0:  73%|███████▎  | 279/380 [00:29<00:10,  9.51it/s, loss=0.442, v_num=21, train_loss_step=0.313]Epoch 0:  74%|███████▎  | 280/380 [00:29<00:10,  9.51it/s, loss=0.442, v_num=21, train_loss_step=0.313]Epoch 0:  74%|███████▎  | 280/380 [00:29<00:10,  9.51it/s, loss=0.444, v_num=21, train_loss_step=0.589]Epoch 0:  74%|███████▍  | 281/380 [00:29<00:10,  9.51it/s, loss=0.444, v_num=21, train_loss_step=0.589]Epoch 0:  74%|███████▍  | 281/380 [00:29<00:10,  9.51it/s, loss=0.428, v_num=21, train_loss_step=0.368]Epoch 0:  74%|███████▍  | 282/380 [00:29<00:10,  9.51it/s, loss=0.428, v_num=21, train_loss_step=0.368]Epoch 0:  74%|███████▍  | 282/380 [00:29<00:10,  9.51it/s, loss=0.432, v_num=21, train_loss_step=0.458]Epoch 0:  74%|███████▍  | 283/380 [00:29<00:10,  9.51it/s, loss=0.432, v_num=21, train_loss_step=0.458]Epoch 0:  74%|███████▍  | 283/380 [00:29<00:10,  9.51it/s, loss=0.429, v_num=21, train_loss_step=0.461]Epoch 0:  75%|███████▍  | 284/380 [00:29<00:10,  9.51it/s, loss=0.429, v_num=21, train_loss_step=0.461]Epoch 0:  75%|███████▍  | 284/380 [00:29<00:10,  9.51it/s, loss=0.427, v_num=21, train_loss_step=0.323]Epoch 0:  75%|███████▌  | 285/380 [00:30<00:09,  9.51it/s, loss=0.427, v_num=21, train_loss_step=0.323]Epoch 0:  75%|███████▌  | 285/380 [00:30<00:09,  9.51it/s, loss=0.45, v_num=21, train_loss_step=0.802] Epoch 0:  75%|███████▌  | 286/380 [00:30<00:09,  9.51it/s, loss=0.45, v_num=21, train_loss_step=0.802]Epoch 0:  75%|███████▌  | 286/380 [00:30<00:09,  9.51it/s, loss=0.453, v_num=21, train_loss_step=0.400]Epoch 0:  76%|███████▌  | 287/380 [00:30<00:09,  9.51it/s, loss=0.453, v_num=21, train_loss_step=0.400]Epoch 0:  76%|███████▌  | 287/380 [00:30<00:09,  9.51it/s, loss=0.454, v_num=21, train_loss_step=0.340]Epoch 0:  76%|███████▌  | 288/380 [00:30<00:09,  9.51it/s, loss=0.454, v_num=21, train_loss_step=0.340]Epoch 0:  76%|███████▌  | 288/380 [00:30<00:09,  9.51it/s, loss=0.443, v_num=21, train_loss_step=0.350]Epoch 0:  76%|███████▌  | 289/380 [00:30<00:09,  9.51it/s, loss=0.443, v_num=21, train_loss_step=0.350]Epoch 0:  76%|███████▌  | 289/380 [00:30<00:09,  9.51it/s, loss=0.443, v_num=21, train_loss_step=0.313]Epoch 0:  76%|███████▋  | 290/380 [00:30<00:09,  9.51it/s, loss=0.443, v_num=21, train_loss_step=0.313]Epoch 0:  76%|███████▋  | 290/380 [00:30<00:09,  9.51it/s, loss=0.423, v_num=21, train_loss_step=0.390]Epoch 0:  77%|███████▋  | 291/380 [00:30<00:09,  9.51it/s, loss=0.423, v_num=21, train_loss_step=0.390]Epoch 0:  77%|███████▋  | 291/380 [00:30<00:09,  9.51it/s, loss=0.423, v_num=21, train_loss_step=0.313]Epoch 0:  77%|███████▋  | 292/380 [00:30<00:09,  9.51it/s, loss=0.423, v_num=21, train_loss_step=0.313]Epoch 0:  77%|███████▋  | 292/380 [00:30<00:09,  9.51it/s, loss=0.417, v_num=21, train_loss_step=0.314]Epoch 0:  77%|███████▋  | 293/380 [00:30<00:09,  9.51it/s, loss=0.417, v_num=21, train_loss_step=0.314]Epoch 0:  77%|███████▋  | 293/380 [00:30<00:09,  9.51it/s, loss=0.398, v_num=21, train_loss_step=0.313]Epoch 0:  77%|███████▋  | 294/380 [00:31<00:09,  9.51it/s, loss=0.398, v_num=21, train_loss_step=0.313]Epoch 0:  77%|███████▋  | 294/380 [00:31<00:09,  9.51it/s, loss=0.411, v_num=21, train_loss_step=0.565]Epoch 0:  78%|███████▊  | 295/380 [00:31<00:08,  9.51it/s, loss=0.411, v_num=21, train_loss_step=0.565]Epoch 0:  78%|███████▊  | 295/380 [00:31<00:08,  9.51it/s, loss=0.41, v_num=21, train_loss_step=0.366] Epoch 0:  78%|███████▊  | 296/380 [00:31<00:08,  9.51it/s, loss=0.41, v_num=21, train_loss_step=0.366]Epoch 0:  78%|███████▊  | 296/380 [00:31<00:08,  9.51it/s, loss=0.427, v_num=21, train_loss_step=0.659]Epoch 0:  78%|███████▊  | 297/380 [00:31<00:08,  9.51it/s, loss=0.427, v_num=21, train_loss_step=0.659]Epoch 0:  78%|███████▊  | 297/380 [00:31<00:08,  9.51it/s, loss=0.419, v_num=21, train_loss_step=0.383]Epoch 0:  78%|███████▊  | 298/380 [00:31<00:08,  9.51it/s, loss=0.419, v_num=21, train_loss_step=0.383]Epoch 0:  78%|███████▊  | 298/380 [00:31<00:08,  9.51it/s, loss=0.419, v_num=21, train_loss_step=0.350]Epoch 0:  79%|███████▊  | 299/380 [00:31<00:08,  9.51it/s, loss=0.419, v_num=21, train_loss_step=0.350]Epoch 0:  79%|███████▊  | 299/380 [00:31<00:08,  9.51it/s, loss=0.421, v_num=21, train_loss_step=0.372]Epoch 0:  79%|███████▉  | 300/380 [00:31<00:08,  9.51it/s, loss=0.421, v_num=21, train_loss_step=0.372]Epoch 0:  79%|███████▉  | 300/380 [00:31<00:08,  9.51it/s, loss=0.416, v_num=21, train_loss_step=0.484]Epoch 0:  79%|███████▉  | 301/380 [00:31<00:08,  9.51it/s, loss=0.416, v_num=21, train_loss_step=0.484]Epoch 0:  79%|███████▉  | 301/380 [00:31<00:08,  9.51it/s, loss=0.414, v_num=21, train_loss_step=0.316]Epoch 0:  79%|███████▉  | 302/380 [00:31<00:08,  9.51it/s, loss=0.414, v_num=21, train_loss_step=0.316]Epoch 0:  79%|███████▉  | 302/380 [00:31<00:08,  9.51it/s, loss=0.424, v_num=21, train_loss_step=0.674]Epoch 0:  80%|███████▉  | 303/380 [00:31<00:08,  9.51it/s, loss=0.424, v_num=21, train_loss_step=0.674]Epoch 0:  80%|███████▉  | 303/380 [00:31<00:08,  9.51it/s, loss=0.417, v_num=21, train_loss_step=0.313]Epoch 0:  80%|████████  | 304/380 [00:32<00:07,  9.51it/s, loss=0.417, v_num=21, train_loss_step=0.313]Epoch 0:  80%|████████  | 304/380 [00:32<00:07,  9.51it/s, loss=0.418, v_num=21, train_loss_step=0.335]Epoch 0:  80%|████████  | 305/380 [00:32<00:07,  9.51it/s, loss=0.418, v_num=21, train_loss_step=0.335]Epoch 0:  80%|████████  | 305/380 [00:32<00:07,  9.51it/s, loss=0.393, v_num=21, train_loss_step=0.313]Epoch 0:  81%|████████  | 306/380 [00:32<00:07,  9.51it/s, loss=0.393, v_num=21, train_loss_step=0.313]Epoch 0:  81%|████████  | 306/380 [00:32<00:07,  9.51it/s, loss=0.402, v_num=21, train_loss_step=0.576]Epoch 0:  81%|████████  | 307/380 [00:32<00:07,  9.51it/s, loss=0.402, v_num=21, train_loss_step=0.576]Epoch 0:  81%|████████  | 307/380 [00:32<00:07,  9.51it/s, loss=0.401, v_num=21, train_loss_step=0.313]Epoch 0:  81%|████████  | 308/380 [00:32<00:07,  9.51it/s, loss=0.401, v_num=21, train_loss_step=0.313]Epoch 0:  81%|████████  | 308/380 [00:32<00:07,  9.51it/s, loss=0.399, v_num=21, train_loss_step=0.313]Epoch 0:  81%|████████▏ | 309/380 [00:32<00:07,  9.51it/s, loss=0.399, v_num=21, train_loss_step=0.313]Epoch 0:  81%|████████▏ | 309/380 [00:32<00:07,  9.51it/s, loss=0.411, v_num=21, train_loss_step=0.566]Epoch 0:  82%|████████▏ | 310/380 [00:32<00:07,  9.51it/s, loss=0.411, v_num=21, train_loss_step=0.566]Epoch 0:  82%|████████▏ | 310/380 [00:32<00:07,  9.51it/s, loss=0.439, v_num=21, train_loss_step=0.944]Epoch 0:  82%|████████▏ | 311/380 [00:32<00:07,  9.51it/s, loss=0.439, v_num=21, train_loss_step=0.944]Epoch 0:  82%|████████▏ | 311/380 [00:32<00:07,  9.51it/s, loss=0.444, v_num=21, train_loss_step=0.414]Epoch 0:  82%|████████▏ | 312/380 [00:32<00:07,  9.50it/s, loss=0.444, v_num=21, train_loss_step=0.414]Epoch 0:  82%|████████▏ | 312/380 [00:32<00:07,  9.50it/s, loss=0.448, v_num=21, train_loss_step=0.397]Epoch 0:  82%|████████▏ | 313/380 [00:33<00:07,  9.50it/s, loss=0.448, v_num=21, train_loss_step=0.397]Epoch 0:  82%|████████▏ | 313/380 [00:33<00:07,  9.50it/s, loss=0.448, v_num=21, train_loss_step=0.313]Epoch 0:  83%|████████▎ | 314/380 [00:33<00:06,  9.50it/s, loss=0.448, v_num=21, train_loss_step=0.313]Epoch 0:  83%|████████▎ | 314/380 [00:33<00:06,  9.50it/s, loss=0.455, v_num=21, train_loss_step=0.688]Epoch 0:  83%|████████▎ | 315/380 [00:33<00:06,  9.50it/s, loss=0.455, v_num=21, train_loss_step=0.688]Epoch 0:  83%|████████▎ | 315/380 [00:33<00:06,  9.50it/s, loss=0.455, v_num=21, train_loss_step=0.382]Epoch 0:  83%|████████▎ | 316/380 [00:33<00:06,  9.50it/s, loss=0.455, v_num=21, train_loss_step=0.382]Epoch 0:  83%|████████▎ | 316/380 [00:33<00:06,  9.50it/s, loss=0.456, v_num=21, train_loss_step=0.674]Epoch 0:  83%|████████▎ | 317/380 [00:33<00:06,  9.50it/s, loss=0.456, v_num=21, train_loss_step=0.674]Epoch 0:  83%|████████▎ | 317/380 [00:33<00:06,  9.50it/s, loss=0.457, v_num=21, train_loss_step=0.408]Epoch 0:  84%|████████▎ | 318/380 [00:33<00:06,  9.50it/s, loss=0.457, v_num=21, train_loss_step=0.408]Epoch 0:  84%|████████▎ | 318/380 [00:33<00:06,  9.50it/s, loss=0.456, v_num=21, train_loss_step=0.313]Epoch 0:  84%|████████▍ | 319/380 [00:33<00:06,  9.50it/s, loss=0.456, v_num=21, train_loss_step=0.313]Epoch 0:  84%|████████▍ | 319/380 [00:33<00:06,  9.50it/s, loss=0.453, v_num=21, train_loss_step=0.313]Epoch 0:  84%|████████▍ | 320/380 [00:33<00:06,  9.50it/s, loss=0.453, v_num=21, train_loss_step=0.313]Epoch 0:  84%|████████▍ | 320/380 [00:33<00:06,  9.50it/s, loss=0.446, v_num=21, train_loss_step=0.345]Epoch 0:  84%|████████▍ | 321/380 [00:33<00:06,  9.50it/s, loss=0.446, v_num=21, train_loss_step=0.345]Epoch 0:  84%|████████▍ | 321/380 [00:33<00:06,  9.50it/s, loss=0.46, v_num=21, train_loss_step=0.602] Epoch 0:  85%|████████▍ | 322/380 [00:33<00:06,  9.50it/s, loss=0.46, v_num=21, train_loss_step=0.602]Epoch 0:  85%|████████▍ | 322/380 [00:33<00:06,  9.50it/s, loss=0.445, v_num=21, train_loss_step=0.379]Epoch 0:  85%|████████▌ | 323/380 [00:34<00:05,  9.50it/s, loss=0.445, v_num=21, train_loss_step=0.379]Epoch 0:  85%|████████▌ | 323/380 [00:34<00:05,  9.50it/s, loss=0.447, v_num=21, train_loss_step=0.346]Epoch 0:  85%|████████▌ | 324/380 [00:34<00:05,  9.50it/s, loss=0.447, v_num=21, train_loss_step=0.346]Epoch 0:  85%|████████▌ | 324/380 [00:34<00:05,  9.50it/s, loss=0.446, v_num=21, train_loss_step=0.313]Epoch 0:  86%|████████▌ | 325/380 [00:34<00:05,  9.50it/s, loss=0.446, v_num=21, train_loss_step=0.313]Epoch 0:  86%|████████▌ | 325/380 [00:34<00:05,  9.50it/s, loss=0.449, v_num=21, train_loss_step=0.381]Epoch 0:  86%|████████▌ | 326/380 [00:34<00:05,  9.50it/s, loss=0.449, v_num=21, train_loss_step=0.381]Epoch 0:  86%|████████▌ | 326/380 [00:34<00:05,  9.50it/s, loss=0.441, v_num=21, train_loss_step=0.421]Epoch 0:  86%|████████▌ | 327/380 [00:34<00:05,  9.50it/s, loss=0.441, v_num=21, train_loss_step=0.421]Epoch 0:  86%|████████▌ | 327/380 [00:34<00:05,  9.50it/s, loss=0.459, v_num=21, train_loss_step=0.671]Epoch 0:  86%|████████▋ | 328/380 [00:34<00:05,  9.50it/s, loss=0.459, v_num=21, train_loss_step=0.671]Epoch 0:  86%|████████▋ | 328/380 [00:34<00:05,  9.50it/s, loss=0.46, v_num=21, train_loss_step=0.320] Epoch 0:  87%|████████▋ | 329/380 [00:34<00:05,  9.50it/s, loss=0.46, v_num=21, train_loss_step=0.320]Epoch 0:  87%|████████▋ | 329/380 [00:34<00:05,  9.50it/s, loss=0.447, v_num=21, train_loss_step=0.313]Epoch 0:  87%|████████▋ | 330/380 [00:34<00:05,  9.50it/s, loss=0.447, v_num=21, train_loss_step=0.313]Epoch 0:  87%|████████▋ | 330/380 [00:34<00:05,  9.50it/s, loss=0.421, v_num=21, train_loss_step=0.418]Epoch 0:  87%|████████▋ | 331/380 [00:34<00:05,  9.50it/s, loss=0.421, v_num=21, train_loss_step=0.418]Epoch 0:  87%|████████▋ | 331/380 [00:34<00:05,  9.50it/s, loss=0.416, v_num=21, train_loss_step=0.313]Epoch 0:  87%|████████▋ | 332/380 [00:35<00:05,  9.50it/s, loss=0.416, v_num=21, train_loss_step=0.313]Epoch 0:  87%|████████▋ | 332/380 [00:35<00:05,  9.50it/s, loss=0.427, v_num=21, train_loss_step=0.617]Epoch 0:  88%|████████▊ | 333/380 [00:35<00:04,  9.50it/s, loss=0.427, v_num=21, train_loss_step=0.617]Epoch 0:  88%|████████▊ | 333/380 [00:35<00:04,  9.50it/s, loss=0.427, v_num=21, train_loss_step=0.313]Epoch 0:  88%|████████▊ | 334/380 [00:35<00:04,  9.51it/s, loss=0.413, v_num=21, train_loss_step=0.413]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/46 [00:00<?, ?it/s][A
Validating:   2%|▏         | 1/46 [00:00<00:12,  3.58it/s][AEpoch 0:  88%|████████▊ | 336/380 [00:35<00:04,  9.49it/s, loss=0.413, v_num=21, train_loss_step=0.413]
Validating:   4%|▍         | 2/46 [00:00<00:12,  3.59it/s][A
Validating:   7%|▋         | 3/46 [00:00<00:11,  3.60it/s][A
Validating:   9%|▊         | 4/46 [00:01<00:11,  3.60it/s][AEpoch 0:  89%|████████▉ | 339/380 [00:36<00:04,  9.35it/s, loss=0.413, v_num=21, train_loss_step=0.413]
Validating:  11%|█         | 5/46 [00:01<00:11,  3.61it/s][A
Validating:  13%|█▎        | 6/46 [00:01<00:11,  3.61it/s][A
Validating:  15%|█▌        | 7/46 [00:01<00:10,  3.62it/s][AEpoch 0:  90%|█████████ | 342/380 [00:37<00:04,  9.23it/s, loss=0.413, v_num=21, train_loss_step=0.413]
Validating:  17%|█▋        | 8/46 [00:02<00:10,  3.62it/s][A
Validating:  20%|█▉        | 9/46 [00:02<00:10,  3.62it/s][A
Validating:  22%|██▏       | 10/46 [00:02<00:09,  3.62it/s][AEpoch 0:  91%|█████████ | 345/380 [00:38<00:03,  9.10it/s, loss=0.413, v_num=21, train_loss_step=0.413]
Validating:  24%|██▍       | 11/46 [00:03<00:09,  3.61it/s][A
Validating:  26%|██▌       | 12/46 [00:03<00:09,  3.62it/s][A
Validating:  28%|██▊       | 13/46 [00:03<00:09,  3.63it/s][AEpoch 0:  92%|█████████▏| 348/380 [00:38<00:03,  8.99it/s, loss=0.413, v_num=21, train_loss_step=0.413]
Validating:  30%|███       | 14/46 [00:03<00:08,  3.64it/s][A
Validating:  33%|███▎      | 15/46 [00:04<00:08,  3.64it/s][A
Validating:  35%|███▍      | 16/46 [00:04<00:08,  3.64it/s][AEpoch 0:  92%|█████████▏| 351/380 [00:39<00:03,  8.88it/s, loss=0.413, v_num=21, train_loss_step=0.413]
Validating:  37%|███▋      | 17/46 [00:04<00:07,  3.64it/s][A
Validating:  39%|███▉      | 18/46 [00:04<00:07,  3.64it/s][A
Validating:  41%|████▏     | 19/46 [00:05<00:07,  3.64it/s][AEpoch 0:  93%|█████████▎| 354/380 [00:40<00:02,  8.77it/s, loss=0.413, v_num=21, train_loss_step=0.413]
Validating:  43%|████▎     | 20/46 [00:05<00:07,  3.63it/s][A
Validating:  46%|████▌     | 21/46 [00:05<00:06,  3.64it/s][A
Validating:  48%|████▊     | 22/46 [00:06<00:06,  3.63it/s][AEpoch 0:  94%|█████████▍| 357/380 [00:41<00:02,  8.67it/s, loss=0.413, v_num=21, train_loss_step=0.413]
Validating:  50%|█████     | 23/46 [00:06<00:06,  3.64it/s][A
Validating:  52%|█████▏    | 24/46 [00:06<00:06,  3.61it/s][A
Validating:  54%|█████▍    | 25/46 [00:06<00:05,  3.61it/s][AEpoch 0:  95%|█████████▍| 360/380 [00:42<00:02,  8.57it/s, loss=0.413, v_num=21, train_loss_step=0.413]
Validating:  57%|█████▋    | 26/46 [00:07<00:05,  3.61it/s][A
Validating:  59%|█████▊    | 27/46 [00:07<00:05,  3.61it/s][A
Validating:  61%|██████    | 28/46 [00:07<00:04,  3.60it/s][AEpoch 0:  96%|█████████▌| 363/380 [00:42<00:02,  8.47it/s, loss=0.413, v_num=21, train_loss_step=0.413]
Validating:  63%|██████▎   | 29/46 [00:08<00:04,  3.61it/s][A
Validating:  65%|██████▌   | 30/46 [00:08<00:04,  3.61it/s][A
Validating:  67%|██████▋   | 31/46 [00:08<00:04,  3.61it/s][AEpoch 0:  96%|█████████▋| 366/380 [00:43<00:01,  8.38it/s, loss=0.413, v_num=21, train_loss_step=0.413]
Validating:  70%|██████▉   | 32/46 [00:08<00:03,  3.61it/s][A
Validating:  72%|███████▏  | 33/46 [00:09<00:03,  3.59it/s][A
Validating:  74%|███████▍  | 34/46 [00:09<00:03,  3.59it/s][AEpoch 0:  97%|█████████▋| 369/380 [00:44<00:01,  8.29it/s, loss=0.413, v_num=21, train_loss_step=0.413]
Validating:  76%|███████▌  | 35/46 [00:09<00:03,  3.58it/s][A
Validating:  78%|███████▊  | 36/46 [00:09<00:02,  3.59it/s][A
Validating:  80%|████████  | 37/46 [00:10<00:02,  3.59it/s][AEpoch 0:  98%|█████████▊| 372/380 [00:45<00:00,  8.20it/s, loss=0.413, v_num=21, train_loss_step=0.413]
Validating:  83%|████████▎ | 38/46 [00:10<00:02,  3.61it/s][A
Validating:  85%|████████▍ | 39/46 [00:10<00:01,  3.61it/s][A
Validating:  87%|████████▋ | 40/46 [00:11<00:01,  3.60it/s][AEpoch 0:  99%|█████████▊| 375/380 [00:46<00:00,  8.12it/s, loss=0.413, v_num=21, train_loss_step=0.413]
Validating:  89%|████████▉ | 41/46 [00:11<00:01,  3.60it/s][A
Validating:  91%|█████████▏| 42/46 [00:11<00:01,  3.59it/s][A
Validating:  93%|█████████▎| 43/46 [00:11<00:00,  3.55it/s][AEpoch 0:  99%|█████████▉| 378/380 [00:47<00:00,  8.04it/s, loss=0.413, v_num=21, train_loss_step=0.413]
Validating:  96%|█████████▌| 44/46 [00:12<00:00,  3.54it/s][A
Validating:  98%|█████████▊| 45/46 [00:12<00:00,  3.56it/s][A
Validating: 100%|██████████| 46/46 [00:12<00:00,  3.57it/s][AEpoch 0: 100%|██████████| 380/380 [00:47<00:00,  7.94it/s, loss=0.413, v_num=21, train_loss_step=0.413]
                                                           [AEpoch 0: 100%|██████████| 380/380 [00:48<00:00,  7.93it/s, loss=0.413, v_num=21, train_loss_step=0.413]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(

Testing: 0it [00:00, ?it/s]Testing:   1%|          | 1/169 [00:00<00:23,  7.21it/s]Testing:   1%|          | 2/169 [00:00<00:21,  7.64it/s]Testing:   2%|▏         | 3/169 [00:00<00:21,  7.79it/s]Testing:   2%|▏         | 4/169 [00:00<00:20,  7.91it/s]Testing:   3%|▎         | 5/169 [00:00<00:20,  7.94it/s]Testing:   4%|▎         | 6/169 [00:00<00:20,  7.95it/s]Testing:   4%|▍         | 7/169 [00:00<00:20,  8.01it/s]Testing:   5%|▍         | 8/169 [00:01<00:19,  8.06it/s]Testing:   5%|▌         | 9/169 [00:01<00:20,  7.96it/s]Testing:   6%|▌         | 10/169 [00:01<00:19,  7.97it/s]Testing:   7%|▋         | 11/169 [00:01<00:19,  8.02it/s]Testing:   7%|▋         | 12/169 [00:01<00:19,  8.01it/s]Testing:   8%|▊         | 13/169 [00:01<00:19,  8.03it/s]Testing:   8%|▊         | 14/169 [00:01<00:19,  7.98it/s]Testing:   9%|▉         | 15/169 [00:01<00:19,  8.00it/s]Testing:   9%|▉         | 16/169 [00:02<00:19,  8.03it/s]Testing:  10%|█         | 17/169 [00:02<00:18,  8.06it/s]Testing:  11%|█         | 18/169 [00:02<00:18,  8.03it/s]Testing:  11%|█         | 19/169 [00:02<00:18,  8.04it/s]Testing:  12%|█▏        | 20/169 [00:02<00:18,  8.08it/s]Testing:  12%|█▏        | 21/169 [00:02<00:18,  8.05it/s]Testing:  13%|█▎        | 22/169 [00:02<00:18,  8.00it/s]Testing:  14%|█▎        | 23/169 [00:02<00:18,  8.01it/s]Testing:  14%|█▍        | 24/169 [00:03<00:18,  8.03it/s]Testing:  15%|█▍        | 25/169 [00:03<00:17,  8.07it/s]Testing:  15%|█▌        | 26/169 [00:03<00:17,  7.98it/s]Testing:  16%|█▌        | 27/169 [00:03<00:17,  7.96it/s]Testing:  17%|█▋        | 28/169 [00:03<00:17,  8.00it/s]Testing:  17%|█▋        | 29/169 [00:03<00:17,  8.02it/s]Testing:  18%|█▊        | 30/169 [00:03<00:17,  8.00it/s]Testing:  18%|█▊        | 31/169 [00:03<00:17,  8.02it/s]Testing:  19%|█▉        | 32/169 [00:04<00:17,  8.02it/s]Testing:  20%|█▉        | 33/169 [00:04<00:17,  7.98it/s]Testing:  20%|██        | 34/169 [00:04<00:16,  8.00it/s]Testing:  21%|██        | 35/169 [00:04<00:16,  7.99it/s]Testing:  21%|██▏       | 36/169 [00:04<00:16,  8.00it/s]Testing:  22%|██▏       | 37/169 [00:04<00:16,  8.01it/s]Testing:  22%|██▏       | 38/169 [00:04<00:16,  8.02it/s]Testing:  23%|██▎       | 39/169 [00:04<00:16,  8.02it/s]Testing:  24%|██▎       | 40/169 [00:05<00:16,  8.04it/s]Testing:  24%|██▍       | 41/169 [00:05<00:15,  8.05it/s]Testing:  25%|██▍       | 42/169 [00:05<00:15,  8.06it/s]Testing:  25%|██▌       | 43/169 [00:05<00:15,  8.04it/s]Testing:  26%|██▌       | 44/169 [00:05<00:15,  8.02it/s]Testing:  27%|██▋       | 45/169 [00:05<00:15,  8.04it/s]Testing:  27%|██▋       | 46/169 [00:05<00:15,  7.99it/s]Testing:  28%|██▊       | 47/169 [00:05<00:15,  7.96it/s]Testing:  28%|██▊       | 48/169 [00:06<00:15,  8.00it/s]Testing:  29%|██▉       | 49/169 [00:06<00:15,  8.00it/s]Testing:  30%|██▉       | 50/169 [00:06<00:14,  8.04it/s]Testing:  30%|███       | 51/169 [00:06<00:14,  8.05it/s]Testing:  31%|███       | 52/169 [00:06<00:14,  8.03it/s]Testing:  31%|███▏      | 53/169 [00:06<00:14,  7.99it/s]Testing:  32%|███▏      | 54/169 [00:06<00:14,  8.05it/s]Testing:  33%|███▎      | 55/169 [00:06<00:14,  8.07it/s]Testing:  33%|███▎      | 56/169 [00:06<00:14,  8.04it/s]Testing:  34%|███▎      | 57/169 [00:07<00:13,  8.06it/s]Testing:  34%|███▍      | 58/169 [00:07<00:13,  8.05it/s]Testing:  35%|███▍      | 59/169 [00:07<00:13,  8.06it/s]Testing:  36%|███▌      | 60/169 [00:07<00:13,  8.00it/s]Testing:  36%|███▌      | 61/169 [00:07<00:13,  8.04it/s]Testing:  37%|███▋      | 62/169 [00:07<00:13,  8.01it/s]Testing:  37%|███▋      | 63/169 [00:07<00:13,  8.00it/s]Testing:  38%|███▊      | 64/169 [00:07<00:13,  8.02it/s]Testing:  38%|███▊      | 65/169 [00:08<00:12,  8.02it/s]Testing:  39%|███▉      | 66/169 [00:08<00:12,  8.03it/s]Testing:  40%|███▉      | 67/169 [00:08<00:12,  8.05it/s]Testing:  40%|████      | 68/169 [00:08<00:12,  8.08it/s]Testing:  41%|████      | 69/169 [00:08<00:12,  8.09it/s]Testing:  41%|████▏     | 70/169 [00:08<00:12,  8.07it/s]Testing:  42%|████▏     | 71/169 [00:08<00:12,  8.02it/s]Testing:  43%|████▎     | 72/169 [00:08<00:12,  8.05it/s]Testing:  43%|████▎     | 73/169 [00:09<00:11,  8.07it/s]Testing:  44%|████▍     | 74/169 [00:09<00:11,  8.06it/s]Testing:  44%|████▍     | 75/169 [00:09<00:11,  8.03it/s]Testing:  45%|████▍     | 76/169 [00:09<00:11,  8.03it/s]Testing:  46%|████▌     | 77/169 [00:09<00:11,  8.03it/s]Testing:  46%|████▌     | 78/169 [00:09<00:11,  8.06it/s]Testing:  47%|████▋     | 79/169 [00:09<00:11,  8.05it/s]Testing:  47%|████▋     | 80/169 [00:09<00:11,  8.07it/s]Testing:  48%|████▊     | 81/169 [00:10<00:10,  8.06it/s]Testing:  49%|████▊     | 82/169 [00:10<00:10,  8.04it/s]Testing:  49%|████▉     | 83/169 [00:10<00:10,  8.06it/s]Testing:  50%|████▉     | 84/169 [00:10<00:10,  8.05it/s]Testing:  50%|█████     | 85/169 [00:10<00:10,  8.06it/s]Testing:  51%|█████     | 86/169 [00:10<00:10,  8.04it/s]Testing:  51%|█████▏    | 87/169 [00:10<00:10,  8.00it/s]Testing:  52%|█████▏    | 88/169 [00:10<00:10,  8.04it/s]Testing:  53%|█████▎    | 89/169 [00:11<00:09,  8.09it/s]Testing:  53%|█████▎    | 90/169 [00:11<00:09,  8.06it/s]Testing:  54%|█████▍    | 91/169 [00:11<00:09,  8.07it/s]Testing:  54%|█████▍    | 92/169 [00:11<00:09,  8.10it/s]Testing:  55%|█████▌    | 93/169 [00:11<00:09,  8.11it/s]Testing:  56%|█████▌    | 94/169 [00:11<00:09,  8.10it/s]Testing:  56%|█████▌    | 95/169 [00:11<00:09,  8.06it/s]Testing:  57%|█████▋    | 96/169 [00:11<00:09,  8.07it/s]Testing:  57%|█████▋    | 97/169 [00:12<00:08,  8.06it/s]Testing:  58%|█████▊    | 98/169 [00:12<00:08,  8.02it/s]Testing:  59%|█████▊    | 99/169 [00:12<00:08,  8.06it/s]Testing:  59%|█████▉    | 100/169 [00:12<00:08,  8.10it/s]Testing:  60%|█████▉    | 101/169 [00:12<00:08,  8.11it/s]Testing:  60%|██████    | 102/169 [00:12<00:08,  8.09it/s]Testing:  61%|██████    | 103/169 [00:12<00:08,  8.11it/s]Testing:  62%|██████▏   | 104/169 [00:12<00:08,  8.07it/s]Testing:  62%|██████▏   | 105/169 [00:13<00:07,  8.04it/s]Testing:  63%|██████▎   | 106/169 [00:13<00:07,  8.05it/s]Testing:  63%|██████▎   | 107/169 [00:13<00:07,  8.02it/s]Testing:  64%|██████▍   | 108/169 [00:13<00:07,  8.07it/s]Testing:  64%|██████▍   | 109/169 [00:13<00:07,  8.04it/s]Testing:  65%|██████▌   | 110/169 [00:13<00:07,  8.09it/s]Testing:  66%|██████▌   | 111/169 [00:13<00:07,  8.04it/s]Testing:  66%|██████▋   | 112/169 [00:13<00:07,  8.06it/s]Testing:  67%|██████▋   | 113/169 [00:14<00:06,  8.06it/s]Testing:  67%|██████▋   | 114/169 [00:14<00:06,  8.01it/s]Testing:  68%|██████▊   | 115/169 [00:14<00:06,  8.03it/s]Testing:  69%|██████▊   | 116/169 [00:14<00:06,  8.07it/s]Testing:  69%|██████▉   | 117/169 [00:14<00:06,  8.06it/s]Testing:  70%|██████▉   | 118/169 [00:14<00:06,  8.07it/s]Testing:  70%|███████   | 119/169 [00:14<00:06,  8.08it/s]Testing:  71%|███████   | 120/169 [00:14<00:06,  8.10it/s]Testing:  72%|███████▏  | 121/169 [00:15<00:05,  8.04it/s]Testing:  72%|███████▏  | 122/169 [00:15<00:05,  8.02it/s]Testing:  73%|███████▎  | 123/169 [00:15<00:05,  8.01it/s]Testing:  73%|███████▎  | 124/169 [00:15<00:05,  8.05it/s]Testing:  74%|███████▍  | 125/169 [00:15<00:05,  8.04it/s]Testing:  75%|███████▍  | 126/169 [00:15<00:05,  8.02it/s]Testing:  75%|███████▌  | 127/169 [00:15<00:05,  8.03it/s]Testing:  76%|███████▌  | 128/169 [00:15<00:05,  8.03it/s]Testing:  76%|███████▋  | 129/169 [00:16<00:04,  8.02it/s]Testing:  77%|███████▋  | 130/169 [00:16<00:04,  8.02it/s]Testing:  78%|███████▊  | 131/169 [00:16<00:04,  8.06it/s]Testing:  78%|███████▊  | 132/169 [00:16<00:04,  8.04it/s]Testing:  79%|███████▊  | 133/169 [00:16<00:04,  8.01it/s]Testing:  79%|███████▉  | 134/169 [00:16<00:04,  8.04it/s]Testing:  80%|███████▉  | 135/169 [00:16<00:04,  8.03it/s]Testing:  80%|████████  | 136/169 [00:16<00:04,  8.06it/s]Testing:  81%|████████  | 137/169 [00:17<00:03,  8.05it/s]Testing:  82%|████████▏ | 138/169 [00:17<00:03,  8.04it/s]Testing:  82%|████████▏ | 139/169 [00:17<00:03,  8.02it/s]Testing:  83%|████████▎ | 140/169 [00:17<00:03,  8.00it/s]Testing:  83%|████████▎ | 141/169 [00:17<00:03,  8.01it/s]Testing:  84%|████████▍ | 142/169 [00:17<00:03,  8.03it/s]Testing:  85%|████████▍ | 143/169 [00:17<00:03,  8.03it/s]Testing:  85%|████████▌ | 144/169 [00:17<00:03,  7.99it/s]Testing:  86%|████████▌ | 145/169 [00:18<00:02,  8.01it/s]Testing:  86%|████████▋ | 146/169 [00:18<00:02,  7.92it/s]Testing:  87%|████████▋ | 147/169 [00:18<00:02,  7.89it/s]Testing:  88%|████████▊ | 148/169 [00:18<00:02,  7.94it/s]Testing:  88%|████████▊ | 149/169 [00:18<00:02,  7.93it/s]Testing:  89%|████████▉ | 150/169 [00:18<00:02,  7.95it/s]Testing:  89%|████████▉ | 151/169 [00:18<00:02,  7.96it/s]Testing:  90%|████████▉ | 152/169 [00:18<00:02,  7.97it/s]Testing:  91%|█████████ | 153/169 [00:19<00:01,  8.02it/s]Testing:  91%|█████████ | 154/169 [00:19<00:01,  8.05it/s]Testing:  92%|█████████▏| 155/169 [00:19<00:01,  8.10it/s]Testing:  92%|█████████▏| 156/169 [00:19<00:01,  8.08it/s]Testing:  93%|█████████▎| 157/169 [00:19<00:01,  8.09it/s]Testing:  93%|█████████▎| 158/169 [00:19<00:01,  8.08it/s]Testing:  94%|█████████▍| 159/169 [00:19<00:01,  8.06it/s]Testing:  95%|█████████▍| 160/169 [00:19<00:01,  8.06it/s]Testing:  95%|█████████▌| 161/169 [00:20<00:00,  8.10it/s]Testing:  96%|█████████▌| 162/169 [00:20<00:00,  8.07it/s]Testing:  96%|█████████▋| 163/169 [00:20<00:00,  8.07it/s]Testing:  97%|█████████▋| 164/169 [00:20<00:00,  8.09it/s]Testing:  98%|█████████▊| 165/169 [00:20<00:00,  8.07it/s]Testing:  98%|█████████▊| 166/169 [00:20<00:00,  7.95it/s]Testing:  99%|█████████▉| 167/169 [00:20<00:00,  7.96it/s]Testing:  99%|█████████▉| 168/169 [00:20<00:00,  7.99it/s]Testing: 100%|██████████| 169/169 [00:21<00:00,  8.03it/s]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'_mean_accuracy': 0.9849863648414612,
 '_standard_dev_accuracy': 0.029312921687960625,
 '_variance_accuracy': 0.0008592474041506648,
 'test_acc': 0.9849863648414612,
 'test_dice_c1': 0.0,
 'test_f2_c1': 0.0,
 'test_loss': 0.4305054843425751,
 'test_mean_c1': 0.0,
 'test_prec_c1': 0.0,
 'test_sens_c1': 0.0,
 'test_spec_c1': 1.0}
--------------------------------------------------------------------------------
Testing: 100%|██████████| 169/169 [00:21<00:00,  8.03it/s]
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

  | Name       | Type             | Params
------------------------------------------------
0 | encoder1   | EncoderBlock     | 37.6 K
1 | encoder2   | EncoderBlock     | 221 K 
2 | bottleneck | ConvolutionBlock | 885 K 
3 | dropout    | Dropout2d        | 0     
4 | decoder1   | DecoderBlock     | 573 K 
5 | decoder2   | DecoderBlock     | 143 K 
6 | conv       | Conv2d           | 130   
7 | softmax    | Softmax2d        | 0     
------------------------------------------------
1.9 M     Trainable params
0         Non-trainable params
1.9 M     Total params
7.447     Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Validation sanity check:  50%|█████     | 1/2 [00:01<00:01,  1.49s/it]Validation sanity check: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]                                                                      /home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Training: -1it [00:00, ?it/s]Training:   0%|          | 0/96 [00:00<00:00, 30840.47it/s]Epoch 0:   0%|          | 0/96 [00:00<00:00, 4271.19it/s]  Epoch 0:   1%|          | 1/96 [00:00<00:22,  4.19it/s]  Epoch 0:   1%|          | 1/96 [00:00<00:22,  4.19it/s, loss=0.706, v_num=22, train_loss_step=0.706]Epoch 0:   2%|▏         | 2/96 [00:00<00:27,  3.36it/s, loss=0.706, v_num=22, train_loss_step=0.706]Epoch 0:   2%|▏         | 2/96 [00:00<00:27,  3.36it/s, loss=0.711, v_num=22, train_loss_step=0.716]Epoch 0:   3%|▎         | 3/96 [00:01<00:30,  3.07it/s, loss=0.711, v_num=22, train_loss_step=0.716]Epoch 0:   3%|▎         | 3/96 [00:01<00:30,  3.06it/s, loss=0.71, v_num=22, train_loss_step=0.708] Epoch 0:   4%|▍         | 4/96 [00:01<00:31,  2.91it/s, loss=0.71, v_num=22, train_loss_step=0.708]Epoch 0:   4%|▍         | 4/96 [00:01<00:31,  2.91it/s, loss=0.708, v_num=22, train_loss_step=0.701]Epoch 0:   5%|▌         | 5/96 [00:02<00:32,  2.82it/s, loss=0.708, v_num=22, train_loss_step=0.701]Epoch 0:   5%|▌         | 5/96 [00:02<00:32,  2.81it/s, loss=0.705, v_num=22, train_loss_step=0.694]Epoch 0:   6%|▋         | 6/96 [00:02<00:32,  2.75it/s, loss=0.705, v_num=22, train_loss_step=0.694]Epoch 0:   6%|▋         | 6/96 [00:02<00:32,  2.75it/s, loss=0.702, v_num=22, train_loss_step=0.687]Epoch 0:   7%|▋         | 7/96 [00:02<00:32,  2.70it/s, loss=0.702, v_num=22, train_loss_step=0.687]Epoch 0:   7%|▋         | 7/96 [00:02<00:32,  2.70it/s, loss=0.698, v_num=22, train_loss_step=0.673]Epoch 0:   8%|▊         | 8/96 [00:03<00:33,  2.66it/s, loss=0.698, v_num=22, train_loss_step=0.673]Epoch 0:   8%|▊         | 8/96 [00:03<00:33,  2.66it/s, loss=0.692, v_num=22, train_loss_step=0.653]Epoch 0:   9%|▉         | 9/96 [00:03<00:33,  2.64it/s, loss=0.692, v_num=22, train_loss_step=0.653]Epoch 0:   9%|▉         | 9/96 [00:03<00:33,  2.64it/s, loss=0.682, v_num=22, train_loss_step=0.597]Epoch 0:  10%|█         | 10/96 [00:04<00:32,  2.61it/s, loss=0.682, v_num=22, train_loss_step=0.597]Epoch 0:  10%|█         | 10/96 [00:04<00:32,  2.61it/s, loss=0.66, v_num=22, train_loss_step=0.463] Epoch 0:  11%|█▏        | 11/96 [00:04<00:32,  2.59it/s, loss=0.66, v_num=22, train_loss_step=0.463]Epoch 0:  11%|█▏        | 11/96 [00:04<00:32,  2.59it/s, loss=0.638, v_num=22, train_loss_step=0.422]Epoch 0:  12%|█▎        | 12/96 [00:05<00:32,  2.57it/s, loss=0.638, v_num=22, train_loss_step=0.422]Epoch 0:  12%|█▎        | 12/96 [00:05<00:32,  2.57it/s, loss=0.617, v_num=22, train_loss_step=0.385]Epoch 0:  14%|█▎        | 13/96 [00:05<00:32,  2.56it/s, loss=0.617, v_num=22, train_loss_step=0.385]Epoch 0:  14%|█▎        | 13/96 [00:05<00:32,  2.56it/s, loss=0.598, v_num=22, train_loss_step=0.365]Epoch 0:  15%|█▍        | 14/96 [00:05<00:32,  2.54it/s, loss=0.598, v_num=22, train_loss_step=0.365]Epoch 0:  15%|█▍        | 14/96 [00:05<00:32,  2.54it/s, loss=0.598, v_num=22, train_loss_step=0.599]Epoch 0:  16%|█▌        | 15/96 [00:06<00:31,  2.53it/s, loss=0.598, v_num=22, train_loss_step=0.599]Epoch 0:  16%|█▌        | 15/96 [00:06<00:31,  2.53it/s, loss=0.596, v_num=22, train_loss_step=0.577]Epoch 0:  17%|█▋        | 16/96 [00:06<00:31,  2.53it/s, loss=0.596, v_num=22, train_loss_step=0.577]Epoch 0:  17%|█▋        | 16/96 [00:06<00:31,  2.53it/s, loss=0.586, v_num=22, train_loss_step=0.436]Epoch 0:  18%|█▊        | 17/96 [00:07<00:31,  2.52it/s, loss=0.586, v_num=22, train_loss_step=0.436]Epoch 0:  18%|█▊        | 17/96 [00:07<00:31,  2.52it/s, loss=0.576, v_num=22, train_loss_step=0.406]Epoch 0:  19%|█▉        | 18/96 [00:07<00:31,  2.51it/s, loss=0.576, v_num=22, train_loss_step=0.406]Epoch 0:  19%|█▉        | 18/96 [00:07<00:31,  2.51it/s, loss=0.565, v_num=22, train_loss_step=0.390]Epoch 0:  20%|█▉        | 19/96 [00:07<00:30,  2.51it/s, loss=0.565, v_num=22, train_loss_step=0.390]Epoch 0:  20%|█▉        | 19/96 [00:07<00:30,  2.51it/s, loss=0.558, v_num=22, train_loss_step=0.422]Epoch 0:  21%|██        | 20/96 [00:08<00:30,  2.51it/s, loss=0.558, v_num=22, train_loss_step=0.422]Epoch 0:  21%|██        | 20/96 [00:08<00:30,  2.51it/s, loss=0.548, v_num=22, train_loss_step=0.362]Epoch 0:  22%|██▏       | 21/96 [00:08<00:29,  2.50it/s, loss=0.548, v_num=22, train_loss_step=0.362]Epoch 0:  22%|██▏       | 21/96 [00:08<00:29,  2.50it/s, loss=0.532, v_num=22, train_loss_step=0.392]Epoch 0:  23%|██▎       | 22/96 [00:09<00:29,  2.50it/s, loss=0.532, v_num=22, train_loss_step=0.392]Epoch 0:  23%|██▎       | 22/96 [00:09<00:29,  2.50it/s, loss=0.516, v_num=22, train_loss_step=0.392]Epoch 0:  24%|██▍       | 23/96 [00:09<00:29,  2.49it/s, loss=0.516, v_num=22, train_loss_step=0.392]Epoch 0:  24%|██▍       | 23/96 [00:09<00:29,  2.49it/s, loss=0.501, v_num=22, train_loss_step=0.395]Epoch 0:  25%|██▌       | 24/96 [00:10<00:28,  2.49it/s, loss=0.501, v_num=22, train_loss_step=0.395]Epoch 0:  25%|██▌       | 24/96 [00:10<00:28,  2.49it/s, loss=0.486, v_num=22, train_loss_step=0.415]Epoch 0:  26%|██▌       | 25/96 [00:10<00:28,  2.49it/s, loss=0.486, v_num=22, train_loss_step=0.415]Epoch 0:  26%|██▌       | 25/96 [00:10<00:28,  2.49it/s, loss=0.473, v_num=22, train_loss_step=0.423]Epoch 0:  27%|██▋       | 26/96 [00:10<00:28,  2.48it/s, loss=0.473, v_num=22, train_loss_step=0.423]Epoch 0:  27%|██▋       | 26/96 [00:10<00:28,  2.48it/s, loss=0.458, v_num=22, train_loss_step=0.398]Epoch 0:  28%|██▊       | 27/96 [00:11<00:27,  2.48it/s, loss=0.458, v_num=22, train_loss_step=0.398]Epoch 0:  28%|██▊       | 27/96 [00:11<00:27,  2.48it/s, loss=0.444, v_num=22, train_loss_step=0.393]Epoch 0:  29%|██▉       | 28/96 [00:11<00:27,  2.48it/s, loss=0.444, v_num=22, train_loss_step=0.393]Epoch 0:  29%|██▉       | 28/96 [00:11<00:27,  2.48it/s, loss=0.433, v_num=22, train_loss_step=0.427]Epoch 0:  30%|███       | 29/96 [00:12<00:27,  2.48it/s, loss=0.433, v_num=22, train_loss_step=0.427]Epoch 0:  30%|███       | 29/96 [00:12<00:27,  2.48it/s, loss=0.422, v_num=22, train_loss_step=0.376]Epoch 0:  31%|███▏      | 30/96 [00:12<00:26,  2.48it/s, loss=0.422, v_num=22, train_loss_step=0.376]Epoch 0:  31%|███▏      | 30/96 [00:12<00:26,  2.48it/s, loss=0.417, v_num=22, train_loss_step=0.357]Epoch 0:  32%|███▏      | 31/96 [00:12<00:26,  2.47it/s, loss=0.417, v_num=22, train_loss_step=0.357]Epoch 0:  32%|███▏      | 31/96 [00:12<00:26,  2.47it/s, loss=0.414, v_num=22, train_loss_step=0.375]Epoch 0:  33%|███▎      | 32/96 [00:13<00:25,  2.47it/s, loss=0.414, v_num=22, train_loss_step=0.375]Epoch 0:  33%|███▎      | 32/96 [00:13<00:25,  2.47it/s, loss=0.414, v_num=22, train_loss_step=0.372]Epoch 0:  34%|███▍      | 33/96 [00:13<00:25,  2.47it/s, loss=0.414, v_num=22, train_loss_step=0.372]Epoch 0:  34%|███▍      | 33/96 [00:13<00:25,  2.47it/s, loss=0.415, v_num=22, train_loss_step=0.393]Epoch 0:  35%|███▌      | 34/96 [00:14<00:25,  2.47it/s, loss=0.415, v_num=22, train_loss_step=0.393]Epoch 0:  35%|███▌      | 34/96 [00:14<00:25,  2.47it/s, loss=0.406, v_num=22, train_loss_step=0.413]Epoch 0:  36%|███▋      | 35/96 [00:14<00:24,  2.47it/s, loss=0.406, v_num=22, train_loss_step=0.413]Epoch 0:  36%|███▋      | 35/96 [00:14<00:24,  2.47it/s, loss=0.398, v_num=22, train_loss_step=0.415]Epoch 0:  38%|███▊      | 36/96 [00:15<00:24,  2.47it/s, loss=0.398, v_num=22, train_loss_step=0.415]Epoch 0:  38%|███▊      | 36/96 [00:15<00:24,  2.47it/s, loss=0.394, v_num=22, train_loss_step=0.370]Epoch 0:  39%|███▊      | 37/96 [00:15<00:23,  2.46it/s, loss=0.394, v_num=22, train_loss_step=0.370]Epoch 0:  39%|███▊      | 37/96 [00:15<00:23,  2.46it/s, loss=0.393, v_num=22, train_loss_step=0.376]Epoch 0:  40%|███▉      | 38/96 [00:15<00:23,  2.46it/s, loss=0.393, v_num=22, train_loss_step=0.376]Epoch 0:  40%|███▉      | 38/96 [00:15<00:23,  2.46it/s, loss=0.393, v_num=22, train_loss_step=0.384]Epoch 0:  41%|████      | 39/96 [00:16<00:23,  2.46it/s, loss=0.393, v_num=22, train_loss_step=0.384]Epoch 0:  41%|████      | 39/96 [00:16<00:23,  2.46it/s, loss=0.39, v_num=22, train_loss_step=0.375] Epoch 0:  42%|████▏     | 40/96 [00:16<00:22,  2.46it/s, loss=0.39, v_num=22, train_loss_step=0.375]Epoch 0:  42%|████▏     | 40/96 [00:16<00:22,  2.46it/s, loss=0.391, v_num=22, train_loss_step=0.371]Epoch 0:  43%|████▎     | 41/96 [00:17<00:22,  2.46it/s, loss=0.391, v_num=22, train_loss_step=0.371]Epoch 0:  43%|████▎     | 41/96 [00:17<00:22,  2.46it/s, loss=0.389, v_num=22, train_loss_step=0.367]Epoch 0:  44%|████▍     | 42/96 [00:17<00:21,  2.46it/s, loss=0.389, v_num=22, train_loss_step=0.367]Epoch 0:  44%|████▍     | 42/96 [00:17<00:21,  2.46it/s, loss=0.389, v_num=22, train_loss_step=0.375]Epoch 0:  45%|████▍     | 43/96 [00:17<00:21,  2.46it/s, loss=0.389, v_num=22, train_loss_step=0.375]Epoch 0:  45%|████▍     | 43/96 [00:17<00:21,  2.46it/s, loss=0.387, v_num=22, train_loss_step=0.367]Epoch 0:  46%|████▌     | 44/96 [00:18<00:21,  2.46it/s, loss=0.387, v_num=22, train_loss_step=0.367]Epoch 0:  46%|████▌     | 44/96 [00:18<00:21,  2.46it/s, loss=0.386, v_num=22, train_loss_step=0.399]Epoch 0:  47%|████▋     | 45/96 [00:18<00:20,  2.45it/s, loss=0.386, v_num=22, train_loss_step=0.399]Epoch 0:  47%|████▋     | 45/96 [00:18<00:20,  2.45it/s, loss=0.387, v_num=22, train_loss_step=0.437]Epoch 0:  48%|████▊     | 46/96 [00:19<00:20,  2.45it/s, loss=0.387, v_num=22, train_loss_step=0.437]Epoch 0:  48%|████▊     | 46/96 [00:19<00:20,  2.45it/s, loss=0.387, v_num=22, train_loss_step=0.392]Epoch 0:  49%|████▉     | 47/96 [00:19<00:19,  2.45it/s, loss=0.387, v_num=22, train_loss_step=0.392]Epoch 0:  49%|████▉     | 47/96 [00:19<00:19,  2.45it/s, loss=0.387, v_num=22, train_loss_step=0.401]Epoch 0:  50%|█████     | 48/96 [00:19<00:19,  2.45it/s, loss=0.387, v_num=22, train_loss_step=0.401]Epoch 0:  50%|█████     | 48/96 [00:19<00:19,  2.45it/s, loss=0.384, v_num=22, train_loss_step=0.362]Epoch 0:  51%|█████     | 49/96 [00:20<00:19,  2.45it/s, loss=0.384, v_num=22, train_loss_step=0.362]Epoch 0:  51%|█████     | 49/96 [00:20<00:19,  2.45it/s, loss=0.384, v_num=22, train_loss_step=0.370]Epoch 0:  52%|█████▏    | 50/96 [00:20<00:18,  2.45it/s, loss=0.384, v_num=22, train_loss_step=0.370]Epoch 0:  52%|█████▏    | 50/96 [00:20<00:18,  2.45it/s, loss=0.383, v_num=22, train_loss_step=0.347]Epoch 0:  53%|█████▎    | 51/96 [00:21<00:18,  2.45it/s, loss=0.383, v_num=22, train_loss_step=0.347]Epoch 0:  53%|█████▎    | 51/96 [00:21<00:18,  2.45it/s, loss=0.383, v_num=22, train_loss_step=0.381]Epoch 0:  54%|█████▍    | 52/96 [00:21<00:17,  2.45it/s, loss=0.383, v_num=22, train_loss_step=0.381]Epoch 0:  54%|█████▍    | 52/96 [00:21<00:17,  2.45it/s, loss=0.383, v_num=22, train_loss_step=0.362]Epoch 0:  55%|█████▌    | 53/96 [00:22<00:17,  2.45it/s, loss=0.383, v_num=22, train_loss_step=0.362]Epoch 0:  55%|█████▌    | 53/96 [00:22<00:17,  2.45it/s, loss=0.381, v_num=22, train_loss_step=0.352]Epoch 0:  56%|█████▋    | 54/96 [00:22<00:17,  2.45it/s, loss=0.381, v_num=22, train_loss_step=0.352]Epoch 0:  56%|█████▋    | 54/96 [00:22<00:17,  2.45it/s, loss=0.383, v_num=22, train_loss_step=0.445]Epoch 0:  57%|█████▋    | 55/96 [00:22<00:16,  2.45it/s, loss=0.383, v_num=22, train_loss_step=0.445]Epoch 0:  57%|█████▋    | 55/96 [00:22<00:16,  2.45it/s, loss=0.38, v_num=22, train_loss_step=0.356] Epoch 0:  58%|█████▊    | 56/96 [00:23<00:16,  2.45it/s, loss=0.38, v_num=22, train_loss_step=0.356]Epoch 0:  58%|█████▊    | 56/96 [00:23<00:16,  2.45it/s, loss=0.38, v_num=22, train_loss_step=0.383]Epoch 0:  59%|█████▉    | 57/96 [00:23<00:15,  2.45it/s, loss=0.38, v_num=22, train_loss_step=0.383]Epoch 0:  59%|█████▉    | 57/96 [00:23<00:15,  2.45it/s, loss=0.381, v_num=22, train_loss_step=0.382]Epoch 0:  60%|██████    | 58/96 [00:24<00:15,  2.45it/s, loss=0.381, v_num=22, train_loss_step=0.382]Epoch 0:  60%|██████    | 58/96 [00:24<00:15,  2.45it/s, loss=0.38, v_num=22, train_loss_step=0.367] Epoch 0:  61%|██████▏   | 59/96 [00:24<00:15,  2.45it/s, loss=0.38, v_num=22, train_loss_step=0.367]Epoch 0:  61%|██████▏   | 59/96 [00:24<00:15,  2.45it/s, loss=0.38, v_num=22, train_loss_step=0.391]Epoch 0:  62%|██████▎   | 60/96 [00:24<00:14,  2.45it/s, loss=0.38, v_num=22, train_loss_step=0.391]Epoch 0:  62%|██████▎   | 60/96 [00:24<00:14,  2.45it/s, loss=0.382, v_num=22, train_loss_step=0.400]Epoch 0:  64%|██████▎   | 61/96 [00:25<00:14,  2.45it/s, loss=0.382, v_num=22, train_loss_step=0.400]Epoch 0:  64%|██████▎   | 61/96 [00:25<00:14,  2.45it/s, loss=0.382, v_num=22, train_loss_step=0.367]Epoch 0:  65%|██████▍   | 62/96 [00:25<00:13,  2.44it/s, loss=0.382, v_num=22, train_loss_step=0.367]Epoch 0:  65%|██████▍   | 62/96 [00:25<00:13,  2.44it/s, loss=0.383, v_num=22, train_loss_step=0.387]Epoch 0:  66%|██████▌   | 63/96 [00:26<00:13,  2.44it/s, loss=0.383, v_num=22, train_loss_step=0.387]Epoch 0:  66%|██████▌   | 63/96 [00:26<00:13,  2.44it/s, loss=0.382, v_num=22, train_loss_step=0.360]Epoch 0:  67%|██████▋   | 64/96 [00:26<00:13,  2.44it/s, loss=0.382, v_num=22, train_loss_step=0.360]Epoch 0:  67%|██████▋   | 64/96 [00:26<00:13,  2.44it/s, loss=0.38, v_num=22, train_loss_step=0.358] Epoch 0:  68%|██████▊   | 65/96 [00:27<00:12,  2.44it/s, loss=0.38, v_num=22, train_loss_step=0.358]Epoch 0:  68%|██████▊   | 65/96 [00:27<00:12,  2.44it/s, loss=0.378, v_num=22, train_loss_step=0.398]Epoch 0:  69%|██████▉   | 66/96 [00:27<00:12,  2.44it/s, loss=0.378, v_num=22, train_loss_step=0.398]Epoch 0:  69%|██████▉   | 66/96 [00:27<00:12,  2.44it/s, loss=0.378, v_num=22, train_loss_step=0.383]Epoch 0:  70%|██████▉   | 67/96 [00:27<00:11,  2.44it/s, loss=0.378, v_num=22, train_loss_step=0.383]Epoch 0:  70%|██████▉   | 67/96 [00:27<00:11,  2.44it/s, loss=0.376, v_num=22, train_loss_step=0.370]Epoch 0:  71%|███████   | 68/96 [00:28<00:11,  2.44it/s, loss=0.376, v_num=22, train_loss_step=0.370]Epoch 0:  71%|███████   | 68/96 [00:28<00:11,  2.44it/s, loss=0.378, v_num=22, train_loss_step=0.394]Epoch 0:  72%|███████▏  | 69/96 [00:28<00:11,  2.44it/s, loss=0.378, v_num=22, train_loss_step=0.394]Epoch 0:  72%|███████▏  | 69/96 [00:28<00:11,  2.44it/s, loss=0.378, v_num=22, train_loss_step=0.370]Epoch 0:  73%|███████▎  | 70/96 [00:29<00:10,  2.44it/s, loss=0.378, v_num=22, train_loss_step=0.370]Epoch 0:  73%|███████▎  | 70/96 [00:29<00:10,  2.44it/s, loss=0.378, v_num=22, train_loss_step=0.347]Epoch 0:  74%|███████▍  | 71/96 [00:29<00:10,  2.44it/s, loss=0.378, v_num=22, train_loss_step=0.347]Epoch 0:  74%|███████▍  | 71/96 [00:29<00:10,  2.44it/s, loss=0.376, v_num=22, train_loss_step=0.351]Epoch 0:  75%|███████▌  | 72/96 [00:29<00:09,  2.44it/s, loss=0.376, v_num=22, train_loss_step=0.351]Epoch 0:  75%|███████▌  | 72/96 [00:29<00:09,  2.44it/s, loss=0.377, v_num=22, train_loss_step=0.379]Epoch 0:  76%|███████▌  | 73/96 [00:30<00:09,  2.44it/s, loss=0.377, v_num=22, train_loss_step=0.379]Epoch 0:  76%|███████▌  | 73/96 [00:30<00:09,  2.44it/s, loss=0.378, v_num=22, train_loss_step=0.364]Epoch 0:  77%|███████▋  | 74/96 [00:30<00:09,  2.44it/s, loss=0.378, v_num=22, train_loss_step=0.364]Epoch 0:  77%|███████▋  | 74/96 [00:30<00:09,  2.44it/s, loss=0.373, v_num=22, train_loss_step=0.362]Epoch 0:  78%|███████▊  | 75/96 [00:31<00:08,  2.44it/s, loss=0.373, v_num=22, train_loss_step=0.362]Epoch 0:  78%|███████▊  | 75/96 [00:31<00:08,  2.44it/s, loss=0.374, v_num=22, train_loss_step=0.365]Epoch 0:  79%|███████▉  | 76/96 [00:31<00:08,  2.44it/s, loss=0.374, v_num=22, train_loss_step=0.365]Epoch 0:  79%|███████▉  | 76/96 [00:31<00:08,  2.44it/s, loss=0.374, v_num=22, train_loss_step=0.394]Epoch 0:  80%|████████  | 77/96 [00:32<00:07,  2.44it/s, loss=0.374, v_num=22, train_loss_step=0.394]Epoch 0:  80%|████████  | 77/96 [00:32<00:07,  2.44it/s, loss=0.374, v_num=22, train_loss_step=0.365]Epoch 0:  81%|████████▏ | 78/96 [00:32<00:07,  2.44it/s, loss=0.374, v_num=22, train_loss_step=0.365]Epoch 0:  81%|████████▏ | 78/96 [00:32<00:07,  2.44it/s, loss=0.373, v_num=22, train_loss_step=0.354]Epoch 0:  82%|████████▏ | 79/96 [00:32<00:06,  2.44it/s, loss=0.373, v_num=22, train_loss_step=0.354]Epoch 0:  82%|████████▏ | 79/96 [00:32<00:06,  2.44it/s, loss=0.371, v_num=22, train_loss_step=0.351]Epoch 0:  83%|████████▎ | 80/96 [00:33<00:06,  2.44it/s, loss=0.371, v_num=22, train_loss_step=0.351]Epoch 0:  83%|████████▎ | 80/96 [00:33<00:06,  2.44it/s, loss=0.371, v_num=22, train_loss_step=0.405]Epoch 0:  84%|████████▍ | 81/96 [00:33<00:06,  2.44it/s, loss=0.371, v_num=22, train_loss_step=0.405]Epoch 0:  84%|████████▍ | 81/96 [00:33<00:06,  2.44it/s, loss=0.37, v_num=22, train_loss_step=0.343] Epoch 0:  85%|████████▌ | 82/96 [00:34<00:05,  2.44it/s, loss=0.37, v_num=22, train_loss_step=0.343]Epoch 0:  85%|████████▌ | 82/96 [00:34<00:05,  2.44it/s, loss=0.369, v_num=22, train_loss_step=0.366]Epoch 0:  86%|████████▋ | 83/96 [00:34<00:05,  2.44it/s, loss=0.369, v_num=22, train_loss_step=0.366]Epoch 0:  86%|████████▋ | 83/96 [00:34<00:05,  2.44it/s, loss=0.369, v_num=22, train_loss_step=0.367]Epoch 0:  88%|████████▊ | 84/96 [00:34<00:04,  2.45it/s, loss=0.369, v_num=22, train_loss_step=0.367]Epoch 0:  88%|████████▊ | 84/96 [00:34<00:04,  2.45it/s, loss=0.369, v_num=22, train_loss_step=0.356]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/12 [00:00<?, ?it/s][A
Validating:   8%|▊         | 1/12 [00:01<00:13,  1.23s/it][AEpoch 0:  90%|████████▉ | 86/96 [00:35<00:04,  2.42it/s, loss=0.369, v_num=22, train_loss_step=0.356]
Validating:  17%|█▋        | 2/12 [00:02<00:12,  1.21s/it][A
Validating:  25%|██▌       | 3/12 [00:03<00:10,  1.22s/it][AEpoch 0:  92%|█████████▏| 88/96 [00:38<00:03,  2.32it/s, loss=0.369, v_num=22, train_loss_step=0.356]
Validating:  33%|███▎      | 4/12 [00:04<00:09,  1.23s/it][A
Validating:  42%|████▏     | 5/12 [00:06<00:08,  1.23s/it][AEpoch 0:  94%|█████████▍| 90/96 [00:40<00:02,  2.23it/s, loss=0.369, v_num=22, train_loss_step=0.356]
Validating:  50%|█████     | 6/12 [00:07<00:07,  1.24s/it][A
Validating:  58%|█████▊    | 7/12 [00:08<00:06,  1.24s/it][AEpoch 0:  96%|█████████▌| 92/96 [00:43<00:01,  2.15it/s, loss=0.369, v_num=22, train_loss_step=0.356]
Validating:  67%|██████▋   | 8/12 [00:09<00:04,  1.21s/it][A
Validating:  75%|███████▌  | 9/12 [00:10<00:03,  1.21s/it][AEpoch 0:  98%|█████████▊| 94/96 [00:45<00:00,  2.08it/s, loss=0.369, v_num=22, train_loss_step=0.356]
Validating:  83%|████████▎ | 10/12 [00:12<00:02,  1.21s/it][A
Validating:  92%|█████████▏| 11/12 [00:13<00:01,  1.19s/it][AEpoch 0: 100%|██████████| 96/96 [00:48<00:00,  2.02it/s, loss=0.369, v_num=22, train_loss_step=0.356]
Validating: 100%|██████████| 12/12 [00:13<00:00,  1.00s/it][AEpoch 0: 100%|██████████| 96/96 [00:48<00:00,  2.00it/s, loss=0.369, v_num=22, train_loss_step=0.356]
                                                           [AEpoch 0: 100%|██████████| 96/96 [00:48<00:00,  1.99it/s, loss=0.369, v_num=22, train_loss_step=0.356]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(

Testing: 0it [00:00, ?it/s]Testing:   1%|          | 1/169 [00:00<00:23,  7.29it/s]Testing:   1%|          | 2/169 [00:00<00:21,  7.66it/s]Testing:   2%|▏         | 3/169 [00:00<00:21,  7.82it/s]Testing:   2%|▏         | 4/169 [00:00<00:20,  7.88it/s]Testing:   3%|▎         | 5/169 [00:00<00:20,  7.94it/s]Testing:   4%|▎         | 6/169 [00:00<00:20,  7.96it/s]Testing:   4%|▍         | 7/169 [00:00<00:20,  8.00it/s]Testing:   5%|▍         | 8/169 [00:01<00:20,  8.03it/s]Testing:   5%|▌         | 9/169 [00:01<00:19,  8.04it/s]Testing:   6%|▌         | 10/169 [00:01<00:19,  8.04it/s]Testing:   7%|▋         | 11/169 [00:01<00:19,  8.06it/s]Testing:   7%|▋         | 12/169 [00:01<00:19,  8.04it/s]Testing:   8%|▊         | 13/169 [00:01<00:19,  8.06it/s]Testing:   8%|▊         | 14/169 [00:01<00:19,  8.03it/s]Testing:   9%|▉         | 15/169 [00:01<00:19,  8.03it/s]Testing:   9%|▉         | 16/169 [00:02<00:18,  8.08it/s]Testing:  10%|█         | 17/169 [00:02<00:18,  8.11it/s]Testing:  11%|█         | 18/169 [00:02<00:18,  8.09it/s]Testing:  11%|█         | 19/169 [00:02<00:18,  8.06it/s]Testing:  12%|█▏        | 20/169 [00:02<00:18,  8.05it/s]Testing:  12%|█▏        | 21/169 [00:02<00:18,  8.04it/s]Testing:  13%|█▎        | 22/169 [00:02<00:18,  7.99it/s]Testing:  14%|█▎        | 23/169 [00:02<00:18,  8.03it/s]Testing:  14%|█▍        | 24/169 [00:02<00:18,  8.02it/s]Testing:  15%|█▍        | 25/169 [00:03<00:17,  8.03it/s]Testing:  15%|█▌        | 26/169 [00:03<00:17,  7.98it/s]Testing:  16%|█▌        | 27/169 [00:03<00:17,  7.97it/s]Testing:  17%|█▋        | 28/169 [00:03<00:17,  7.97it/s]Testing:  17%|█▋        | 29/169 [00:03<00:17,  7.90it/s]Testing:  18%|█▊        | 30/169 [00:03<00:17,  7.88it/s]Testing:  18%|█▊        | 31/169 [00:03<00:17,  7.93it/s]Testing:  19%|█▉        | 32/169 [00:04<00:17,  7.94it/s]Testing:  20%|█▉        | 33/169 [00:04<00:17,  7.95it/s]Testing:  20%|██        | 34/169 [00:04<00:17,  7.94it/s]Testing:  21%|██        | 35/169 [00:04<00:16,  7.97it/s]Testing:  21%|██▏       | 36/169 [00:04<00:16,  8.00it/s]Testing:  22%|██▏       | 37/169 [00:04<00:16,  8.00it/s]Testing:  22%|██▏       | 38/169 [00:04<00:16,  8.00it/s]Testing:  23%|██▎       | 39/169 [00:04<00:16,  8.00it/s]Testing:  24%|██▎       | 40/169 [00:05<00:16,  7.99it/s]Testing:  24%|██▍       | 41/169 [00:05<00:15,  8.01it/s]Testing:  25%|██▍       | 42/169 [00:05<00:15,  7.98it/s]Testing:  25%|██▌       | 43/169 [00:05<00:15,  7.98it/s]Testing:  26%|██▌       | 44/169 [00:05<00:15,  7.99it/s]Testing:  27%|██▋       | 45/169 [00:05<00:15,  7.98it/s]Testing:  27%|██▋       | 46/169 [00:05<00:15,  7.95it/s]Testing:  28%|██▊       | 47/169 [00:05<00:15,  7.96it/s]Testing:  28%|██▊       | 48/169 [00:06<00:15,  7.99it/s]Testing:  29%|██▉       | 49/169 [00:06<00:15,  8.00it/s]Testing:  30%|██▉       | 50/169 [00:06<00:14,  8.01it/s]Testing:  30%|███       | 51/169 [00:06<00:14,  8.00it/s]Testing:  31%|███       | 52/169 [00:06<00:14,  7.98it/s]Testing:  31%|███▏      | 53/169 [00:06<00:14,  7.95it/s]Testing:  32%|███▏      | 54/169 [00:06<00:14,  7.98it/s]Testing:  33%|███▎      | 55/169 [00:06<00:14,  7.98it/s]Testing:  33%|███▎      | 56/169 [00:07<00:14,  7.99it/s]Testing:  34%|███▎      | 57/169 [00:07<00:13,  8.01it/s]Testing:  34%|███▍      | 58/169 [00:07<00:13,  8.01it/s]Testing:  35%|███▍      | 59/169 [00:07<00:13,  8.04it/s]Testing:  36%|███▌      | 60/169 [00:07<00:13,  8.00it/s]Testing:  36%|███▌      | 61/169 [00:07<00:13,  8.01it/s]Testing:  37%|███▋      | 62/169 [00:07<00:13,  7.97it/s]Testing:  37%|███▋      | 63/169 [00:07<00:13,  7.91it/s]Testing:  38%|███▊      | 64/169 [00:08<00:13,  7.93it/s]Testing:  38%|███▊      | 65/169 [00:08<00:13,  7.98it/s]Testing:  39%|███▉      | 66/169 [00:08<00:12,  7.97it/s]Testing:  40%|███▉      | 67/169 [00:08<00:12,  7.93it/s]Testing:  40%|████      | 68/169 [00:08<00:12,  7.96it/s]Testing:  41%|████      | 69/169 [00:08<00:12,  7.94it/s]Testing:  41%|████▏     | 70/169 [00:08<00:12,  7.94it/s]Testing:  42%|████▏     | 71/169 [00:08<00:12,  7.95it/s]Testing:  43%|████▎     | 72/169 [00:09<00:12,  7.96it/s]Testing:  43%|████▎     | 73/169 [00:09<00:12,  7.93it/s]Testing:  44%|████▍     | 74/169 [00:09<00:11,  7.94it/s]Testing:  44%|████▍     | 75/169 [00:09<00:11,  7.95it/s]Testing:  45%|████▍     | 76/169 [00:09<00:11,  8.00it/s]Testing:  46%|████▌     | 77/169 [00:09<00:11,  7.99it/s]Testing:  46%|████▌     | 78/169 [00:09<00:11,  7.99it/s]Testing:  47%|████▋     | 79/169 [00:09<00:11,  7.97it/s]Testing:  47%|████▋     | 80/169 [00:10<00:11,  7.93it/s]Testing:  48%|████▊     | 81/169 [00:10<00:11,  7.91it/s]Testing:  49%|████▊     | 82/169 [00:10<00:11,  7.91it/s]Testing:  49%|████▉     | 83/169 [00:10<00:10,  7.91it/s]Testing:  50%|████▉     | 84/169 [00:10<00:10,  7.88it/s]Testing:  50%|█████     | 85/169 [00:10<00:10,  7.91it/s]Testing:  51%|█████     | 86/169 [00:10<00:10,  7.89it/s]Testing:  51%|█████▏    | 87/169 [00:10<00:10,  7.95it/s]Testing:  52%|█████▏    | 88/169 [00:11<00:10,  7.98it/s]Testing:  53%|█████▎    | 89/169 [00:11<00:10,  7.99it/s]Testing:  53%|█████▎    | 90/169 [00:11<00:09,  8.00it/s]Testing:  54%|█████▍    | 91/169 [00:11<00:09,  8.00it/s]Testing:  54%|█████▍    | 92/169 [00:11<00:09,  8.00it/s]Testing:  55%|█████▌    | 93/169 [00:11<00:09,  8.01it/s]Testing:  56%|█████▌    | 94/169 [00:11<00:09,  7.99it/s]Testing:  56%|█████▌    | 95/169 [00:11<00:09,  7.95it/s]Testing:  57%|█████▋    | 96/169 [00:12<00:09,  7.95it/s]Testing:  57%|█████▋    | 97/169 [00:12<00:09,  7.92it/s]Testing:  58%|█████▊    | 98/169 [00:12<00:08,  7.93it/s]Testing:  59%|█████▊    | 99/169 [00:12<00:08,  7.89it/s]Testing:  59%|█████▉    | 100/169 [00:12<00:08,  7.90it/s]Testing:  60%|█████▉    | 101/169 [00:12<00:08,  7.93it/s]Testing:  60%|██████    | 102/169 [00:12<00:08,  7.94it/s]Testing:  61%|██████    | 103/169 [00:12<00:08,  7.94it/s]Testing:  62%|██████▏   | 104/169 [00:13<00:08,  7.98it/s]Testing:  62%|██████▏   | 105/169 [00:13<00:08,  7.98it/s]Testing:  63%|██████▎   | 106/169 [00:13<00:07,  7.98it/s]Testing:  63%|██████▎   | 107/169 [00:13<00:07,  8.00it/s]Testing:  64%|██████▍   | 108/169 [00:13<00:07,  8.04it/s]Testing:  64%|██████▍   | 109/169 [00:13<00:07,  8.03it/s]Testing:  65%|██████▌   | 110/169 [00:13<00:07,  8.02it/s]Testing:  66%|██████▌   | 111/169 [00:13<00:07,  7.95it/s]Testing:  66%|██████▋   | 112/169 [00:14<00:07,  7.97it/s]Testing:  67%|██████▋   | 113/169 [00:14<00:07,  7.96it/s]Testing:  67%|██████▋   | 114/169 [00:14<00:06,  7.91it/s]Testing:  68%|██████▊   | 115/169 [00:14<00:06,  7.96it/s]Testing:  69%|██████▊   | 116/169 [00:14<00:06,  7.92it/s]Testing:  69%|██████▉   | 117/169 [00:14<00:06,  7.97it/s]Testing:  70%|██████▉   | 118/169 [00:14<00:06,  7.97it/s]Testing:  70%|███████   | 119/169 [00:14<00:06,  7.92it/s]Testing:  71%|███████   | 120/169 [00:15<00:06,  7.96it/s]Testing:  72%|███████▏  | 121/169 [00:15<00:06,  7.97it/s]Testing:  72%|███████▏  | 122/169 [00:15<00:05,  7.98it/s]Testing:  73%|███████▎  | 123/169 [00:15<00:05,  7.98it/s]Testing:  73%|███████▎  | 124/169 [00:15<00:05,  7.98it/s]Testing:  74%|███████▍  | 125/169 [00:15<00:05,  7.95it/s]Testing:  75%|███████▍  | 126/169 [00:15<00:05,  7.96it/s]Testing:  75%|███████▌  | 127/169 [00:15<00:05,  8.00it/s]Testing:  76%|███████▌  | 128/169 [00:16<00:05,  7.99it/s]Testing:  76%|███████▋  | 129/169 [00:16<00:05,  7.99it/s]Testing:  77%|███████▋  | 130/169 [00:16<00:04,  7.99it/s]Testing:  78%|███████▊  | 131/169 [00:16<00:04,  7.96it/s]Testing:  78%|███████▊  | 132/169 [00:16<00:04,  7.95it/s]Testing:  79%|███████▊  | 133/169 [00:16<00:04,  7.96it/s]Testing:  79%|███████▉  | 134/169 [00:16<00:04,  7.98it/s]Testing:  80%|███████▉  | 135/169 [00:16<00:04,  7.99it/s]Testing:  80%|████████  | 136/169 [00:17<00:04,  8.02it/s]Testing:  81%|████████  | 137/169 [00:17<00:03,  8.03it/s]Testing:  82%|████████▏ | 138/169 [00:17<00:03,  8.02it/s]Testing:  82%|████████▏ | 139/169 [00:17<00:03,  8.01it/s]Testing:  83%|████████▎ | 140/169 [00:17<00:03,  7.96it/s]Testing:  83%|████████▎ | 141/169 [00:17<00:03,  7.99it/s]Testing:  84%|████████▍ | 142/169 [00:17<00:03,  8.00it/s]Testing:  85%|████████▍ | 143/169 [00:17<00:03,  8.01it/s]Testing:  85%|████████▌ | 144/169 [00:18<00:03,  8.02it/s]Testing:  86%|████████▌ | 145/169 [00:18<00:03,  7.98it/s]Testing:  86%|████████▋ | 146/169 [00:18<00:02,  7.99it/s]Testing:  87%|████████▋ | 147/169 [00:18<00:02,  7.98it/s]Testing:  88%|████████▊ | 148/169 [00:18<00:02,  7.97it/s]Testing:  88%|████████▊ | 149/169 [00:18<00:02,  7.98it/s]Testing:  89%|████████▉ | 150/169 [00:18<00:02,  7.96it/s]Testing:  89%|████████▉ | 151/169 [00:18<00:02,  7.97it/s]Testing:  90%|████████▉ | 152/169 [00:19<00:02,  7.97it/s]Testing:  91%|█████████ | 153/169 [00:19<00:02,  7.97it/s]Testing:  91%|█████████ | 154/169 [00:19<00:01,  7.98it/s]Testing:  92%|█████████▏| 155/169 [00:19<00:01,  7.99it/s]Testing:  92%|█████████▏| 156/169 [00:19<00:01,  7.99it/s]Testing:  93%|█████████▎| 157/169 [00:19<00:01,  8.01it/s]Testing:  93%|█████████▎| 158/169 [00:19<00:01,  7.99it/s]Testing:  94%|█████████▍| 159/169 [00:19<00:01,  7.98it/s]Testing:  95%|█████████▍| 160/169 [00:20<00:01,  7.91it/s]Testing:  95%|█████████▌| 161/169 [00:20<00:01,  7.93it/s]Testing:  96%|█████████▌| 162/169 [00:20<00:00,  7.94it/s]Testing:  96%|█████████▋| 163/169 [00:20<00:00,  7.97it/s]Testing:  97%|█████████▋| 164/169 [00:20<00:00,  7.97it/s]Testing:  98%|█████████▊| 165/169 [00:20<00:00,  7.89it/s]Testing:  98%|█████████▊| 166/169 [00:20<00:00,  7.91it/s]Testing:  99%|█████████▉| 167/169 [00:20<00:00,  7.88it/s]Testing:  99%|█████████▉| 168/169 [00:21<00:00,  7.93it/s]Testing: 100%|██████████| 169/169 [00:21<00:00,  7.96it/s]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'_mean_accuracy': 0.9802982807159424,
 '_standard_dev_accuracy': 0.019383462145924568,
 '_variance_accuracy': 0.0003757186350412667,
 'test_acc': 0.9802984595298767,
 'test_dice_c1': 0.25199809670448303,
 'test_f2_c1': 0.3175565302371979,
 'test_loss': 0.35027265548706055,
 'test_mean_c1': 0.47571876645088196,
 'test_prec_c1': 0.20820249617099762,
 'test_sens_c1': 0.4449410140514374,
 'test_spec_c1': 0.9827843904495239}
--------------------------------------------------------------------------------
Testing: 100%|██████████| 169/169 [00:21<00:00,  7.97it/s]
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

  | Name       | Type             | Params
------------------------------------------------
0 | encoder1   | EncoderBlock     | 37.6 K
1 | encoder2   | EncoderBlock     | 221 K 
2 | bottleneck | ConvolutionBlock | 885 K 
3 | dropout    | Dropout2d        | 0     
4 | decoder1   | DecoderBlock     | 573 K 
5 | decoder2   | DecoderBlock     | 143 K 
6 | conv       | Conv2d           | 130   
7 | softmax    | Softmax2d        | 0     
------------------------------------------------
1.9 M     Trainable params
0         Non-trainable params
1.9 M     Total params
7.447     Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Validation sanity check:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Validation sanity check: 100%|██████████| 2/2 [00:03<00:00,  1.95s/it]                                                                      /home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Training: -1it [00:00, ?it/s]Training:   0%|          | 0/64 [00:00<00:00, 33288.13it/s]Epoch 0:   0%|          | 0/64 [00:00<00:00, 5652.70it/s]  Epoch 0:   2%|▏         | 1/64 [00:00<00:23,  2.72it/s]  Epoch 0:   2%|▏         | 1/64 [00:00<00:23,  2.72it/s, loss=0.692, v_num=23, train_loss_step=0.692]Epoch 0:   3%|▎         | 2/64 [00:01<00:28,  2.18it/s, loss=0.692, v_num=23, train_loss_step=0.692]Epoch 0:   3%|▎         | 2/64 [00:01<00:28,  2.18it/s, loss=0.689, v_num=23, train_loss_step=0.686]Epoch 0:   5%|▍         | 3/64 [00:02<00:30,  1.98it/s, loss=0.689, v_num=23, train_loss_step=0.686]Epoch 0:   5%|▍         | 3/64 [00:02<00:30,  1.98it/s, loss=0.686, v_num=23, train_loss_step=0.679]Epoch 0:   6%|▋         | 4/64 [00:02<00:31,  1.88it/s, loss=0.686, v_num=23, train_loss_step=0.679]Epoch 0:   6%|▋         | 4/64 [00:02<00:31,  1.88it/s, loss=0.682, v_num=23, train_loss_step=0.669]Epoch 0:   8%|▊         | 5/64 [00:03<00:32,  1.81it/s, loss=0.682, v_num=23, train_loss_step=0.669]Epoch 0:   8%|▊         | 5/64 [00:03<00:32,  1.81it/s, loss=0.679, v_num=23, train_loss_step=0.667]Epoch 0:   9%|▉         | 6/64 [00:03<00:32,  1.77it/s, loss=0.679, v_num=23, train_loss_step=0.667]Epoch 0:   9%|▉         | 6/64 [00:03<00:32,  1.77it/s, loss=0.674, v_num=23, train_loss_step=0.648]Epoch 0:  11%|█         | 7/64 [00:04<00:32,  1.74it/s, loss=0.674, v_num=23, train_loss_step=0.648]Epoch 0:  11%|█         | 7/64 [00:04<00:32,  1.74it/s, loss=0.671, v_num=23, train_loss_step=0.655]Epoch 0:  12%|█▎        | 8/64 [00:05<00:32,  1.71it/s, loss=0.671, v_num=23, train_loss_step=0.655]Epoch 0:  12%|█▎        | 8/64 [00:05<00:32,  1.71it/s, loss=0.659, v_num=23, train_loss_step=0.579]Epoch 0:  14%|█▍        | 9/64 [00:05<00:32,  1.69it/s, loss=0.659, v_num=23, train_loss_step=0.579]Epoch 0:  14%|█▍        | 9/64 [00:05<00:32,  1.69it/s, loss=0.647, v_num=23, train_loss_step=0.544]Epoch 0:  16%|█▌        | 10/64 [00:06<00:32,  1.68it/s, loss=0.647, v_num=23, train_loss_step=0.544]Epoch 0:  16%|█▌        | 10/64 [00:06<00:32,  1.68it/s, loss=0.635, v_num=23, train_loss_step=0.529]Epoch 0:  17%|█▋        | 11/64 [00:07<00:31,  1.67it/s, loss=0.635, v_num=23, train_loss_step=0.529]Epoch 0:  17%|█▋        | 11/64 [00:07<00:31,  1.67it/s, loss=0.622, v_num=23, train_loss_step=0.493]Epoch 0:  19%|█▉        | 12/64 [00:07<00:31,  1.66it/s, loss=0.622, v_num=23, train_loss_step=0.493]Epoch 0:  19%|█▉        | 12/64 [00:07<00:31,  1.66it/s, loss=0.604, v_num=23, train_loss_step=0.405]Epoch 0:  20%|██        | 13/64 [00:08<00:30,  1.65it/s, loss=0.604, v_num=23, train_loss_step=0.405]Epoch 0:  20%|██        | 13/64 [00:08<00:30,  1.65it/s, loss=0.591, v_num=23, train_loss_step=0.430]Epoch 0:  22%|██▏       | 14/64 [00:09<00:30,  1.65it/s, loss=0.591, v_num=23, train_loss_step=0.430]Epoch 0:  22%|██▏       | 14/64 [00:09<00:30,  1.65it/s, loss=0.576, v_num=23, train_loss_step=0.385]Epoch 0:  23%|██▎       | 15/64 [00:09<00:29,  1.64it/s, loss=0.576, v_num=23, train_loss_step=0.385]Epoch 0:  23%|██▎       | 15/64 [00:09<00:29,  1.64it/s, loss=0.561, v_num=23, train_loss_step=0.358]Epoch 0:  25%|██▌       | 16/64 [00:10<00:29,  1.63it/s, loss=0.561, v_num=23, train_loss_step=0.358]Epoch 0:  25%|██▌       | 16/64 [00:10<00:29,  1.63it/s, loss=0.551, v_num=23, train_loss_step=0.390]Epoch 0:  27%|██▋       | 17/64 [00:11<00:28,  1.63it/s, loss=0.551, v_num=23, train_loss_step=0.390]Epoch 0:  27%|██▋       | 17/64 [00:11<00:28,  1.63it/s, loss=0.544, v_num=23, train_loss_step=0.431]Epoch 0:  28%|██▊       | 18/64 [00:11<00:28,  1.63it/s, loss=0.544, v_num=23, train_loss_step=0.431]Epoch 0:  28%|██▊       | 18/64 [00:11<00:28,  1.63it/s, loss=0.534, v_num=23, train_loss_step=0.365]Epoch 0:  30%|██▉       | 19/64 [00:12<00:27,  1.62it/s, loss=0.534, v_num=23, train_loss_step=0.365]Epoch 0:  30%|██▉       | 19/64 [00:12<00:27,  1.62it/s, loss=0.527, v_num=23, train_loss_step=0.400]Epoch 0:  31%|███▏      | 20/64 [00:12<00:27,  1.62it/s, loss=0.527, v_num=23, train_loss_step=0.400]Epoch 0:  31%|███▏      | 20/64 [00:12<00:27,  1.62it/s, loss=0.521, v_num=23, train_loss_step=0.409]Epoch 0:  33%|███▎      | 21/64 [00:13<00:26,  1.62it/s, loss=0.521, v_num=23, train_loss_step=0.409]Epoch 0:  33%|███▎      | 21/64 [00:13<00:26,  1.62it/s, loss=0.506, v_num=23, train_loss_step=0.391]Epoch 0:  34%|███▍      | 22/64 [00:14<00:26,  1.61it/s, loss=0.506, v_num=23, train_loss_step=0.391]Epoch 0:  34%|███▍      | 22/64 [00:14<00:26,  1.61it/s, loss=0.491, v_num=23, train_loss_step=0.394]Epoch 0:  36%|███▌      | 23/64 [00:14<00:25,  1.61it/s, loss=0.491, v_num=23, train_loss_step=0.394]Epoch 0:  36%|███▌      | 23/64 [00:14<00:25,  1.61it/s, loss=0.475, v_num=23, train_loss_step=0.365]Epoch 0:  38%|███▊      | 24/64 [00:15<00:24,  1.61it/s, loss=0.475, v_num=23, train_loss_step=0.365]Epoch 0:  38%|███▊      | 24/64 [00:15<00:24,  1.61it/s, loss=0.462, v_num=23, train_loss_step=0.392]Epoch 0:  39%|███▉      | 25/64 [00:16<00:24,  1.60it/s, loss=0.462, v_num=23, train_loss_step=0.392]Epoch 0:  39%|███▉      | 25/64 [00:16<00:24,  1.60it/s, loss=0.447, v_num=23, train_loss_step=0.381]Epoch 0:  41%|████      | 26/64 [00:16<00:23,  1.60it/s, loss=0.447, v_num=23, train_loss_step=0.381]Epoch 0:  41%|████      | 26/64 [00:16<00:23,  1.60it/s, loss=0.435, v_num=23, train_loss_step=0.404]Epoch 0:  42%|████▏     | 27/64 [00:17<00:23,  1.60it/s, loss=0.435, v_num=23, train_loss_step=0.404]Epoch 0:  42%|████▏     | 27/64 [00:17<00:23,  1.60it/s, loss=0.421, v_num=23, train_loss_step=0.365]Epoch 0:  44%|████▍     | 28/64 [00:18<00:22,  1.60it/s, loss=0.421, v_num=23, train_loss_step=0.365]Epoch 0:  44%|████▍     | 28/64 [00:18<00:22,  1.60it/s, loss=0.409, v_num=23, train_loss_step=0.353]Epoch 0:  45%|████▌     | 29/64 [00:18<00:21,  1.59it/s, loss=0.409, v_num=23, train_loss_step=0.353]Epoch 0:  45%|████▌     | 29/64 [00:18<00:21,  1.59it/s, loss=0.399, v_num=23, train_loss_step=0.341]Epoch 0:  47%|████▋     | 30/64 [00:19<00:21,  1.59it/s, loss=0.399, v_num=23, train_loss_step=0.341]Epoch 0:  47%|████▋     | 30/64 [00:19<00:21,  1.59it/s, loss=0.39, v_num=23, train_loss_step=0.339] Epoch 0:  48%|████▊     | 31/64 [00:20<00:20,  1.59it/s, loss=0.39, v_num=23, train_loss_step=0.339]Epoch 0:  48%|████▊     | 31/64 [00:20<00:20,  1.59it/s, loss=0.383, v_num=23, train_loss_step=0.367]Epoch 0:  50%|█████     | 32/64 [00:20<00:20,  1.59it/s, loss=0.383, v_num=23, train_loss_step=0.367]Epoch 0:  50%|█████     | 32/64 [00:20<00:20,  1.59it/s, loss=0.384, v_num=23, train_loss_step=0.427]Epoch 0:  52%|█████▏    | 33/64 [00:21<00:19,  1.59it/s, loss=0.384, v_num=23, train_loss_step=0.427]Epoch 0:  52%|█████▏    | 33/64 [00:21<00:19,  1.59it/s, loss=0.382, v_num=23, train_loss_step=0.390]Epoch 0:  53%|█████▎    | 34/64 [00:22<00:18,  1.59it/s, loss=0.382, v_num=23, train_loss_step=0.390]Epoch 0:  53%|█████▎    | 34/64 [00:22<00:18,  1.59it/s, loss=0.382, v_num=23, train_loss_step=0.386]Epoch 0:  55%|█████▍    | 35/64 [00:22<00:18,  1.59it/s, loss=0.382, v_num=23, train_loss_step=0.386]Epoch 0:  55%|█████▍    | 35/64 [00:22<00:18,  1.59it/s, loss=0.383, v_num=23, train_loss_step=0.381]Epoch 0:  56%|█████▋    | 36/64 [00:23<00:17,  1.59it/s, loss=0.383, v_num=23, train_loss_step=0.381]Epoch 0:  56%|█████▋    | 36/64 [00:23<00:17,  1.59it/s, loss=0.383, v_num=23, train_loss_step=0.374]Epoch 0:  58%|█████▊    | 37/64 [00:23<00:17,  1.59it/s, loss=0.383, v_num=23, train_loss_step=0.374]Epoch 0:  58%|█████▊    | 37/64 [00:23<00:17,  1.59it/s, loss=0.38, v_num=23, train_loss_step=0.383] Epoch 0:  59%|█████▉    | 38/64 [00:24<00:16,  1.58it/s, loss=0.38, v_num=23, train_loss_step=0.383]Epoch 0:  59%|█████▉    | 38/64 [00:24<00:16,  1.58it/s, loss=0.381, v_num=23, train_loss_step=0.380]Epoch 0:  61%|██████    | 39/64 [00:25<00:15,  1.58it/s, loss=0.381, v_num=23, train_loss_step=0.380]Epoch 0:  61%|██████    | 39/64 [00:25<00:15,  1.58it/s, loss=0.379, v_num=23, train_loss_step=0.361]Epoch 0:  62%|██████▎   | 40/64 [00:25<00:15,  1.58it/s, loss=0.379, v_num=23, train_loss_step=0.361]Epoch 0:  62%|██████▎   | 40/64 [00:25<00:15,  1.58it/s, loss=0.376, v_num=23, train_loss_step=0.353]Epoch 0:  64%|██████▍   | 41/64 [00:26<00:14,  1.58it/s, loss=0.376, v_num=23, train_loss_step=0.353]Epoch 0:  64%|██████▍   | 41/64 [00:26<00:14,  1.58it/s, loss=0.375, v_num=23, train_loss_step=0.374]Epoch 0:  66%|██████▌   | 42/64 [00:27<00:13,  1.58it/s, loss=0.375, v_num=23, train_loss_step=0.374]Epoch 0:  66%|██████▌   | 42/64 [00:27<00:13,  1.58it/s, loss=0.374, v_num=23, train_loss_step=0.363]Epoch 0:  67%|██████▋   | 43/64 [00:27<00:13,  1.58it/s, loss=0.374, v_num=23, train_loss_step=0.363]Epoch 0:  67%|██████▋   | 43/64 [00:27<00:13,  1.58it/s, loss=0.375, v_num=23, train_loss_step=0.394]Epoch 0:  69%|██████▉   | 44/64 [00:28<00:12,  1.58it/s, loss=0.375, v_num=23, train_loss_step=0.394]Epoch 0:  69%|██████▉   | 44/64 [00:28<00:12,  1.58it/s, loss=0.379, v_num=23, train_loss_step=0.471]Epoch 0:  70%|███████   | 45/64 [00:29<00:12,  1.58it/s, loss=0.379, v_num=23, train_loss_step=0.471]Epoch 0:  70%|███████   | 45/64 [00:29<00:12,  1.58it/s, loss=0.378, v_num=23, train_loss_step=0.361]Epoch 0:  72%|███████▏  | 46/64 [00:29<00:11,  1.58it/s, loss=0.378, v_num=23, train_loss_step=0.361]Epoch 0:  72%|███████▏  | 46/64 [00:29<00:11,  1.58it/s, loss=0.376, v_num=23, train_loss_step=0.361]Epoch 0:  73%|███████▎  | 47/64 [00:30<00:10,  1.58it/s, loss=0.376, v_num=23, train_loss_step=0.361]Epoch 0:  73%|███████▎  | 47/64 [00:30<00:10,  1.58it/s, loss=0.375, v_num=23, train_loss_step=0.350]Epoch 0:  75%|███████▌  | 48/64 [00:31<00:10,  1.58it/s, loss=0.375, v_num=23, train_loss_step=0.350]Epoch 0:  75%|███████▌  | 48/64 [00:31<00:10,  1.58it/s, loss=0.376, v_num=23, train_loss_step=0.364]Epoch 0:  77%|███████▋  | 49/64 [00:31<00:09,  1.58it/s, loss=0.376, v_num=23, train_loss_step=0.364]Epoch 0:  77%|███████▋  | 49/64 [00:31<00:09,  1.58it/s, loss=0.377, v_num=23, train_loss_step=0.353]Epoch 0:  78%|███████▊  | 50/64 [00:32<00:08,  1.58it/s, loss=0.377, v_num=23, train_loss_step=0.353]Epoch 0:  78%|███████▊  | 50/64 [00:32<00:08,  1.58it/s, loss=0.378, v_num=23, train_loss_step=0.369]Epoch 0:  80%|███████▉  | 51/64 [00:33<00:08,  1.57it/s, loss=0.378, v_num=23, train_loss_step=0.369]Epoch 0:  80%|███████▉  | 51/64 [00:33<00:08,  1.57it/s, loss=0.378, v_num=23, train_loss_step=0.360]Epoch 0:  81%|████████▏ | 52/64 [00:33<00:07,  1.57it/s, loss=0.378, v_num=23, train_loss_step=0.360]Epoch 0:  81%|████████▏ | 52/64 [00:33<00:07,  1.57it/s, loss=0.377, v_num=23, train_loss_step=0.410]Epoch 0:  83%|████████▎ | 53/64 [00:34<00:06,  1.57it/s, loss=0.377, v_num=23, train_loss_step=0.410]Epoch 0:  83%|████████▎ | 53/64 [00:34<00:06,  1.57it/s, loss=0.375, v_num=23, train_loss_step=0.349]Epoch 0:  84%|████████▍ | 54/64 [00:34<00:06,  1.57it/s, loss=0.375, v_num=23, train_loss_step=0.349]Epoch 0:  84%|████████▍ | 54/64 [00:34<00:06,  1.57it/s, loss=0.374, v_num=23, train_loss_step=0.368]Epoch 0:  86%|████████▌ | 55/64 [00:35<00:05,  1.57it/s, loss=0.374, v_num=23, train_loss_step=0.368]Epoch 0:  86%|████████▌ | 55/64 [00:35<00:05,  1.57it/s, loss=0.374, v_num=23, train_loss_step=0.383]Epoch 0:  88%|████████▊ | 56/64 [00:35<00:05,  1.59it/s, loss=0.374, v_num=23, train_loss_step=0.383]Epoch 0:  88%|████████▊ | 56/64 [00:35<00:05,  1.59it/s, loss=0.373, v_num=23, train_loss_step=0.347]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/8 [00:00<?, ?it/s][A
Validating:  12%|█▎        | 1/8 [00:01<00:13,  1.87s/it][AEpoch 0:  91%|█████████ | 58/64 [00:37<00:03,  1.56it/s, loss=0.373, v_num=23, train_loss_step=0.347]
Validating:  25%|██▌       | 2/8 [00:03<00:10,  1.79s/it][A
Validating:  38%|███▊      | 3/8 [00:05<00:08,  1.76s/it][AEpoch 0:  94%|█████████▍| 60/64 [00:41<00:02,  1.48it/s, loss=0.373, v_num=23, train_loss_step=0.347]
Validating:  50%|█████     | 4/8 [00:07<00:07,  1.79s/it][A
Validating:  62%|██████▎   | 5/8 [00:08<00:05,  1.80s/it][AEpoch 0:  97%|█████████▋| 62/64 [00:44<00:01,  1.40it/s, loss=0.373, v_num=23, train_loss_step=0.347]
Validating:  75%|███████▌  | 6/8 [00:10<00:03,  1.81s/it][A
Validating:  88%|████████▊ | 7/8 [00:12<00:01,  1.81s/it][AEpoch 0: 100%|██████████| 64/64 [00:48<00:00,  1.34it/s, loss=0.373, v_num=23, train_loss_step=0.347]
Validating: 100%|██████████| 8/8 [00:13<00:00,  1.60s/it][AEpoch 0: 100%|██████████| 64/64 [00:49<00:00,  1.31it/s, loss=0.373, v_num=23, train_loss_step=0.347]
                                                         [AEpoch 0: 100%|██████████| 64/64 [00:49<00:00,  1.31it/s, loss=0.373, v_num=23, train_loss_step=0.347]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(

Testing: 0it [00:00, ?it/s]Testing:   1%|          | 1/169 [00:00<00:23,  7.28it/s]Testing:   1%|          | 2/169 [00:00<00:21,  7.68it/s]Testing:   2%|▏         | 3/169 [00:00<00:21,  7.78it/s]Testing:   2%|▏         | 4/169 [00:00<00:20,  7.86it/s]Testing:   3%|▎         | 5/169 [00:00<00:20,  7.93it/s]Testing:   4%|▎         | 6/169 [00:00<00:20,  7.97it/s]Testing:   4%|▍         | 7/169 [00:00<00:20,  8.04it/s]Testing:   5%|▍         | 8/169 [00:01<00:19,  8.05it/s]Testing:   5%|▌         | 9/169 [00:01<00:19,  8.06it/s]Testing:   6%|▌         | 10/169 [00:01<00:19,  8.08it/s]Testing:   7%|▋         | 11/169 [00:01<00:19,  8.09it/s]Testing:   7%|▋         | 12/169 [00:01<00:19,  8.09it/s]Testing:   8%|▊         | 13/169 [00:01<00:19,  8.08it/s]Testing:   8%|▊         | 14/169 [00:01<00:19,  8.02it/s]Testing:   9%|▉         | 15/169 [00:01<00:19,  8.02it/s]Testing:   9%|▉         | 16/169 [00:02<00:19,  8.02it/s]Testing:  10%|█         | 17/169 [00:02<00:18,  8.06it/s]Testing:  11%|█         | 18/169 [00:02<00:18,  8.09it/s]Testing:  11%|█         | 19/169 [00:02<00:18,  8.14it/s]Testing:  12%|█▏        | 20/169 [00:02<00:18,  8.11it/s]Testing:  12%|█▏        | 21/169 [00:02<00:18,  8.03it/s]Testing:  13%|█▎        | 22/169 [00:02<00:18,  8.03it/s]Testing:  14%|█▎        | 23/169 [00:02<00:18,  8.06it/s]Testing:  14%|█▍        | 24/169 [00:02<00:18,  7.97it/s]Testing:  15%|█▍        | 25/169 [00:03<00:18,  7.99it/s]Testing:  15%|█▌        | 26/169 [00:03<00:17,  7.98it/s]Testing:  16%|█▌        | 27/169 [00:03<00:17,  8.00it/s]Testing:  17%|█▋        | 28/169 [00:03<00:17,  8.02it/s]Testing:  17%|█▋        | 29/169 [00:03<00:17,  8.00it/s]Testing:  18%|█▊        | 30/169 [00:03<00:17,  7.96it/s]Testing:  18%|█▊        | 31/169 [00:03<00:17,  7.95it/s]Testing:  19%|█▉        | 32/169 [00:03<00:17,  7.97it/s]Testing:  20%|█▉        | 33/169 [00:04<00:16,  8.00it/s]Testing:  20%|██        | 34/169 [00:04<00:16,  7.98it/s]Testing:  21%|██        | 35/169 [00:04<00:16,  8.00it/s]Testing:  21%|██▏       | 36/169 [00:04<00:16,  7.99it/s]Testing:  22%|██▏       | 37/169 [00:04<00:16,  8.00it/s]Testing:  22%|██▏       | 38/169 [00:04<00:16,  8.04it/s]Testing:  23%|██▎       | 39/169 [00:04<00:16,  8.06it/s]Testing:  24%|██▎       | 40/169 [00:04<00:16,  8.06it/s]Testing:  24%|██▍       | 41/169 [00:05<00:15,  8.02it/s]Testing:  25%|██▍       | 42/169 [00:05<00:15,  8.04it/s]Testing:  25%|██▌       | 43/169 [00:05<00:15,  8.04it/s]Testing:  26%|██▌       | 44/169 [00:05<00:15,  8.05it/s]Testing:  27%|██▋       | 45/169 [00:05<00:15,  8.06it/s]Testing:  27%|██▋       | 46/169 [00:05<00:15,  8.05it/s]Testing:  28%|██▊       | 47/169 [00:05<00:15,  8.03it/s]Testing:  28%|██▊       | 48/169 [00:05<00:15,  8.02it/s]Testing:  29%|██▉       | 49/169 [00:06<00:14,  8.01it/s]Testing:  30%|██▉       | 50/169 [00:06<00:14,  8.01it/s]Testing:  30%|███       | 51/169 [00:06<00:14,  8.02it/s]Testing:  31%|███       | 52/169 [00:06<00:14,  8.02it/s]Testing:  31%|███▏      | 53/169 [00:06<00:14,  7.99it/s]Testing:  32%|███▏      | 54/169 [00:06<00:14,  7.99it/s]Testing:  33%|███▎      | 55/169 [00:06<00:14,  7.96it/s]Testing:  33%|███▎      | 56/169 [00:06<00:14,  7.97it/s]Testing:  34%|███▎      | 57/169 [00:07<00:14,  7.95it/s]Testing:  34%|███▍      | 58/169 [00:07<00:14,  7.91it/s]Testing:  35%|███▍      | 59/169 [00:07<00:13,  7.93it/s]Testing:  36%|███▌      | 60/169 [00:07<00:13,  7.96it/s]Testing:  36%|███▌      | 61/169 [00:07<00:13,  7.96it/s]Testing:  37%|███▋      | 62/169 [00:07<00:13,  7.91it/s]Testing:  37%|███▋      | 63/169 [00:07<00:13,  7.97it/s]Testing:  38%|███▊      | 64/169 [00:07<00:13,  7.98it/s]Testing:  38%|███▊      | 65/169 [00:08<00:13,  7.96it/s]Testing:  39%|███▉      | 66/169 [00:08<00:12,  7.99it/s]Testing:  40%|███▉      | 67/169 [00:08<00:12,  7.99it/s]Testing:  40%|████      | 68/169 [00:08<00:12,  8.00it/s]Testing:  41%|████      | 69/169 [00:08<00:12,  7.99it/s]Testing:  41%|████▏     | 70/169 [00:08<00:12,  8.01it/s]Testing:  42%|████▏     | 71/169 [00:08<00:12,  8.02it/s]Testing:  43%|████▎     | 72/169 [00:08<00:12,  8.04it/s]Testing:  43%|████▎     | 73/169 [00:09<00:12,  7.98it/s]Testing:  44%|████▍     | 74/169 [00:09<00:11,  8.01it/s]Testing:  44%|████▍     | 75/169 [00:09<00:11,  7.96it/s]Testing:  45%|████▍     | 76/169 [00:09<00:11,  7.99it/s]Testing:  46%|████▌     | 77/169 [00:09<00:11,  8.01it/s]Testing:  46%|████▌     | 78/169 [00:09<00:11,  7.99it/s]Testing:  47%|████▋     | 79/169 [00:09<00:11,  7.99it/s]Testing:  47%|████▋     | 80/169 [00:09<00:11,  8.03it/s]Testing:  48%|████▊     | 81/169 [00:10<00:10,  8.02it/s]Testing:  49%|████▊     | 82/169 [00:10<00:10,  8.03it/s]Testing:  49%|████▉     | 83/169 [00:10<00:10,  8.00it/s]Testing:  50%|████▉     | 84/169 [00:10<00:10,  8.05it/s]Testing:  50%|█████     | 85/169 [00:10<00:10,  8.07it/s]Testing:  51%|█████     | 86/169 [00:10<00:10,  8.04it/s]Testing:  51%|█████▏    | 87/169 [00:10<00:10,  7.99it/s]Testing:  52%|█████▏    | 88/169 [00:10<00:10,  7.99it/s]Testing:  53%|█████▎    | 89/169 [00:11<00:10,  7.97it/s]Testing:  53%|█████▎    | 90/169 [00:11<00:09,  7.99it/s]Testing:  54%|█████▍    | 91/169 [00:11<00:09,  7.95it/s]Testing:  54%|█████▍    | 92/169 [00:11<00:09,  7.92it/s]Testing:  55%|█████▌    | 93/169 [00:11<00:09,  7.95it/s]Testing:  56%|█████▌    | 94/169 [00:11<00:09,  7.90it/s]Testing:  56%|█████▌    | 95/169 [00:11<00:09,  7.90it/s]Testing:  57%|█████▋    | 96/169 [00:12<00:09,  7.90it/s]Testing:  57%|█████▋    | 97/169 [00:12<00:09,  7.91it/s]Testing:  58%|█████▊    | 98/169 [00:12<00:08,  7.96it/s]Testing:  59%|█████▊    | 99/169 [00:12<00:08,  7.98it/s]Testing:  59%|█████▉    | 100/169 [00:12<00:08,  7.95it/s]Testing:  60%|█████▉    | 101/169 [00:12<00:08,  7.96it/s]Testing:  60%|██████    | 102/169 [00:12<00:08,  8.00it/s]Testing:  61%|██████    | 103/169 [00:12<00:08,  8.00it/s]Testing:  62%|██████▏   | 104/169 [00:13<00:08,  8.03it/s]Testing:  62%|██████▏   | 105/169 [00:13<00:07,  8.01it/s]Testing:  63%|██████▎   | 106/169 [00:13<00:07,  8.03it/s]Testing:  63%|██████▎   | 107/169 [00:13<00:07,  8.04it/s]Testing:  64%|██████▍   | 108/169 [00:13<00:07,  8.03it/s]Testing:  64%|██████▍   | 109/169 [00:13<00:07,  7.91it/s]Testing:  65%|██████▌   | 110/169 [00:13<00:07,  7.95it/s]Testing:  66%|██████▌   | 111/169 [00:13<00:07,  8.00it/s]Testing:  66%|██████▋   | 112/169 [00:14<00:07,  7.99it/s]Testing:  67%|██████▋   | 113/169 [00:14<00:07,  8.00it/s]Testing:  67%|██████▋   | 114/169 [00:14<00:06,  8.03it/s]Testing:  68%|██████▊   | 115/169 [00:14<00:06,  8.01it/s]Testing:  69%|██████▊   | 116/169 [00:14<00:06,  8.00it/s]Testing:  69%|██████▉   | 117/169 [00:14<00:06,  7.96it/s]Testing:  70%|██████▉   | 118/169 [00:14<00:06,  7.96it/s]Testing:  70%|███████   | 119/169 [00:14<00:06,  7.95it/s]Testing:  71%|███████   | 120/169 [00:15<00:06,  7.91it/s]Testing:  72%|███████▏  | 121/169 [00:15<00:06,  7.93it/s]Testing:  72%|███████▏  | 122/169 [00:15<00:05,  7.92it/s]Testing:  73%|███████▎  | 123/169 [00:15<00:05,  7.92it/s]Testing:  73%|███████▎  | 124/169 [00:15<00:05,  7.94it/s]Testing:  74%|███████▍  | 125/169 [00:15<00:05,  7.98it/s]Testing:  75%|███████▍  | 126/169 [00:15<00:05,  7.93it/s]Testing:  75%|███████▌  | 127/169 [00:15<00:05,  7.97it/s]Testing:  76%|███████▌  | 128/169 [00:16<00:05,  7.97it/s]Testing:  76%|███████▋  | 129/169 [00:16<00:05,  7.98it/s]Testing:  77%|███████▋  | 130/169 [00:16<00:04,  7.98it/s]Testing:  78%|███████▊  | 131/169 [00:16<00:04,  8.03it/s]Testing:  78%|███████▊  | 132/169 [00:16<00:04,  8.05it/s]Testing:  79%|███████▊  | 133/169 [00:16<00:04,  8.06it/s]Testing:  79%|███████▉  | 134/169 [00:16<00:04,  7.98it/s]Testing:  80%|███████▉  | 135/169 [00:16<00:04,  7.96it/s]Testing:  80%|████████  | 136/169 [00:17<00:04,  7.96it/s]Testing:  81%|████████  | 137/169 [00:17<00:04,  7.98it/s]Testing:  82%|████████▏ | 138/169 [00:17<00:03,  7.97it/s]Testing:  82%|████████▏ | 139/169 [00:17<00:03,  8.03it/s]Testing:  83%|████████▎ | 140/169 [00:17<00:03,  8.01it/s]Testing:  83%|████████▎ | 141/169 [00:17<00:03,  7.95it/s]Testing:  84%|████████▍ | 142/169 [00:17<00:03,  7.96it/s]Testing:  85%|████████▍ | 143/169 [00:17<00:03,  7.96it/s]Testing:  85%|████████▌ | 144/169 [00:18<00:03,  7.97it/s]Testing:  86%|████████▌ | 145/169 [00:18<00:02,  8.00it/s]Testing:  86%|████████▋ | 146/169 [00:18<00:02,  8.00it/s]Testing:  87%|████████▋ | 147/169 [00:18<00:02,  8.00it/s]Testing:  88%|████████▊ | 148/169 [00:18<00:02,  8.00it/s]Testing:  88%|████████▊ | 149/169 [00:18<00:02,  7.96it/s]Testing:  89%|████████▉ | 150/169 [00:18<00:02,  7.98it/s]Testing:  89%|████████▉ | 151/169 [00:18<00:02,  7.96it/s]Testing:  90%|████████▉ | 152/169 [00:19<00:02,  7.97it/s]Testing:  91%|█████████ | 153/169 [00:19<00:02,  7.96it/s]Testing:  91%|█████████ | 154/169 [00:19<00:01,  7.99it/s]Testing:  92%|█████████▏| 155/169 [00:19<00:01,  7.93it/s]Testing:  92%|█████████▏| 156/169 [00:19<00:01,  7.96it/s]Testing:  93%|█████████▎| 157/169 [00:19<00:01,  8.01it/s]Testing:  93%|█████████▎| 158/169 [00:19<00:01,  8.03it/s]Testing:  94%|█████████▍| 159/169 [00:19<00:01,  7.92it/s]Testing:  95%|█████████▍| 160/169 [00:20<00:01,  7.84it/s]Testing:  95%|█████████▌| 161/169 [00:20<00:01,  7.90it/s]Testing:  96%|█████████▌| 162/169 [00:20<00:00,  7.89it/s]Testing:  96%|█████████▋| 163/169 [00:20<00:00,  7.93it/s]Testing:  97%|█████████▋| 164/169 [00:20<00:00,  7.93it/s]Testing:  98%|█████████▊| 165/169 [00:20<00:00,  7.95it/s]Testing:  98%|█████████▊| 166/169 [00:20<00:00,  7.98it/s]Testing:  99%|█████████▉| 167/169 [00:20<00:00,  8.01it/s]Testing:  99%|█████████▉| 168/169 [00:21<00:00,  7.99it/s]Testing: 100%|██████████| 169/169 [00:21<00:00,  8.02it/s]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'_mean_accuracy': 0.9774656295776367,
 '_standard_dev_accuracy': 0.031434088945388794,
 '_variance_accuracy': 0.000988102052360773,
 'test_acc': 0.9774660468101501,
 'test_dice_c1': 0.23941130936145782,
 'test_f2_c1': 0.29685550928115845,
 'test_loss': 0.3477550148963928,
 'test_mean_c1': 0.4360247254371643,
 'test_prec_c1': 0.2003524899482727,
 'test_sens_c1': 0.4123898148536682,
 'test_spec_c1': 0.9790018200874329}
--------------------------------------------------------------------------------
Testing: 100%|██████████| 169/169 [00:21<00:00,  7.98it/s]
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

  | Name       | Type             | Params
------------------------------------------------
0 | encoder1   | EncoderBlock     | 37.6 K
1 | encoder2   | EncoderBlock     | 221 K 
2 | bottleneck | ConvolutionBlock | 885 K 
3 | dropout    | Dropout2d        | 0     
4 | decoder1   | DecoderBlock     | 573 K 
5 | decoder2   | DecoderBlock     | 143 K 
6 | conv       | Conv2d           | 130   
7 | softmax    | Softmax2d        | 0     
------------------------------------------------
1.9 M     Trainable params
0         Non-trainable params
1.9 M     Total params
7.447     Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  2.02it/s]Validation sanity check: 100%|██████████| 2/2 [00:00<00:00,  2.69it/s]                                                                      /home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Training: -1it [00:00, ?it/s]Training:   0%|          | 0/380 [00:00<00:00, 23431.87it/s]Epoch 0:   0%|          | 0/380 [00:00<00:00, 3826.92it/s]  Epoch 0:   0%|          | 1/380 [00:00<00:26, 14.44it/s]  Epoch 0:   0%|          | 1/380 [00:00<00:26, 14.40it/s, loss=0.689, v_num=24, train_loss_step=0.689]Epoch 0:   1%|          | 2/380 [00:00<00:31, 12.07it/s, loss=0.689, v_num=24, train_loss_step=0.689]Epoch 0:   1%|          | 2/380 [00:00<00:31, 12.05it/s, loss=0.688, v_num=24, train_loss_step=0.687]Epoch 0:   1%|          | 3/380 [00:00<00:33, 11.28it/s, loss=0.688, v_num=24, train_loss_step=0.687]Epoch 0:   1%|          | 3/380 [00:00<00:33, 11.27it/s, loss=0.685, v_num=24, train_loss_step=0.678]Epoch 0:   1%|          | 4/380 [00:00<00:34, 10.90it/s, loss=0.685, v_num=24, train_loss_step=0.678]Epoch 0:   1%|          | 4/380 [00:00<00:34, 10.89it/s, loss=0.68, v_num=24, train_loss_step=0.666] Epoch 0:   1%|▏         | 5/380 [00:00<00:35, 10.65it/s, loss=0.68, v_num=24, train_loss_step=0.666]Epoch 0:   1%|▏         | 5/380 [00:00<00:35, 10.64it/s, loss=0.677, v_num=24, train_loss_step=0.665]Epoch 0:   2%|▏         | 6/380 [00:00<00:35, 10.46it/s, loss=0.677, v_num=24, train_loss_step=0.665]Epoch 0:   2%|▏         | 6/380 [00:00<00:35, 10.46it/s, loss=0.673, v_num=24, train_loss_step=0.653]Epoch 0:   2%|▏         | 7/380 [00:00<00:36, 10.33it/s, loss=0.673, v_num=24, train_loss_step=0.653]Epoch 0:   2%|▏         | 7/380 [00:00<00:36, 10.32it/s, loss=0.673, v_num=24, train_loss_step=0.670]Epoch 0:   2%|▏         | 8/380 [00:00<00:36, 10.22it/s, loss=0.673, v_num=24, train_loss_step=0.670]Epoch 0:   2%|▏         | 8/380 [00:00<00:36, 10.21it/s, loss=0.665, v_num=24, train_loss_step=0.608]Epoch 0:   2%|▏         | 9/380 [00:00<00:36, 10.14it/s, loss=0.665, v_num=24, train_loss_step=0.608]Epoch 0:   2%|▏         | 9/380 [00:00<00:36, 10.14it/s, loss=0.65, v_num=24, train_loss_step=0.534] Epoch 0:   3%|▎         | 10/380 [00:01<00:36, 10.07it/s, loss=0.65, v_num=24, train_loss_step=0.534]Epoch 0:   3%|▎         | 10/380 [00:01<00:36, 10.07it/s, loss=0.63, v_num=24, train_loss_step=0.451]Epoch 0:   3%|▎         | 11/380 [00:01<00:36, 10.02it/s, loss=0.63, v_num=24, train_loss_step=0.451]Epoch 0:   3%|▎         | 11/380 [00:01<00:36, 10.02it/s, loss=0.604, v_num=24, train_loss_step=0.336]Epoch 0:   3%|▎         | 12/380 [00:01<00:36,  9.97it/s, loss=0.604, v_num=24, train_loss_step=0.336]Epoch 0:   3%|▎         | 12/380 [00:01<00:36,  9.97it/s, loss=0.584, v_num=24, train_loss_step=0.373]Epoch 0:   3%|▎         | 13/380 [00:01<00:36,  9.95it/s, loss=0.584, v_num=24, train_loss_step=0.373]Epoch 0:   3%|▎         | 13/380 [00:01<00:36,  9.95it/s, loss=0.568, v_num=24, train_loss_step=0.367]Epoch 0:   4%|▎         | 14/380 [00:01<00:36,  9.92it/s, loss=0.568, v_num=24, train_loss_step=0.367]Epoch 0:   4%|▎         | 14/380 [00:01<00:36,  9.92it/s, loss=0.554, v_num=24, train_loss_step=0.376]Epoch 0:   4%|▍         | 15/380 [00:01<00:36,  9.91it/s, loss=0.554, v_num=24, train_loss_step=0.376]Epoch 0:   4%|▍         | 15/380 [00:01<00:36,  9.91it/s, loss=0.548, v_num=24, train_loss_step=0.467]Epoch 0:   4%|▍         | 16/380 [00:01<00:36,  9.88it/s, loss=0.548, v_num=24, train_loss_step=0.467]Epoch 0:   4%|▍         | 16/380 [00:01<00:36,  9.88it/s, loss=0.533, v_num=24, train_loss_step=0.313]Epoch 0:   4%|▍         | 17/380 [00:01<00:36,  9.86it/s, loss=0.533, v_num=24, train_loss_step=0.313]Epoch 0:   4%|▍         | 17/380 [00:01<00:36,  9.86it/s, loss=0.526, v_num=24, train_loss_step=0.403]Epoch 0:   5%|▍         | 18/380 [00:01<00:36,  9.84it/s, loss=0.526, v_num=24, train_loss_step=0.403]Epoch 0:   5%|▍         | 18/380 [00:01<00:36,  9.83it/s, loss=0.517, v_num=24, train_loss_step=0.369]Epoch 0:   5%|▌         | 19/380 [00:02<00:36,  9.82it/s, loss=0.517, v_num=24, train_loss_step=0.369]Epoch 0:   5%|▌         | 19/380 [00:02<00:36,  9.82it/s, loss=0.512, v_num=24, train_loss_step=0.424]Epoch 0:   5%|▌         | 20/380 [00:02<00:36,  9.80it/s, loss=0.512, v_num=24, train_loss_step=0.424]Epoch 0:   5%|▌         | 20/380 [00:02<00:36,  9.80it/s, loss=0.504, v_num=24, train_loss_step=0.345]Epoch 0:   6%|▌         | 21/380 [00:02<00:36,  9.79it/s, loss=0.504, v_num=24, train_loss_step=0.345]Epoch 0:   6%|▌         | 21/380 [00:02<00:36,  9.78it/s, loss=0.492, v_num=24, train_loss_step=0.463]Epoch 0:   6%|▌         | 22/380 [00:02<00:36,  9.77it/s, loss=0.492, v_num=24, train_loss_step=0.463]Epoch 0:   6%|▌         | 22/380 [00:02<00:36,  9.77it/s, loss=0.475, v_num=24, train_loss_step=0.342]Epoch 0:   6%|▌         | 23/380 [00:02<00:36,  9.76it/s, loss=0.475, v_num=24, train_loss_step=0.342]Epoch 0:   6%|▌         | 23/380 [00:02<00:36,  9.76it/s, loss=0.461, v_num=24, train_loss_step=0.386]Epoch 0:   6%|▋         | 24/380 [00:02<00:36,  9.75it/s, loss=0.461, v_num=24, train_loss_step=0.386]Epoch 0:   6%|▋         | 24/380 [00:02<00:36,  9.75it/s, loss=0.447, v_num=24, train_loss_step=0.400]Epoch 0:   7%|▋         | 25/380 [00:02<00:36,  9.74it/s, loss=0.447, v_num=24, train_loss_step=0.400]Epoch 0:   7%|▋         | 25/380 [00:02<00:36,  9.74it/s, loss=0.435, v_num=24, train_loss_step=0.421]Epoch 0:   7%|▋         | 26/380 [00:02<00:36,  9.73it/s, loss=0.435, v_num=24, train_loss_step=0.421]Epoch 0:   7%|▋         | 26/380 [00:02<00:36,  9.73it/s, loss=0.426, v_num=24, train_loss_step=0.477]Epoch 0:   7%|▋         | 27/380 [00:02<00:36,  9.72it/s, loss=0.426, v_num=24, train_loss_step=0.477]Epoch 0:   7%|▋         | 27/380 [00:02<00:36,  9.71it/s, loss=0.412, v_num=24, train_loss_step=0.379]Epoch 0:   7%|▋         | 28/380 [00:02<00:36,  9.72it/s, loss=0.412, v_num=24, train_loss_step=0.379]Epoch 0:   7%|▋         | 28/380 [00:02<00:36,  9.72it/s, loss=0.398, v_num=24, train_loss_step=0.345]Epoch 0:   8%|▊         | 29/380 [00:03<00:36,  9.70it/s, loss=0.398, v_num=24, train_loss_step=0.345]Epoch 0:   8%|▊         | 29/380 [00:03<00:36,  9.70it/s, loss=0.387, v_num=24, train_loss_step=0.314]Epoch 0:   8%|▊         | 30/380 [00:03<00:36,  9.70it/s, loss=0.387, v_num=24, train_loss_step=0.314]Epoch 0:   8%|▊         | 30/380 [00:03<00:36,  9.70it/s, loss=0.389, v_num=24, train_loss_step=0.472]Epoch 0:   8%|▊         | 31/380 [00:03<00:36,  9.69it/s, loss=0.389, v_num=24, train_loss_step=0.472]Epoch 0:   8%|▊         | 31/380 [00:03<00:36,  9.69it/s, loss=0.392, v_num=24, train_loss_step=0.397]Epoch 0:   8%|▊         | 32/380 [00:03<00:35,  9.68it/s, loss=0.392, v_num=24, train_loss_step=0.397]Epoch 0:   8%|▊         | 32/380 [00:03<00:35,  9.68it/s, loss=0.394, v_num=24, train_loss_step=0.430]Epoch 0:   9%|▊         | 33/380 [00:03<00:35,  9.67it/s, loss=0.394, v_num=24, train_loss_step=0.430]Epoch 0:   9%|▊         | 33/380 [00:03<00:35,  9.67it/s, loss=0.396, v_num=24, train_loss_step=0.399]Epoch 0:   9%|▉         | 34/380 [00:03<00:35,  9.67it/s, loss=0.396, v_num=24, train_loss_step=0.399]Epoch 0:   9%|▉         | 34/380 [00:03<00:35,  9.67it/s, loss=0.4, v_num=24, train_loss_step=0.451]  Epoch 0:   9%|▉         | 35/380 [00:03<00:35,  9.66it/s, loss=0.4, v_num=24, train_loss_step=0.451]Epoch 0:   9%|▉         | 35/380 [00:03<00:35,  9.66it/s, loss=0.395, v_num=24, train_loss_step=0.375]Epoch 0:   9%|▉         | 36/380 [00:03<00:35,  9.65it/s, loss=0.395, v_num=24, train_loss_step=0.375]Epoch 0:   9%|▉         | 36/380 [00:03<00:35,  9.65it/s, loss=0.4, v_num=24, train_loss_step=0.412]  Epoch 0:  10%|▉         | 37/380 [00:03<00:35,  9.64it/s, loss=0.4, v_num=24, train_loss_step=0.412]Epoch 0:  10%|▉         | 37/380 [00:03<00:35,  9.64it/s, loss=0.4, v_num=24, train_loss_step=0.396]Epoch 0:  10%|█         | 38/380 [00:04<00:35,  9.64it/s, loss=0.4, v_num=24, train_loss_step=0.396]Epoch 0:  10%|█         | 38/380 [00:04<00:35,  9.64it/s, loss=0.401, v_num=24, train_loss_step=0.400]Epoch 0:  10%|█         | 39/380 [00:04<00:35,  9.64it/s, loss=0.401, v_num=24, train_loss_step=0.400]Epoch 0:  10%|█         | 39/380 [00:04<00:35,  9.64it/s, loss=0.4, v_num=24, train_loss_step=0.391]  Epoch 0:  11%|█         | 40/380 [00:04<00:35,  9.63it/s, loss=0.4, v_num=24, train_loss_step=0.391]Epoch 0:  11%|█         | 40/380 [00:04<00:35,  9.63it/s, loss=0.402, v_num=24, train_loss_step=0.393]Epoch 0:  11%|█         | 41/380 [00:04<00:35,  9.62it/s, loss=0.402, v_num=24, train_loss_step=0.393]Epoch 0:  11%|█         | 41/380 [00:04<00:35,  9.62it/s, loss=0.409, v_num=24, train_loss_step=0.600]Epoch 0:  11%|█         | 42/380 [00:04<00:35,  9.62it/s, loss=0.409, v_num=24, train_loss_step=0.600]Epoch 0:  11%|█         | 42/380 [00:04<00:35,  9.62it/s, loss=0.415, v_num=24, train_loss_step=0.455]Epoch 0:  11%|█▏        | 43/380 [00:04<00:35,  9.62it/s, loss=0.415, v_num=24, train_loss_step=0.455]Epoch 0:  11%|█▏        | 43/380 [00:04<00:35,  9.62it/s, loss=0.415, v_num=24, train_loss_step=0.391]Epoch 0:  12%|█▏        | 44/380 [00:04<00:34,  9.61it/s, loss=0.415, v_num=24, train_loss_step=0.391]Epoch 0:  12%|█▏        | 44/380 [00:04<00:34,  9.61it/s, loss=0.418, v_num=24, train_loss_step=0.454]Epoch 0:  12%|█▏        | 45/380 [00:04<00:34,  9.61it/s, loss=0.418, v_num=24, train_loss_step=0.454]Epoch 0:  12%|█▏        | 45/380 [00:04<00:34,  9.61it/s, loss=0.417, v_num=24, train_loss_step=0.407]Epoch 0:  12%|█▏        | 46/380 [00:04<00:34,  9.60it/s, loss=0.417, v_num=24, train_loss_step=0.407]Epoch 0:  12%|█▏        | 46/380 [00:04<00:34,  9.60it/s, loss=0.414, v_num=24, train_loss_step=0.417]Epoch 0:  12%|█▏        | 47/380 [00:05<00:34,  9.59it/s, loss=0.414, v_num=24, train_loss_step=0.417]Epoch 0:  12%|█▏        | 47/380 [00:05<00:34,  9.59it/s, loss=0.413, v_num=24, train_loss_step=0.369]Epoch 0:  13%|█▎        | 48/380 [00:05<00:34,  9.59it/s, loss=0.413, v_num=24, train_loss_step=0.369]Epoch 0:  13%|█▎        | 48/380 [00:05<00:34,  9.59it/s, loss=0.414, v_num=24, train_loss_step=0.361]Epoch 0:  13%|█▎        | 49/380 [00:05<00:34,  9.59it/s, loss=0.414, v_num=24, train_loss_step=0.361]Epoch 0:  13%|█▎        | 49/380 [00:05<00:34,  9.59it/s, loss=0.419, v_num=24, train_loss_step=0.417]Epoch 0:  13%|█▎        | 50/380 [00:05<00:34,  9.59it/s, loss=0.419, v_num=24, train_loss_step=0.417]Epoch 0:  13%|█▎        | 50/380 [00:05<00:34,  9.59it/s, loss=0.415, v_num=24, train_loss_step=0.386]Epoch 0:  13%|█▎        | 51/380 [00:05<00:34,  9.59it/s, loss=0.415, v_num=24, train_loss_step=0.386]Epoch 0:  13%|█▎        | 51/380 [00:05<00:34,  9.59it/s, loss=0.411, v_num=24, train_loss_step=0.321]Epoch 0:  14%|█▎        | 52/380 [00:05<00:34,  9.58it/s, loss=0.411, v_num=24, train_loss_step=0.321]Epoch 0:  14%|█▎        | 52/380 [00:05<00:34,  9.58it/s, loss=0.407, v_num=24, train_loss_step=0.353]Epoch 0:  14%|█▍        | 53/380 [00:05<00:34,  9.58it/s, loss=0.407, v_num=24, train_loss_step=0.353]Epoch 0:  14%|█▍        | 53/380 [00:05<00:34,  9.58it/s, loss=0.405, v_num=24, train_loss_step=0.356]Epoch 0:  14%|█▍        | 54/380 [00:05<00:34,  9.58it/s, loss=0.405, v_num=24, train_loss_step=0.356]Epoch 0:  14%|█▍        | 54/380 [00:05<00:34,  9.58it/s, loss=0.399, v_num=24, train_loss_step=0.336]Epoch 0:  14%|█▍        | 55/380 [00:05<00:33,  9.57it/s, loss=0.399, v_num=24, train_loss_step=0.336]Epoch 0:  14%|█▍        | 55/380 [00:05<00:33,  9.57it/s, loss=0.397, v_num=24, train_loss_step=0.324]Epoch 0:  15%|█▍        | 56/380 [00:05<00:33,  9.57it/s, loss=0.397, v_num=24, train_loss_step=0.324]Epoch 0:  15%|█▍        | 56/380 [00:05<00:33,  9.57it/s, loss=0.404, v_num=24, train_loss_step=0.564]Epoch 0:  15%|█▌        | 57/380 [00:06<00:33,  9.56it/s, loss=0.404, v_num=24, train_loss_step=0.564]Epoch 0:  15%|█▌        | 57/380 [00:06<00:33,  9.56it/s, loss=0.402, v_num=24, train_loss_step=0.338]Epoch 0:  15%|█▌        | 58/380 [00:06<00:33,  9.56it/s, loss=0.402, v_num=24, train_loss_step=0.338]Epoch 0:  15%|█▌        | 58/380 [00:06<00:33,  9.56it/s, loss=0.397, v_num=24, train_loss_step=0.313]Epoch 0:  16%|█▌        | 59/380 [00:06<00:33,  9.56it/s, loss=0.397, v_num=24, train_loss_step=0.313]Epoch 0:  16%|█▌        | 59/380 [00:06<00:33,  9.56it/s, loss=0.393, v_num=24, train_loss_step=0.314]Epoch 0:  16%|█▌        | 60/380 [00:06<00:33,  9.56it/s, loss=0.393, v_num=24, train_loss_step=0.314]Epoch 0:  16%|█▌        | 60/380 [00:06<00:33,  9.56it/s, loss=0.39, v_num=24, train_loss_step=0.326] Epoch 0:  16%|█▌        | 61/380 [00:06<00:33,  9.56it/s, loss=0.39, v_num=24, train_loss_step=0.326]Epoch 0:  16%|█▌        | 61/380 [00:06<00:33,  9.56it/s, loss=0.389, v_num=24, train_loss_step=0.590]Epoch 0:  16%|█▋        | 62/380 [00:06<00:33,  9.56it/s, loss=0.389, v_num=24, train_loss_step=0.590]Epoch 0:  16%|█▋        | 62/380 [00:06<00:33,  9.56it/s, loss=0.39, v_num=24, train_loss_step=0.456] Epoch 0:  17%|█▋        | 63/380 [00:06<00:33,  9.56it/s, loss=0.39, v_num=24, train_loss_step=0.456]Epoch 0:  17%|█▋        | 63/380 [00:06<00:33,  9.55it/s, loss=0.386, v_num=24, train_loss_step=0.324]Epoch 0:  17%|█▋        | 64/380 [00:06<00:33,  9.55it/s, loss=0.386, v_num=24, train_loss_step=0.324]Epoch 0:  17%|█▋        | 64/380 [00:06<00:33,  9.55it/s, loss=0.381, v_num=24, train_loss_step=0.348]Epoch 0:  17%|█▋        | 65/380 [00:06<00:32,  9.55it/s, loss=0.381, v_num=24, train_loss_step=0.348]Epoch 0:  17%|█▋        | 65/380 [00:06<00:32,  9.55it/s, loss=0.381, v_num=24, train_loss_step=0.418]Epoch 0:  17%|█▋        | 66/380 [00:07<00:32,  9.55it/s, loss=0.381, v_num=24, train_loss_step=0.418]Epoch 0:  17%|█▋        | 66/380 [00:07<00:32,  9.55it/s, loss=0.379, v_num=24, train_loss_step=0.373]Epoch 0:  18%|█▊        | 67/380 [00:07<00:32,  9.54it/s, loss=0.379, v_num=24, train_loss_step=0.373]Epoch 0:  18%|█▊        | 67/380 [00:07<00:32,  9.54it/s, loss=0.38, v_num=24, train_loss_step=0.377] Epoch 0:  18%|█▊        | 68/380 [00:07<00:32,  9.54it/s, loss=0.38, v_num=24, train_loss_step=0.377]Epoch 0:  18%|█▊        | 68/380 [00:07<00:32,  9.54it/s, loss=0.381, v_num=24, train_loss_step=0.385]Epoch 0:  18%|█▊        | 69/380 [00:07<00:32,  9.54it/s, loss=0.381, v_num=24, train_loss_step=0.385]Epoch 0:  18%|█▊        | 69/380 [00:07<00:32,  9.54it/s, loss=0.377, v_num=24, train_loss_step=0.343]Epoch 0:  18%|█▊        | 70/380 [00:07<00:32,  9.53it/s, loss=0.377, v_num=24, train_loss_step=0.343]Epoch 0:  18%|█▊        | 70/380 [00:07<00:32,  9.53it/s, loss=0.377, v_num=24, train_loss_step=0.386]Epoch 0:  19%|█▊        | 71/380 [00:07<00:32,  9.53it/s, loss=0.377, v_num=24, train_loss_step=0.386]Epoch 0:  19%|█▊        | 71/380 [00:07<00:32,  9.53it/s, loss=0.383, v_num=24, train_loss_step=0.430]Epoch 0:  19%|█▉        | 72/380 [00:07<00:32,  9.53it/s, loss=0.383, v_num=24, train_loss_step=0.430]Epoch 0:  19%|█▉        | 72/380 [00:07<00:32,  9.53it/s, loss=0.386, v_num=24, train_loss_step=0.411]Epoch 0:  19%|█▉        | 73/380 [00:07<00:32,  9.53it/s, loss=0.386, v_num=24, train_loss_step=0.411]Epoch 0:  19%|█▉        | 73/380 [00:07<00:32,  9.53it/s, loss=0.387, v_num=24, train_loss_step=0.378]Epoch 0:  19%|█▉        | 74/380 [00:07<00:32,  9.53it/s, loss=0.387, v_num=24, train_loss_step=0.378]Epoch 0:  19%|█▉        | 74/380 [00:07<00:32,  9.53it/s, loss=0.388, v_num=24, train_loss_step=0.369]Epoch 0:  20%|█▉        | 75/380 [00:07<00:32,  9.53it/s, loss=0.388, v_num=24, train_loss_step=0.369]Epoch 0:  20%|█▉        | 75/380 [00:07<00:32,  9.53it/s, loss=0.389, v_num=24, train_loss_step=0.346]Epoch 0:  20%|██        | 76/380 [00:08<00:31,  9.53it/s, loss=0.389, v_num=24, train_loss_step=0.346]Epoch 0:  20%|██        | 76/380 [00:08<00:31,  9.53it/s, loss=0.382, v_num=24, train_loss_step=0.406]Epoch 0:  20%|██        | 77/380 [00:08<00:31,  9.53it/s, loss=0.382, v_num=24, train_loss_step=0.406]Epoch 0:  20%|██        | 77/380 [00:08<00:31,  9.53it/s, loss=0.382, v_num=24, train_loss_step=0.342]Epoch 0:  21%|██        | 78/380 [00:08<00:31,  9.53it/s, loss=0.382, v_num=24, train_loss_step=0.342]Epoch 0:  21%|██        | 78/380 [00:08<00:31,  9.53it/s, loss=0.383, v_num=24, train_loss_step=0.338]Epoch 0:  21%|██        | 79/380 [00:08<00:31,  9.53it/s, loss=0.383, v_num=24, train_loss_step=0.338]Epoch 0:  21%|██        | 79/380 [00:08<00:31,  9.53it/s, loss=0.385, v_num=24, train_loss_step=0.362]Epoch 0:  21%|██        | 80/380 [00:08<00:31,  9.53it/s, loss=0.385, v_num=24, train_loss_step=0.362]Epoch 0:  21%|██        | 80/380 [00:08<00:31,  9.53it/s, loss=0.387, v_num=24, train_loss_step=0.360]Epoch 0:  21%|██▏       | 81/380 [00:08<00:31,  9.53it/s, loss=0.387, v_num=24, train_loss_step=0.360]Epoch 0:  21%|██▏       | 81/380 [00:08<00:31,  9.53it/s, loss=0.374, v_num=24, train_loss_step=0.328]Epoch 0:  22%|██▏       | 82/380 [00:08<00:31,  9.53it/s, loss=0.374, v_num=24, train_loss_step=0.328]Epoch 0:  22%|██▏       | 82/380 [00:08<00:31,  9.52it/s, loss=0.37, v_num=24, train_loss_step=0.379] Epoch 0:  22%|██▏       | 83/380 [00:08<00:31,  9.52it/s, loss=0.37, v_num=24, train_loss_step=0.379]Epoch 0:  22%|██▏       | 83/380 [00:08<00:31,  9.52it/s, loss=0.374, v_num=24, train_loss_step=0.399]Epoch 0:  22%|██▏       | 84/380 [00:08<00:31,  9.52it/s, loss=0.374, v_num=24, train_loss_step=0.399]Epoch 0:  22%|██▏       | 84/380 [00:08<00:31,  9.52it/s, loss=0.377, v_num=24, train_loss_step=0.410]Epoch 0:  22%|██▏       | 85/380 [00:09<00:30,  9.52it/s, loss=0.377, v_num=24, train_loss_step=0.410]Epoch 0:  22%|██▏       | 85/380 [00:09<00:30,  9.52it/s, loss=0.375, v_num=24, train_loss_step=0.386]Epoch 0:  23%|██▎       | 86/380 [00:09<00:30,  9.53it/s, loss=0.375, v_num=24, train_loss_step=0.386]Epoch 0:  23%|██▎       | 86/380 [00:09<00:30,  9.52it/s, loss=0.374, v_num=24, train_loss_step=0.351]Epoch 0:  23%|██▎       | 87/380 [00:09<00:30,  9.53it/s, loss=0.374, v_num=24, train_loss_step=0.351]Epoch 0:  23%|██▎       | 87/380 [00:09<00:30,  9.52it/s, loss=0.371, v_num=24, train_loss_step=0.313]Epoch 0:  23%|██▎       | 88/380 [00:09<00:30,  9.52it/s, loss=0.371, v_num=24, train_loss_step=0.313]Epoch 0:  23%|██▎       | 88/380 [00:09<00:30,  9.52it/s, loss=0.369, v_num=24, train_loss_step=0.350]Epoch 0:  23%|██▎       | 89/380 [00:09<00:30,  9.52it/s, loss=0.369, v_num=24, train_loss_step=0.350]Epoch 0:  23%|██▎       | 89/380 [00:09<00:30,  9.52it/s, loss=0.371, v_num=24, train_loss_step=0.376]Epoch 0:  24%|██▎       | 90/380 [00:09<00:30,  9.53it/s, loss=0.371, v_num=24, train_loss_step=0.376]Epoch 0:  24%|██▎       | 90/380 [00:09<00:30,  9.53it/s, loss=0.368, v_num=24, train_loss_step=0.330]Epoch 0:  24%|██▍       | 91/380 [00:09<00:30,  9.52it/s, loss=0.368, v_num=24, train_loss_step=0.330]Epoch 0:  24%|██▍       | 91/380 [00:09<00:30,  9.52it/s, loss=0.366, v_num=24, train_loss_step=0.390]Epoch 0:  24%|██▍       | 92/380 [00:09<00:30,  9.52it/s, loss=0.366, v_num=24, train_loss_step=0.390]Epoch 0:  24%|██▍       | 92/380 [00:09<00:30,  9.52it/s, loss=0.363, v_num=24, train_loss_step=0.344]Epoch 0:  24%|██▍       | 93/380 [00:09<00:30,  9.52it/s, loss=0.363, v_num=24, train_loss_step=0.344]Epoch 0:  24%|██▍       | 93/380 [00:09<00:30,  9.52it/s, loss=0.362, v_num=24, train_loss_step=0.367]Epoch 0:  25%|██▍       | 94/380 [00:09<00:30,  9.52it/s, loss=0.362, v_num=24, train_loss_step=0.367]Epoch 0:  25%|██▍       | 94/380 [00:09<00:30,  9.52it/s, loss=0.361, v_num=24, train_loss_step=0.347]Epoch 0:  25%|██▌       | 95/380 [00:10<00:29,  9.52it/s, loss=0.361, v_num=24, train_loss_step=0.347]Epoch 0:  25%|██▌       | 95/380 [00:10<00:29,  9.52it/s, loss=0.361, v_num=24, train_loss_step=0.343]Epoch 0:  25%|██▌       | 96/380 [00:10<00:29,  9.52it/s, loss=0.361, v_num=24, train_loss_step=0.343]Epoch 0:  25%|██▌       | 96/380 [00:10<00:29,  9.52it/s, loss=0.357, v_num=24, train_loss_step=0.317]Epoch 0:  26%|██▌       | 97/380 [00:10<00:29,  9.52it/s, loss=0.357, v_num=24, train_loss_step=0.317]Epoch 0:  26%|██▌       | 97/380 [00:10<00:29,  9.52it/s, loss=0.357, v_num=24, train_loss_step=0.343]Epoch 0:  26%|██▌       | 98/380 [00:10<00:29,  9.52it/s, loss=0.357, v_num=24, train_loss_step=0.343]Epoch 0:  26%|██▌       | 98/380 [00:10<00:29,  9.52it/s, loss=0.356, v_num=24, train_loss_step=0.333]Epoch 0:  26%|██▌       | 99/380 [00:10<00:29,  9.52it/s, loss=0.356, v_num=24, train_loss_step=0.333]Epoch 0:  26%|██▌       | 99/380 [00:10<00:29,  9.52it/s, loss=0.355, v_num=24, train_loss_step=0.342]Epoch 0:  26%|██▋       | 100/380 [00:10<00:29,  9.52it/s, loss=0.355, v_num=24, train_loss_step=0.342]Epoch 0:  26%|██▋       | 100/380 [00:10<00:29,  9.52it/s, loss=0.357, v_num=24, train_loss_step=0.386]Epoch 0:  27%|██▋       | 101/380 [00:10<00:29,  9.53it/s, loss=0.357, v_num=24, train_loss_step=0.386]Epoch 0:  27%|██▋       | 101/380 [00:10<00:29,  9.53it/s, loss=0.358, v_num=24, train_loss_step=0.352]Epoch 0:  27%|██▋       | 102/380 [00:10<00:29,  9.53it/s, loss=0.358, v_num=24, train_loss_step=0.352]Epoch 0:  27%|██▋       | 102/380 [00:10<00:29,  9.53it/s, loss=0.356, v_num=24, train_loss_step=0.348]Epoch 0:  27%|██▋       | 103/380 [00:10<00:29,  9.53it/s, loss=0.356, v_num=24, train_loss_step=0.348]Epoch 0:  27%|██▋       | 103/380 [00:10<00:29,  9.52it/s, loss=0.353, v_num=24, train_loss_step=0.339]Epoch 0:  27%|██▋       | 104/380 [00:11<00:28,  9.53it/s, loss=0.353, v_num=24, train_loss_step=0.339]Epoch 0:  27%|██▋       | 104/380 [00:11<00:28,  9.53it/s, loss=0.349, v_num=24, train_loss_step=0.331]Epoch 0:  28%|██▊       | 105/380 [00:11<00:28,  9.52it/s, loss=0.349, v_num=24, train_loss_step=0.331]Epoch 0:  28%|██▊       | 105/380 [00:11<00:28,  9.52it/s, loss=0.347, v_num=24, train_loss_step=0.331]Epoch 0:  28%|██▊       | 106/380 [00:11<00:28,  9.52it/s, loss=0.347, v_num=24, train_loss_step=0.331]Epoch 0:  28%|██▊       | 106/380 [00:11<00:28,  9.52it/s, loss=0.347, v_num=24, train_loss_step=0.352]Epoch 0:  28%|██▊       | 107/380 [00:11<00:28,  9.52it/s, loss=0.347, v_num=24, train_loss_step=0.352]Epoch 0:  28%|██▊       | 107/380 [00:11<00:28,  9.52it/s, loss=0.352, v_num=24, train_loss_step=0.411]Epoch 0:  28%|██▊       | 108/380 [00:11<00:28,  9.52it/s, loss=0.352, v_num=24, train_loss_step=0.411]Epoch 0:  28%|██▊       | 108/380 [00:11<00:28,  9.52it/s, loss=0.351, v_num=24, train_loss_step=0.333]Epoch 0:  29%|██▊       | 109/380 [00:11<00:28,  9.52it/s, loss=0.351, v_num=24, train_loss_step=0.333]Epoch 0:  29%|██▊       | 109/380 [00:11<00:28,  9.52it/s, loss=0.349, v_num=24, train_loss_step=0.331]Epoch 0:  29%|██▉       | 110/380 [00:11<00:28,  9.52it/s, loss=0.349, v_num=24, train_loss_step=0.331]Epoch 0:  29%|██▉       | 110/380 [00:11<00:28,  9.52it/s, loss=0.349, v_num=24, train_loss_step=0.338]Epoch 0:  29%|██▉       | 111/380 [00:11<00:28,  9.52it/s, loss=0.349, v_num=24, train_loss_step=0.338]Epoch 0:  29%|██▉       | 111/380 [00:11<00:28,  9.52it/s, loss=0.347, v_num=24, train_loss_step=0.353]Epoch 0:  29%|██▉       | 112/380 [00:11<00:28,  9.52it/s, loss=0.347, v_num=24, train_loss_step=0.353]Epoch 0:  29%|██▉       | 112/380 [00:11<00:28,  9.52it/s, loss=0.346, v_num=24, train_loss_step=0.323]Epoch 0:  30%|██▉       | 113/380 [00:11<00:28,  9.52it/s, loss=0.346, v_num=24, train_loss_step=0.323]Epoch 0:  30%|██▉       | 113/380 [00:11<00:28,  9.52it/s, loss=0.349, v_num=24, train_loss_step=0.425]Epoch 0:  30%|███       | 114/380 [00:12<00:27,  9.52it/s, loss=0.349, v_num=24, train_loss_step=0.425]Epoch 0:  30%|███       | 114/380 [00:12<00:27,  9.52it/s, loss=0.35, v_num=24, train_loss_step=0.364] Epoch 0:  30%|███       | 115/380 [00:12<00:27,  9.52it/s, loss=0.35, v_num=24, train_loss_step=0.364]Epoch 0:  30%|███       | 115/380 [00:12<00:27,  9.52it/s, loss=0.348, v_num=24, train_loss_step=0.316]Epoch 0:  31%|███       | 116/380 [00:12<00:27,  9.52it/s, loss=0.348, v_num=24, train_loss_step=0.316]Epoch 0:  31%|███       | 116/380 [00:12<00:27,  9.52it/s, loss=0.356, v_num=24, train_loss_step=0.469]Epoch 0:  31%|███       | 117/380 [00:12<00:27,  9.52it/s, loss=0.356, v_num=24, train_loss_step=0.469]Epoch 0:  31%|███       | 117/380 [00:12<00:27,  9.52it/s, loss=0.355, v_num=24, train_loss_step=0.319]Epoch 0:  31%|███       | 118/380 [00:12<00:27,  9.52it/s, loss=0.355, v_num=24, train_loss_step=0.319]Epoch 0:  31%|███       | 118/380 [00:12<00:27,  9.52it/s, loss=0.355, v_num=24, train_loss_step=0.332]Epoch 0:  31%|███▏      | 119/380 [00:12<00:27,  9.52it/s, loss=0.355, v_num=24, train_loss_step=0.332]Epoch 0:  31%|███▏      | 119/380 [00:12<00:27,  9.52it/s, loss=0.356, v_num=24, train_loss_step=0.372]Epoch 0:  32%|███▏      | 120/380 [00:12<00:27,  9.52it/s, loss=0.356, v_num=24, train_loss_step=0.372]Epoch 0:  32%|███▏      | 120/380 [00:12<00:27,  9.52it/s, loss=0.353, v_num=24, train_loss_step=0.329]Epoch 0:  32%|███▏      | 121/380 [00:12<00:27,  9.52it/s, loss=0.353, v_num=24, train_loss_step=0.329]Epoch 0:  32%|███▏      | 121/380 [00:12<00:27,  9.52it/s, loss=0.352, v_num=24, train_loss_step=0.318]Epoch 0:  32%|███▏      | 122/380 [00:12<00:27,  9.53it/s, loss=0.352, v_num=24, train_loss_step=0.318]Epoch 0:  32%|███▏      | 122/380 [00:12<00:27,  9.53it/s, loss=0.35, v_num=24, train_loss_step=0.316] Epoch 0:  32%|███▏      | 123/380 [00:13<00:26,  9.52it/s, loss=0.35, v_num=24, train_loss_step=0.316]Epoch 0:  32%|███▏      | 123/380 [00:13<00:26,  9.52it/s, loss=0.35, v_num=24, train_loss_step=0.335]Epoch 0:  33%|███▎      | 124/380 [00:13<00:26,  9.52it/s, loss=0.35, v_num=24, train_loss_step=0.335]Epoch 0:  33%|███▎      | 124/380 [00:13<00:26,  9.52it/s, loss=0.351, v_num=24, train_loss_step=0.351]Epoch 0:  33%|███▎      | 125/380 [00:13<00:26,  9.52it/s, loss=0.351, v_num=24, train_loss_step=0.351]Epoch 0:  33%|███▎      | 125/380 [00:13<00:26,  9.52it/s, loss=0.35, v_num=24, train_loss_step=0.319] Epoch 0:  33%|███▎      | 126/380 [00:13<00:26,  9.52it/s, loss=0.35, v_num=24, train_loss_step=0.319]Epoch 0:  33%|███▎      | 126/380 [00:13<00:26,  9.52it/s, loss=0.35, v_num=24, train_loss_step=0.352]Epoch 0:  33%|███▎      | 127/380 [00:13<00:26,  9.52it/s, loss=0.35, v_num=24, train_loss_step=0.352]Epoch 0:  33%|███▎      | 127/380 [00:13<00:26,  9.52it/s, loss=0.346, v_num=24, train_loss_step=0.333]Epoch 0:  34%|███▎      | 128/380 [00:13<00:26,  9.52it/s, loss=0.346, v_num=24, train_loss_step=0.333]Epoch 0:  34%|███▎      | 128/380 [00:13<00:26,  9.52it/s, loss=0.346, v_num=24, train_loss_step=0.320]Epoch 0:  34%|███▍      | 129/380 [00:13<00:26,  9.52it/s, loss=0.346, v_num=24, train_loss_step=0.320]Epoch 0:  34%|███▍      | 129/380 [00:13<00:26,  9.52it/s, loss=0.349, v_num=24, train_loss_step=0.403]Epoch 0:  34%|███▍      | 130/380 [00:13<00:26,  9.52it/s, loss=0.349, v_num=24, train_loss_step=0.403]Epoch 0:  34%|███▍      | 130/380 [00:13<00:26,  9.52it/s, loss=0.35, v_num=24, train_loss_step=0.342] Epoch 0:  34%|███▍      | 131/380 [00:13<00:26,  9.52it/s, loss=0.35, v_num=24, train_loss_step=0.342]Epoch 0:  34%|███▍      | 131/380 [00:13<00:26,  9.52it/s, loss=0.357, v_num=24, train_loss_step=0.500]Epoch 0:  35%|███▍      | 132/380 [00:13<00:26,  9.52it/s, loss=0.357, v_num=24, train_loss_step=0.500]Epoch 0:  35%|███▍      | 132/380 [00:13<00:26,  9.52it/s, loss=0.363, v_num=24, train_loss_step=0.437]Epoch 0:  35%|███▌      | 133/380 [00:14<00:25,  9.52it/s, loss=0.363, v_num=24, train_loss_step=0.437]Epoch 0:  35%|███▌      | 133/380 [00:14<00:25,  9.52it/s, loss=0.358, v_num=24, train_loss_step=0.332]Epoch 0:  35%|███▌      | 134/380 [00:14<00:25,  9.52it/s, loss=0.358, v_num=24, train_loss_step=0.332]Epoch 0:  35%|███▌      | 134/380 [00:14<00:25,  9.52it/s, loss=0.36, v_num=24, train_loss_step=0.412] Epoch 0:  36%|███▌      | 135/380 [00:14<00:25,  9.52it/s, loss=0.36, v_num=24, train_loss_step=0.412]Epoch 0:  36%|███▌      | 135/380 [00:14<00:25,  9.52it/s, loss=0.363, v_num=24, train_loss_step=0.368]Epoch 0:  36%|███▌      | 136/380 [00:14<00:25,  9.52it/s, loss=0.363, v_num=24, train_loss_step=0.368]Epoch 0:  36%|███▌      | 136/380 [00:14<00:25,  9.52it/s, loss=0.358, v_num=24, train_loss_step=0.373]Epoch 0:  36%|███▌      | 137/380 [00:14<00:25,  9.52it/s, loss=0.358, v_num=24, train_loss_step=0.373]Epoch 0:  36%|███▌      | 137/380 [00:14<00:25,  9.52it/s, loss=0.36, v_num=24, train_loss_step=0.352] Epoch 0:  36%|███▋      | 138/380 [00:14<00:25,  9.52it/s, loss=0.36, v_num=24, train_loss_step=0.352]Epoch 0:  36%|███▋      | 138/380 [00:14<00:25,  9.52it/s, loss=0.362, v_num=24, train_loss_step=0.367]Epoch 0:  37%|███▋      | 139/380 [00:14<00:25,  9.52it/s, loss=0.362, v_num=24, train_loss_step=0.367]Epoch 0:  37%|███▋      | 139/380 [00:14<00:25,  9.52it/s, loss=0.362, v_num=24, train_loss_step=0.369]Epoch 0:  37%|███▋      | 140/380 [00:14<00:25,  9.51it/s, loss=0.362, v_num=24, train_loss_step=0.369]Epoch 0:  37%|███▋      | 140/380 [00:14<00:25,  9.51it/s, loss=0.362, v_num=24, train_loss_step=0.339]Epoch 0:  37%|███▋      | 141/380 [00:14<00:25,  9.51it/s, loss=0.362, v_num=24, train_loss_step=0.339]Epoch 0:  37%|███▋      | 141/380 [00:14<00:25,  9.51it/s, loss=0.365, v_num=24, train_loss_step=0.373]Epoch 0:  37%|███▋      | 142/380 [00:15<00:25,  9.51it/s, loss=0.365, v_num=24, train_loss_step=0.373]Epoch 0:  37%|███▋      | 142/380 [00:15<00:25,  9.51it/s, loss=0.366, v_num=24, train_loss_step=0.348]Epoch 0:  38%|███▊      | 143/380 [00:15<00:24,  9.51it/s, loss=0.366, v_num=24, train_loss_step=0.348]Epoch 0:  38%|███▊      | 143/380 [00:15<00:24,  9.51it/s, loss=0.366, v_num=24, train_loss_step=0.325]Epoch 0:  38%|███▊      | 144/380 [00:15<00:24,  9.52it/s, loss=0.366, v_num=24, train_loss_step=0.325]Epoch 0:  38%|███▊      | 144/380 [00:15<00:24,  9.52it/s, loss=0.365, v_num=24, train_loss_step=0.340]Epoch 0:  38%|███▊      | 145/380 [00:15<00:24,  9.52it/s, loss=0.365, v_num=24, train_loss_step=0.340]Epoch 0:  38%|███▊      | 145/380 [00:15<00:24,  9.52it/s, loss=0.365, v_num=24, train_loss_step=0.314]Epoch 0:  38%|███▊      | 146/380 [00:15<00:24,  9.52it/s, loss=0.365, v_num=24, train_loss_step=0.314]Epoch 0:  38%|███▊      | 146/380 [00:15<00:24,  9.52it/s, loss=0.365, v_num=24, train_loss_step=0.352]Epoch 0:  39%|███▊      | 147/380 [00:15<00:24,  9.52it/s, loss=0.365, v_num=24, train_loss_step=0.352]Epoch 0:  39%|███▊      | 147/380 [00:15<00:24,  9.52it/s, loss=0.364, v_num=24, train_loss_step=0.323]Epoch 0:  39%|███▉      | 148/380 [00:15<00:24,  9.51it/s, loss=0.364, v_num=24, train_loss_step=0.323]Epoch 0:  39%|███▉      | 148/380 [00:15<00:24,  9.51it/s, loss=0.366, v_num=24, train_loss_step=0.341]Epoch 0:  39%|███▉      | 149/380 [00:15<00:24,  9.51it/s, loss=0.366, v_num=24, train_loss_step=0.341]Epoch 0:  39%|███▉      | 149/380 [00:15<00:24,  9.51it/s, loss=0.363, v_num=24, train_loss_step=0.348]Epoch 0:  39%|███▉      | 150/380 [00:15<00:24,  9.52it/s, loss=0.363, v_num=24, train_loss_step=0.348]Epoch 0:  39%|███▉      | 150/380 [00:15<00:24,  9.52it/s, loss=0.362, v_num=24, train_loss_step=0.326]Epoch 0:  40%|███▉      | 151/380 [00:15<00:24,  9.51it/s, loss=0.362, v_num=24, train_loss_step=0.326]Epoch 0:  40%|███▉      | 151/380 [00:15<00:24,  9.51it/s, loss=0.357, v_num=24, train_loss_step=0.401]Epoch 0:  40%|████      | 152/380 [00:16<00:23,  9.51it/s, loss=0.357, v_num=24, train_loss_step=0.401]Epoch 0:  40%|████      | 152/380 [00:16<00:23,  9.51it/s, loss=0.354, v_num=24, train_loss_step=0.379]Epoch 0:  40%|████      | 153/380 [00:16<00:23,  9.51it/s, loss=0.354, v_num=24, train_loss_step=0.379]Epoch 0:  40%|████      | 153/380 [00:16<00:23,  9.51it/s, loss=0.355, v_num=24, train_loss_step=0.341]Epoch 0:  41%|████      | 154/380 [00:16<00:23,  9.52it/s, loss=0.355, v_num=24, train_loss_step=0.341]Epoch 0:  41%|████      | 154/380 [00:16<00:23,  9.52it/s, loss=0.35, v_num=24, train_loss_step=0.325] Epoch 0:  41%|████      | 155/380 [00:16<00:23,  9.51it/s, loss=0.35, v_num=24, train_loss_step=0.325]Epoch 0:  41%|████      | 155/380 [00:16<00:23,  9.51it/s, loss=0.348, v_num=24, train_loss_step=0.320]Epoch 0:  41%|████      | 156/380 [00:16<00:23,  9.52it/s, loss=0.348, v_num=24, train_loss_step=0.320]Epoch 0:  41%|████      | 156/380 [00:16<00:23,  9.52it/s, loss=0.349, v_num=24, train_loss_step=0.393]Epoch 0:  41%|████▏     | 157/380 [00:16<00:23,  9.52it/s, loss=0.349, v_num=24, train_loss_step=0.393]Epoch 0:  41%|████▏     | 157/380 [00:16<00:23,  9.52it/s, loss=0.347, v_num=24, train_loss_step=0.313]Epoch 0:  42%|████▏     | 158/380 [00:16<00:23,  9.52it/s, loss=0.347, v_num=24, train_loss_step=0.313]Epoch 0:  42%|████▏     | 158/380 [00:16<00:23,  9.52it/s, loss=0.345, v_num=24, train_loss_step=0.320]Epoch 0:  42%|████▏     | 159/380 [00:16<00:23,  9.52it/s, loss=0.345, v_num=24, train_loss_step=0.320]Epoch 0:  42%|████▏     | 159/380 [00:16<00:23,  9.52it/s, loss=0.342, v_num=24, train_loss_step=0.315]Epoch 0:  42%|████▏     | 160/380 [00:16<00:23,  9.52it/s, loss=0.342, v_num=24, train_loss_step=0.315]Epoch 0:  42%|████▏     | 160/380 [00:16<00:23,  9.52it/s, loss=0.343, v_num=24, train_loss_step=0.362]Epoch 0:  42%|████▏     | 161/380 [00:17<00:23,  9.52it/s, loss=0.343, v_num=24, train_loss_step=0.362]Epoch 0:  42%|████▏     | 161/380 [00:17<00:23,  9.52it/s, loss=0.34, v_num=24, train_loss_step=0.319] Epoch 0:  43%|████▎     | 162/380 [00:17<00:22,  9.52it/s, loss=0.34, v_num=24, train_loss_step=0.319]Epoch 0:  43%|████▎     | 162/380 [00:17<00:22,  9.52it/s, loss=0.339, v_num=24, train_loss_step=0.328]Epoch 0:  43%|████▎     | 163/380 [00:17<00:22,  9.52it/s, loss=0.339, v_num=24, train_loss_step=0.328]Epoch 0:  43%|████▎     | 163/380 [00:17<00:22,  9.52it/s, loss=0.341, v_num=24, train_loss_step=0.353]Epoch 0:  43%|████▎     | 164/380 [00:17<00:22,  9.52it/s, loss=0.341, v_num=24, train_loss_step=0.353]Epoch 0:  43%|████▎     | 164/380 [00:17<00:22,  9.52it/s, loss=0.34, v_num=24, train_loss_step=0.334] Epoch 0:  43%|████▎     | 165/380 [00:17<00:22,  9.52it/s, loss=0.34, v_num=24, train_loss_step=0.334]Epoch 0:  43%|████▎     | 165/380 [00:17<00:22,  9.52it/s, loss=0.341, v_num=24, train_loss_step=0.332]Epoch 0:  44%|████▎     | 166/380 [00:17<00:22,  9.52it/s, loss=0.341, v_num=24, train_loss_step=0.332]Epoch 0:  44%|████▎     | 166/380 [00:17<00:22,  9.52it/s, loss=0.341, v_num=24, train_loss_step=0.340]Epoch 0:  44%|████▍     | 167/380 [00:17<00:22,  9.52it/s, loss=0.341, v_num=24, train_loss_step=0.340]Epoch 0:  44%|████▍     | 167/380 [00:17<00:22,  9.52it/s, loss=0.34, v_num=24, train_loss_step=0.314] Epoch 0:  44%|████▍     | 168/380 [00:17<00:22,  9.51it/s, loss=0.34, v_num=24, train_loss_step=0.314]Epoch 0:  44%|████▍     | 168/380 [00:17<00:22,  9.51it/s, loss=0.343, v_num=24, train_loss_step=0.404]Epoch 0:  44%|████▍     | 169/380 [00:17<00:22,  9.52it/s, loss=0.343, v_num=24, train_loss_step=0.404]Epoch 0:  44%|████▍     | 169/380 [00:17<00:22,  9.52it/s, loss=0.342, v_num=24, train_loss_step=0.329]Epoch 0:  45%|████▍     | 170/380 [00:17<00:22,  9.52it/s, loss=0.342, v_num=24, train_loss_step=0.329]Epoch 0:  45%|████▍     | 170/380 [00:17<00:22,  9.52it/s, loss=0.342, v_num=24, train_loss_step=0.313]Epoch 0:  45%|████▌     | 171/380 [00:18<00:21,  9.51it/s, loss=0.342, v_num=24, train_loss_step=0.313]Epoch 0:  45%|████▌     | 171/380 [00:18<00:21,  9.51it/s, loss=0.338, v_num=24, train_loss_step=0.332]Epoch 0:  45%|████▌     | 172/380 [00:18<00:21,  9.51it/s, loss=0.338, v_num=24, train_loss_step=0.332]Epoch 0:  45%|████▌     | 172/380 [00:18<00:21,  9.51it/s, loss=0.342, v_num=24, train_loss_step=0.444]Epoch 0:  46%|████▌     | 173/380 [00:18<00:21,  9.51it/s, loss=0.342, v_num=24, train_loss_step=0.444]Epoch 0:  46%|████▌     | 173/380 [00:18<00:21,  9.51it/s, loss=0.344, v_num=24, train_loss_step=0.392]Epoch 0:  46%|████▌     | 174/380 [00:18<00:21,  9.51it/s, loss=0.344, v_num=24, train_loss_step=0.392]Epoch 0:  46%|████▌     | 174/380 [00:18<00:21,  9.51it/s, loss=0.345, v_num=24, train_loss_step=0.354]Epoch 0:  46%|████▌     | 175/380 [00:18<00:21,  9.51it/s, loss=0.345, v_num=24, train_loss_step=0.354]Epoch 0:  46%|████▌     | 175/380 [00:18<00:21,  9.51it/s, loss=0.346, v_num=24, train_loss_step=0.320]Epoch 0:  46%|████▋     | 176/380 [00:18<00:21,  9.51it/s, loss=0.346, v_num=24, train_loss_step=0.320]Epoch 0:  46%|████▋     | 176/380 [00:18<00:21,  9.51it/s, loss=0.342, v_num=24, train_loss_step=0.331]Epoch 0:  47%|████▋     | 177/380 [00:18<00:21,  9.51it/s, loss=0.342, v_num=24, train_loss_step=0.331]Epoch 0:  47%|████▋     | 177/380 [00:18<00:21,  9.51it/s, loss=0.346, v_num=24, train_loss_step=0.378]Epoch 0:  47%|████▋     | 178/380 [00:18<00:21,  9.51it/s, loss=0.346, v_num=24, train_loss_step=0.378]Epoch 0:  47%|████▋     | 178/380 [00:18<00:21,  9.51it/s, loss=0.347, v_num=24, train_loss_step=0.341]Epoch 0:  47%|████▋     | 179/380 [00:18<00:21,  9.51it/s, loss=0.347, v_num=24, train_loss_step=0.341]Epoch 0:  47%|████▋     | 179/380 [00:18<00:21,  9.51it/s, loss=0.354, v_num=24, train_loss_step=0.465]Epoch 0:  47%|████▋     | 180/380 [00:19<00:21,  9.51it/s, loss=0.354, v_num=24, train_loss_step=0.465]Epoch 0:  47%|████▋     | 180/380 [00:19<00:21,  9.51it/s, loss=0.356, v_num=24, train_loss_step=0.409]Epoch 0:  48%|████▊     | 181/380 [00:19<00:20,  9.51it/s, loss=0.356, v_num=24, train_loss_step=0.409]Epoch 0:  48%|████▊     | 181/380 [00:19<00:20,  9.51it/s, loss=0.358, v_num=24, train_loss_step=0.355]Epoch 0:  48%|████▊     | 182/380 [00:19<00:20,  9.51it/s, loss=0.358, v_num=24, train_loss_step=0.355]Epoch 0:  48%|████▊     | 182/380 [00:19<00:20,  9.51it/s, loss=0.361, v_num=24, train_loss_step=0.383]Epoch 0:  48%|████▊     | 183/380 [00:19<00:20,  9.51it/s, loss=0.361, v_num=24, train_loss_step=0.383]Epoch 0:  48%|████▊     | 183/380 [00:19<00:20,  9.51it/s, loss=0.362, v_num=24, train_loss_step=0.370]Epoch 0:  48%|████▊     | 184/380 [00:19<00:20,  9.51it/s, loss=0.362, v_num=24, train_loss_step=0.370]Epoch 0:  48%|████▊     | 184/380 [00:19<00:20,  9.51it/s, loss=0.364, v_num=24, train_loss_step=0.382]Epoch 0:  49%|████▊     | 185/380 [00:19<00:20,  9.51it/s, loss=0.364, v_num=24, train_loss_step=0.382]Epoch 0:  49%|████▊     | 185/380 [00:19<00:20,  9.51it/s, loss=0.364, v_num=24, train_loss_step=0.330]Epoch 0:  49%|████▉     | 186/380 [00:19<00:20,  9.51it/s, loss=0.364, v_num=24, train_loss_step=0.330]Epoch 0:  49%|████▉     | 186/380 [00:19<00:20,  9.51it/s, loss=0.365, v_num=24, train_loss_step=0.352]Epoch 0:  49%|████▉     | 187/380 [00:19<00:20,  9.51it/s, loss=0.365, v_num=24, train_loss_step=0.352]Epoch 0:  49%|████▉     | 187/380 [00:19<00:20,  9.51it/s, loss=0.365, v_num=24, train_loss_step=0.321]Epoch 0:  49%|████▉     | 188/380 [00:19<00:20,  9.51it/s, loss=0.365, v_num=24, train_loss_step=0.321]Epoch 0:  49%|████▉     | 188/380 [00:19<00:20,  9.51it/s, loss=0.367, v_num=24, train_loss_step=0.439]Epoch 0:  50%|████▉     | 189/380 [00:19<00:20,  9.51it/s, loss=0.367, v_num=24, train_loss_step=0.439]Epoch 0:  50%|████▉     | 189/380 [00:19<00:20,  9.51it/s, loss=0.372, v_num=24, train_loss_step=0.438]Epoch 0:  50%|█████     | 190/380 [00:20<00:19,  9.51it/s, loss=0.372, v_num=24, train_loss_step=0.438]Epoch 0:  50%|█████     | 190/380 [00:20<00:19,  9.51it/s, loss=0.373, v_num=24, train_loss_step=0.320]Epoch 0:  50%|█████     | 191/380 [00:20<00:19,  9.51it/s, loss=0.373, v_num=24, train_loss_step=0.320]Epoch 0:  50%|█████     | 191/380 [00:20<00:19,  9.51it/s, loss=0.372, v_num=24, train_loss_step=0.325]Epoch 0:  51%|█████     | 192/380 [00:20<00:19,  9.51it/s, loss=0.372, v_num=24, train_loss_step=0.325]Epoch 0:  51%|█████     | 192/380 [00:20<00:19,  9.51it/s, loss=0.366, v_num=24, train_loss_step=0.317]Epoch 0:  51%|█████     | 193/380 [00:20<00:19,  9.51it/s, loss=0.366, v_num=24, train_loss_step=0.317]Epoch 0:  51%|█████     | 193/380 [00:20<00:19,  9.51it/s, loss=0.363, v_num=24, train_loss_step=0.337]Epoch 0:  51%|█████     | 194/380 [00:20<00:19,  9.51it/s, loss=0.363, v_num=24, train_loss_step=0.337]Epoch 0:  51%|█████     | 194/380 [00:20<00:19,  9.51it/s, loss=0.362, v_num=24, train_loss_step=0.322]Epoch 0:  51%|█████▏    | 195/380 [00:20<00:19,  9.51it/s, loss=0.362, v_num=24, train_loss_step=0.322]Epoch 0:  51%|█████▏    | 195/380 [00:20<00:19,  9.51it/s, loss=0.362, v_num=24, train_loss_step=0.325]Epoch 0:  52%|█████▏    | 196/380 [00:20<00:19,  9.51it/s, loss=0.362, v_num=24, train_loss_step=0.325]Epoch 0:  52%|█████▏    | 196/380 [00:20<00:19,  9.51it/s, loss=0.361, v_num=24, train_loss_step=0.316]Epoch 0:  52%|█████▏    | 197/380 [00:20<00:19,  9.51it/s, loss=0.361, v_num=24, train_loss_step=0.316]Epoch 0:  52%|█████▏    | 197/380 [00:20<00:19,  9.51it/s, loss=0.358, v_num=24, train_loss_step=0.313]Epoch 0:  52%|█████▏    | 198/380 [00:20<00:19,  9.51it/s, loss=0.358, v_num=24, train_loss_step=0.313]Epoch 0:  52%|█████▏    | 198/380 [00:20<00:19,  9.51it/s, loss=0.37, v_num=24, train_loss_step=0.585] Epoch 0:  52%|█████▏    | 199/380 [00:21<00:19,  9.51it/s, loss=0.37, v_num=24, train_loss_step=0.585]Epoch 0:  52%|█████▏    | 199/380 [00:21<00:19,  9.51it/s, loss=0.363, v_num=24, train_loss_step=0.317]Epoch 0:  53%|█████▎    | 200/380 [00:21<00:18,  9.50it/s, loss=0.363, v_num=24, train_loss_step=0.317]Epoch 0:  53%|█████▎    | 200/380 [00:21<00:18,  9.50it/s, loss=0.365, v_num=24, train_loss_step=0.447]Epoch 0:  53%|█████▎    | 201/380 [00:21<00:18,  9.51it/s, loss=0.365, v_num=24, train_loss_step=0.447]Epoch 0:  53%|█████▎    | 201/380 [00:21<00:18,  9.51it/s, loss=0.379, v_num=24, train_loss_step=0.644]Epoch 0:  53%|█████▎    | 202/380 [00:21<00:18,  9.50it/s, loss=0.379, v_num=24, train_loss_step=0.644]Epoch 0:  53%|█████▎    | 202/380 [00:21<00:18,  9.50it/s, loss=0.376, v_num=24, train_loss_step=0.314]Epoch 0:  53%|█████▎    | 203/380 [00:21<00:18,  9.50it/s, loss=0.376, v_num=24, train_loss_step=0.314]Epoch 0:  53%|█████▎    | 203/380 [00:21<00:18,  9.50it/s, loss=0.376, v_num=24, train_loss_step=0.366]Epoch 0:  54%|█████▎    | 204/380 [00:21<00:18,  9.50it/s, loss=0.376, v_num=24, train_loss_step=0.366]Epoch 0:  54%|█████▎    | 204/380 [00:21<00:18,  9.50it/s, loss=0.381, v_num=24, train_loss_step=0.496]Epoch 0:  54%|█████▍    | 205/380 [00:21<00:18,  9.50it/s, loss=0.381, v_num=24, train_loss_step=0.496]Epoch 0:  54%|█████▍    | 205/380 [00:21<00:18,  9.50it/s, loss=0.386, v_num=24, train_loss_step=0.426]Epoch 0:  54%|█████▍    | 206/380 [00:21<00:18,  9.50it/s, loss=0.386, v_num=24, train_loss_step=0.426]Epoch 0:  54%|█████▍    | 206/380 [00:21<00:18,  9.50it/s, loss=0.385, v_num=24, train_loss_step=0.327]Epoch 0:  54%|█████▍    | 207/380 [00:21<00:18,  9.50it/s, loss=0.385, v_num=24, train_loss_step=0.327]Epoch 0:  54%|█████▍    | 207/380 [00:21<00:18,  9.50it/s, loss=0.387, v_num=24, train_loss_step=0.372]Epoch 0:  55%|█████▍    | 208/380 [00:21<00:18,  9.50it/s, loss=0.387, v_num=24, train_loss_step=0.372]Epoch 0:  55%|█████▍    | 208/380 [00:21<00:18,  9.50it/s, loss=0.384, v_num=24, train_loss_step=0.368]Epoch 0:  55%|█████▌    | 209/380 [00:22<00:17,  9.50it/s, loss=0.384, v_num=24, train_loss_step=0.368]Epoch 0:  55%|█████▌    | 209/380 [00:22<00:17,  9.50it/s, loss=0.379, v_num=24, train_loss_step=0.337]Epoch 0:  55%|█████▌    | 210/380 [00:22<00:17,  9.50it/s, loss=0.379, v_num=24, train_loss_step=0.337]Epoch 0:  55%|█████▌    | 210/380 [00:22<00:17,  9.50it/s, loss=0.385, v_num=24, train_loss_step=0.436]Epoch 0:  56%|█████▌    | 211/380 [00:22<00:17,  9.50it/s, loss=0.385, v_num=24, train_loss_step=0.436]Epoch 0:  56%|█████▌    | 211/380 [00:22<00:17,  9.50it/s, loss=0.387, v_num=24, train_loss_step=0.383]Epoch 0:  56%|█████▌    | 212/380 [00:22<00:17,  9.50it/s, loss=0.387, v_num=24, train_loss_step=0.383]Epoch 0:  56%|█████▌    | 212/380 [00:22<00:17,  9.50it/s, loss=0.388, v_num=24, train_loss_step=0.333]Epoch 0:  56%|█████▌    | 213/380 [00:22<00:17,  9.50it/s, loss=0.388, v_num=24, train_loss_step=0.333]Epoch 0:  56%|█████▌    | 213/380 [00:22<00:17,  9.50it/s, loss=0.393, v_num=24, train_loss_step=0.424]Epoch 0:  56%|█████▋    | 214/380 [00:22<00:17,  9.50it/s, loss=0.393, v_num=24, train_loss_step=0.424]Epoch 0:  56%|█████▋    | 214/380 [00:22<00:17,  9.50it/s, loss=0.397, v_num=24, train_loss_step=0.411]Epoch 0:  57%|█████▋    | 215/380 [00:22<00:17,  9.50it/s, loss=0.397, v_num=24, train_loss_step=0.411]Epoch 0:  57%|█████▋    | 215/380 [00:22<00:17,  9.50it/s, loss=0.401, v_num=24, train_loss_step=0.402]Epoch 0:  57%|█████▋    | 216/380 [00:22<00:17,  9.50it/s, loss=0.401, v_num=24, train_loss_step=0.402]Epoch 0:  57%|█████▋    | 216/380 [00:22<00:17,  9.50it/s, loss=0.407, v_num=24, train_loss_step=0.431]Epoch 0:  57%|█████▋    | 217/380 [00:22<00:17,  9.50it/s, loss=0.407, v_num=24, train_loss_step=0.431]Epoch 0:  57%|█████▋    | 217/380 [00:22<00:17,  9.50it/s, loss=0.408, v_num=24, train_loss_step=0.337]Epoch 0:  57%|█████▋    | 218/380 [00:23<00:17,  9.50it/s, loss=0.408, v_num=24, train_loss_step=0.337]Epoch 0:  57%|█████▋    | 218/380 [00:23<00:17,  9.50it/s, loss=0.396, v_num=24, train_loss_step=0.350]Epoch 0:  58%|█████▊    | 219/380 [00:23<00:16,  9.50it/s, loss=0.396, v_num=24, train_loss_step=0.350]Epoch 0:  58%|█████▊    | 219/380 [00:23<00:16,  9.50it/s, loss=0.399, v_num=24, train_loss_step=0.369]Epoch 0:  58%|█████▊    | 220/380 [00:23<00:16,  9.50it/s, loss=0.399, v_num=24, train_loss_step=0.369]Epoch 0:  58%|█████▊    | 220/380 [00:23<00:16,  9.50it/s, loss=0.392, v_num=24, train_loss_step=0.315]Epoch 0:  58%|█████▊    | 221/380 [00:23<00:16,  9.50it/s, loss=0.392, v_num=24, train_loss_step=0.315]Epoch 0:  58%|█████▊    | 221/380 [00:23<00:16,  9.50it/s, loss=0.376, v_num=24, train_loss_step=0.323]Epoch 0:  58%|█████▊    | 222/380 [00:23<00:16,  9.50it/s, loss=0.376, v_num=24, train_loss_step=0.323]Epoch 0:  58%|█████▊    | 222/380 [00:23<00:16,  9.50it/s, loss=0.378, v_num=24, train_loss_step=0.344]Epoch 0:  59%|█████▊    | 223/380 [00:23<00:16,  9.50it/s, loss=0.378, v_num=24, train_loss_step=0.344]Epoch 0:  59%|█████▊    | 223/380 [00:23<00:16,  9.50it/s, loss=0.377, v_num=24, train_loss_step=0.357]Epoch 0:  59%|█████▉    | 224/380 [00:23<00:16,  9.50it/s, loss=0.377, v_num=24, train_loss_step=0.357]Epoch 0:  59%|█████▉    | 224/380 [00:23<00:16,  9.50it/s, loss=0.369, v_num=24, train_loss_step=0.330]Epoch 0:  59%|█████▉    | 225/380 [00:23<00:16,  9.50it/s, loss=0.369, v_num=24, train_loss_step=0.330]Epoch 0:  59%|█████▉    | 225/380 [00:23<00:16,  9.50it/s, loss=0.368, v_num=24, train_loss_step=0.407]Epoch 0:  59%|█████▉    | 226/380 [00:23<00:16,  9.50it/s, loss=0.368, v_num=24, train_loss_step=0.407]Epoch 0:  59%|█████▉    | 226/380 [00:23<00:16,  9.50it/s, loss=0.369, v_num=24, train_loss_step=0.345]Epoch 0:  60%|█████▉    | 227/380 [00:23<00:16,  9.50it/s, loss=0.369, v_num=24, train_loss_step=0.345]Epoch 0:  60%|█████▉    | 227/380 [00:23<00:16,  9.50it/s, loss=0.366, v_num=24, train_loss_step=0.313]Epoch 0:  60%|██████    | 228/380 [00:24<00:15,  9.50it/s, loss=0.366, v_num=24, train_loss_step=0.313]Epoch 0:  60%|██████    | 228/380 [00:24<00:15,  9.50it/s, loss=0.363, v_num=24, train_loss_step=0.314]Epoch 0:  60%|██████    | 229/380 [00:24<00:15,  9.50it/s, loss=0.363, v_num=24, train_loss_step=0.314]Epoch 0:  60%|██████    | 229/380 [00:24<00:15,  9.50it/s, loss=0.363, v_num=24, train_loss_step=0.324]Epoch 0:  61%|██████    | 230/380 [00:24<00:15,  9.50it/s, loss=0.363, v_num=24, train_loss_step=0.324]Epoch 0:  61%|██████    | 230/380 [00:24<00:15,  9.50it/s, loss=0.357, v_num=24, train_loss_step=0.323]Epoch 0:  61%|██████    | 231/380 [00:24<00:15,  9.50it/s, loss=0.357, v_num=24, train_loss_step=0.323]Epoch 0:  61%|██████    | 231/380 [00:24<00:15,  9.50it/s, loss=0.36, v_num=24, train_loss_step=0.436] Epoch 0:  61%|██████    | 232/380 [00:24<00:15,  9.50it/s, loss=0.36, v_num=24, train_loss_step=0.436]Epoch 0:  61%|██████    | 232/380 [00:24<00:15,  9.50it/s, loss=0.359, v_num=24, train_loss_step=0.313]Epoch 0:  61%|██████▏   | 233/380 [00:24<00:15,  9.50it/s, loss=0.359, v_num=24, train_loss_step=0.313]Epoch 0:  61%|██████▏   | 233/380 [00:24<00:15,  9.50it/s, loss=0.355, v_num=24, train_loss_step=0.346]Epoch 0:  62%|██████▏   | 234/380 [00:24<00:15,  9.50it/s, loss=0.355, v_num=24, train_loss_step=0.346]Epoch 0:  62%|██████▏   | 234/380 [00:24<00:15,  9.50it/s, loss=0.355, v_num=24, train_loss_step=0.422]Epoch 0:  62%|██████▏   | 235/380 [00:24<00:15,  9.50it/s, loss=0.355, v_num=24, train_loss_step=0.422]Epoch 0:  62%|██████▏   | 235/380 [00:24<00:15,  9.50it/s, loss=0.351, v_num=24, train_loss_step=0.320]Epoch 0:  62%|██████▏   | 236/380 [00:24<00:15,  9.51it/s, loss=0.351, v_num=24, train_loss_step=0.320]Epoch 0:  62%|██████▏   | 236/380 [00:24<00:15,  9.51it/s, loss=0.346, v_num=24, train_loss_step=0.321]Epoch 0:  62%|██████▏   | 237/380 [00:25<00:15,  9.51it/s, loss=0.346, v_num=24, train_loss_step=0.321]Epoch 0:  62%|██████▏   | 237/380 [00:25<00:15,  9.51it/s, loss=0.345, v_num=24, train_loss_step=0.317]Epoch 0:  63%|██████▎   | 238/380 [00:25<00:14,  9.51it/s, loss=0.345, v_num=24, train_loss_step=0.317]Epoch 0:  63%|██████▎   | 238/380 [00:25<00:14,  9.51it/s, loss=0.344, v_num=24, train_loss_step=0.338]Epoch 0:  63%|██████▎   | 239/380 [00:25<00:14,  9.51it/s, loss=0.344, v_num=24, train_loss_step=0.338]Epoch 0:  63%|██████▎   | 239/380 [00:25<00:14,  9.50it/s, loss=0.342, v_num=24, train_loss_step=0.337]Epoch 0:  63%|██████▎   | 240/380 [00:25<00:14,  9.51it/s, loss=0.342, v_num=24, train_loss_step=0.337]Epoch 0:  63%|██████▎   | 240/380 [00:25<00:14,  9.51it/s, loss=0.345, v_num=24, train_loss_step=0.362]Epoch 0:  63%|██████▎   | 241/380 [00:25<00:14,  9.51it/s, loss=0.345, v_num=24, train_loss_step=0.362]Epoch 0:  63%|██████▎   | 241/380 [00:25<00:14,  9.51it/s, loss=0.346, v_num=24, train_loss_step=0.350]Epoch 0:  64%|██████▎   | 242/380 [00:25<00:14,  9.51it/s, loss=0.346, v_num=24, train_loss_step=0.350]Epoch 0:  64%|██████▎   | 242/380 [00:25<00:14,  9.51it/s, loss=0.345, v_num=24, train_loss_step=0.326]Epoch 0:  64%|██████▍   | 243/380 [00:25<00:14,  9.50it/s, loss=0.345, v_num=24, train_loss_step=0.326]Epoch 0:  64%|██████▍   | 243/380 [00:25<00:14,  9.50it/s, loss=0.345, v_num=24, train_loss_step=0.359]Epoch 0:  64%|██████▍   | 244/380 [00:25<00:14,  9.50it/s, loss=0.345, v_num=24, train_loss_step=0.359]Epoch 0:  64%|██████▍   | 244/380 [00:25<00:14,  9.50it/s, loss=0.346, v_num=24, train_loss_step=0.346]Epoch 0:  64%|██████▍   | 245/380 [00:25<00:14,  9.50it/s, loss=0.346, v_num=24, train_loss_step=0.346]Epoch 0:  64%|██████▍   | 245/380 [00:25<00:14,  9.50it/s, loss=0.355, v_num=24, train_loss_step=0.596]Epoch 0:  65%|██████▍   | 246/380 [00:25<00:14,  9.50it/s, loss=0.355, v_num=24, train_loss_step=0.596]Epoch 0:  65%|██████▍   | 246/380 [00:25<00:14,  9.50it/s, loss=0.36, v_num=24, train_loss_step=0.439] Epoch 0:  65%|██████▌   | 247/380 [00:26<00:13,  9.50it/s, loss=0.36, v_num=24, train_loss_step=0.439]Epoch 0:  65%|██████▌   | 247/380 [00:26<00:13,  9.50it/s, loss=0.361, v_num=24, train_loss_step=0.334]Epoch 0:  65%|██████▌   | 248/380 [00:26<00:13,  9.50it/s, loss=0.361, v_num=24, train_loss_step=0.334]Epoch 0:  65%|██████▌   | 248/380 [00:26<00:13,  9.50it/s, loss=0.361, v_num=24, train_loss_step=0.318]Epoch 0:  66%|██████▌   | 249/380 [00:26<00:13,  9.50it/s, loss=0.361, v_num=24, train_loss_step=0.318]Epoch 0:  66%|██████▌   | 249/380 [00:26<00:13,  9.50it/s, loss=0.362, v_num=24, train_loss_step=0.342]Epoch 0:  66%|██████▌   | 250/380 [00:26<00:13,  9.50it/s, loss=0.362, v_num=24, train_loss_step=0.342]Epoch 0:  66%|██████▌   | 250/380 [00:26<00:13,  9.50it/s, loss=0.366, v_num=24, train_loss_step=0.396]Epoch 0:  66%|██████▌   | 251/380 [00:26<00:13,  9.50it/s, loss=0.366, v_num=24, train_loss_step=0.396]Epoch 0:  66%|██████▌   | 251/380 [00:26<00:13,  9.50it/s, loss=0.362, v_num=24, train_loss_step=0.356]Epoch 0:  66%|██████▋   | 252/380 [00:26<00:13,  9.50it/s, loss=0.362, v_num=24, train_loss_step=0.356]Epoch 0:  66%|██████▋   | 252/380 [00:26<00:13,  9.50it/s, loss=0.366, v_num=24, train_loss_step=0.389]Epoch 0:  67%|██████▋   | 253/380 [00:26<00:13,  9.50it/s, loss=0.366, v_num=24, train_loss_step=0.389]Epoch 0:  67%|██████▋   | 253/380 [00:26<00:13,  9.50it/s, loss=0.364, v_num=24, train_loss_step=0.320]Epoch 0:  67%|██████▋   | 254/380 [00:26<00:13,  9.51it/s, loss=0.364, v_num=24, train_loss_step=0.320]Epoch 0:  67%|██████▋   | 254/380 [00:26<00:13,  9.51it/s, loss=0.36, v_num=24, train_loss_step=0.335] Epoch 0:  67%|██████▋   | 255/380 [00:26<00:13,  9.51it/s, loss=0.36, v_num=24, train_loss_step=0.335]Epoch 0:  67%|██████▋   | 255/380 [00:26<00:13,  9.51it/s, loss=0.362, v_num=24, train_loss_step=0.352]Epoch 0:  67%|██████▋   | 256/380 [00:27<00:13,  9.51it/s, loss=0.362, v_num=24, train_loss_step=0.352]Epoch 0:  67%|██████▋   | 256/380 [00:27<00:13,  9.51it/s, loss=0.366, v_num=24, train_loss_step=0.407]Epoch 0:  68%|██████▊   | 257/380 [00:27<00:12,  9.50it/s, loss=0.366, v_num=24, train_loss_step=0.407]Epoch 0:  68%|██████▊   | 257/380 [00:27<00:12,  9.50it/s, loss=0.368, v_num=24, train_loss_step=0.361]Epoch 0:  68%|██████▊   | 258/380 [00:27<00:12,  9.50it/s, loss=0.368, v_num=24, train_loss_step=0.361]Epoch 0:  68%|██████▊   | 258/380 [00:27<00:12,  9.50it/s, loss=0.372, v_num=24, train_loss_step=0.408]Epoch 0:  68%|██████▊   | 259/380 [00:27<00:12,  9.50it/s, loss=0.372, v_num=24, train_loss_step=0.408]Epoch 0:  68%|██████▊   | 259/380 [00:27<00:12,  9.50it/s, loss=0.372, v_num=24, train_loss_step=0.346]Epoch 0:  68%|██████▊   | 260/380 [00:27<00:12,  9.50it/s, loss=0.372, v_num=24, train_loss_step=0.346]Epoch 0:  68%|██████▊   | 260/380 [00:27<00:12,  9.50it/s, loss=0.371, v_num=24, train_loss_step=0.332]Epoch 0:  69%|██████▊   | 261/380 [00:27<00:12,  9.50it/s, loss=0.371, v_num=24, train_loss_step=0.332]Epoch 0:  69%|██████▊   | 261/380 [00:27<00:12,  9.50it/s, loss=0.37, v_num=24, train_loss_step=0.336] Epoch 0:  69%|██████▉   | 262/380 [00:27<00:12,  9.50it/s, loss=0.37, v_num=24, train_loss_step=0.336]Epoch 0:  69%|██████▉   | 262/380 [00:27<00:12,  9.50it/s, loss=0.371, v_num=24, train_loss_step=0.348]Epoch 0:  69%|██████▉   | 263/380 [00:27<00:12,  9.50it/s, loss=0.371, v_num=24, train_loss_step=0.348]Epoch 0:  69%|██████▉   | 263/380 [00:27<00:12,  9.50it/s, loss=0.369, v_num=24, train_loss_step=0.319]Epoch 0:  69%|██████▉   | 264/380 [00:27<00:12,  9.51it/s, loss=0.369, v_num=24, train_loss_step=0.319]Epoch 0:  69%|██████▉   | 264/380 [00:27<00:12,  9.51it/s, loss=0.374, v_num=24, train_loss_step=0.445]Epoch 0:  70%|██████▉   | 265/380 [00:27<00:12,  9.51it/s, loss=0.374, v_num=24, train_loss_step=0.445]Epoch 0:  70%|██████▉   | 265/380 [00:27<00:12,  9.51it/s, loss=0.361, v_num=24, train_loss_step=0.342]Epoch 0:  70%|███████   | 266/380 [00:28<00:11,  9.50it/s, loss=0.361, v_num=24, train_loss_step=0.342]Epoch 0:  70%|███████   | 266/380 [00:28<00:11,  9.50it/s, loss=0.356, v_num=24, train_loss_step=0.328]Epoch 0:  70%|███████   | 267/380 [00:28<00:11,  9.50it/s, loss=0.356, v_num=24, train_loss_step=0.328]Epoch 0:  70%|███████   | 267/380 [00:28<00:11,  9.50it/s, loss=0.356, v_num=24, train_loss_step=0.333]Epoch 0:  71%|███████   | 268/380 [00:28<00:11,  9.50it/s, loss=0.356, v_num=24, train_loss_step=0.333]Epoch 0:  71%|███████   | 268/380 [00:28<00:11,  9.50it/s, loss=0.356, v_num=24, train_loss_step=0.323]Epoch 0:  71%|███████   | 269/380 [00:28<00:11,  9.50it/s, loss=0.356, v_num=24, train_loss_step=0.323]Epoch 0:  71%|███████   | 269/380 [00:28<00:11,  9.50it/s, loss=0.357, v_num=24, train_loss_step=0.366]Epoch 0:  71%|███████   | 270/380 [00:28<00:11,  9.50it/s, loss=0.357, v_num=24, train_loss_step=0.366]Epoch 0:  71%|███████   | 270/380 [00:28<00:11,  9.50it/s, loss=0.353, v_num=24, train_loss_step=0.322]Epoch 0:  71%|███████▏  | 271/380 [00:28<00:11,  9.50it/s, loss=0.353, v_num=24, train_loss_step=0.322]Epoch 0:  71%|███████▏  | 271/380 [00:28<00:11,  9.50it/s, loss=0.354, v_num=24, train_loss_step=0.359]Epoch 0:  72%|███████▏  | 272/380 [00:28<00:11,  9.50it/s, loss=0.354, v_num=24, train_loss_step=0.359]Epoch 0:  72%|███████▏  | 272/380 [00:28<00:11,  9.50it/s, loss=0.357, v_num=24, train_loss_step=0.463]Epoch 0:  72%|███████▏  | 273/380 [00:28<00:11,  9.50it/s, loss=0.357, v_num=24, train_loss_step=0.463]Epoch 0:  72%|███████▏  | 273/380 [00:28<00:11,  9.50it/s, loss=0.357, v_num=24, train_loss_step=0.321]Epoch 0:  72%|███████▏  | 274/380 [00:28<00:11,  9.50it/s, loss=0.357, v_num=24, train_loss_step=0.321]Epoch 0:  72%|███████▏  | 274/380 [00:28<00:11,  9.50it/s, loss=0.356, v_num=24, train_loss_step=0.318]Epoch 0:  72%|███████▏  | 275/380 [00:29<00:11,  9.50it/s, loss=0.356, v_num=24, train_loss_step=0.318]Epoch 0:  72%|███████▏  | 275/380 [00:29<00:11,  9.50it/s, loss=0.36, v_num=24, train_loss_step=0.427] Epoch 0:  73%|███████▎  | 276/380 [00:29<00:10,  9.50it/s, loss=0.36, v_num=24, train_loss_step=0.427]Epoch 0:  73%|███████▎  | 276/380 [00:29<00:10,  9.50it/s, loss=0.356, v_num=24, train_loss_step=0.322]Epoch 0:  73%|███████▎  | 277/380 [00:29<00:10,  9.50it/s, loss=0.356, v_num=24, train_loss_step=0.322]Epoch 0:  73%|███████▎  | 277/380 [00:29<00:10,  9.50it/s, loss=0.354, v_num=24, train_loss_step=0.315]Epoch 0:  73%|███████▎  | 278/380 [00:29<00:10,  9.50it/s, loss=0.354, v_num=24, train_loss_step=0.315]Epoch 0:  73%|███████▎  | 278/380 [00:29<00:10,  9.50it/s, loss=0.358, v_num=24, train_loss_step=0.487]Epoch 0:  73%|███████▎  | 279/380 [00:29<00:10,  9.50it/s, loss=0.358, v_num=24, train_loss_step=0.487]Epoch 0:  73%|███████▎  | 279/380 [00:29<00:10,  9.50it/s, loss=0.36, v_num=24, train_loss_step=0.392] Epoch 0:  74%|███████▎  | 280/380 [00:29<00:10,  9.51it/s, loss=0.36, v_num=24, train_loss_step=0.392]Epoch 0:  74%|███████▎  | 280/380 [00:29<00:10,  9.51it/s, loss=0.359, v_num=24, train_loss_step=0.324]Epoch 0:  74%|███████▍  | 281/380 [00:29<00:10,  9.51it/s, loss=0.359, v_num=24, train_loss_step=0.324]Epoch 0:  74%|███████▍  | 281/380 [00:29<00:10,  9.51it/s, loss=0.358, v_num=24, train_loss_step=0.317]Epoch 0:  74%|███████▍  | 282/380 [00:29<00:10,  9.51it/s, loss=0.358, v_num=24, train_loss_step=0.317]Epoch 0:  74%|███████▍  | 282/380 [00:29<00:10,  9.51it/s, loss=0.357, v_num=24, train_loss_step=0.325]Epoch 0:  74%|███████▍  | 283/380 [00:29<00:10,  9.51it/s, loss=0.357, v_num=24, train_loss_step=0.325]Epoch 0:  74%|███████▍  | 283/380 [00:29<00:10,  9.51it/s, loss=0.366, v_num=24, train_loss_step=0.483]Epoch 0:  75%|███████▍  | 284/380 [00:29<00:10,  9.51it/s, loss=0.366, v_num=24, train_loss_step=0.483]Epoch 0:  75%|███████▍  | 284/380 [00:29<00:10,  9.51it/s, loss=0.36, v_num=24, train_loss_step=0.332] Epoch 0:  75%|███████▌  | 285/380 [00:30<00:09,  9.51it/s, loss=0.36, v_num=24, train_loss_step=0.332]Epoch 0:  75%|███████▌  | 285/380 [00:30<00:09,  9.51it/s, loss=0.36, v_num=24, train_loss_step=0.351]Epoch 0:  75%|███████▌  | 286/380 [00:30<00:09,  9.51it/s, loss=0.36, v_num=24, train_loss_step=0.351]Epoch 0:  75%|███████▌  | 286/380 [00:30<00:09,  9.51it/s, loss=0.36, v_num=24, train_loss_step=0.329]Epoch 0:  76%|███████▌  | 287/380 [00:30<00:09,  9.51it/s, loss=0.36, v_num=24, train_loss_step=0.329]Epoch 0:  76%|███████▌  | 287/380 [00:30<00:09,  9.51it/s, loss=0.361, v_num=24, train_loss_step=0.340]Epoch 0:  76%|███████▌  | 288/380 [00:30<00:09,  9.51it/s, loss=0.361, v_num=24, train_loss_step=0.340]Epoch 0:  76%|███████▌  | 288/380 [00:30<00:09,  9.51it/s, loss=0.362, v_num=24, train_loss_step=0.351]Epoch 0:  76%|███████▌  | 289/380 [00:30<00:09,  9.51it/s, loss=0.362, v_num=24, train_loss_step=0.351]Epoch 0:  76%|███████▌  | 289/380 [00:30<00:09,  9.51it/s, loss=0.361, v_num=24, train_loss_step=0.341]Epoch 0:  76%|███████▋  | 290/380 [00:30<00:09,  9.51it/s, loss=0.361, v_num=24, train_loss_step=0.341]Epoch 0:  76%|███████▋  | 290/380 [00:30<00:09,  9.51it/s, loss=0.361, v_num=24, train_loss_step=0.323]Epoch 0:  77%|███████▋  | 291/380 [00:30<00:09,  9.51it/s, loss=0.361, v_num=24, train_loss_step=0.323]Epoch 0:  77%|███████▋  | 291/380 [00:30<00:09,  9.51it/s, loss=0.361, v_num=24, train_loss_step=0.362]Epoch 0:  77%|███████▋  | 292/380 [00:30<00:09,  9.51it/s, loss=0.361, v_num=24, train_loss_step=0.362]Epoch 0:  77%|███████▋  | 292/380 [00:30<00:09,  9.51it/s, loss=0.355, v_num=24, train_loss_step=0.345]Epoch 0:  77%|███████▋  | 293/380 [00:30<00:09,  9.51it/s, loss=0.355, v_num=24, train_loss_step=0.345]Epoch 0:  77%|███████▋  | 293/380 [00:30<00:09,  9.51it/s, loss=0.357, v_num=24, train_loss_step=0.358]Epoch 0:  77%|███████▋  | 294/380 [00:31<00:09,  9.51it/s, loss=0.357, v_num=24, train_loss_step=0.358]Epoch 0:  77%|███████▋  | 294/380 [00:31<00:09,  9.51it/s, loss=0.359, v_num=24, train_loss_step=0.357]Epoch 0:  78%|███████▊  | 295/380 [00:31<00:08,  9.51it/s, loss=0.359, v_num=24, train_loss_step=0.357]Epoch 0:  78%|███████▊  | 295/380 [00:31<00:08,  9.51it/s, loss=0.354, v_num=24, train_loss_step=0.322]Epoch 0:  78%|███████▊  | 296/380 [00:31<00:08,  9.51it/s, loss=0.354, v_num=24, train_loss_step=0.322]Epoch 0:  78%|███████▊  | 296/380 [00:31<00:08,  9.51it/s, loss=0.353, v_num=24, train_loss_step=0.316]Epoch 0:  78%|███████▊  | 297/380 [00:31<00:08,  9.51it/s, loss=0.353, v_num=24, train_loss_step=0.316]Epoch 0:  78%|███████▊  | 297/380 [00:31<00:08,  9.51it/s, loss=0.354, v_num=24, train_loss_step=0.326]Epoch 0:  78%|███████▊  | 298/380 [00:31<00:08,  9.51it/s, loss=0.354, v_num=24, train_loss_step=0.326]Epoch 0:  78%|███████▊  | 298/380 [00:31<00:08,  9.51it/s, loss=0.35, v_num=24, train_loss_step=0.409] Epoch 0:  79%|███████▊  | 299/380 [00:31<00:08,  9.51it/s, loss=0.35, v_num=24, train_loss_step=0.409]Epoch 0:  79%|███████▊  | 299/380 [00:31<00:08,  9.51it/s, loss=0.35, v_num=24, train_loss_step=0.392]Epoch 0:  79%|███████▉  | 300/380 [00:31<00:08,  9.51it/s, loss=0.35, v_num=24, train_loss_step=0.392]Epoch 0:  79%|███████▉  | 300/380 [00:31<00:08,  9.51it/s, loss=0.352, v_num=24, train_loss_step=0.362]Epoch 0:  79%|███████▉  | 301/380 [00:31<00:08,  9.51it/s, loss=0.352, v_num=24, train_loss_step=0.362]Epoch 0:  79%|███████▉  | 301/380 [00:31<00:08,  9.51it/s, loss=0.353, v_num=24, train_loss_step=0.341]Epoch 0:  79%|███████▉  | 302/380 [00:31<00:08,  9.51it/s, loss=0.353, v_num=24, train_loss_step=0.341]Epoch 0:  79%|███████▉  | 302/380 [00:31<00:08,  9.51it/s, loss=0.353, v_num=24, train_loss_step=0.316]Epoch 0:  80%|███████▉  | 303/380 [00:31<00:08,  9.51it/s, loss=0.353, v_num=24, train_loss_step=0.316]Epoch 0:  80%|███████▉  | 303/380 [00:31<00:08,  9.50it/s, loss=0.355, v_num=24, train_loss_step=0.518]Epoch 0:  80%|████████  | 304/380 [00:32<00:07,  9.50it/s, loss=0.355, v_num=24, train_loss_step=0.518]Epoch 0:  80%|████████  | 304/380 [00:32<00:07,  9.50it/s, loss=0.355, v_num=24, train_loss_step=0.349]Epoch 0:  80%|████████  | 305/380 [00:32<00:07,  9.50it/s, loss=0.355, v_num=24, train_loss_step=0.349]Epoch 0:  80%|████████  | 305/380 [00:32<00:07,  9.50it/s, loss=0.357, v_num=24, train_loss_step=0.382]Epoch 0:  81%|████████  | 306/380 [00:32<00:07,  9.50it/s, loss=0.357, v_num=24, train_loss_step=0.382]Epoch 0:  81%|████████  | 306/380 [00:32<00:07,  9.50it/s, loss=0.358, v_num=24, train_loss_step=0.356]Epoch 0:  81%|████████  | 307/380 [00:32<00:07,  9.51it/s, loss=0.358, v_num=24, train_loss_step=0.356]Epoch 0:  81%|████████  | 307/380 [00:32<00:07,  9.50it/s, loss=0.358, v_num=24, train_loss_step=0.324]Epoch 0:  81%|████████  | 308/380 [00:32<00:07,  9.51it/s, loss=0.358, v_num=24, train_loss_step=0.324]Epoch 0:  81%|████████  | 308/380 [00:32<00:07,  9.51it/s, loss=0.358, v_num=24, train_loss_step=0.356]Epoch 0:  81%|████████▏ | 309/380 [00:32<00:07,  9.51it/s, loss=0.358, v_num=24, train_loss_step=0.356]Epoch 0:  81%|████████▏ | 309/380 [00:32<00:07,  9.51it/s, loss=0.358, v_num=24, train_loss_step=0.335]Epoch 0:  82%|████████▏ | 310/380 [00:32<00:07,  9.50it/s, loss=0.358, v_num=24, train_loss_step=0.335]Epoch 0:  82%|████████▏ | 310/380 [00:32<00:07,  9.50it/s, loss=0.359, v_num=24, train_loss_step=0.361]Epoch 0:  82%|████████▏ | 311/380 [00:32<00:07,  9.50it/s, loss=0.359, v_num=24, train_loss_step=0.361]Epoch 0:  82%|████████▏ | 311/380 [00:32<00:07,  9.50it/s, loss=0.359, v_num=24, train_loss_step=0.355]Epoch 0:  82%|████████▏ | 312/380 [00:32<00:07,  9.50it/s, loss=0.359, v_num=24, train_loss_step=0.355]Epoch 0:  82%|████████▏ | 312/380 [00:32<00:07,  9.50it/s, loss=0.36, v_num=24, train_loss_step=0.367] Epoch 0:  82%|████████▏ | 313/380 [00:33<00:07,  9.50it/s, loss=0.36, v_num=24, train_loss_step=0.367]Epoch 0:  82%|████████▏ | 313/380 [00:33<00:07,  9.50it/s, loss=0.362, v_num=24, train_loss_step=0.396]Epoch 0:  83%|████████▎ | 314/380 [00:33<00:06,  9.50it/s, loss=0.362, v_num=24, train_loss_step=0.396]Epoch 0:  83%|████████▎ | 314/380 [00:33<00:06,  9.50it/s, loss=0.36, v_num=24, train_loss_step=0.321] Epoch 0:  83%|████████▎ | 315/380 [00:33<00:06,  9.51it/s, loss=0.36, v_num=24, train_loss_step=0.321]Epoch 0:  83%|████████▎ | 315/380 [00:33<00:06,  9.51it/s, loss=0.361, v_num=24, train_loss_step=0.328]Epoch 0:  83%|████████▎ | 316/380 [00:33<00:06,  9.51it/s, loss=0.361, v_num=24, train_loss_step=0.328]Epoch 0:  83%|████████▎ | 316/380 [00:33<00:06,  9.51it/s, loss=0.361, v_num=24, train_loss_step=0.327]Epoch 0:  83%|████████▎ | 317/380 [00:33<00:06,  9.51it/s, loss=0.361, v_num=24, train_loss_step=0.327]Epoch 0:  83%|████████▎ | 317/380 [00:33<00:06,  9.51it/s, loss=0.361, v_num=24, train_loss_step=0.321]Epoch 0:  84%|████████▎ | 318/380 [00:33<00:06,  9.51it/s, loss=0.361, v_num=24, train_loss_step=0.321]Epoch 0:  84%|████████▎ | 318/380 [00:33<00:06,  9.51it/s, loss=0.36, v_num=24, train_loss_step=0.393] Epoch 0:  84%|████████▍ | 319/380 [00:33<00:06,  9.51it/s, loss=0.36, v_num=24, train_loss_step=0.393]Epoch 0:  84%|████████▍ | 319/380 [00:33<00:06,  9.51it/s, loss=0.357, v_num=24, train_loss_step=0.328]Epoch 0:  84%|████████▍ | 320/380 [00:33<00:06,  9.51it/s, loss=0.357, v_num=24, train_loss_step=0.328]Epoch 0:  84%|████████▍ | 320/380 [00:33<00:06,  9.51it/s, loss=0.355, v_num=24, train_loss_step=0.319]Epoch 0:  84%|████████▍ | 321/380 [00:33<00:06,  9.51it/s, loss=0.355, v_num=24, train_loss_step=0.319]Epoch 0:  84%|████████▍ | 321/380 [00:33<00:06,  9.51it/s, loss=0.354, v_num=24, train_loss_step=0.319]Epoch 0:  85%|████████▍ | 322/380 [00:33<00:06,  9.51it/s, loss=0.354, v_num=24, train_loss_step=0.319]Epoch 0:  85%|████████▍ | 322/380 [00:33<00:06,  9.51it/s, loss=0.354, v_num=24, train_loss_step=0.318]Epoch 0:  85%|████████▌ | 323/380 [00:34<00:05,  9.51it/s, loss=0.354, v_num=24, train_loss_step=0.318]Epoch 0:  85%|████████▌ | 323/380 [00:34<00:05,  9.51it/s, loss=0.351, v_num=24, train_loss_step=0.471]Epoch 0:  85%|████████▌ | 324/380 [00:34<00:05,  9.51it/s, loss=0.351, v_num=24, train_loss_step=0.471]Epoch 0:  85%|████████▌ | 324/380 [00:34<00:05,  9.51it/s, loss=0.351, v_num=24, train_loss_step=0.337]Epoch 0:  86%|████████▌ | 325/380 [00:34<00:05,  9.51it/s, loss=0.351, v_num=24, train_loss_step=0.337]Epoch 0:  86%|████████▌ | 325/380 [00:34<00:05,  9.51it/s, loss=0.348, v_num=24, train_loss_step=0.329]Epoch 0:  86%|████████▌ | 326/380 [00:34<00:05,  9.51it/s, loss=0.348, v_num=24, train_loss_step=0.329]Epoch 0:  86%|████████▌ | 326/380 [00:34<00:05,  9.51it/s, loss=0.348, v_num=24, train_loss_step=0.348]Epoch 0:  86%|████████▌ | 327/380 [00:34<00:05,  9.50it/s, loss=0.348, v_num=24, train_loss_step=0.348]Epoch 0:  86%|████████▌ | 327/380 [00:34<00:05,  9.50it/s, loss=0.348, v_num=24, train_loss_step=0.330]Epoch 0:  86%|████████▋ | 328/380 [00:34<00:05,  9.50it/s, loss=0.348, v_num=24, train_loss_step=0.330]Epoch 0:  86%|████████▋ | 328/380 [00:34<00:05,  9.50it/s, loss=0.352, v_num=24, train_loss_step=0.430]Epoch 0:  87%|████████▋ | 329/380 [00:34<00:05,  9.51it/s, loss=0.352, v_num=24, train_loss_step=0.430]Epoch 0:  87%|████████▋ | 329/380 [00:34<00:05,  9.51it/s, loss=0.351, v_num=24, train_loss_step=0.320]Epoch 0:  87%|████████▋ | 330/380 [00:34<00:05,  9.50it/s, loss=0.351, v_num=24, train_loss_step=0.320]Epoch 0:  87%|████████▋ | 330/380 [00:34<00:05,  9.50it/s, loss=0.355, v_num=24, train_loss_step=0.435]Epoch 0:  87%|████████▋ | 331/380 [00:34<00:05,  9.50it/s, loss=0.355, v_num=24, train_loss_step=0.435]Epoch 0:  87%|████████▋ | 331/380 [00:34<00:05,  9.50it/s, loss=0.355, v_num=24, train_loss_step=0.371]Epoch 0:  87%|████████▋ | 332/380 [00:35<00:05,  9.50it/s, loss=0.355, v_num=24, train_loss_step=0.371]Epoch 0:  87%|████████▋ | 332/380 [00:35<00:05,  9.50it/s, loss=0.354, v_num=24, train_loss_step=0.337]Epoch 0:  88%|████████▊ | 333/380 [00:35<00:04,  9.51it/s, loss=0.354, v_num=24, train_loss_step=0.337]Epoch 0:  88%|████████▊ | 333/380 [00:35<00:04,  9.51it/s, loss=0.351, v_num=24, train_loss_step=0.331]Epoch 0:  88%|████████▊ | 334/380 [00:35<00:04,  9.51it/s, loss=0.351, v_num=24, train_loss_step=0.325]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/46 [00:00<?, ?it/s][A
Validating:   2%|▏         | 1/46 [00:00<00:12,  3.61it/s][AEpoch 0:  88%|████████▊ | 336/380 [00:35<00:04,  9.49it/s, loss=0.351, v_num=24, train_loss_step=0.325]
Validating:   4%|▍         | 2/46 [00:00<00:12,  3.61it/s][A
Validating:   7%|▋         | 3/46 [00:00<00:11,  3.63it/s][A
Validating:   9%|▊         | 4/46 [00:01<00:11,  3.65it/s][AEpoch 0:  89%|████████▉ | 339/380 [00:36<00:04,  9.36it/s, loss=0.351, v_num=24, train_loss_step=0.325]
Validating:  11%|█         | 5/46 [00:01<00:11,  3.62it/s][A
Validating:  13%|█▎        | 6/46 [00:01<00:11,  3.62it/s][A
Validating:  15%|█▌        | 7/46 [00:01<00:10,  3.64it/s][AEpoch 0:  90%|█████████ | 342/380 [00:37<00:04,  9.23it/s, loss=0.351, v_num=24, train_loss_step=0.325]
Validating:  17%|█▋        | 8/46 [00:02<00:10,  3.64it/s][A
Validating:  20%|█▉        | 9/46 [00:02<00:10,  3.65it/s][A
Validating:  22%|██▏       | 10/46 [00:02<00:09,  3.66it/s][AEpoch 0:  91%|█████████ | 345/380 [00:37<00:03,  9.11it/s, loss=0.351, v_num=24, train_loss_step=0.325]
Validating:  24%|██▍       | 11/46 [00:03<00:09,  3.64it/s][A
Validating:  26%|██▌       | 12/46 [00:03<00:09,  3.65it/s][A
Validating:  28%|██▊       | 13/46 [00:03<00:09,  3.64it/s][AEpoch 0:  92%|█████████▏| 348/380 [00:38<00:03,  8.99it/s, loss=0.351, v_num=24, train_loss_step=0.325]
Validating:  30%|███       | 14/46 [00:03<00:08,  3.64it/s][A
Validating:  33%|███▎      | 15/46 [00:04<00:08,  3.64it/s][A
Validating:  35%|███▍      | 16/46 [00:04<00:08,  3.63it/s][AEpoch 0:  92%|█████████▏| 351/380 [00:39<00:03,  8.88it/s, loss=0.351, v_num=24, train_loss_step=0.325]
Validating:  37%|███▋      | 17/46 [00:04<00:07,  3.63it/s][A
Validating:  39%|███▉      | 18/46 [00:04<00:07,  3.62it/s][A
Validating:  41%|████▏     | 19/46 [00:05<00:07,  3.63it/s][AEpoch 0:  93%|█████████▎| 354/380 [00:40<00:02,  8.77it/s, loss=0.351, v_num=24, train_loss_step=0.325]
Validating:  43%|████▎     | 20/46 [00:05<00:07,  3.64it/s][A
Validating:  46%|████▌     | 21/46 [00:05<00:06,  3.62it/s][A
Validating:  48%|████▊     | 22/46 [00:06<00:06,  3.61it/s][AEpoch 0:  94%|█████████▍| 357/380 [00:41<00:02,  8.67it/s, loss=0.351, v_num=24, train_loss_step=0.325]
Validating:  50%|█████     | 23/46 [00:06<00:06,  3.61it/s][A
Validating:  52%|█████▏    | 24/46 [00:06<00:06,  3.60it/s][A
Validating:  54%|█████▍    | 25/46 [00:06<00:05,  3.60it/s][AEpoch 0:  95%|█████████▍| 360/380 [00:42<00:02,  8.57it/s, loss=0.351, v_num=24, train_loss_step=0.325]
Validating:  57%|█████▋    | 26/46 [00:07<00:05,  3.59it/s][A
Validating:  59%|█████▊    | 27/46 [00:07<00:05,  3.59it/s][A
Validating:  61%|██████    | 28/46 [00:07<00:05,  3.59it/s][AEpoch 0:  96%|█████████▌| 363/380 [00:42<00:02,  8.47it/s, loss=0.351, v_num=24, train_loss_step=0.325]
Validating:  63%|██████▎   | 29/46 [00:08<00:04,  3.60it/s][A
Validating:  65%|██████▌   | 30/46 [00:08<00:04,  3.59it/s][A
Validating:  67%|██████▋   | 31/46 [00:08<00:04,  3.61it/s][AEpoch 0:  96%|█████████▋| 366/380 [00:43<00:01,  8.38it/s, loss=0.351, v_num=24, train_loss_step=0.325]
Validating:  70%|██████▉   | 32/46 [00:08<00:03,  3.61it/s][A
Validating:  72%|███████▏  | 33/46 [00:09<00:03,  3.61it/s][A
Validating:  74%|███████▍  | 34/46 [00:09<00:03,  3.60it/s][AEpoch 0:  97%|█████████▋| 369/380 [00:44<00:01,  8.29it/s, loss=0.351, v_num=24, train_loss_step=0.325]
Validating:  76%|███████▌  | 35/46 [00:09<00:03,  3.60it/s][A
Validating:  78%|███████▊  | 36/46 [00:09<00:02,  3.61it/s][A
Validating:  80%|████████  | 37/46 [00:10<00:02,  3.61it/s][AEpoch 0:  98%|█████████▊| 372/380 [00:45<00:00,  8.21it/s, loss=0.351, v_num=24, train_loss_step=0.325]
Validating:  83%|████████▎ | 38/46 [00:10<00:02,  3.60it/s][A
Validating:  85%|████████▍ | 39/46 [00:10<00:01,  3.60it/s][A
Validating:  87%|████████▋ | 40/46 [00:11<00:01,  3.61it/s][AEpoch 0:  99%|█████████▊| 375/380 [00:46<00:00,  8.12it/s, loss=0.351, v_num=24, train_loss_step=0.325]
Validating:  89%|████████▉ | 41/46 [00:11<00:01,  3.60it/s][A
Validating:  91%|█████████▏| 42/46 [00:11<00:01,  3.59it/s][A
Validating:  93%|█████████▎| 43/46 [00:11<00:00,  3.57it/s][AEpoch 0:  99%|█████████▉| 378/380 [00:47<00:00,  8.04it/s, loss=0.351, v_num=24, train_loss_step=0.325]
Validating:  96%|█████████▌| 44/46 [00:12<00:00,  3.57it/s][A
Validating:  98%|█████████▊| 45/46 [00:12<00:00,  3.58it/s][A
Validating: 100%|██████████| 46/46 [00:12<00:00,  3.60it/s][AEpoch 0: 100%|██████████| 380/380 [00:47<00:00,  7.94it/s, loss=0.351, v_num=24, train_loss_step=0.325]
                                                           [AEpoch 0: 100%|██████████| 380/380 [00:48<00:00,  7.94it/s, loss=0.351, v_num=24, train_loss_step=0.325]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(

Testing: 0it [00:00, ?it/s]Testing:   1%|          | 1/169 [00:00<00:23,  7.25it/s]Testing:   1%|          | 2/169 [00:00<00:21,  7.71it/s]Testing:   2%|▏         | 3/169 [00:00<00:21,  7.88it/s]Testing:   2%|▏         | 4/169 [00:00<00:20,  7.99it/s]Testing:   3%|▎         | 5/169 [00:00<00:20,  7.94it/s]Testing:   4%|▎         | 6/169 [00:00<00:20,  8.00it/s]Testing:   4%|▍         | 7/169 [00:00<00:20,  7.98it/s]Testing:   5%|▍         | 8/169 [00:01<00:20,  7.99it/s]Testing:   5%|▌         | 9/169 [00:01<00:20,  7.94it/s]Testing:   6%|▌         | 10/169 [00:01<00:20,  7.95it/s]Testing:   7%|▋         | 11/169 [00:01<00:19,  7.99it/s]Testing:   7%|▋         | 12/169 [00:01<00:19,  8.01it/s]Testing:   8%|▊         | 13/169 [00:01<00:19,  7.95it/s]Testing:   8%|▊         | 14/169 [00:01<00:19,  7.97it/s]Testing:   9%|▉         | 15/169 [00:01<00:19,  7.97it/s]Testing:   9%|▉         | 16/169 [00:02<00:19,  8.01it/s]Testing:  10%|█         | 17/169 [00:02<00:18,  8.05it/s]Testing:  11%|█         | 18/169 [00:02<00:18,  8.08it/s]Testing:  11%|█         | 19/169 [00:02<00:18,  8.10it/s]Testing:  12%|█▏        | 20/169 [00:02<00:18,  8.11it/s]Testing:  12%|█▏        | 21/169 [00:02<00:18,  8.12it/s]Testing:  13%|█▎        | 22/169 [00:02<00:18,  8.13it/s]Testing:  14%|█▎        | 23/169 [00:02<00:18,  8.11it/s]Testing:  14%|█▍        | 24/169 [00:02<00:17,  8.07it/s]Testing:  15%|█▍        | 25/169 [00:03<00:17,  8.07it/s]Testing:  15%|█▌        | 26/169 [00:03<00:17,  8.01it/s]Testing:  16%|█▌        | 27/169 [00:03<00:17,  8.01it/s]Testing:  17%|█▋        | 28/169 [00:03<00:17,  8.00it/s]Testing:  17%|█▋        | 29/169 [00:03<00:17,  7.98it/s]Testing:  18%|█▊        | 30/169 [00:03<00:17,  7.97it/s]Testing:  18%|█▊        | 31/169 [00:03<00:17,  7.96it/s]Testing:  19%|█▉        | 32/169 [00:04<00:17,  7.99it/s]Testing:  20%|█▉        | 33/169 [00:04<00:17,  7.99it/s]Testing:  20%|██        | 34/169 [00:04<00:16,  7.96it/s]Testing:  21%|██        | 35/169 [00:04<00:16,  7.96it/s]Testing:  21%|██▏       | 36/169 [00:04<00:16,  7.99it/s]Testing:  22%|██▏       | 37/169 [00:04<00:16,  8.01it/s]Testing:  22%|██▏       | 38/169 [00:04<00:16,  8.02it/s]Testing:  23%|██▎       | 39/169 [00:04<00:16,  8.07it/s]Testing:  24%|██▎       | 40/169 [00:05<00:16,  7.99it/s]Testing:  24%|██▍       | 41/169 [00:05<00:15,  8.01it/s]Testing:  25%|██▍       | 42/169 [00:05<00:15,  8.06it/s]Testing:  25%|██▌       | 43/169 [00:05<00:15,  8.03it/s]Testing:  26%|██▌       | 44/169 [00:05<00:15,  8.02it/s]Testing:  27%|██▋       | 45/169 [00:05<00:15,  8.04it/s]Testing:  27%|██▋       | 46/169 [00:05<00:15,  8.06it/s]Testing:  28%|██▊       | 47/169 [00:05<00:15,  8.05it/s]Testing:  28%|██▊       | 48/169 [00:05<00:15,  8.04it/s]Testing:  29%|██▉       | 49/169 [00:06<00:14,  8.03it/s]Testing:  30%|██▉       | 50/169 [00:06<00:14,  8.05it/s]Testing:  30%|███       | 51/169 [00:06<00:14,  8.03it/s]Testing:  31%|███       | 52/169 [00:06<00:14,  8.04it/s]Testing:  31%|███▏      | 53/169 [00:06<00:14,  8.09it/s]Testing:  32%|███▏      | 54/169 [00:06<00:14,  8.08it/s]Testing:  33%|███▎      | 55/169 [00:06<00:14,  8.04it/s]Testing:  33%|███▎      | 56/169 [00:06<00:14,  8.05it/s]Testing:  34%|███▎      | 57/169 [00:07<00:14,  8.00it/s]Testing:  34%|███▍      | 58/169 [00:07<00:13,  8.01it/s]Testing:  35%|███▍      | 59/169 [00:07<00:13,  7.98it/s]Testing:  36%|███▌      | 60/169 [00:07<00:13,  7.99it/s]Testing:  36%|███▌      | 61/169 [00:07<00:13,  8.02it/s]Testing:  37%|███▋      | 62/169 [00:07<00:13,  8.04it/s]Testing:  37%|███▋      | 63/169 [00:07<00:13,  8.04it/s]Testing:  38%|███▊      | 64/169 [00:07<00:13,  8.03it/s]Testing:  38%|███▊      | 65/169 [00:08<00:12,  8.07it/s]Testing:  39%|███▉      | 66/169 [00:08<00:12,  8.03it/s]Testing:  40%|███▉      | 67/169 [00:08<00:12,  8.00it/s]Testing:  40%|████      | 68/169 [00:08<00:12,  8.02it/s]Testing:  41%|████      | 69/169 [00:08<00:12,  8.07it/s]Testing:  41%|████▏     | 70/169 [00:08<00:12,  8.08it/s]Testing:  42%|████▏     | 71/169 [00:08<00:12,  8.08it/s]Testing:  43%|████▎     | 72/169 [00:08<00:11,  8.11it/s]Testing:  43%|████▎     | 73/169 [00:09<00:11,  8.13it/s]Testing:  44%|████▍     | 74/169 [00:09<00:11,  8.11it/s]Testing:  44%|████▍     | 75/169 [00:09<00:11,  8.08it/s]Testing:  45%|████▍     | 76/169 [00:09<00:11,  8.08it/s]Testing:  46%|████▌     | 77/169 [00:09<00:11,  8.08it/s]Testing:  46%|████▌     | 78/169 [00:09<00:11,  8.09it/s]Testing:  47%|████▋     | 79/169 [00:09<00:11,  8.12it/s]Testing:  47%|████▋     | 80/169 [00:09<00:11,  8.07it/s]Testing:  48%|████▊     | 81/169 [00:10<00:10,  8.05it/s]Testing:  49%|████▊     | 82/169 [00:10<00:10,  8.07it/s]Testing:  49%|████▉     | 83/169 [00:10<00:10,  8.09it/s]Testing:  50%|████▉     | 84/169 [00:10<00:10,  8.11it/s]Testing:  50%|█████     | 85/169 [00:10<00:10,  8.08it/s]Testing:  51%|█████     | 86/169 [00:10<00:10,  8.09it/s]Testing:  51%|█████▏    | 87/169 [00:10<00:10,  8.10it/s]Testing:  52%|█████▏    | 88/169 [00:10<00:10,  8.05it/s]Testing:  53%|█████▎    | 89/169 [00:11<00:09,  8.04it/s]Testing:  53%|█████▎    | 90/169 [00:11<00:09,  8.03it/s]Testing:  54%|█████▍    | 91/169 [00:11<00:09,  8.04it/s]Testing:  54%|█████▍    | 92/169 [00:11<00:09,  8.04it/s]Testing:  55%|█████▌    | 93/169 [00:11<00:09,  8.06it/s]Testing:  56%|█████▌    | 94/169 [00:11<00:09,  8.06it/s]Testing:  56%|█████▌    | 95/169 [00:11<00:09,  8.02it/s]Testing:  57%|█████▋    | 96/169 [00:11<00:09,  7.98it/s]Testing:  57%|█████▋    | 97/169 [00:12<00:09,  7.99it/s]Testing:  58%|█████▊    | 98/169 [00:12<00:08,  8.00it/s]Testing:  59%|█████▊    | 99/169 [00:12<00:08,  8.02it/s]Testing:  59%|█████▉    | 100/169 [00:12<00:08,  8.03it/s]Testing:  60%|█████▉    | 101/169 [00:12<00:08,  8.03it/s]Testing:  60%|██████    | 102/169 [00:12<00:08,  8.04it/s]Testing:  61%|██████    | 103/169 [00:12<00:08,  8.06it/s]Testing:  62%|██████▏   | 104/169 [00:12<00:08,  8.07it/s]Testing:  62%|██████▏   | 105/169 [00:13<00:07,  8.07it/s]Testing:  63%|██████▎   | 106/169 [00:13<00:07,  8.08it/s]Testing:  63%|██████▎   | 107/169 [00:13<00:07,  8.09it/s]Testing:  64%|██████▍   | 108/169 [00:13<00:07,  8.11it/s]Testing:  64%|██████▍   | 109/169 [00:13<00:07,  8.11it/s]Testing:  65%|██████▌   | 110/169 [00:13<00:07,  8.04it/s]Testing:  66%|██████▌   | 111/169 [00:13<00:07,  8.02it/s]Testing:  66%|██████▋   | 112/169 [00:13<00:07,  7.97it/s]Testing:  67%|██████▋   | 113/169 [00:14<00:06,  8.03it/s]Testing:  67%|██████▋   | 114/169 [00:14<00:06,  8.04it/s]Testing:  68%|██████▊   | 115/169 [00:14<00:06,  8.05it/s]Testing:  69%|██████▊   | 116/169 [00:14<00:06,  8.05it/s]Testing:  69%|██████▉   | 117/169 [00:14<00:06,  8.06it/s]Testing:  70%|██████▉   | 118/169 [00:14<00:06,  8.09it/s]Testing:  70%|███████   | 119/169 [00:14<00:06,  8.08it/s]Testing:  71%|███████   | 120/169 [00:14<00:06,  8.07it/s]Testing:  72%|███████▏  | 121/169 [00:15<00:05,  8.07it/s]Testing:  72%|███████▏  | 122/169 [00:15<00:05,  8.06it/s]Testing:  73%|███████▎  | 123/169 [00:15<00:05,  8.01it/s]Testing:  73%|███████▎  | 124/169 [00:15<00:05,  8.02it/s]Testing:  74%|███████▍  | 125/169 [00:15<00:05,  8.02it/s]Testing:  75%|███████▍  | 126/169 [00:15<00:05,  8.03it/s]Testing:  75%|███████▌  | 127/169 [00:15<00:05,  7.99it/s]Testing:  76%|███████▌  | 128/169 [00:15<00:05,  8.00it/s]Testing:  76%|███████▋  | 129/169 [00:16<00:05,  7.99it/s]Testing:  77%|███████▋  | 130/169 [00:16<00:04,  8.00it/s]Testing:  78%|███████▊  | 131/169 [00:16<00:04,  8.04it/s]Testing:  78%|███████▊  | 132/169 [00:16<00:04,  8.04it/s]Testing:  79%|███████▊  | 133/169 [00:16<00:04,  8.07it/s]Testing:  79%|███████▉  | 134/169 [00:16<00:04,  8.10it/s]Testing:  80%|███████▉  | 135/169 [00:16<00:04,  8.07it/s]Testing:  80%|████████  | 136/169 [00:16<00:04,  8.07it/s]Testing:  81%|████████  | 137/169 [00:17<00:03,  8.08it/s]Testing:  82%|████████▏ | 138/169 [00:17<00:03,  8.11it/s]Testing:  82%|████████▏ | 139/169 [00:17<00:03,  8.13it/s]Testing:  83%|████████▎ | 140/169 [00:17<00:03,  8.14it/s]Testing:  83%|████████▎ | 141/169 [00:17<00:03,  8.10it/s]Testing:  84%|████████▍ | 142/169 [00:17<00:03,  8.07it/s]Testing:  85%|████████▍ | 143/169 [00:17<00:03,  8.01it/s]Testing:  85%|████████▌ | 144/169 [00:17<00:03,  8.02it/s]Testing:  86%|████████▌ | 145/169 [00:18<00:02,  8.07it/s]Testing:  86%|████████▋ | 146/169 [00:18<00:02,  7.96it/s]Testing:  87%|████████▋ | 147/169 [00:18<00:02,  7.98it/s]Testing:  88%|████████▊ | 148/169 [00:18<00:02,  8.01it/s]Testing:  88%|████████▊ | 149/169 [00:18<00:02,  8.03it/s]Testing:  89%|████████▉ | 150/169 [00:18<00:02,  8.02it/s]Testing:  89%|████████▉ | 151/169 [00:18<00:02,  8.03it/s]Testing:  90%|████████▉ | 152/169 [00:18<00:02,  8.02it/s]Testing:  91%|█████████ | 153/169 [00:19<00:01,  8.06it/s]Testing:  91%|█████████ | 154/169 [00:19<00:01,  8.02it/s]Testing:  92%|█████████▏| 155/169 [00:19<00:01,  8.01it/s]Testing:  92%|█████████▏| 156/169 [00:19<00:01,  8.03it/s]Testing:  93%|█████████▎| 157/169 [00:19<00:01,  8.05it/s]Testing:  93%|█████████▎| 158/169 [00:19<00:01,  8.05it/s]Testing:  94%|█████████▍| 159/169 [00:19<00:01,  8.06it/s]Testing:  95%|█████████▍| 160/169 [00:19<00:01,  8.02it/s]Testing:  95%|█████████▌| 161/169 [00:20<00:00,  8.01it/s]Testing:  96%|█████████▌| 162/169 [00:20<00:00,  7.97it/s]Testing:  96%|█████████▋| 163/169 [00:20<00:00,  8.02it/s]Testing:  97%|█████████▋| 164/169 [00:20<00:00,  8.04it/s]Testing:  98%|█████████▊| 165/169 [00:20<00:00,  8.04it/s]Testing:  98%|█████████▊| 166/169 [00:20<00:00,  7.97it/s]Testing:  99%|█████████▉| 167/169 [00:20<00:00,  8.01it/s]Testing:  99%|█████████▉| 168/169 [00:20<00:00,  8.00it/s]Testing: 100%|██████████| 169/169 [00:21<00:00,  7.95it/s]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'_mean_accuracy': 0.9688625931739807,
 '_standard_dev_accuracy': 0.035655729472637177,
 '_variance_accuracy': 0.0012713311007246375,
 'test_acc': 0.968862771987915,
 'test_dice_c1': 0.21018271148204803,
 'test_f2_c1': 0.2733513116836548,
 'test_loss': 0.3496658205986023,
 'test_mean_c1': 0.42598384618759155,
 'test_prec_c1': 0.16739141941070557,
 'test_sens_c1': 0.4121739864349365,
 'test_spec_c1': 0.9699773788452148}
--------------------------------------------------------------------------------
Testing: 100%|██████████| 169/169 [00:21<00:00,  8.03it/s]
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

  | Name       | Type             | Params
------------------------------------------------
0 | encoder1   | EncoderBlock     | 37.6 K
1 | encoder2   | EncoderBlock     | 221 K 
2 | bottleneck | ConvolutionBlock | 885 K 
3 | dropout    | Dropout2d        | 0     
4 | decoder1   | DecoderBlock     | 573 K 
5 | decoder2   | DecoderBlock     | 143 K 
6 | conv       | Conv2d           | 130   
7 | softmax    | Softmax2d        | 0     
------------------------------------------------
1.9 M     Trainable params
0         Non-trainable params
1.9 M     Total params
7.447     Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Validation sanity check:  50%|█████     | 1/2 [00:01<00:01,  1.50s/it]Validation sanity check: 100%|██████████| 2/2 [00:02<00:00,  1.34s/it]                                                                      /home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Training: -1it [00:00, ?it/s]Training:   0%|          | 0/96 [00:00<00:00, 28728.11it/s]Epoch 0:   0%|          | 0/96 [00:00<00:00, 4202.71it/s]  Epoch 0:   1%|          | 1/96 [00:00<00:22,  4.19it/s]  Epoch 0:   1%|          | 1/96 [00:00<00:22,  4.19it/s, loss=0.678, v_num=25, train_loss_step=0.678]Epoch 0:   2%|▏         | 2/96 [00:00<00:27,  3.39it/s, loss=0.678, v_num=25, train_loss_step=0.678]Epoch 0:   2%|▏         | 2/96 [00:00<00:27,  3.38it/s, loss=0.675, v_num=25, train_loss_step=0.672]Epoch 0:   3%|▎         | 3/96 [00:01<00:30,  3.08it/s, loss=0.675, v_num=25, train_loss_step=0.672]Epoch 0:   3%|▎         | 3/96 [00:01<00:30,  3.08it/s, loss=0.667, v_num=25, train_loss_step=0.651]Epoch 0:   4%|▍         | 4/96 [00:01<00:31,  2.93it/s, loss=0.667, v_num=25, train_loss_step=0.651]Epoch 0:   4%|▍         | 4/96 [00:01<00:31,  2.93it/s, loss=0.657, v_num=25, train_loss_step=0.630]Epoch 0:   5%|▌         | 5/96 [00:02<00:32,  2.83it/s, loss=0.657, v_num=25, train_loss_step=0.630]Epoch 0:   5%|▌         | 5/96 [00:02<00:32,  2.83it/s, loss=0.647, v_num=25, train_loss_step=0.605]Epoch 0:   6%|▋         | 6/96 [00:02<00:32,  2.77it/s, loss=0.647, v_num=25, train_loss_step=0.605]Epoch 0:   6%|▋         | 6/96 [00:02<00:32,  2.77it/s, loss=0.623, v_num=25, train_loss_step=0.505]Epoch 0:   7%|▋         | 7/96 [00:02<00:32,  2.72it/s, loss=0.623, v_num=25, train_loss_step=0.505]Epoch 0:   7%|▋         | 7/96 [00:02<00:32,  2.72it/s, loss=0.585, v_num=25, train_loss_step=0.357]Epoch 0:   8%|▊         | 8/96 [00:03<00:32,  2.68it/s, loss=0.585, v_num=25, train_loss_step=0.357]Epoch 0:   8%|▊         | 8/96 [00:03<00:32,  2.68it/s, loss=0.575, v_num=25, train_loss_step=0.506]Epoch 0:   9%|▉         | 9/96 [00:03<00:32,  2.65it/s, loss=0.575, v_num=25, train_loss_step=0.506]Epoch 0:   9%|▉         | 9/96 [00:03<00:32,  2.65it/s, loss=0.56, v_num=25, train_loss_step=0.434] Epoch 0:  10%|█         | 10/96 [00:04<00:32,  2.63it/s, loss=0.56, v_num=25, train_loss_step=0.434]Epoch 0:  10%|█         | 10/96 [00:04<00:32,  2.63it/s, loss=0.544, v_num=25, train_loss_step=0.406]Epoch 0:  11%|█▏        | 11/96 [00:04<00:32,  2.60it/s, loss=0.544, v_num=25, train_loss_step=0.406]Epoch 0:  11%|█▏        | 11/96 [00:04<00:32,  2.60it/s, loss=0.54, v_num=25, train_loss_step=0.500] Epoch 0:  12%|█▎        | 12/96 [00:05<00:32,  2.58it/s, loss=0.54, v_num=25, train_loss_step=0.500]Epoch 0:  12%|█▎        | 12/96 [00:05<00:32,  2.58it/s, loss=0.532, v_num=25, train_loss_step=0.445]Epoch 0:  14%|█▎        | 13/96 [00:05<00:32,  2.57it/s, loss=0.532, v_num=25, train_loss_step=0.445]Epoch 0:  14%|█▎        | 13/96 [00:05<00:32,  2.57it/s, loss=0.53, v_num=25, train_loss_step=0.499] Epoch 0:  15%|█▍        | 14/96 [00:05<00:32,  2.56it/s, loss=0.53, v_num=25, train_loss_step=0.499]Epoch 0:  15%|█▍        | 14/96 [00:05<00:32,  2.56it/s, loss=0.532, v_num=25, train_loss_step=0.562]Epoch 0:  16%|█▌        | 15/96 [00:06<00:31,  2.55it/s, loss=0.532, v_num=25, train_loss_step=0.562]Epoch 0:  16%|█▌        | 15/96 [00:06<00:31,  2.55it/s, loss=0.527, v_num=25, train_loss_step=0.450]Epoch 0:  17%|█▋        | 16/96 [00:06<00:31,  2.54it/s, loss=0.527, v_num=25, train_loss_step=0.450]Epoch 0:  17%|█▋        | 16/96 [00:06<00:31,  2.54it/s, loss=0.523, v_num=25, train_loss_step=0.467]Epoch 0:  18%|█▊        | 17/96 [00:07<00:31,  2.53it/s, loss=0.523, v_num=25, train_loss_step=0.467]Epoch 0:  18%|█▊        | 17/96 [00:07<00:31,  2.53it/s, loss=0.521, v_num=25, train_loss_step=0.485]Epoch 0:  19%|█▉        | 18/96 [00:07<00:30,  2.52it/s, loss=0.521, v_num=25, train_loss_step=0.485]Epoch 0:  19%|█▉        | 18/96 [00:07<00:30,  2.52it/s, loss=0.518, v_num=25, train_loss_step=0.480]Epoch 0:  20%|█▉        | 19/96 [00:07<00:30,  2.52it/s, loss=0.518, v_num=25, train_loss_step=0.480]Epoch 0:  20%|█▉        | 19/96 [00:07<00:30,  2.52it/s, loss=0.511, v_num=25, train_loss_step=0.382]Epoch 0:  21%|██        | 20/96 [00:08<00:30,  2.51it/s, loss=0.511, v_num=25, train_loss_step=0.382]Epoch 0:  21%|██        | 20/96 [00:08<00:30,  2.51it/s, loss=0.511, v_num=25, train_loss_step=0.503]Epoch 0:  22%|██▏       | 21/96 [00:08<00:29,  2.50it/s, loss=0.511, v_num=25, train_loss_step=0.503]Epoch 0:  22%|██▏       | 21/96 [00:08<00:29,  2.50it/s, loss=0.51, v_num=25, train_loss_step=0.663] Epoch 0:  23%|██▎       | 22/96 [00:09<00:29,  2.50it/s, loss=0.51, v_num=25, train_loss_step=0.663]Epoch 0:  23%|██▎       | 22/96 [00:09<00:29,  2.50it/s, loss=0.502, v_num=25, train_loss_step=0.506]Epoch 0:  24%|██▍       | 23/96 [00:09<00:29,  2.50it/s, loss=0.502, v_num=25, train_loss_step=0.506]Epoch 0:  24%|██▍       | 23/96 [00:09<00:29,  2.50it/s, loss=0.492, v_num=25, train_loss_step=0.461]Epoch 0:  25%|██▌       | 24/96 [00:10<00:28,  2.49it/s, loss=0.492, v_num=25, train_loss_step=0.461]Epoch 0:  25%|██▌       | 24/96 [00:10<00:28,  2.49it/s, loss=0.477, v_num=25, train_loss_step=0.324]Epoch 0:  26%|██▌       | 25/96 [00:10<00:28,  2.49it/s, loss=0.477, v_num=25, train_loss_step=0.324]Epoch 0:  26%|██▌       | 25/96 [00:10<00:28,  2.49it/s, loss=0.467, v_num=25, train_loss_step=0.403]Epoch 0:  27%|██▋       | 26/96 [00:10<00:28,  2.49it/s, loss=0.467, v_num=25, train_loss_step=0.403]Epoch 0:  27%|██▋       | 26/96 [00:10<00:28,  2.49it/s, loss=0.46, v_num=25, train_loss_step=0.365] Epoch 0:  28%|██▊       | 27/96 [00:11<00:27,  2.48it/s, loss=0.46, v_num=25, train_loss_step=0.365]Epoch 0:  28%|██▊       | 27/96 [00:11<00:27,  2.48it/s, loss=0.46, v_num=25, train_loss_step=0.358]Epoch 0:  29%|██▉       | 28/96 [00:11<00:27,  2.48it/s, loss=0.46, v_num=25, train_loss_step=0.358]Epoch 0:  29%|██▉       | 28/96 [00:11<00:27,  2.48it/s, loss=0.461, v_num=25, train_loss_step=0.525]Epoch 0:  30%|███       | 29/96 [00:12<00:27,  2.48it/s, loss=0.461, v_num=25, train_loss_step=0.525]Epoch 0:  30%|███       | 29/96 [00:12<00:27,  2.48it/s, loss=0.459, v_num=25, train_loss_step=0.396]Epoch 0:  31%|███▏      | 30/96 [00:12<00:26,  2.48it/s, loss=0.459, v_num=25, train_loss_step=0.396]Epoch 0:  31%|███▏      | 30/96 [00:12<00:26,  2.48it/s, loss=0.471, v_num=25, train_loss_step=0.651]Epoch 0:  32%|███▏      | 31/96 [00:12<00:26,  2.47it/s, loss=0.471, v_num=25, train_loss_step=0.651]Epoch 0:  32%|███▏      | 31/96 [00:12<00:26,  2.47it/s, loss=0.469, v_num=25, train_loss_step=0.446]Epoch 0:  33%|███▎      | 32/96 [00:13<00:25,  2.47it/s, loss=0.469, v_num=25, train_loss_step=0.446]Epoch 0:  33%|███▎      | 32/96 [00:13<00:25,  2.47it/s, loss=0.463, v_num=25, train_loss_step=0.333]Epoch 0:  34%|███▍      | 33/96 [00:13<00:25,  2.47it/s, loss=0.463, v_num=25, train_loss_step=0.333]Epoch 0:  34%|███▍      | 33/96 [00:13<00:25,  2.47it/s, loss=0.455, v_num=25, train_loss_step=0.347]Epoch 0:  35%|███▌      | 34/96 [00:14<00:25,  2.47it/s, loss=0.455, v_num=25, train_loss_step=0.347]Epoch 0:  35%|███▌      | 34/96 [00:14<00:25,  2.47it/s, loss=0.453, v_num=25, train_loss_step=0.506]Epoch 0:  36%|███▋      | 35/96 [00:14<00:24,  2.47it/s, loss=0.453, v_num=25, train_loss_step=0.506]Epoch 0:  36%|███▋      | 35/96 [00:14<00:24,  2.47it/s, loss=0.459, v_num=25, train_loss_step=0.588]Epoch 0:  38%|███▊      | 36/96 [00:15<00:24,  2.47it/s, loss=0.459, v_num=25, train_loss_step=0.588]Epoch 0:  38%|███▊      | 36/96 [00:15<00:24,  2.47it/s, loss=0.456, v_num=25, train_loss_step=0.393]Epoch 0:  39%|███▊      | 37/96 [00:15<00:23,  2.47it/s, loss=0.456, v_num=25, train_loss_step=0.393]Epoch 0:  39%|███▊      | 37/96 [00:15<00:23,  2.47it/s, loss=0.449, v_num=25, train_loss_step=0.349]Epoch 0:  40%|███▉      | 38/96 [00:15<00:23,  2.46it/s, loss=0.449, v_num=25, train_loss_step=0.349]Epoch 0:  40%|███▉      | 38/96 [00:15<00:23,  2.46it/s, loss=0.45, v_num=25, train_loss_step=0.507] Epoch 0:  41%|████      | 39/96 [00:16<00:23,  2.46it/s, loss=0.45, v_num=25, train_loss_step=0.507]Epoch 0:  41%|████      | 39/96 [00:16<00:23,  2.46it/s, loss=0.463, v_num=25, train_loss_step=0.635]Epoch 0:  42%|████▏     | 40/96 [00:16<00:22,  2.46it/s, loss=0.463, v_num=25, train_loss_step=0.635]Epoch 0:  42%|████▏     | 40/96 [00:16<00:22,  2.46it/s, loss=0.464, v_num=25, train_loss_step=0.531]Epoch 0:  43%|████▎     | 41/96 [00:17<00:22,  2.46it/s, loss=0.464, v_num=25, train_loss_step=0.531]Epoch 0:  43%|████▎     | 41/96 [00:17<00:22,  2.46it/s, loss=0.452, v_num=25, train_loss_step=0.419]Epoch 0:  44%|████▍     | 42/96 [00:17<00:21,  2.46it/s, loss=0.452, v_num=25, train_loss_step=0.419]Epoch 0:  44%|████▍     | 42/96 [00:17<00:21,  2.46it/s, loss=0.457, v_num=25, train_loss_step=0.610]Epoch 0:  45%|████▍     | 43/96 [00:17<00:21,  2.45it/s, loss=0.457, v_num=25, train_loss_step=0.610]Epoch 0:  45%|████▍     | 43/96 [00:17<00:21,  2.45it/s, loss=0.454, v_num=25, train_loss_step=0.385]Epoch 0:  46%|████▌     | 44/96 [00:18<00:21,  2.45it/s, loss=0.454, v_num=25, train_loss_step=0.385]Epoch 0:  46%|████▌     | 44/96 [00:18<00:21,  2.45it/s, loss=0.458, v_num=25, train_loss_step=0.413]Epoch 0:  47%|████▋     | 45/96 [00:18<00:20,  2.45it/s, loss=0.458, v_num=25, train_loss_step=0.413]Epoch 0:  47%|████▋     | 45/96 [00:18<00:20,  2.45it/s, loss=0.47, v_num=25, train_loss_step=0.638] Epoch 0:  48%|████▊     | 46/96 [00:19<00:20,  2.45it/s, loss=0.47, v_num=25, train_loss_step=0.638]Epoch 0:  48%|████▊     | 46/96 [00:19<00:20,  2.45it/s, loss=0.474, v_num=25, train_loss_step=0.451]Epoch 0:  49%|████▉     | 47/96 [00:19<00:20,  2.45it/s, loss=0.474, v_num=25, train_loss_step=0.451]Epoch 0:  49%|████▉     | 47/96 [00:19<00:20,  2.45it/s, loss=0.478, v_num=25, train_loss_step=0.438]Epoch 0:  50%|█████     | 48/96 [00:20<00:19,  2.45it/s, loss=0.478, v_num=25, train_loss_step=0.438]Epoch 0:  50%|█████     | 48/96 [00:20<00:19,  2.45it/s, loss=0.47, v_num=25, train_loss_step=0.368] Epoch 0:  51%|█████     | 49/96 [00:20<00:19,  2.45it/s, loss=0.47, v_num=25, train_loss_step=0.368]Epoch 0:  51%|█████     | 49/96 [00:20<00:19,  2.45it/s, loss=0.468, v_num=25, train_loss_step=0.359]Epoch 0:  52%|█████▏    | 50/96 [00:20<00:18,  2.45it/s, loss=0.468, v_num=25, train_loss_step=0.359]Epoch 0:  52%|█████▏    | 50/96 [00:20<00:18,  2.45it/s, loss=0.452, v_num=25, train_loss_step=0.322]Epoch 0:  53%|█████▎    | 51/96 [00:21<00:18,  2.45it/s, loss=0.452, v_num=25, train_loss_step=0.322]Epoch 0:  53%|█████▎    | 51/96 [00:21<00:18,  2.45it/s, loss=0.465, v_num=25, train_loss_step=0.711]Epoch 0:  54%|█████▍    | 52/96 [00:21<00:17,  2.44it/s, loss=0.465, v_num=25, train_loss_step=0.711]Epoch 0:  54%|█████▍    | 52/96 [00:21<00:18,  2.44it/s, loss=0.484, v_num=25, train_loss_step=0.717]Epoch 0:  55%|█████▌    | 53/96 [00:22<00:17,  2.44it/s, loss=0.484, v_num=25, train_loss_step=0.717]Epoch 0:  55%|█████▌    | 53/96 [00:22<00:17,  2.44it/s, loss=0.5, v_num=25, train_loss_step=0.660]  Epoch 0:  56%|█████▋    | 54/96 [00:22<00:17,  2.44it/s, loss=0.5, v_num=25, train_loss_step=0.660]Epoch 0:  56%|█████▋    | 54/96 [00:22<00:17,  2.44it/s, loss=0.506, v_num=25, train_loss_step=0.636]Epoch 0:  57%|█████▋    | 55/96 [00:22<00:16,  2.44it/s, loss=0.506, v_num=25, train_loss_step=0.636]Epoch 0:  57%|█████▋    | 55/96 [00:22<00:16,  2.44it/s, loss=0.505, v_num=25, train_loss_step=0.555]Epoch 0:  58%|█████▊    | 56/96 [00:23<00:16,  2.44it/s, loss=0.505, v_num=25, train_loss_step=0.555]Epoch 0:  58%|█████▊    | 56/96 [00:23<00:16,  2.44it/s, loss=0.504, v_num=25, train_loss_step=0.376]Epoch 0:  59%|█████▉    | 57/96 [00:23<00:15,  2.44it/s, loss=0.504, v_num=25, train_loss_step=0.376]Epoch 0:  59%|█████▉    | 57/96 [00:23<00:15,  2.44it/s, loss=0.515, v_num=25, train_loss_step=0.570]Epoch 0:  60%|██████    | 58/96 [00:24<00:15,  2.44it/s, loss=0.515, v_num=25, train_loss_step=0.570]Epoch 0:  60%|██████    | 58/96 [00:24<00:15,  2.44it/s, loss=0.506, v_num=25, train_loss_step=0.335]Epoch 0:  61%|██████▏   | 59/96 [00:24<00:15,  2.44it/s, loss=0.506, v_num=25, train_loss_step=0.335]Epoch 0:  61%|██████▏   | 59/96 [00:24<00:15,  2.44it/s, loss=0.503, v_num=25, train_loss_step=0.561]Epoch 0:  62%|██████▎   | 60/96 [00:25<00:14,  2.44it/s, loss=0.503, v_num=25, train_loss_step=0.561]Epoch 0:  62%|██████▎   | 60/96 [00:25<00:14,  2.44it/s, loss=0.495, v_num=25, train_loss_step=0.386]Epoch 0:  64%|██████▎   | 61/96 [00:25<00:14,  2.44it/s, loss=0.495, v_num=25, train_loss_step=0.386]Epoch 0:  64%|██████▎   | 61/96 [00:25<00:14,  2.44it/s, loss=0.499, v_num=25, train_loss_step=0.496]Epoch 0:  65%|██████▍   | 62/96 [00:25<00:13,  2.44it/s, loss=0.499, v_num=25, train_loss_step=0.496]Epoch 0:  65%|██████▍   | 62/96 [00:25<00:13,  2.44it/s, loss=0.496, v_num=25, train_loss_step=0.553]Epoch 0:  66%|██████▌   | 63/96 [00:26<00:13,  2.44it/s, loss=0.496, v_num=25, train_loss_step=0.553]Epoch 0:  66%|██████▌   | 63/96 [00:26<00:13,  2.44it/s, loss=0.495, v_num=25, train_loss_step=0.358]Epoch 0:  67%|██████▋   | 64/96 [00:26<00:13,  2.44it/s, loss=0.495, v_num=25, train_loss_step=0.358]Epoch 0:  67%|██████▋   | 64/96 [00:26<00:13,  2.44it/s, loss=0.494, v_num=25, train_loss_step=0.384]Epoch 0:  68%|██████▊   | 65/96 [00:27<00:12,  2.44it/s, loss=0.494, v_num=25, train_loss_step=0.384]Epoch 0:  68%|██████▊   | 65/96 [00:27<00:12,  2.44it/s, loss=0.481, v_num=25, train_loss_step=0.380]Epoch 0:  69%|██████▉   | 66/96 [00:27<00:12,  2.44it/s, loss=0.481, v_num=25, train_loss_step=0.380]Epoch 0:  69%|██████▉   | 66/96 [00:27<00:12,  2.44it/s, loss=0.477, v_num=25, train_loss_step=0.376]Epoch 0:  70%|██████▉   | 67/96 [00:27<00:11,  2.44it/s, loss=0.477, v_num=25, train_loss_step=0.376]Epoch 0:  70%|██████▉   | 67/96 [00:27<00:11,  2.44it/s, loss=0.491, v_num=25, train_loss_step=0.712]Epoch 0:  71%|███████   | 68/96 [00:28<00:11,  2.44it/s, loss=0.491, v_num=25, train_loss_step=0.712]Epoch 0:  71%|███████   | 68/96 [00:28<00:11,  2.44it/s, loss=0.491, v_num=25, train_loss_step=0.369]Epoch 0:  72%|███████▏  | 69/96 [00:28<00:11,  2.44it/s, loss=0.491, v_num=25, train_loss_step=0.369]Epoch 0:  72%|███████▏  | 69/96 [00:28<00:11,  2.44it/s, loss=0.492, v_num=25, train_loss_step=0.392]Epoch 0:  73%|███████▎  | 70/96 [00:29<00:10,  2.44it/s, loss=0.492, v_num=25, train_loss_step=0.392]Epoch 0:  73%|███████▎  | 70/96 [00:29<00:10,  2.44it/s, loss=0.495, v_num=25, train_loss_step=0.370]Epoch 0:  74%|███████▍  | 71/96 [00:29<00:10,  2.44it/s, loss=0.495, v_num=25, train_loss_step=0.370]Epoch 0:  74%|███████▍  | 71/96 [00:29<00:10,  2.44it/s, loss=0.479, v_num=25, train_loss_step=0.400]Epoch 0:  75%|███████▌  | 72/96 [00:29<00:09,  2.44it/s, loss=0.479, v_num=25, train_loss_step=0.400]Epoch 0:  75%|███████▌  | 72/96 [00:29<00:09,  2.44it/s, loss=0.475, v_num=25, train_loss_step=0.637]Epoch 0:  76%|███████▌  | 73/96 [00:30<00:09,  2.43it/s, loss=0.475, v_num=25, train_loss_step=0.637]Epoch 0:  76%|███████▌  | 73/96 [00:30<00:09,  2.43it/s, loss=0.463, v_num=25, train_loss_step=0.420]Epoch 0:  77%|███████▋  | 74/96 [00:30<00:09,  2.44it/s, loss=0.463, v_num=25, train_loss_step=0.420]Epoch 0:  77%|███████▋  | 74/96 [00:30<00:09,  2.43it/s, loss=0.448, v_num=25, train_loss_step=0.321]Epoch 0:  78%|███████▊  | 75/96 [00:31<00:08,  2.43it/s, loss=0.448, v_num=25, train_loss_step=0.321]Epoch 0:  78%|███████▊  | 75/96 [00:31<00:08,  2.43it/s, loss=0.441, v_num=25, train_loss_step=0.434]Epoch 0:  79%|███████▉  | 76/96 [00:31<00:08,  2.43it/s, loss=0.441, v_num=25, train_loss_step=0.434]Epoch 0:  79%|███████▉  | 76/96 [00:31<00:08,  2.43it/s, loss=0.449, v_num=25, train_loss_step=0.531]Epoch 0:  80%|████████  | 77/96 [00:32<00:07,  2.43it/s, loss=0.449, v_num=25, train_loss_step=0.531]Epoch 0:  80%|████████  | 77/96 [00:32<00:07,  2.43it/s, loss=0.438, v_num=25, train_loss_step=0.337]Epoch 0:  81%|████████▏ | 78/96 [00:32<00:07,  2.43it/s, loss=0.438, v_num=25, train_loss_step=0.337]Epoch 0:  81%|████████▏ | 78/96 [00:32<00:07,  2.43it/s, loss=0.453, v_num=25, train_loss_step=0.646]Epoch 0:  82%|████████▏ | 79/96 [00:32<00:06,  2.43it/s, loss=0.453, v_num=25, train_loss_step=0.646]Epoch 0:  82%|████████▏ | 79/96 [00:32<00:06,  2.43it/s, loss=0.446, v_num=25, train_loss_step=0.410]Epoch 0:  83%|████████▎ | 80/96 [00:33<00:06,  2.43it/s, loss=0.446, v_num=25, train_loss_step=0.410]Epoch 0:  83%|████████▎ | 80/96 [00:33<00:06,  2.43it/s, loss=0.454, v_num=25, train_loss_step=0.555]Epoch 0:  84%|████████▍ | 81/96 [00:33<00:06,  2.43it/s, loss=0.454, v_num=25, train_loss_step=0.555]Epoch 0:  84%|████████▍ | 81/96 [00:33<00:06,  2.43it/s, loss=0.455, v_num=25, train_loss_step=0.519]Epoch 0:  85%|████████▌ | 82/96 [00:34<00:05,  2.43it/s, loss=0.455, v_num=25, train_loss_step=0.519]Epoch 0:  85%|████████▌ | 82/96 [00:34<00:05,  2.43it/s, loss=0.448, v_num=25, train_loss_step=0.400]Epoch 0:  86%|████████▋ | 83/96 [00:34<00:05,  2.43it/s, loss=0.448, v_num=25, train_loss_step=0.400]Epoch 0:  86%|████████▋ | 83/96 [00:34<00:05,  2.43it/s, loss=0.454, v_num=25, train_loss_step=0.485]Epoch 0:  88%|████████▊ | 84/96 [00:34<00:04,  2.45it/s, loss=0.454, v_num=25, train_loss_step=0.485]Epoch 0:  88%|████████▊ | 84/96 [00:34<00:04,  2.45it/s, loss=0.465, v_num=25, train_loss_step=0.604]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/12 [00:00<?, ?it/s][A
Validating:   8%|▊         | 1/12 [00:01<00:14,  1.30s/it][AEpoch 0:  90%|████████▉ | 86/96 [00:36<00:04,  2.42it/s, loss=0.465, v_num=25, train_loss_step=0.604]
Validating:  17%|█▋        | 2/12 [00:02<00:12,  1.22s/it][A
Validating:  25%|██▌       | 3/12 [00:03<00:10,  1.22s/it][AEpoch 0:  92%|█████████▏| 88/96 [00:38<00:03,  2.32it/s, loss=0.465, v_num=25, train_loss_step=0.604]
Validating:  33%|███▎      | 4/12 [00:04<00:09,  1.24s/it][A
Validating:  42%|████▏     | 5/12 [00:06<00:08,  1.23s/it][AEpoch 0:  94%|█████████▍| 90/96 [00:40<00:02,  2.23it/s, loss=0.465, v_num=25, train_loss_step=0.604]
Validating:  50%|█████     | 6/12 [00:07<00:07,  1.23s/it][A
Validating:  58%|█████▊    | 7/12 [00:08<00:06,  1.21s/it][AEpoch 0:  96%|█████████▌| 92/96 [00:43<00:01,  2.15it/s, loss=0.465, v_num=25, train_loss_step=0.604]
Validating:  67%|██████▋   | 8/12 [00:09<00:04,  1.19s/it][A
Validating:  75%|███████▌  | 9/12 [00:10<00:03,  1.22s/it][AEpoch 0:  98%|█████████▊| 94/96 [00:45<00:00,  2.08it/s, loss=0.465, v_num=25, train_loss_step=0.604]
Validating:  83%|████████▎ | 10/12 [00:12<00:02,  1.22s/it][A
Validating:  92%|█████████▏| 11/12 [00:13<00:01,  1.20s/it][AEpoch 0: 100%|██████████| 96/96 [00:48<00:00,  2.02it/s, loss=0.465, v_num=25, train_loss_step=0.604]
Validating: 100%|██████████| 12/12 [00:13<00:00,  1.02s/it][AEpoch 0: 100%|██████████| 96/96 [00:48<00:00,  1.99it/s, loss=0.465, v_num=25, train_loss_step=0.604]
                                                           [AEpoch 0: 100%|██████████| 96/96 [00:48<00:00,  1.99it/s, loss=0.465, v_num=25, train_loss_step=0.604]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(

Testing: 0it [00:00, ?it/s]Testing:   1%|          | 1/169 [00:00<00:22,  7.32it/s]Testing:   1%|          | 2/169 [00:00<00:21,  7.69it/s]Testing:   2%|▏         | 3/169 [00:00<00:21,  7.78it/s]Testing:   2%|▏         | 4/169 [00:00<00:21,  7.85it/s]Testing:   3%|▎         | 5/169 [00:00<00:20,  7.92it/s]Testing:   4%|▎         | 6/169 [00:00<00:20,  7.98it/s]Testing:   4%|▍         | 7/169 [00:00<00:20,  8.03it/s]Testing:   5%|▍         | 8/169 [00:01<00:19,  8.06it/s]Testing:   5%|▌         | 9/169 [00:01<00:19,  8.04it/s]Testing:   6%|▌         | 10/169 [00:01<00:19,  8.03it/s]Testing:   7%|▋         | 11/169 [00:01<00:19,  8.01it/s]Testing:   7%|▋         | 12/169 [00:01<00:19,  8.01it/s]Testing:   8%|▊         | 13/169 [00:01<00:19,  8.01it/s]Testing:   8%|▊         | 14/169 [00:01<00:19,  8.00it/s]Testing:   9%|▉         | 15/169 [00:01<00:19,  8.01it/s]Testing:   9%|▉         | 16/169 [00:02<00:19,  8.03it/s]Testing:  10%|█         | 17/169 [00:02<00:18,  8.02it/s]Testing:  11%|█         | 18/169 [00:02<00:18,  8.02it/s]Testing:  11%|█         | 19/169 [00:02<00:18,  8.03it/s]Testing:  12%|█▏        | 20/169 [00:02<00:18,  8.03it/s]Testing:  12%|█▏        | 21/169 [00:02<00:18,  8.05it/s]Testing:  13%|█▎        | 22/169 [00:02<00:18,  8.05it/s]Testing:  14%|█▎        | 23/169 [00:02<00:18,  8.07it/s]Testing:  14%|█▍        | 24/169 [00:02<00:17,  8.08it/s]Testing:  15%|█▍        | 25/169 [00:03<00:17,  8.04it/s]Testing:  15%|█▌        | 26/169 [00:03<00:17,  7.99it/s]Testing:  16%|█▌        | 27/169 [00:03<00:17,  7.97it/s]Testing:  17%|█▋        | 28/169 [00:03<00:17,  7.90it/s]Testing:  17%|█▋        | 29/169 [00:03<00:17,  7.87it/s]Testing:  18%|█▊        | 30/169 [00:03<00:17,  7.90it/s]Testing:  18%|█▊        | 31/169 [00:03<00:17,  7.94it/s]Testing:  19%|█▉        | 32/169 [00:04<00:17,  7.94it/s]Testing:  20%|█▉        | 33/169 [00:04<00:17,  7.92it/s]Testing:  20%|██        | 34/169 [00:04<00:17,  7.94it/s]Testing:  21%|██        | 35/169 [00:04<00:16,  7.95it/s]Testing:  21%|██▏       | 36/169 [00:04<00:16,  7.96it/s]Testing:  22%|██▏       | 37/169 [00:04<00:16,  7.94it/s]Testing:  22%|██▏       | 38/169 [00:04<00:16,  7.97it/s]Testing:  23%|██▎       | 39/169 [00:04<00:16,  7.97it/s]Testing:  24%|██▎       | 40/169 [00:05<00:16,  7.95it/s]Testing:  24%|██▍       | 41/169 [00:05<00:16,  7.95it/s]Testing:  25%|██▍       | 42/169 [00:05<00:16,  7.92it/s]Testing:  25%|██▌       | 43/169 [00:05<00:15,  7.93it/s]Testing:  26%|██▌       | 44/169 [00:05<00:15,  7.97it/s]Testing:  27%|██▋       | 45/169 [00:05<00:15,  7.92it/s]Testing:  27%|██▋       | 46/169 [00:05<00:15,  7.91it/s]Testing:  28%|██▊       | 47/169 [00:05<00:15,  7.93it/s]Testing:  28%|██▊       | 48/169 [00:06<00:15,  7.94it/s]Testing:  29%|██▉       | 49/169 [00:06<00:15,  7.91it/s]Testing:  30%|██▉       | 50/169 [00:06<00:14,  7.94it/s]Testing:  30%|███       | 51/169 [00:06<00:14,  7.94it/s]Testing:  31%|███       | 52/169 [00:06<00:14,  7.96it/s]Testing:  31%|███▏      | 53/169 [00:06<00:14,  7.96it/s]Testing:  32%|███▏      | 54/169 [00:06<00:14,  8.00it/s]Testing:  33%|███▎      | 55/169 [00:06<00:14,  7.98it/s]Testing:  33%|███▎      | 56/169 [00:07<00:14,  8.02it/s]Testing:  34%|███▎      | 57/169 [00:07<00:13,  8.03it/s]Testing:  34%|███▍      | 58/169 [00:07<00:13,  8.02it/s]Testing:  35%|███▍      | 59/169 [00:07<00:13,  8.04it/s]Testing:  36%|███▌      | 60/169 [00:07<00:13,  8.00it/s]Testing:  36%|███▌      | 61/169 [00:07<00:13,  7.95it/s]Testing:  37%|███▋      | 62/169 [00:07<00:13,  7.89it/s]Testing:  37%|███▋      | 63/169 [00:07<00:13,  7.96it/s]Testing:  38%|███▊      | 64/169 [00:08<00:13,  7.98it/s]Testing:  38%|███▊      | 65/169 [00:08<00:13,  7.99it/s]Testing:  39%|███▉      | 66/169 [00:08<00:12,  8.00it/s]Testing:  40%|███▉      | 67/169 [00:08<00:12,  8.01it/s]Testing:  40%|████      | 68/169 [00:08<00:12,  8.02it/s]Testing:  41%|████      | 69/169 [00:08<00:12,  8.02it/s]Testing:  41%|████▏     | 70/169 [00:08<00:12,  8.03it/s]Testing:  42%|████▏     | 71/169 [00:08<00:12,  8.01it/s]Testing:  43%|████▎     | 72/169 [00:09<00:12,  7.94it/s]Testing:  43%|████▎     | 73/169 [00:09<00:12,  7.98it/s]Testing:  44%|████▍     | 74/169 [00:09<00:11,  8.00it/s]Testing:  44%|████▍     | 75/169 [00:09<00:11,  8.00it/s]Testing:  45%|████▍     | 76/169 [00:09<00:11,  8.02it/s]Testing:  46%|████▌     | 77/169 [00:09<00:11,  8.04it/s]Testing:  46%|████▌     | 78/169 [00:09<00:11,  8.02it/s]Testing:  47%|████▋     | 79/169 [00:09<00:11,  7.99it/s]Testing:  47%|████▋     | 80/169 [00:10<00:11,  8.01it/s]Testing:  48%|████▊     | 81/169 [00:10<00:10,  8.04it/s]Testing:  49%|████▊     | 82/169 [00:10<00:10,  8.02it/s]Testing:  49%|████▉     | 83/169 [00:10<00:10,  8.00it/s]Testing:  50%|████▉     | 84/169 [00:10<00:10,  8.04it/s]Testing:  50%|█████     | 85/169 [00:10<00:10,  8.01it/s]Testing:  51%|█████     | 86/169 [00:10<00:10,  8.05it/s]Testing:  51%|█████▏    | 87/169 [00:10<00:10,  8.02it/s]Testing:  52%|█████▏    | 88/169 [00:11<00:10,  8.02it/s]Testing:  53%|█████▎    | 89/169 [00:11<00:09,  8.03it/s]Testing:  53%|█████▎    | 90/169 [00:11<00:09,  8.03it/s]Testing:  54%|█████▍    | 91/169 [00:11<00:09,  8.02it/s]Testing:  54%|█████▍    | 92/169 [00:11<00:09,  7.98it/s]Testing:  55%|█████▌    | 93/169 [00:11<00:09,  7.99it/s]Testing:  56%|█████▌    | 94/169 [00:11<00:09,  7.98it/s]Testing:  56%|█████▌    | 95/169 [00:11<00:09,  7.97it/s]Testing:  57%|█████▋    | 96/169 [00:12<00:09,  7.91it/s]Testing:  57%|█████▋    | 97/169 [00:12<00:09,  7.94it/s]Testing:  58%|█████▊    | 98/169 [00:12<00:08,  7.95it/s]Testing:  59%|█████▊    | 99/169 [00:12<00:08,  7.97it/s]Testing:  59%|█████▉    | 100/169 [00:12<00:08,  7.97it/s]Testing:  60%|█████▉    | 101/169 [00:12<00:08,  7.98it/s]Testing:  60%|██████    | 102/169 [00:12<00:08,  7.96it/s]Testing:  61%|██████    | 103/169 [00:12<00:08,  7.94it/s]Testing:  62%|██████▏   | 104/169 [00:13<00:08,  7.92it/s]Testing:  62%|██████▏   | 105/169 [00:13<00:08,  7.94it/s]Testing:  63%|██████▎   | 106/169 [00:13<00:07,  7.95it/s]Testing:  63%|██████▎   | 107/169 [00:13<00:07,  7.97it/s]Testing:  64%|██████▍   | 108/169 [00:13<00:07,  7.95it/s]Testing:  64%|██████▍   | 109/169 [00:13<00:07,  7.95it/s]Testing:  65%|██████▌   | 110/169 [00:13<00:07,  7.99it/s]Testing:  66%|██████▌   | 111/169 [00:13<00:07,  7.97it/s]Testing:  66%|██████▋   | 112/169 [00:14<00:07,  7.95it/s]Testing:  67%|██████▋   | 113/169 [00:14<00:07,  7.95it/s]Testing:  67%|██████▋   | 114/169 [00:14<00:06,  7.97it/s]Testing:  68%|██████▊   | 115/169 [00:14<00:06,  7.97it/s]Testing:  69%|██████▊   | 116/169 [00:14<00:06,  7.96it/s]Testing:  69%|██████▉   | 117/169 [00:14<00:06,  7.97it/s]Testing:  70%|██████▉   | 118/169 [00:14<00:06,  7.98it/s]Testing:  70%|███████   | 119/169 [00:14<00:06,  8.01it/s]Testing:  71%|███████   | 120/169 [00:15<00:06,  7.96it/s]Testing:  72%|███████▏  | 121/169 [00:15<00:05,  8.01it/s]Testing:  72%|███████▏  | 122/169 [00:15<00:05,  7.96it/s]Testing:  73%|███████▎  | 123/169 [00:15<00:05,  7.94it/s]Testing:  73%|███████▎  | 124/169 [00:15<00:05,  7.94it/s]Testing:  74%|███████▍  | 125/169 [00:15<00:05,  7.97it/s]Testing:  75%|███████▍  | 126/169 [00:15<00:05,  7.97it/s]Testing:  75%|███████▌  | 127/169 [00:15<00:05,  7.94it/s]Testing:  76%|███████▌  | 128/169 [00:16<00:05,  7.92it/s]Testing:  76%|███████▋  | 129/169 [00:16<00:05,  7.93it/s]Testing:  77%|███████▋  | 130/169 [00:16<00:04,  7.93it/s]Testing:  78%|███████▊  | 131/169 [00:16<00:04,  7.90it/s]Testing:  78%|███████▊  | 132/169 [00:16<00:04,  7.93it/s]Testing:  79%|███████▊  | 133/169 [00:16<00:04,  7.97it/s]Testing:  79%|███████▉  | 134/169 [00:16<00:04,  7.99it/s]Testing:  80%|███████▉  | 135/169 [00:16<00:04,  8.00it/s]Testing:  80%|████████  | 136/169 [00:17<00:04,  7.98it/s]Testing:  81%|████████  | 137/169 [00:17<00:03,  8.00it/s]Testing:  82%|████████▏ | 138/169 [00:17<00:03,  7.97it/s]Testing:  82%|████████▏ | 139/169 [00:17<00:03,  7.96it/s]Testing:  83%|████████▎ | 140/169 [00:17<00:03,  7.97it/s]Testing:  83%|████████▎ | 141/169 [00:17<00:03,  7.93it/s]Testing:  84%|████████▍ | 142/169 [00:17<00:03,  7.93it/s]Testing:  85%|████████▍ | 143/169 [00:17<00:03,  7.91it/s]Testing:  85%|████████▌ | 144/169 [00:18<00:03,  7.92it/s]Testing:  86%|████████▌ | 145/169 [00:18<00:03,  7.93it/s]Testing:  86%|████████▋ | 146/169 [00:18<00:02,  7.91it/s]Testing:  87%|████████▋ | 147/169 [00:18<00:02,  7.91it/s]Testing:  88%|████████▊ | 148/169 [00:18<00:02,  7.90it/s]Testing:  88%|████████▊ | 149/169 [00:18<00:02,  7.90it/s]Testing:  89%|████████▉ | 150/169 [00:18<00:02,  7.94it/s]Testing:  89%|████████▉ | 151/169 [00:18<00:02,  7.96it/s]Testing:  90%|████████▉ | 152/169 [00:19<00:02,  7.97it/s]Testing:  91%|█████████ | 153/169 [00:19<00:02,  7.97it/s]Testing:  91%|█████████ | 154/169 [00:19<00:01,  8.00it/s]Testing:  92%|█████████▏| 155/169 [00:19<00:01,  7.98it/s]Testing:  92%|█████████▏| 156/169 [00:19<00:01,  7.99it/s]Testing:  93%|█████████▎| 157/169 [00:19<00:01,  7.99it/s]Testing:  93%|█████████▎| 158/169 [00:19<00:01,  7.99it/s]Testing:  94%|█████████▍| 159/169 [00:19<00:01,  8.01it/s]Testing:  95%|█████████▍| 160/169 [00:20<00:01,  8.01it/s]Testing:  95%|█████████▌| 161/169 [00:20<00:01,  7.98it/s]Testing:  96%|█████████▌| 162/169 [00:20<00:00,  7.97it/s]Testing:  96%|█████████▋| 163/169 [00:20<00:00,  7.88it/s]Testing:  97%|█████████▋| 164/169 [00:20<00:00,  7.91it/s]Testing:  98%|█████████▊| 165/169 [00:20<00:00,  7.91it/s]Testing:  98%|█████████▊| 166/169 [00:20<00:00,  7.91it/s]Testing:  99%|█████████▉| 167/169 [00:20<00:00,  7.89it/s]Testing:  99%|█████████▉| 168/169 [00:21<00:00,  7.90it/s]Testing: 100%|██████████| 169/169 [00:21<00:00,  7.90it/s]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'_mean_accuracy': 0.9858136773109436,
 '_standard_dev_accuracy': 0.030533961951732635,
 '_variance_accuracy': 0.0009323228150606155,
 'test_acc': 0.9858136773109436,
 'test_dice_c1': 0.0,
 'test_f2_c1': 0.0,
 'test_loss': 0.4237208068370819,
 'test_mean_c1': 0.0,
 'test_prec_c1': 0.0,
 'test_sens_c1': 0.0,
 'test_spec_c1': 1.0}
--------------------------------------------------------------------------------
Testing: 100%|██████████| 169/169 [00:21<00:00,  7.97it/s]
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

  | Name       | Type             | Params
------------------------------------------------
0 | encoder1   | EncoderBlock     | 37.6 K
1 | encoder2   | EncoderBlock     | 221 K 
2 | bottleneck | ConvolutionBlock | 885 K 
3 | dropout    | Dropout2d        | 0     
4 | decoder1   | DecoderBlock     | 573 K 
5 | decoder2   | DecoderBlock     | 143 K 
6 | conv       | Conv2d           | 130   
7 | softmax    | Softmax2d        | 0     
------------------------------------------------
1.9 M     Trainable params
0         Non-trainable params
1.9 M     Total params
7.447     Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Validation sanity check:  50%|█████     | 1/2 [00:02<00:02,  2.55s/it]Validation sanity check: 100%|██████████| 2/2 [00:04<00:00,  2.36s/it]                                                                      /home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Training: -1it [00:00, ?it/s]Training:   0%|          | 0/64 [00:00<00:00, 30840.47it/s]Epoch 0:   0%|          | 0/64 [00:00<00:00, 5777.28it/s]  Epoch 0:   2%|▏         | 1/64 [00:00<00:23,  2.73it/s]  Epoch 0:   2%|▏         | 1/64 [00:00<00:23,  2.73it/s, loss=0.7, v_num=26, train_loss_step=0.700]Epoch 0:   3%|▎         | 2/64 [00:01<00:28,  2.19it/s, loss=0.7, v_num=26, train_loss_step=0.700]Epoch 0:   3%|▎         | 2/64 [00:01<00:28,  2.19it/s, loss=0.695, v_num=26, train_loss_step=0.690]Epoch 0:   5%|▍         | 3/64 [00:02<00:30,  1.99it/s, loss=0.695, v_num=26, train_loss_step=0.690]Epoch 0:   5%|▍         | 3/64 [00:02<00:30,  1.99it/s, loss=0.688, v_num=26, train_loss_step=0.673]Epoch 0:   6%|▋         | 4/64 [00:02<00:31,  1.88it/s, loss=0.688, v_num=26, train_loss_step=0.673]Epoch 0:   6%|▋         | 4/64 [00:02<00:31,  1.88it/s, loss=0.675, v_num=26, train_loss_step=0.636]Epoch 0:   8%|▊         | 5/64 [00:03<00:32,  1.82it/s, loss=0.675, v_num=26, train_loss_step=0.636]Epoch 0:   8%|▊         | 5/64 [00:03<00:32,  1.81it/s, loss=0.652, v_num=26, train_loss_step=0.563]Epoch 0:   9%|▉         | 6/64 [00:03<00:32,  1.77it/s, loss=0.652, v_num=26, train_loss_step=0.563]Epoch 0:   9%|▉         | 6/64 [00:03<00:32,  1.77it/s, loss=0.61, v_num=26, train_loss_step=0.400] Epoch 0:  11%|█         | 7/64 [00:04<00:32,  1.74it/s, loss=0.61, v_num=26, train_loss_step=0.400]Epoch 0:  11%|█         | 7/64 [00:04<00:32,  1.74it/s, loss=0.577, v_num=26, train_loss_step=0.377]Epoch 0:  12%|█▎        | 8/64 [00:05<00:32,  1.71it/s, loss=0.577, v_num=26, train_loss_step=0.377]Epoch 0:  12%|█▎        | 8/64 [00:05<00:32,  1.71it/s, loss=0.568, v_num=26, train_loss_step=0.502]Epoch 0:  14%|█▍        | 9/64 [00:05<00:32,  1.70it/s, loss=0.568, v_num=26, train_loss_step=0.502]Epoch 0:  14%|█▍        | 9/64 [00:05<00:32,  1.70it/s, loss=0.564, v_num=26, train_loss_step=0.533]Epoch 0:  16%|█▌        | 10/64 [00:06<00:32,  1.69it/s, loss=0.564, v_num=26, train_loss_step=0.533]Epoch 0:  16%|█▌        | 10/64 [00:06<00:32,  1.69it/s, loss=0.55, v_num=26, train_loss_step=0.426] Epoch 0:  17%|█▋        | 11/64 [00:07<00:31,  1.67it/s, loss=0.55, v_num=26, train_loss_step=0.426]Epoch 0:  17%|█▋        | 11/64 [00:07<00:31,  1.67it/s, loss=0.535, v_num=26, train_loss_step=0.382]Epoch 0:  19%|█▉        | 12/64 [00:07<00:31,  1.66it/s, loss=0.535, v_num=26, train_loss_step=0.382]Epoch 0:  19%|█▉        | 12/64 [00:07<00:31,  1.66it/s, loss=0.543, v_num=26, train_loss_step=0.628]Epoch 0:  20%|██        | 13/64 [00:08<00:30,  1.66it/s, loss=0.543, v_num=26, train_loss_step=0.628]Epoch 0:  20%|██        | 13/64 [00:08<00:30,  1.66it/s, loss=0.531, v_num=26, train_loss_step=0.393]Epoch 0:  22%|██▏       | 14/64 [00:09<00:30,  1.65it/s, loss=0.531, v_num=26, train_loss_step=0.393]Epoch 0:  22%|██▏       | 14/64 [00:09<00:30,  1.65it/s, loss=0.525, v_num=26, train_loss_step=0.446]Epoch 0:  23%|██▎       | 15/64 [00:09<00:29,  1.64it/s, loss=0.525, v_num=26, train_loss_step=0.446]Epoch 0:  23%|██▎       | 15/64 [00:09<00:29,  1.64it/s, loss=0.516, v_num=26, train_loss_step=0.389]Epoch 0:  25%|██▌       | 16/64 [00:10<00:29,  1.64it/s, loss=0.516, v_num=26, train_loss_step=0.389]Epoch 0:  25%|██▌       | 16/64 [00:10<00:29,  1.64it/s, loss=0.511, v_num=26, train_loss_step=0.438]Epoch 0:  27%|██▋       | 17/64 [00:11<00:28,  1.63it/s, loss=0.511, v_num=26, train_loss_step=0.438]Epoch 0:  27%|██▋       | 17/64 [00:11<00:28,  1.63it/s, loss=0.503, v_num=26, train_loss_step=0.376]Epoch 0:  28%|██▊       | 18/64 [00:11<00:28,  1.63it/s, loss=0.503, v_num=26, train_loss_step=0.376]Epoch 0:  28%|██▊       | 18/64 [00:11<00:28,  1.63it/s, loss=0.498, v_num=26, train_loss_step=0.419]Epoch 0:  30%|██▉       | 19/64 [00:12<00:27,  1.62it/s, loss=0.498, v_num=26, train_loss_step=0.419]Epoch 0:  30%|██▉       | 19/64 [00:12<00:27,  1.62it/s, loss=0.493, v_num=26, train_loss_step=0.400]Epoch 0:  31%|███▏      | 20/64 [00:12<00:27,  1.62it/s, loss=0.493, v_num=26, train_loss_step=0.400]Epoch 0:  31%|███▏      | 20/64 [00:12<00:27,  1.62it/s, loss=0.488, v_num=26, train_loss_step=0.390]Epoch 0:  33%|███▎      | 21/64 [00:13<00:26,  1.62it/s, loss=0.488, v_num=26, train_loss_step=0.390]Epoch 0:  33%|███▎      | 21/64 [00:13<00:26,  1.62it/s, loss=0.472, v_num=26, train_loss_step=0.376]Epoch 0:  34%|███▍      | 22/64 [00:14<00:26,  1.61it/s, loss=0.472, v_num=26, train_loss_step=0.376]Epoch 0:  34%|███▍      | 22/64 [00:14<00:26,  1.61it/s, loss=0.457, v_num=26, train_loss_step=0.393]Epoch 0:  36%|███▌      | 23/64 [00:14<00:25,  1.61it/s, loss=0.457, v_num=26, train_loss_step=0.393]Epoch 0:  36%|███▌      | 23/64 [00:14<00:25,  1.61it/s, loss=0.442, v_num=26, train_loss_step=0.362]Epoch 0:  38%|███▊      | 24/64 [00:15<00:24,  1.61it/s, loss=0.442, v_num=26, train_loss_step=0.362]Epoch 0:  38%|███▊      | 24/64 [00:15<00:24,  1.61it/s, loss=0.439, v_num=26, train_loss_step=0.586]Epoch 0:  39%|███▉      | 25/64 [00:16<00:24,  1.60it/s, loss=0.439, v_num=26, train_loss_step=0.586]Epoch 0:  39%|███▉      | 25/64 [00:16<00:24,  1.60it/s, loss=0.43, v_num=26, train_loss_step=0.390] Epoch 0:  41%|████      | 26/64 [00:16<00:23,  1.60it/s, loss=0.43, v_num=26, train_loss_step=0.390]Epoch 0:  41%|████      | 26/64 [00:16<00:23,  1.60it/s, loss=0.43, v_num=26, train_loss_step=0.397]Epoch 0:  42%|████▏     | 27/64 [00:17<00:23,  1.60it/s, loss=0.43, v_num=26, train_loss_step=0.397]Epoch 0:  42%|████▏     | 27/64 [00:17<00:23,  1.60it/s, loss=0.43, v_num=26, train_loss_step=0.377]Epoch 0:  44%|████▍     | 28/64 [00:18<00:22,  1.60it/s, loss=0.43, v_num=26, train_loss_step=0.377]Epoch 0:  44%|████▍     | 28/64 [00:18<00:22,  1.60it/s, loss=0.425, v_num=26, train_loss_step=0.399]Epoch 0:  45%|████▌     | 29/64 [00:18<00:21,  1.60it/s, loss=0.425, v_num=26, train_loss_step=0.399]Epoch 0:  45%|████▌     | 29/64 [00:18<00:21,  1.60it/s, loss=0.418, v_num=26, train_loss_step=0.396]Epoch 0:  47%|████▋     | 30/64 [00:19<00:21,  1.59it/s, loss=0.418, v_num=26, train_loss_step=0.396]Epoch 0:  47%|████▋     | 30/64 [00:19<00:21,  1.59it/s, loss=0.418, v_num=26, train_loss_step=0.430]Epoch 0:  48%|████▊     | 31/64 [00:20<00:20,  1.59it/s, loss=0.418, v_num=26, train_loss_step=0.430]Epoch 0:  48%|████▊     | 31/64 [00:20<00:20,  1.59it/s, loss=0.419, v_num=26, train_loss_step=0.403]Epoch 0:  50%|█████     | 32/64 [00:20<00:20,  1.59it/s, loss=0.419, v_num=26, train_loss_step=0.403]Epoch 0:  50%|█████     | 32/64 [00:20<00:20,  1.59it/s, loss=0.409, v_num=26, train_loss_step=0.414]Epoch 0:  52%|█████▏    | 33/64 [00:21<00:19,  1.59it/s, loss=0.409, v_num=26, train_loss_step=0.414]Epoch 0:  52%|█████▏    | 33/64 [00:21<00:19,  1.59it/s, loss=0.409, v_num=26, train_loss_step=0.404]Epoch 0:  53%|█████▎    | 34/64 [00:22<00:18,  1.59it/s, loss=0.409, v_num=26, train_loss_step=0.404]Epoch 0:  53%|█████▎    | 34/64 [00:22<00:18,  1.59it/s, loss=0.409, v_num=26, train_loss_step=0.435]Epoch 0:  55%|█████▍    | 35/64 [00:22<00:18,  1.59it/s, loss=0.409, v_num=26, train_loss_step=0.435]Epoch 0:  55%|█████▍    | 35/64 [00:22<00:18,  1.59it/s, loss=0.41, v_num=26, train_loss_step=0.406] Epoch 0:  56%|█████▋    | 36/64 [00:23<00:17,  1.59it/s, loss=0.41, v_num=26, train_loss_step=0.406]Epoch 0:  56%|█████▋    | 36/64 [00:23<00:17,  1.59it/s, loss=0.407, v_num=26, train_loss_step=0.388]Epoch 0:  58%|█████▊    | 37/64 [00:23<00:17,  1.59it/s, loss=0.407, v_num=26, train_loss_step=0.388]Epoch 0:  58%|█████▊    | 37/64 [00:23<00:17,  1.59it/s, loss=0.407, v_num=26, train_loss_step=0.382]Epoch 0:  59%|█████▉    | 38/64 [00:24<00:16,  1.59it/s, loss=0.407, v_num=26, train_loss_step=0.382]Epoch 0:  59%|█████▉    | 38/64 [00:24<00:16,  1.59it/s, loss=0.406, v_num=26, train_loss_step=0.393]Epoch 0:  61%|██████    | 39/64 [00:25<00:15,  1.59it/s, loss=0.406, v_num=26, train_loss_step=0.393]Epoch 0:  61%|██████    | 39/64 [00:25<00:15,  1.59it/s, loss=0.406, v_num=26, train_loss_step=0.393]Epoch 0:  62%|██████▎   | 40/64 [00:25<00:15,  1.59it/s, loss=0.406, v_num=26, train_loss_step=0.393]Epoch 0:  62%|██████▎   | 40/64 [00:25<00:15,  1.59it/s, loss=0.406, v_num=26, train_loss_step=0.389]Epoch 0:  64%|██████▍   | 41/64 [00:26<00:14,  1.58it/s, loss=0.406, v_num=26, train_loss_step=0.389]Epoch 0:  64%|██████▍   | 41/64 [00:26<00:14,  1.58it/s, loss=0.407, v_num=26, train_loss_step=0.394]Epoch 0:  66%|██████▌   | 42/64 [00:27<00:13,  1.58it/s, loss=0.407, v_num=26, train_loss_step=0.394]Epoch 0:  66%|██████▌   | 42/64 [00:27<00:13,  1.58it/s, loss=0.405, v_num=26, train_loss_step=0.364]Epoch 0:  67%|██████▋   | 43/64 [00:27<00:13,  1.58it/s, loss=0.405, v_num=26, train_loss_step=0.364]Epoch 0:  67%|██████▋   | 43/64 [00:27<00:13,  1.58it/s, loss=0.408, v_num=26, train_loss_step=0.414]Epoch 0:  69%|██████▉   | 44/64 [00:28<00:12,  1.58it/s, loss=0.408, v_num=26, train_loss_step=0.414]Epoch 0:  69%|██████▉   | 44/64 [00:28<00:12,  1.58it/s, loss=0.396, v_num=26, train_loss_step=0.348]Epoch 0:  70%|███████   | 45/64 [00:29<00:12,  1.58it/s, loss=0.396, v_num=26, train_loss_step=0.348]Epoch 0:  70%|███████   | 45/64 [00:29<00:12,  1.58it/s, loss=0.395, v_num=26, train_loss_step=0.373]Epoch 0:  72%|███████▏  | 46/64 [00:29<00:11,  1.58it/s, loss=0.395, v_num=26, train_loss_step=0.373]Epoch 0:  72%|███████▏  | 46/64 [00:29<00:11,  1.58it/s, loss=0.394, v_num=26, train_loss_step=0.384]Epoch 0:  73%|███████▎  | 47/64 [00:30<00:10,  1.58it/s, loss=0.394, v_num=26, train_loss_step=0.384]Epoch 0:  73%|███████▎  | 47/64 [00:30<00:10,  1.58it/s, loss=0.394, v_num=26, train_loss_step=0.371]Epoch 0:  75%|███████▌  | 48/64 [00:31<00:10,  1.58it/s, loss=0.394, v_num=26, train_loss_step=0.371]Epoch 0:  75%|███████▌  | 48/64 [00:31<00:10,  1.58it/s, loss=0.396, v_num=26, train_loss_step=0.445]Epoch 0:  77%|███████▋  | 49/64 [00:31<00:09,  1.58it/s, loss=0.396, v_num=26, train_loss_step=0.445]Epoch 0:  77%|███████▋  | 49/64 [00:31<00:09,  1.58it/s, loss=0.394, v_num=26, train_loss_step=0.359]Epoch 0:  78%|███████▊  | 50/64 [00:32<00:08,  1.58it/s, loss=0.394, v_num=26, train_loss_step=0.359]Epoch 0:  78%|███████▊  | 50/64 [00:32<00:08,  1.58it/s, loss=0.39, v_num=26, train_loss_step=0.334] Epoch 0:  80%|███████▉  | 51/64 [00:32<00:08,  1.58it/s, loss=0.39, v_num=26, train_loss_step=0.334]Epoch 0:  80%|███████▉  | 51/64 [00:32<00:08,  1.58it/s, loss=0.387, v_num=26, train_loss_step=0.359]Epoch 0:  81%|████████▏ | 52/64 [00:33<00:07,  1.58it/s, loss=0.387, v_num=26, train_loss_step=0.359]Epoch 0:  81%|████████▏ | 52/64 [00:33<00:07,  1.58it/s, loss=0.384, v_num=26, train_loss_step=0.351]Epoch 0:  83%|████████▎ | 53/64 [00:34<00:06,  1.58it/s, loss=0.384, v_num=26, train_loss_step=0.351]Epoch 0:  83%|████████▎ | 53/64 [00:34<00:06,  1.58it/s, loss=0.384, v_num=26, train_loss_step=0.400]Epoch 0:  84%|████████▍ | 54/64 [00:34<00:06,  1.58it/s, loss=0.384, v_num=26, train_loss_step=0.400]Epoch 0:  84%|████████▍ | 54/64 [00:34<00:06,  1.58it/s, loss=0.38, v_num=26, train_loss_step=0.358] Epoch 0:  86%|████████▌ | 55/64 [00:35<00:05,  1.58it/s, loss=0.38, v_num=26, train_loss_step=0.358]Epoch 0:  86%|████████▌ | 55/64 [00:35<00:05,  1.58it/s, loss=0.377, v_num=26, train_loss_step=0.333]Epoch 0:  88%|████████▊ | 56/64 [00:35<00:05,  1.59it/s, loss=0.377, v_num=26, train_loss_step=0.333]Epoch 0:  88%|████████▊ | 56/64 [00:35<00:05,  1.59it/s, loss=0.374, v_num=26, train_loss_step=0.344]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/8 [00:00<?, ?it/s][A
Validating:  12%|█▎        | 1/8 [00:02<00:15,  2.25s/it][AEpoch 0:  91%|█████████ | 58/64 [00:38<00:03,  1.55it/s, loss=0.374, v_num=26, train_loss_step=0.344]
Validating:  25%|██▌       | 2/8 [00:04<00:13,  2.27s/it][A
Validating:  38%|███▊      | 3/8 [00:06<00:11,  2.27s/it][AEpoch 0:  94%|█████████▍| 60/64 [00:42<00:02,  1.43it/s, loss=0.374, v_num=26, train_loss_step=0.344]
Validating:  50%|█████     | 4/8 [00:09<00:09,  2.28s/it][A
Validating:  62%|██████▎   | 5/8 [00:11<00:06,  2.28s/it][AEpoch 0:  97%|█████████▋| 62/64 [00:47<00:01,  1.33it/s, loss=0.374, v_num=26, train_loss_step=0.344]
Validating:  75%|███████▌  | 6/8 [00:13<00:04,  2.29s/it][A
Validating:  88%|████████▊ | 7/8 [00:15<00:02,  2.29s/it][AEpoch 0: 100%|██████████| 64/64 [00:51<00:00,  1.25it/s, loss=0.374, v_num=26, train_loss_step=0.344]
Validating: 100%|██████████| 8/8 [00:17<00:00,  2.02s/it][AEpoch 0: 100%|██████████| 64/64 [00:53<00:00,  1.22it/s, loss=0.374, v_num=26, train_loss_step=0.344]
                                                         [AEpoch 0: 100%|██████████| 64/64 [00:53<00:00,  1.22it/s, loss=0.374, v_num=26, train_loss_step=0.344]/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/hd/hd_hd/hd_ei260/miniconda3/envs/covid_seg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(

Testing: 0it [00:00, ?it/s]Testing:   1%|          | 1/169 [00:00<00:28,  5.98it/s]Testing:   1%|          | 2/169 [00:00<00:26,  6.22it/s]Testing:   2%|▏         | 3/169 [00:00<00:26,  6.35it/s]Testing:   2%|▏         | 4/169 [00:00<00:25,  6.38it/s]Testing:   3%|▎         | 5/169 [00:00<00:25,  6.42it/s]Testing:   4%|▎         | 6/169 [00:00<00:25,  6.42it/s]Testing:   4%|▍         | 7/169 [00:01<00:25,  6.39it/s]Testing:   5%|▍         | 8/169 [00:01<00:25,  6.43it/s]Testing:   5%|▌         | 9/169 [00:01<00:24,  6.46it/s]Testing:   6%|▌         | 10/169 [00:01<00:24,  6.48it/s]Testing:   7%|▋         | 11/169 [00:01<00:24,  6.49it/s]Testing:   7%|▋         | 12/169 [00:01<00:24,  6.46it/s]Testing:   8%|▊         | 13/169 [00:02<00:24,  6.46it/s]Testing:   8%|▊         | 14/169 [00:02<00:24,  6.46it/s]Testing:   9%|▉         | 15/169 [00:02<00:23,  6.49it/s]Testing:   9%|▉         | 16/169 [00:02<00:23,  6.50it/s]Testing:  10%|█         | 17/169 [00:02<00:23,  6.45it/s]Testing:  11%|█         | 18/169 [00:02<00:23,  6.46it/s]Testing:  11%|█         | 19/169 [00:02<00:23,  6.47it/s]Testing:  12%|█▏        | 20/169 [00:03<00:23,  6.45it/s]Testing:  12%|█▏        | 21/169 [00:03<00:23,  6.43it/s]Testing:  13%|█▎        | 22/169 [00:03<00:22,  6.45it/s]Testing:  14%|█▎        | 23/169 [00:03<00:22,  6.42it/s]Testing:  14%|█▍        | 24/169 [00:03<00:22,  6.41it/s]Testing:  15%|█▍        | 25/169 [00:03<00:22,  6.39it/s]Testing:  15%|█▌        | 26/169 [00:04<00:22,  6.40it/s]Testing:  16%|█▌        | 27/169 [00:04<00:22,  6.39it/s]Testing:  17%|█▋        | 28/169 [00:04<00:22,  6.40it/s]Testing:  17%|█▋        | 29/169 [00:04<00:21,  6.40it/s]Testing:  18%|█▊        | 30/169 [00:04<00:21,  6.42it/s]Testing:  18%|█▊        | 31/169 [00:04<00:21,  6.43it/s]Testing:  19%|█▉        | 32/169 [00:04<00:21,  6.45it/s]Testing:  20%|█▉        | 33/169 [00:05<00:21,  6.44it/s]Testing:  20%|██        | 34/169 [00:05<00:20,  6.43it/s]Testing:  21%|██        | 35/169 [00:05<00:20,  6.42it/s]Testing:  21%|██▏       | 36/169 [00:05<00:20,  6.41it/s]Testing:  22%|██▏       | 37/169 [00:05<00:20,  6.42it/s]Testing:  22%|██▏       | 38/169 [00:05<00:20,  6.44it/s]Testing:  23%|██▎       | 39/169 [00:06<00:20,  6.44it/s]Testing:  24%|██▎       | 40/169 [00:06<00:20,  6.40it/s]Testing:  24%|██▍       | 41/169 [00:06<00:20,  6.37it/s]Testing:  25%|██▍       | 42/169 [00:06<00:19,  6.40it/s]Testing:  25%|██▌       | 43/169 [00:06<00:19,  6.40it/s]Testing:  26%|██▌       | 44/169 [00:06<00:19,  6.40it/s]Testing:  27%|██▋       | 45/169 [00:07<00:19,  6.40it/s]Testing:  27%|██▋       | 46/169 [00:07<00:19,  6.40it/s]Testing:  28%|██▊       | 47/169 [00:07<00:19,  6.40it/s]Testing:  28%|██▊       | 48/169 [00:07<00:18,  6.41it/s]Testing:  29%|██▉       | 49/169 [00:07<00:18,  6.41it/s]Testing:  30%|██▉       | 50/169 [00:07<00:18,  6.38it/s]Testing:  30%|███       | 51/169 [00:07<00:18,  6.40it/s]Testing:  31%|███       | 52/169 [00:08<00:18,  6.39it/s]Testing:  31%|███▏      | 53/169 [00:08<00:18,  6.40it/s]Testing:  32%|███▏      | 54/169 [00:08<00:17,  6.40it/s]Testing:  33%|███▎      | 55/169 [00:08<00:17,  6.37it/s]Testing:  33%|███▎      | 56/169 [00:08<00:17,  6.39it/s]Testing:  34%|███▎      | 57/169 [00:08<00:17,  6.41it/s]Testing:  34%|███▍      | 58/169 [00:09<00:17,  6.42it/s]Testing:  35%|███▍      | 59/169 [00:09<00:17,  6.39it/s]Testing:  36%|███▌      | 60/169 [00:09<00:17,  6.40it/s]Testing:  36%|███▌      | 61/169 [00:09<00:16,  6.43it/s]Testing:  37%|███▋      | 62/169 [00:09<00:16,  6.37it/s]Testing:  37%|███▋      | 63/169 [00:09<00:16,  6.39it/s]Testing:  38%|███▊      | 64/169 [00:09<00:16,  6.41it/s]Testing:  38%|███▊      | 65/169 [00:10<00:16,  6.41it/s]Testing:  39%|███▉      | 66/169 [00:10<00:16,  6.40it/s]Testing:  40%|███▉      | 67/169 [00:10<00:15,  6.41it/s]Testing:  40%|████      | 68/169 [00:10<00:15,  6.38it/s]Testing:  41%|████      | 69/169 [00:10<00:15,  6.41it/s]Testing:  41%|████▏     | 70/169 [00:10<00:15,  6.41it/s]Testing:  42%|████▏     | 71/169 [00:11<00:15,  6.41it/s]Testing:  43%|████▎     | 72/169 [00:11<00:15,  6.43it/s]Testing:  43%|████▎     | 73/169 [00:11<00:14,  6.42it/s]Testing:  44%|████▍     | 74/169 [00:11<00:14,  6.43it/s]Testing:  44%|████▍     | 75/169 [00:11<00:14,  6.40it/s]Testing:  45%|████▍     | 76/169 [00:11<00:14,  6.39it/s]Testing:  46%|████▌     | 77/169 [00:12<00:14,  6.38it/s]Testing:  46%|████▌     | 78/169 [00:12<00:14,  6.38it/s]Testing:  47%|████▋     | 79/169 [00:12<00:14,  6.42it/s]Testing:  47%|████▋     | 80/169 [00:12<00:13,  6.40it/s]Testing:  48%|████▊     | 81/169 [00:12<00:13,  6.38it/s]Testing:  49%|████▊     | 82/169 [00:12<00:13,  6.38it/s]Testing:  49%|████▉     | 83/169 [00:12<00:13,  6.38it/s]Testing:  50%|████▉     | 84/169 [00:13<00:13,  6.40it/s]Testing:  50%|█████     | 85/169 [00:13<00:13,  6.38it/s]Testing:  51%|█████     | 86/169 [00:13<00:12,  6.38it/s]Testing:  51%|█████▏    | 87/169 [00:13<00:12,  6.41it/s]Testing:  52%|█████▏    | 88/169 [00:13<00:12,  6.40it/s]Testing:  53%|█████▎    | 89/169 [00:13<00:12,  6.37it/s]Testing:  53%|█████▎    | 90/169 [00:14<00:12,  6.39it/s]Testing:  54%|█████▍    | 91/169 [00:14<00:12,  6.41it/s]Testing:  54%|█████▍    | 92/169 [00:14<00:12,  6.39it/s]Testing:  55%|█████▌    | 93/169 [00:14<00:11,  6.40it/s]Testing:  56%|█████▌    | 94/169 [00:14<00:11,  6.41it/s]Testing:  56%|█████▌    | 95/169 [00:14<00:11,  6.39it/s]Testing:  57%|█████▋    | 96/169 [00:14<00:11,  6.39it/s]Testing:  57%|█████▋    | 97/169 [00:15<00:11,  6.37it/s]Testing:  58%|█████▊    | 98/169 [00:15<00:11,  6.38it/s]Testing:  59%|█████▊    | 99/169 [00:15<00:10,  6.39it/s]Testing:  59%|█████▉    | 100/169 [00:15<00:10,  6.40it/s]Testing:  60%|█████▉    | 101/169 [00:15<00:10,  6.41it/s]Testing:  60%|██████    | 102/169 [00:15<00:10,  6.42it/s]Testing:  61%|██████    | 103/169 [00:16<00:10,  6.39it/s]Testing:  62%|██████▏   | 104/169 [00:16<00:10,  6.38it/s]Testing:  62%|██████▏   | 105/169 [00:16<00:09,  6.41it/s]Testing:  63%|██████▎   | 106/169 [00:16<00:09,  6.41it/s]Testing:  63%|██████▎   | 107/169 [00:16<00:09,  6.40it/s]Testing:  64%|██████▍   | 108/169 [00:16<00:09,  6.39it/s]Testing:  64%|██████▍   | 109/169 [00:17<00:09,  6.38it/s]Testing:  65%|██████▌   | 110/169 [00:17<00:09,  6.36it/s]Testing:  66%|██████▌   | 111/169 [00:17<00:09,  6.36it/s]Testing:  66%|██████▋   | 112/169 [00:17<00:08,  6.37it/s]Testing:  67%|██████▋   | 113/169 [00:17<00:08,  6.36it/s]Testing:  67%|██████▋   | 114/169 [00:17<00:08,  6.39it/s]Testing:  68%|██████▊   | 115/169 [00:17<00:08,  6.42it/s]Testing:  69%|██████▊   | 116/169 [00:18<00:08,  6.41it/s]Testing:  69%|██████▉   | 117/169 [00:18<00:08,  6.41it/s]Testing:  70%|██████▉   | 118/169 [00:18<00:08,  6.35it/s]Testing:  70%|███████   | 119/169 [00:18<00:07,  6.36it/s]Testing:  71%|███████   | 120/169 [00:18<00:07,  6.38it/s]Testing:  72%|███████▏  | 121/169 [00:18<00:07,  6.36it/s]Testing:  72%|███████▏  | 122/169 [00:19<00:07,  6.38it/s]Testing:  73%|███████▎  | 123/169 [00:19<00:07,  6.37it/s]Testing:  73%|███████▎  | 124/169 [00:19<00:07,  6.37it/s]Testing:  74%|███████▍  | 125/169 [00:19<00:06,  6.37it/s]Testing:  75%|███████▍  | 126/169 [00:19<00:06,  6.39it/s]Testing:  75%|███████▌  | 127/169 [00:19<00:06,  6.38it/s]Testing:  76%|███████▌  | 128/169 [00:19<00:06,  6.38it/s]Testing:  76%|███████▋  | 129/169 [00:20<00:06,  6.40it/s]Testing:  77%|███████▋  | 130/169 [00:20<00:06,  6.42it/s]Testing:  78%|███████▊  | 131/169 [00:20<00:05,  6.45it/s]Testing:  78%|███████▊  | 132/169 [00:20<00:05,  6.45it/s]Testing:  79%|███████▊  | 133/169 [00:20<00:05,  6.46it/s]Testing:  79%|███████▉  | 134/169 [00:20<00:05,  6.40it/s]Testing:  80%|███████▉  | 135/169 [00:21<00:05,  6.39it/s]Testing:  80%|████████  | 136/169 [00:21<00:05,  6.40it/s]Testing:  81%|████████  | 137/169 [00:21<00:04,  6.41it/s]Testing:  82%|████████▏ | 138/169 [00:21<00:04,  6.42it/s]Testing:  82%|████████▏ | 139/169 [00:21<00:04,  6.43it/s]Testing:  83%|████████▎ | 140/169 [00:21<00:04,  6.46it/s]Testing:  83%|████████▎ | 141/169 [00:22<00:04,  6.47it/s]Testing:  84%|████████▍ | 142/169 [00:22<00:04,  6.49it/s]Testing:  85%|████████▍ | 143/169 [00:22<00:04,  6.49it/s]Testing:  85%|████████▌ | 144/169 [00:22<00:03,  6.48it/s]Testing:  86%|████████▌ | 145/169 [00:22<00:03,  6.45it/s]Testing:  86%|████████▋ | 146/169 [00:22<00:03,  6.48it/s]Testing:  87%|████████▋ | 147/169 [00:22<00:03,  6.49it/s]Testing:  88%|████████▊ | 148/169 [00:23<00:03,  6.49it/s]Testing:  88%|████████▊ | 149/169 [00:23<00:03,  6.49it/s]Testing:  89%|████████▉ | 150/169 [00:23<00:02,  6.48it/s]Testing:  89%|████████▉ | 151/169 [00:23<00:02,  6.41it/s]Testing:  90%|████████▉ | 152/169 [00:23<00:02,  6.43it/s]Testing:  91%|█████████ | 153/169 [00:23<00:02,  6.44it/s]Testing:  91%|█████████ | 154/169 [00:24<00:02,  6.43it/s]Testing:  92%|█████████▏| 155/169 [00:24<00:02,  6.45it/s]Testing:  92%|█████████▏| 156/169 [00:24<00:02,  6.44it/s]Testing:  93%|█████████▎| 157/169 [00:24<00:01,  6.48it/s]Testing:  93%|█████████▎| 158/169 [00:24<00:01,  6.49it/s]Testing:  94%|█████████▍| 159/169 [00:24<00:01,  6.50it/s]Testing:  95%|█████████▍| 160/169 [00:24<00:01,  6.48it/s]Testing:  95%|█████████▌| 161/169 [00:25<00:01,  6.48it/s]Testing:  96%|█████████▌| 162/169 [00:25<00:01,  6.46it/s]Testing:  96%|█████████▋| 163/169 [00:25<00:00,  6.48it/s]Testing:  97%|█████████▋| 164/169 [00:25<00:00,  6.50it/s]Testing:  98%|█████████▊| 165/169 [00:25<00:00,  6.48it/s]Testing:  98%|█████████▊| 166/169 [00:25<00:00,  6.49it/s]Testing:  99%|█████████▉| 167/169 [00:26<00:00,  6.48it/s]Testing:  99%|█████████▉| 168/169 [00:26<00:00,  6.47it/s]Testing: 100%|██████████| 169/169 [00:26<00:00,  6.50it/s]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'_mean_accuracy': 0.9771252870559692,
 '_standard_dev_accuracy': 0.0225972943007946,
 '_variance_accuracy': 0.0005106377066113055,
 'test_acc': 0.9771257042884827,
 'test_dice_c1': 0.2271653115749359,
 'test_f2_c1': 0.28643742203712463,
 'test_loss': 0.3459998369216919,
 'test_mean_c1': 0.4328586757183075,
 'test_prec_c1': 0.18492233753204346,
 'test_sens_c1': 0.4070420265197754,
 'test_spec_c1': 0.9785019159317017}
--------------------------------------------------------------------------------
Testing: 100%|██████████| 169/169 [00:26<00:00,  6.42it/s]

============================= JOB FEEDBACK =============================

NodeName=uc2n513
Job ID: 19836120
Cluster: uc2
User/Group: hd_ei260/hd_hd
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 20
CPU Utilized: 00:17:50
CPU Efficiency: 4.36% of 06:49:00 core-walltime
Job Wall-clock time: 00:20:27
Memory Utilized: 2.99 GB
Memory Efficiency: 29.87% of 10.00 GB
